[["index.html", "A lavaan Compendium for Structural Equation Modeling in Educational Research Preface Copyright Acknowledgments", " A lavaan Compendium for Structural Equation Modeling in Educational Research Suzanne Jak and Terrence D. Jorgensen Last updated 11 April 2025 Preface This compendium began as a collection of documents used a teaching materials, to supplement software-agnostic textbooks about structural equation modeling (SEM). Materials were originally developed for a University of Amsterdam course (search here for a description of the course “structural equation modelling in educational research”) taught by Frans Oort and Suzanne Jak using the OpenMx package, and later adapted for the lavaan by Suzanne Jak, Mathilde Verdam, and Terrence D. Jorgensen. The latest version of the materials were compiled into the current compendium by Suzanne Jak and Terrence D. Jorgensen using RMarkdown, and assisted by Lennert J. Groot to compile the separate chapters into a bookdown project hosted on GitHub. Copyright Unless otherwise noted, this book is released under a Creative Commons Attribution-ShareAlike 4.0 International License also known as a CC BY-SA 4.0 license. This means you are free to Share (copy and redistribute) the material in any medium or format for any purpose, even commercially Adapt (remix, transform, and build upon) the material for any purpose, even commercially as long as any derivative materials are also distributed using a CC BY-SA 4.0 license. Under this license, anyone who redistributes this textbook can do so for free on the condition they properly attribute the book as follows: Jak, S., &amp; Jorgensen, T. D. (2023). A lavaan Compendium for Structural Equation Modeling in Educational Research. https://tdjorgensen.github.io/SEM-in-Ed-compendium/ Acknowledgments We thank Lennert J. Groot for compiling the chapters into the initial bookdown project, now maintained by Terrence D. Jorgensen. This was facilitated by a Grassroots grant (project Unstatic: Towards an adaptive online learning environment for statistics education), funded by the University of Amsterdam in academic year 2021–2022. "],["ch1.html", "1 Regression as Mean- and Covariance-Structure Analysis 1.1 What Are Mean and Covariance Structures? 1.2 Importing Data for SEM 1.3 Regression Using Matrix Algebra 1.4 Summary References", " 1 Regression as Mean- and Covariance-Structure Analysis This chapter prepares the reader to learn about structural equation modeling (SEM) by reviewing the fundamentals of ordinary least-squares (OLS) regression in the general(ized) linear modeling (GLM) framework. Different types of data are discussed, and some review of matrix algebra will be incorporated into the regression review. 1.1 What Are Mean and Covariance Structures? Another (older) name for an SEM is covariance structure analysis. What is meant by this? Covariance is the linear relationship we observe between 2 variables (more on this below). There might be many reasons why 2 variables covary, such as one variable influences the other common causes influence them both both variables appear in a chain or web of causal effects A covariance can be partitioned into components that are due to these different reasons. The decomposition of covariances will be explained after introducing path analysis, but recall how many statistical procedures you may already have learned about, which partition variance into components: Regression: explained (\\(R^2\\)) vs. unexplained (residual) variance ANOVA: variance between vs. within groups Multilevel modeling: Level-1 v. -2 variance and (un)explained at each level Between vs. within multiple imputations of missing data Regression models in the GLM framework primarily analyze how the mean and variance of the outcome are structured. A grand mean (\\(\\bar{y}\\)) is an unconditional expected value, whereas a predicted value from a regression model (\\(\\hat{y}\\)) is an expected value under a particular condition (e.g., \\(\\hat{y}=\\beta_0\\) when \\(X=0\\)). We calculate these conditional expectations as the intercept (\\(\\beta_0\\)) plus each predictor times its slope: \\(\\sum \\beta_j x_j\\). Variance is partitioned into (un)explained variance (e.g., \\(R^2\\)), and its structure can be further explored via unique contributions of each predictor (e.g., partial \\(\\eta^2\\) in AN(C)OVA). SEM is a multivariate method capable of partitioning means and variances of each variable, as well as partitioning the covariance between any pair of variables. 1.1.1 Types of Data Used in SEM SEM can be seen as a generalization of the GLM for multivariate data. But rather than merely allowing multiple predictors and multiple outcomes, any variable can operate both as a predictor and an outcome in the same model. This allows us to model complex relationships among variables, including chains of causation (i.e., mediation). Estimation of a GLM involves minimizing discrepancies (differences) between observed (\\(y\\)) and expected (\\(\\hat{y}\\)) casewise values (i.e., an individual subject’s score on an outcome variable \\(y\\)). These discrepancies are called “residuals” (\\(y - \\hat{y}\\)). In contrast, estimation of a SEM involves minimizing discrepancies between observed and expected summary statistics (i.e., the modeled variables’ means and covariance matrix, see table below). This is why another (older) name for an SEM is covariance structure analysis (when only trying to explain why variables are related to each other), or mean and covariance structure (MACS) analysis when means are also modeled. Casewise observations (GLM) Mean vector (SEM) Covariance matrix (SEM) Observations \\(y_i\\) \\(\\bar{y}\\) \\(\\mathbf{S}\\) Expectations \\(\\hat{y}_i\\) \\(\\widehat{\\mu}\\) \\(\\widehat{\\Sigma}\\) Residuals \\(y_i - \\hat{y}_i\\) \\(\\bar{y} - \\widehat{\\mu}\\) \\(\\mathbf{S} - \\widehat{\\Sigma}\\) Summary statistics can be calculated from observed raw data, so raw data can be provided directly to SEM software for analysis. But if data are complete and come from a multivariate normal distribution, summary statistics can also be passed directly to the SEM software, which has advantages. Unlike raw data, summary statistics do not compromise the privacy of the research participants, so summary statistics can be reported in published empirical research. That allows research-consumers (like you) to have access to the same summary statistics to replicate the results or to fit a different model (e.g., that represents a competing theory). Thus, this chapter will show how to import both raw and summary data, as well as how to calculate summary statistics from raw data so that they can be reported along with results. First, we provide some information about interpreting the summary statistics most relevant for SEM. 1.1.2 Interpreting Covariance Whether in a GLM or as part of a larger SEM, a regression model includes both mean-structure parameters (intercepts) and covariance-structure parameters (slopes, residual variance). Generally speaking, covariance-structure parameters are informative about how variables are related to each other, and even the variances of (and covariances among) predictors are pivotal to estimating regression slopes. In GLM, this is not immediately apparent from regression output, so later in this chapter we will demonstrate how to manually calculate regression slopes from raw data, revealing the role of summary statistics in estimating slopes. But first, what is covariance? Recall that a variable’s variance (\\(\\sigma^2_y\\)) is the mean of squared deviations from \\(\\bar{y}\\), which quantifies how individual scores vary: \\[\\text{Var}(y) = \\frac{\\sum_{i=1}^N (y_i - \\bar{y})^2}{N-1} = \\frac{\\sum_{i=1}^N (y_i - \\bar{y})(y_i - \\bar{y})}{N-1}\\] Covariance (\\(\\sigma_{xy}\\)) quantifies how \\(x\\) and \\(y\\) are linearly related (covary means “vary together”). \\[\\text{Cov}(x,y) = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{N-1}\\] Thus, a variance can be seen as a special case of covariance, when \\(x=y\\). Its absolute value is difficult to interpret because it is in a squared metric. For a variance, we usually overcome this limitation by interpreting its square-root: the standard deviation (\\(\\sigma\\), or sample estimate SD), expressed in the original units of measurement. In contrast, the square-root of a covariance does not have a meaningful or practical interpretation. However, the covariance between 2 variables cannot exceed the product of their SDs (\\(\\pm \\sigma_x \\sigma_y\\)), so we can standardize a covariance via division of \\(\\sigma_{xy}\\) by \\(\\sigma_x \\sigma_y\\). This limits the range to \\(\\pm 1\\), and we call the standardized covariance a correlation coefficient: \\[\\rho_{xy} = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y}\\] For \\(&gt;2\\) variables in a data set \\(\\mathbf{Y}\\), we can simultaneously calculate all (co)variances using matrix algebra: Mean-center the data-matrix \\(\\mathbf{Y} - \\bar{\\mathbf{Y}}\\) “Square” it by (pre)multiplying it by its transpose Divide the result by (1 minus) the sample size \\[\\Sigma = \\frac{1}{N-1} (\\mathbf{Y} - \\bar{\\mathbf{Y}})^{&#39;} (\\mathbf{Y} - \\bar{\\mathbf{Y}})\\] Each off-diagonal cell of \\(\\Sigma\\) contains the covariance between the row-variable and the column-variable. A covariance matrix is symmetric above/below the diagonal because the covariance (or correlation) between \\(x\\) and \\(y\\) is the same as between \\(y\\) and \\(x\\). On the diagonal of \\(\\Sigma\\), the row and column variables are the same—how does a variable covary with itself? The diagonal contains each variable’s variance. Some authors refer to \\(\\Sigma\\) as a “variance–covariance matrix”, but that is redundant because variances appear on the diagonal by definition (see Cov(\\(x,y\\)) formula above). So the term “covariance matrix” is sufficiently descriptive. Standardizing a covariance (i.e., scaling by both SDs) is only one way to facilitate its interpretation. If it makes sense to think of one variable \\(x\\) affecting another variable \\(y\\), then another way to scale the covariance would be to divide by variance of \\(x\\). \\[\\beta_{yx} = \\frac{\\sigma_{xy}}{\\sigma^2_x} = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_x}\\] This provides a familiar interpretation from simple regression of \\(y\\) on \\(x\\): the slope (\\(\\beta_{yx}\\)) is interpreted as the change in \\(y\\) per unit \\(x\\). Recall that a standardized simple regression slope (\\(\\beta^*_{yx}\\)) is the correlation \\(\\rho_{xy}\\). The transformation below reveals why: \\[\\begin{align*} \\beta^*_{yx} &amp;= \\beta_{yx} \\times \\frac{\\sigma_x}{\\sigma_y} \\\\ &amp;= \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_x} \\times \\frac{\\sigma_x}{\\sigma_y} \\\\ &amp;= \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y} (= \\rho_{xy}) \\end{align*},\\] where one pair of \\(\\sigma_x\\) terms cancels out. This transformation is how slopes can be standardized even when there are multiple predictors. Partial regression slopes can also be calculated from summary statistics, but the formulas are more complicated because they take into account how the predictors are related to each other. The take-home message is that (un)standardized slopes and (zero-order or partial) correlations are just different ways of scaling a covariance to make it more interpretable. Like covariances, correlations are agnostic about whether one variable affects another, but slopes imply a causal direction (although other conditions must be met to draw a valid causal inference). 1.2 Importing Data for SEM This section covers importing both raw data and summary statistics, either of which can be analyzed by SEM software. We will utilize some special features in the open-source R package for SEM called lavaan (Rosseel, 2012), which is also the primary software we use for conducting SEM analyses in later chapters. 1.2.1 Installing lavaan To install the lavaan package you can type the following command in the R console: install.packages(&quot;lavaan&quot;, dependencies = TRUE) Depending on your R(Studio) settings, this might open a window where you have to select a CRAN mirror (select “[your country], [closest city]”) prior to installing the package, including all additional packages that it depends on. You only need to install the package once (on a specific computer), but you must also “load” the library to access its functionality (similar to first installing an app, then opening the app to use it): library(lavaan) Every time you start R you need to use this command to activate the lavaan package into the current R workspace. Therefore, it is advisable to start every script with this command. Sometimes, it will be necessary to install the development version of lavaan before the next version is made available on CRAN. For example, if the developer has fixed a bug or introduced a new feature in the source code (hosted on GitHub), the development version can be installed using the remotes package: install.packages(&quot;remotes&quot;) # if necessary remotes::install_github(&quot;yrosseel/lavaan&quot;) 1.2.2 Importing Raw Data Typically, data are already stored in an external file with a predefined format, such as SPSS (*.sav) or Excel (*.xlsx), and there are some pre-specified functions in R that can read in data from such type of formats, although they require the installation of specific packages. As an alternative, you can store the data in a plain text (with .txt or .csv extensions), where each line represents the observed responses of one individual. Spaces, commas, semicolons or tabs can be used to separate the individual responses. Some programs (like SPSS) can also export data to these types of file formats. read.table(&quot;data.txt&quot;, header = TRUE) read.spss(&quot;data.sav&quot;, to.data.frame = TRUE) # requires the package foreign read.xls(&quot;data.xls&quot;) # requires the package gdata as.data.frame(read_excel(&quot;data.xlsx&quot;)) # requires the package readxl This chapter uses data from a tutorial published on the Social Change Lab’s web site. dat &lt;- foreign::read.spss(&quot;demoData/MODMED.sav&quot;, to.data.frame = TRUE)[c(2, 3, 5, 7)] head(dat) ## MOOD NFC POS ATT ## 1 -1 3.07579 6.2500 18.5455 ## 2 -1 2.59489 -5.0671 -16.9684 ## 3 -1 -1.00952 0.9346 -5.9578 ## 4 -1 -0.43824 2.8668 -7.2256 ## 5 -1 0.21788 -16.5601 -26.7000 ## 6 -1 0.43842 -13.1365 -24.1241 MOOD indicates experimental conditions \\(+1\\) = positive mood induction \\(-1\\) = neutral mood (control condition) NFC = need for cognition, POS = positive thoughts, and ATT = attitude 1.2.3 Calculate Summary Statistics from Raw Data To report summary statistics of your modeled variables, they can be calculated using the colMeans() function for means, the cov() function for a covariance matrix, and the nrow() function for the sample size Note: Counting the number of rows assumes you have complete data (M &lt;- colMeans(dat)) # mean vector ## MOOD NFC POS ATT ## 0.0000000 -0.0000002 0.0000040 1.9807230 (S &lt;- cov(dat)) # covariance matrix ## MOOD NFC POS ATT ## MOOD 1.01010101 -0.03243879 4.3546465 6.841187 ## NFC -0.03243879 1.97289018 0.7953901 2.598788 ## POS 4.35464646 0.79539011 69.2629723 87.914121 ## ATT 6.84118687 2.59878834 87.9141208 282.059756 (N &lt;- nrow(dat)) # complete-data sample size ## [1] 100 Covariances are explained in more detail in a later section, but it is sufficient here to understand that the covariance between variables \\(x\\) and \\(y\\) (i.e., \\(\\sigma_{xy}\\)) is their unstandardized correlation coefficient (\\(r_{xy}\\)). That is, a correlation is a covariance between \\(z\\) scores. Because correlations are easier to interpret than covariances, it is common to report the means, SDs, and correlations. Using the SDs, readers can rescale correlations to covariances in the orignal units of measurement (i.e., \\(\\sigma_{xy} = \\sigma_x \\times \\sigma_y \\times r_{xy}\\)). The cov2cor() function can standardize a covariance matrix, or you can use the cor() function directly. (SD &lt;- sapply(dat, sd)) ## MOOD NFC POS ATT ## 1.005038 1.404596 8.322438 16.794635 sqrt(diag(S)) # SDs == square-roots of variances ## MOOD NFC POS ATT ## 1.005038 1.404596 8.322438 16.794635 cov2cor(S) # standardize the covariance matrix, or use cor() ## MOOD NFC POS ATT ## MOOD 1.00000000 -0.02297898 0.52061891 0.4053018 ## NFC -0.02297898 1.00000000 0.06804217 0.1101663 ## POS 0.52061891 0.06804217 1.00000000 0.6289810 ## ATT 0.40530176 0.11016633 0.62898098 1.0000000 (R &lt;- cor(dat)) ## MOOD NFC POS ATT ## MOOD 1.00000000 -0.02297898 0.52061891 0.4053018 ## NFC -0.02297898 1.00000000 0.06804217 0.1101663 ## POS 0.52061891 0.06804217 1.00000000 0.6289810 ## ATT 0.40530176 0.11016633 0.62898098 1.0000000 Because covariance and correlation matrices are symmetric (and diagonal elements of a correlation matrix are 1 by definition), both could be reported in a single table. For example, the upper triangle could be correlations, and the lower triangle (including the diagonal) could be (co)variances. printS &lt;- S printS[upper.tri(R)] &lt;- R[upper.tri(R)] printS # not symmetric, correlations in upper triangle ## MOOD NFC POS ATT ## MOOD 1.01010101 -0.02297898 0.52061891 0.4053018 ## NFC -0.03243879 1.97289018 0.06804217 0.1101663 ## POS 4.35464646 0.79539011 69.26297231 0.6289810 ## ATT 6.84118687 2.59878834 87.91412077 282.0597561 1.2.3.1 Calculate Summary Statistics for Multiple Groups In SEM, it is common to estimate model parameters simultaneously in multiple groups (i.e., multigroup SEM or MG-SEM). In our example data, the MOOD variable is a 2-group variable, so we could create a factor from the numeric codes: dat$mood.f &lt;- factor(dat$MOOD, levels = c(-1, 1), labels = c(&quot;neutral&quot;,&quot;positive&quot;)) Then we can calculate the summary statistics separately within each group. modVars &lt;- c(&quot;ATT&quot;,&quot;NFC&quot;,&quot;POS&quot;) # modeled variables neuRows &lt;- dat$mood.f == &quot;neutral&quot; # rows for neutral group posRows &lt;- dat$mood.f == &quot;positive&quot; # rows for positive group gM &lt;- list(neutral = colMeans(dat[neuRows, modVars] ), positive = colMeans(dat[posRows, modVars] )) gS &lt;- list(neutral = cov( dat[neuRows, modVars] ), positive = cov( dat[posRows, modVars] )) gN &lt;- table(dat$mood.f) To fit a MG-SEM in lavaan, the summary statistics must be a list with one (mean vector or covariance matrix) per group, as well as a vector of group sample sizes. gM ## $neutral ## ATT NFC POS ## -4.7920520 0.0321142 -4.3110960 ## ## $positive ## ATT NFC POS ## 8.7534980 -0.0321146 4.3111040 gS ## $neutral ## ATT NFC POS ## ATT 245.020884 4.812796 61.799307 ## NFC 4.812796 2.456274 -1.201971 ## POS 61.799307 -1.201971 47.663230 ## ## $positive ## ATT NFC POS ## ATT 231.2417228 0.8817017 56.235120 ## NFC 0.8817017 1.5276643 3.091531 ## POS 56.2351197 3.0915313 54.346483 gN ## ## neutral positive ## 50 50 1.2.4 Importing Summary Data 1.2.4.1 Full Covariance Matrix If we are importing summary data (e.g., from an article that reported them), we can type our data directly to our R script. Suppose the values above from S were rounded to 3 decimal places: covVals &lt;- c( 1.010, -0.032, 4.355, 6.841, -0.032, 1.973, 0.795, 2.599, 4.355, 0.795, 69.263, 87.914, 6.841, 2.599, 87.914, 282.060) covVals ## [1] 1.010 -0.032 4.355 6.841 -0.032 1.973 0.795 2.599 4.355 0.795 69.263 ## [12] 87.914 6.841 2.599 87.914 282.060 If these values were saved as plain text, we could also read the data from a file using the scan() function, which returns a vector that contains the stored values in the file \"values.txt\". covVals &lt;- scan(&quot;values.txt&quot;) Either way, we can place these values from the full covariance matrix into a matrix using the matrix() function, specifying how many rows and columns there are: (newS &lt;- matrix(data = covVals, nrow = 4, ncol = 4)) ## [,1] [,2] [,3] [,4] ## [1,] 1.010 -0.032 4.355 6.841 ## [2,] -0.032 1.973 0.795 2.599 ## [3,] 4.355 0.795 69.263 87.914 ## [4,] 6.841 2.599 87.914 282.060 We can give names to the variables in the covariance matrix by using the dimnames= argument of the matrix() function, or by using the dimnames() function after creating the matrix. Let’s save the variable names in an object obsnames, then use them to assign names. obsnames &lt;- c(&quot;MOOD&quot;, &quot;NFC&quot;, &quot;POS&quot;, &quot;ATT&quot;) ## providing names when creating matrix newS &lt;- matrix(covVals, nrow = 4, ncol = 4, dimnames = list(obsnames, obsnames)) ## or assign afterward, all at once dimnames(newS) &lt;- list(obsnames, obsnames) # (rows, columns) ## or one dimension at a time (useful for asymmetric matrix) rownames(newS) &lt;- obsnames colnames(newS) &lt;- obsnames 1.2.4.1.1 Rescaling a Correlation Matrix If the imported matrix is instead a full correlation matrix (i.e., assuming all variables have \\(SD=1\\)), then it can be transformed back into a covariance matrix using the \\(SD\\)s, so variables will be in their original units. This is important because an SEM fitted to a correlation matrix will have biased \\(SE\\)s and inflated Type I error rates unless complex constraints are imposed. ## store values from correlation matrix corVals &lt;- c( 1, -0.023, 0.521, 0.405, -0.023, 1, 0.068, 0.110, 0.521, 0.068, 1, 0.629, 0.405, 0.110, 0.629, 1) newR &lt;- matrix(data = corVals, nrow = 4, ncol = 4, dimnames = list(obsnames, obsnames)) newR ## MOOD NFC POS ATT ## MOOD 1.000 -0.023 0.521 0.405 ## NFC -0.023 1.000 0.068 0.110 ## POS 0.521 0.068 1.000 0.629 ## ATT 0.405 0.110 0.629 1.000 ## store SDs as a diagonal matrix (SDs &lt;- diag(SD)) ## [,1] [,2] [,3] [,4] ## [1,] 1.005038 0.000000 0.000000 0.00000 ## [2,] 0.000000 1.404596 0.000000 0.00000 ## [3,] 0.000000 0.000000 8.322438 0.00000 ## [4,] 0.000000 0.000000 0.000000 16.79463 ## transform correlations to covariances scaled.S &lt;- SDs %*% newR %*% SDs round(scaled.S, 3) ## [,1] [,2] [,3] [,4] ## [1,] 1.010 -0.032 4.358 6.836 ## [2,] -0.032 1.973 0.795 2.595 ## [3,] 4.358 0.795 69.263 87.917 ## [4,] 6.836 2.595 87.917 282.060 ## matches covariance matrix (within rounding error) newS ## MOOD NFC POS ATT ## MOOD 1.010 -0.032 4.355 6.841 ## NFC -0.032 1.973 0.795 2.599 ## POS 4.355 0.795 69.263 87.914 ## ATT 6.841 2.599 87.914 282.060 Note that rescaling the correlation matrix to be a covariance matrix required pre- and postmultipication of the (diagnal matrix of) \\(SD\\)s. The operator for matrix multiplication is %*% (the normal scalar multiplication operator * would simply multiply each cell of one matrix with the corresponding cell of another matrix). The table below gives an overview of commonly used functions in matrix algebra in R. Symbol Function Example in R \\(A+B\\) Addition A + B \\(A-B\\) Subtraction A - B (none) Elementwise Multiplication (in R) A * B (none) Elementwise Division (in R) A / B \\(AB\\) Matrix Multiplication A %*% B \\(A^{-1}\\) Inverse (enables “division” analog) solve(A) \\(A^{&#39;}\\) Transpose (rows become columns) t(A) \\(|A|\\) Determinant (generalized variance) det(A) To review basic matrix algebra, consult a linear algebra text or an appendix of some SEM textbooks (e.g., Bollen, 1989; Schumacker &amp; Lomax, 2016). 1.2.4.2 Upper/Lower Triangle of a Covariance Matrix As a covariance matrix is a symmetric matrix, we do not need to provide the complete matrix. Instead, we can import only the nonredundant information from only the lower (or upper) triangle of the covariance matrix, then use the lavaan function getCov() to create the full matrix. By default, getCov() expects the values from the lower triangle, and it will read values row-by-row (i.e., left-to-right, top-to-bottom), including the diagonal elements (diagonal = TRUE is the default argument). \\[ \\begin{bmatrix} 1.010 &amp; &amp; &amp; \\\\ -0.032 &amp; 1.973 &amp; &amp; \\\\ 4.355 &amp; 0.795 &amp; 69.263 &amp; \\\\ 6.841 &amp; 2.599 &amp; 87.914 &amp; 282.060 \\end{bmatrix} \\] This is equivalent to reading the upper triangle column-by-column (i.e., top-to-bottom, left-to-right). One can also add a vector with the names= of the observed variables. It returns the complete covariance matrix, including row and column names. The following code can be used to create a full matrix that is equal to S and newS above, using only the values from the lower triangle of the matrix. lowerS &lt;- c( 1.010, -0.032, 1.973, 4.355, 0.795, 69.263, 6.841, 2.599, 87.914, 282.060) getCov(x = lowerS, names = obsnames) ## MOOD NFC POS ATT ## MOOD 1.010 -0.032 4.355 6.841 ## NFC -0.032 1.973 0.795 2.599 ## POS 4.355 0.795 69.263 87.914 ## ATT 6.841 2.599 87.914 282.060 Sometimes you will find the upper triangle reported in a published paper instead of the lower triangle. Because getCov() only reads values row-by-row (i.e., left-to-right, top-to-bottom), reading an upper-triangle requires changing the argument to lower = FALSE. \\[ \\begin{bmatrix} 1.010 &amp; -0.032 &amp; 4.355 &amp; 6.841 \\\\ &amp; 1.973 &amp; 0.795 &amp; 2.599 \\\\ &amp; &amp; 69.263 &amp; 87.914 \\\\ &amp; &amp; &amp; 282.060 \\end{bmatrix} \\] upperS &lt;- c(1.010, -0.032, 4.355, 6.841, 1.973, 0.795, 2.599, 69.263, 87.914, 282.060) getCov(x = upperS, names = obsnames, lower = FALSE) ## MOOD NFC POS ATT ## MOOD 1.010 -0.032 4.355 6.841 ## NFC -0.032 1.973 0.795 2.599 ## POS 4.355 0.795 69.263 87.914 ## ATT 6.841 2.599 87.914 282.060 1.2.4.2.1 Upper/Lower Triangle of a Correlation Matrix Quite frequently, in published papers the covariance matrix is not provided, but instead a correlation matrix and \\(SD\\)s are given separately. The getCov() argument sds= can be used to automatically rescale the correlation matrix. Because the diagonal of a correlation matrix is always 1, it is not necessary to include the diagonal values. \\[ \\begin{bmatrix} 1 &amp; &amp; &amp; \\\\ -0.023 &amp; 1 &amp; &amp; \\\\ 0.521 &amp; 0.068 &amp; 1 &amp; \\\\ 0.405 &amp; 0.110 &amp; 0.629 &amp; 1 \\end{bmatrix} \\] In this case, tell lavaan that the diagonal entries are omitted using the diagonal=FALSE argument. The following syntax creates the complete covariance matrix that was used in the previous examples from the correlations and \\(SD\\)s. getCov(x = c(-0.023, 0.521, 0.068, 0.405, 0.110, 0.629), diagonal = FALSE, sds = SD, names = obsnames) ## MOOD NFC POS ATT ## MOOD 1.01010101 -0.03246846 4.3578341 6.836093 ## NFC -0.03246846 1.97289018 0.7948971 2.594865 ## POS 4.35783405 0.79489713 69.2629723 87.916779 ## ATT 6.83609342 2.59486462 87.9167795 282.059756 If you are wondering whether the correlations appear in the correct order in the matrix, you can first leave the \\(SD\\)s out and check that the cells of the correlation matrix are in the correct order. If everything looks correct, then you can add the \\(SD\\)s. Covariance/correlation matrices are also symmetric, so it is also important to check that the lower triangle is a reflection of the upper triangle (i.e., Row-\\(x\\) Column-\\(y\\) of the matrix should contain the same value as Row-\\(y\\) Column-\\(x\\)). The R function isSymmetric() can perform this check for you: isSymmetric(S) ## [1] TRUE 1.3 Regression Using Matrix Algebra This section is more technical than most remaining chapters will be. The main goal of this section is to demonstrate how GLM parameters can be estimated using raw data and summary statistics, revealing how these approaches are equivalent. Familiarity with the basics of matrix algebra will continue to remain important throughout later chapters as well, not only because much of SEM is expressed in matrix notation, but because later chapters will demonstrate certain methods (e.g., standardizing an entire matrix of regression slopes) using matrix algebra. 1.3.1 Linear Regression Models The GLM expresses an outcome \\(y\\) as a linear combination (weighted sum) of predictors: \\[\\begin{align*} y_i &amp;= \\beta_0 + \\beta_1 x_{i1} + \\ldots + \\beta_p x_{ip} &amp;+&amp; \\varepsilon_i \\\\ &amp;= \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} &amp;+&amp; \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma) \\end{align*}\\] The deterministic component of \\(y\\) can be predicted or explained by \\(X\\) The stochastic component of \\(y\\) includes all other unmodeled effects (omitted variables) and sources of error (\\(\\varepsilon\\)) This is analogous to a recipe for the outcome: How much of \\(x_1\\) and \\(x_2\\) do you need to recreate \\(y\\)? The notation above uses a subscript i as an “index variable” for subject \\(i = 1, \\dots, N\\). There are other notations, such as the full matrix notation showing each subject’s values of the outcome \\(y\\) and predictors \\(j = 1, \\dots, p\\) in columns of the matrix \\(\\mathbf{X}\\): \\[\\begin{equation*} \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix} = \\begin{bmatrix} 1 &amp; x_{1,1} &amp; x_{1,2} &amp; \\dots &amp; x_{1,p} \\\\ 1 &amp; x_{2,1} &amp; x_{2,2} &amp; \\dots &amp; x_{2,p} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_{N,1} &amp; x_{N,2} &amp; \\dots &amp; x_{N,p} \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix} + \\begin{bmatrix} \\varepsilon_1 \\\\ \\varepsilon_2 \\\\ \\vdots \\\\ \\varepsilon_N \\end{bmatrix} \\end{equation*}\\] The shorthand notation simply uses bolded symbols for the matrices above: \\(\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\varepsilon}\\) The ordinary least-squares (OLS) estimator of \\(\\beta\\) minimizes the sum of squared residuals (equivalent to maximizing \\(R^2\\)): \\[\\beta = (\\mathbf{X}^{&#39;} \\mathbf{X})^{-1} \\mathbf{X}^{&#39;} \\mathbf{y}\\] The OLS estimator operates on the raw data: the matrix of predictors (\\(\\mathbf{X}\\)) and the vector of outcomes (\\(\\mathbf{y}\\)). But recall from the previous section that if the data are mean-centered, then \\(\\mathbf{X}^{&#39;} \\mathbf{X}\\) is the covariance matrix of the predictors. In that case, there would be no vector of ones in the first column of \\(\\mathbf{X}\\), and the first element of \\(\\beta\\) (the intercept) can be omitted because it would be zero whenever \\(\\mathbf{X}\\) and \\(\\mathbf{y}\\) are mean-centered. The syntax examples below calculate \\(\\mathbf{\\Sigma}_\\mathbf{X}\\) both manually and using the cov() function to demonstrate their equivalence. ## Manual calculation n &lt;- nrow(dat) - 1 Xc &lt;- scale(dat[c(&quot;MOOD&quot;,&quot;NFC&quot;,&quot;POS&quot;)], center = TRUE, scale = FALSE) t(Xc) %*% Xc / n ## MOOD NFC POS ## MOOD 1.01010101 -0.03243879 4.3546465 ## NFC -0.03243879 1.97289018 0.7953901 ## POS 4.35464646 0.79539011 69.2629723 ## Automated function cov(dat[c(&quot;MOOD&quot;,&quot;NFC&quot;,&quot;POS&quot;)]) ## MOOD NFC POS ## MOOD 1.01010101 -0.03243879 4.3546465 ## NFC -0.03243879 1.97289018 0.7953901 ## POS 4.35464646 0.79539011 69.2629723 Likewise, \\(\\mathbf{X}^{&#39;} \\mathbf{y}\\) captures the covariances of predictors with the outcome: ## Manual calculation t(Xc) %*% dat$ATT / n ## [,1] ## MOOD 6.841187 ## NFC 2.598788 ## POS 87.914121 ## Automated function cov(x = dat[c(&quot;MOOD&quot;,&quot;NFC&quot;,&quot;POS&quot;)], y = dat$ATT) ## [,1] ## MOOD 6.841187 ## NFC 2.598788 ## POS 87.914121 Thus, even without access to raw data, the OLS estimates of slopes can be obtained using the data’s summary statistics: Xcov &lt;- cov(dat[c(&quot;MOOD&quot;,&quot;NFC&quot;,&quot;POS&quot;)]) Xy &lt;- cov(x = dat[c(&quot;MOOD&quot;,&quot;NFC&quot;,&quot;POS&quot;)], y = dat$ATT) solve(Xcov) %*% Xy # calculate slopes from (co)variances ## [,1] ## MOOD 1.8839147 ## NFC 0.8883671 ## POS 1.1406346 These slopes match the estimates from R’s built-in linear-modeling function: mod &lt;- lm(ATT ~ MOOD + NFC + POS, data = dat) coef(mod) ## (Intercept) MOOD NFC POS ## 1.9807186 1.8839147 0.8883671 1.1406346 1.3.2 Intercepts and Means The lm() output above also provides an intercept because the data were not centered. In this case, the matrix \\(X\\) includes a constant (all 1s) in the first column, so its covariance matrix no longer resembles the covariance matrix of the predictors alone. However, the covariation among predictors (and outcome) are still captured, and the column of 1s effectively “partials out” the mean from the predictors and outcome. In the simplest case without any predictors (an intercept-only model), it is easier to see how the vector of 1s captures mean-structure information. Recall the formula for an arithmetic mean is the sum of \\(y\\) scores, divided by the number of \\(y\\) scores: \\(\\bar{y} = \\frac{1}{N} \\sum y\\). For the intercept-only model, the intercept (\\(\\beta_0\\)) is the mean: \\((\\mathbf{X}^{&#39;} \\mathbf{X})^{-1} = (\\mathbf{1}^{&#39;} \\mathbf{1})^{-1} = \\frac{1}{N}\\) \\(\\mathbf{X}^{&#39;} \\mathbf{y} = \\sum y\\) The syntax example below demonstrates the equivalence: ## using matrix algebra y &lt;- dat$ATT ONE &lt;- rep(1, times = length(y)) solve(t(ONE) %*% ONE) %*% t(ONE) %*% y ## [,1] ## [1,] 1.980723 ## fitted linear model with only an intercept coef(lm(y ~ 1)) ## (Intercept) ## 1.980723 ## calculate the mean mean(y) ## [1] 1.980723 Finally, we will apply the OLS formula (\\(\\beta = (\\mathbf{X}^{&#39;} \\mathbf{X})^{-1} \\mathbf{X}^{&#39;} \\mathbf{y}\\)) to the full model with uncentered raw data (i.e., intercept included): X &lt;- cbind(`(Intercept)` = ONE, # first column is constant as.matrix(dat[c(&quot;MOOD&quot;,&quot;NFC&quot;,&quot;POS&quot;)])) solve(t(X) %*% X) %*% t(X) %*% y # beta ## [,1] ## (Intercept) 1.9807186 ## MOOD 1.8839147 ## NFC 0.8883671 ## POS 1.1406346 Which again matches results from the lm() function: coef(mod) ## (Intercept) MOOD NFC POS ## 1.9807186 1.8839147 0.8883671 1.1406346 When we add a predictor to the model, the intercept becomes a conditional mean (i.e., the expected value when each predictor = 0) rather than the “marginal” or “grand” mean. 1.3.3 Categorical Predictors Recall also that groups \\(g = 1, \\ldots, G\\) can be represented using numeric codes, very often 1s, such as dummy codes. For example, a dummy code for Group \\(g\\) indicates whether someone belongs to Group \\(g\\) (1) or not (0). Alternative coding strategies include orthogonal contrast codes or effects coding, the latter of which was how our MOOD variable was coded to indicate experimental conditions: \\(+1\\) = positive mood induction \\(-1\\) = neutral mood (control condition) table(dat$MOOD) ## ## -1 1 ## 50 50 The algebra is identical, capturing how dummy codes covary with each other and with the outcome. However, the set of all \\(G\\) dummy codes would be perfectly multicollinear with the constant used to estimate the intercept (i.e., the column of 1s is exactly equal to the sum of the dummy-coded columns). This is why we typically estimate slopes for \\(G-1\\) dummy codes, treating the last one as the reference group. Thus, each dummy-code’s slope represents how that group’s mean differs from the reference group’s mean. 1.3.3.1 Regression with Group-Specific Intercepts Rather than choosing a baseline group, we can omit the intercept from the model by dropping the vector of 1s from \\(X\\). This prevents multicollinearity among the dummy codes and the constant, so lm() will include all \\(G\\) dummy codes (not \\(G-1\\)). dat$mood.f &lt;- factor(dat$MOOD, levels = c(-1, 1), labels = c(&quot;neutral&quot;,&quot;positive&quot;)) coef( lm(POS ~ -1 + mood.f, data = dat) ) ## mood.fneutral mood.fpositive ## -4.311096 4.311104 Essentially, this model gives each group its own intercept, which is also the group-mean when there are no other predictors in the model aggregate(POS ~ mood.f, data = dat, FUN = mean) ## mood.f POS ## 1 neutral -4.311096 ## 2 positive 4.311104 Later in this course, you will learn about multigroup SEM, which is when the same SEM is fitted separately (but simultaneously) to 2 or more groups. Multigroup SEM is analogously advantageous, but (unlike in the GLM) variances can also differ across groups, so we do not need to assume homoskedasticity when using multigroup SEM. Slopes can also be estimated separately per group when the intercept is dropped from the model. This is specified by multiplying the predictor by each dummy code. ## no &quot;main/simple effect&quot; of NFC without a reference group mod1 &lt;- lm(POS ~ -1 + mood.f + mood.f:NFC, data = dat) coef(mod1) ## mood.fneutral mood.fpositive mood.fneutral:NFC mood.fpositive:NFC ## -4.2953810 4.3760943 -0.4893472 2.0236980 This is equivalent to estimating the effect of NFC separately in each group. mod.neu &lt;- lm(POS ~ NFC, data = dat, subset = dat$mood.f == &quot;neutral&quot;) coef(mod.neu) ## (Intercept) NFC ## -4.2953810 -0.4893472 mod.pos &lt;- lm(POS ~ NFC, data = dat, subset = dat$mood.f == &quot;positive&quot;) coef(mod.pos) ## (Intercept) NFC ## 4.376094 2.023698 We will discuss (dis)advantages of the multigroup approach in the following chapter, after introducing regression models as SEM. 1.4 Summary This chapter introduced the idea of analyzing mean and covariance structures, which partition descriptive statistics (means and (co)variances) into meaningful components. This enables researchers to impose a hypothesized structure on why variables are related to each other. The next chapter will introduce the SEM framework, which was designed for researchers to specify such theoretical structures as statistical models, and fit them to data in order to estimate and test parameters of interest. References Bollen, K. A. (1989). Structural equations with latent variables. Wiley. https://doi.org/10.1002/9781118619179 Rosseel, Y. (2012). lavaan: An R package for structural equation modeling. Journal of Statistical Software, 48(2), 1–36. https://doi.org/10.18637/jss.v048.i02 Schumacker, R. E., &amp; Lomax, R. G. (2016). A beginner’s guide to structural equation modeling (4th ed.). Lawrence Erlbaum. https://doi.org/10.4324/9781315749105 "],["ch2.html", "2 Using lavaan to Run Regression and ANOVA as a SEM 2.1 Prepare Data and Workspace 2.2 Comparing 2 Group Means in GLM and SEM 2.3 Fit an SEM to Summary Statistics 2.4 Moderation in SEM 2.5 Summary References", " 2 Using lavaan to Run Regression and ANOVA as a SEM This chapter prepares the reader to learn about structural equation modeling (SEM) by reviewing the fundamentals of ordinary least-squares (OLS) regression in the general(ized) linear modeling (GLM) framework. Some key take-home messages will reinforce what was discussed about covariance structure analysis in the previous chapter: Analyzing different data formats (raw vs. summary data) yields equivalent results (under conditions of normality and complete data). Recall from the previous chapter that maximum-likelihood estimation (MLE) in SEM chooses parameters that minimize discrepancies between observed and expected summary statistics rather than casewise observations. Grouping variables can be represented as dummy, effects, or contrast codes, but there are some advantages of stratifying results by group. This will be demonstrated using multigroup SEM and comparing results to the single-group approach. Point estimates from SEM will match GLM because OLS estimates are ML estimates when the distributional assumptions are met. independent, identically distributed (normal with homogeneous variance) However, the SEs are typically smaller under ML with SEM than under OLS with GLM. Furthermore, different (but analogous) test statistics will be compared between GLM (t and F statistics) and SEM (z and \\(\\chi^2\\) statistics). Model comparisons require fitting nested models to the same data, which in SEM means fitting them to the same summary statistics. 2.1 Prepare Data and Workspace 2.1.1 Import Example Data We will use data from a tutorial published on the Social Change Lab’s web site. dat &lt;- foreign::read.spss(&quot;demoData/MODMED.sav&quot;, to.data.frame = TRUE)[c(2, 3, 5, 7)] ## print first and last 3 rows dat[c(1:3, 98:100), ] ## MOOD NFC POS ATT ## 1 -1 3.07579 6.2500 18.5455 ## 2 -1 2.59489 -5.0671 -16.9684 ## 3 -1 -1.00952 0.9346 -5.9578 ## 98 1 0.14496 -6.6079 -0.6811 ## 99 1 0.28151 15.1838 30.5421 ## 100 1 -0.06157 -6.0116 11.7879 Recall from Chapter 1 that SEM can equivalently be fitted to summary statistics rather than raw data. This chapter will demonstrate this both approaches. ## Save summary statistics M &lt;- colMeans(dat) S &lt;- cov(dat) N &lt;- nrow(dat) Also recall that it is possible to fit a “multigroup SEM” to obtain parameter estimates separately per group. This chapter will also demonstrate how to fit a multigroup SEM to raw data as well as to summary statistics. For the latter, we require group-specific summary statistics, which Chapter 1 discussed how to obtain. Here, we use slightly more efficient syntax to obtain lists of group-specific summary statistics, although the more sophisticated sapply() function makes the syntax less immediately intuitive to read. ## Create factor from effects-coded conditions dat$mood.f &lt;- factor(dat$MOOD, levels = c(-1, 1), labels = c(&quot;neutral&quot;,&quot;positive&quot;)) ## Save lists of group-specific summary statistics CC &lt;- c(&quot;ATT&quot;,&quot;NFC&quot;,&quot;POS&quot;) # when group = &quot;mood.f&quot; gM &lt;- sapply(c(&quot;neutral&quot;,&quot;positive&quot;), simplify = FALSE, FUN = function(g) colMeans(dat[dat$mood.f == g, CC]) ) gS &lt;- sapply(c(&quot;neutral&quot;,&quot;positive&quot;), simplify = FALSE, FUN = function(g) cov( dat[dat$mood.f == g, CC]) ) gN &lt;- table(dat$mood.f) 2.1.2 lavaan Syntax Notice from the section-header that lavaan should always be lower-case. It is a portmanteau of latent variable analysis, similar to ANalysis Of VAriance (ANOVA). Load lavaan into your workspace. library(lavaan) The standard syntax for regression in R is a formula object. To regress ATTitude on MOOD condition, Need For Cognition (NFC), and POSitive thoughts: ATT ~ MOOD + NFC + POS SEM is a multivariate modeling framework, so a formula object does not allow for sufficient complexity. There can be many outcome variables, each with its own formula (i.e., different predictors) Multivariate GLMs (e.g., MANOVA) require the same predictors for all outcomes e.g., cbind(ATT, POS) ~ MOOD + NFC Outcomes can even predict other outcomes, which GLM does not allow Another name for an SEM is a simultaneous equations model. Later chapters will introduce additional complexity that formula objects do not allow for: Residual variances can be specified explicitly using a “double tilde” operator (~~), which allows specifying equality constraints on variance estimates. There can be unobserved (latent) variables, which require a special operator (=~) to define in lavaan syntax. Details about these and other operators can be found in the Details section of the ?model.syntax help page, and the website also has a syntax tutorial for various short topics. Details about syntax features we will use in this chapter are summarized in the table below. Operator Purpose Example ~ Estimate regression slope(s) 'outcome ~ predictor' ~1 Estimate intercept(s) 'outcome ~ 1' value* Fix (number) or free (missing value) parameters 'posttest ~ 1*pretest + NA*x1' string* Label parameters 'y ~ myLabel*x' + Additional parameters or operators 'y ~ NA*x1 + beta2*x2' c() Operators for multiple groups 'y ~ c(NA, 1)*x1 + c(beta1, beta2)*x2' := Define a function of parameters 'slopeRatio := beta1 / beta2' lavaan requires collecting all of these model parameters in a character vector, even when there is only one outcome. &#39; ATT ~ MOOD + NFC + POS &#39; Note how the syntax above looks exactly like the formula we would pass to lm(), except that it is within quotation marks. lavaan’s model syntax is flexible enough that we can equivalently specify each parameter on a different line, which can be useful in larger models or to make #comments in syntax. &#39; ATT ~ 1 # intercept ATT ~ MOOD # slopes ATT ~ NFC ATT ~ POS &#39; Once we specify a model (typically saving the character string to an object), we can fit that model to the (raw or summary) data. There are multiple model-fitting functions in the lavaan package: lavaan() is the main “engine”, but expects that models are fully specified in complete detail sem() is a “wrapper” that calls lavaan() with some sensible defaults that apply to most SEMs (e.g., automatically estimating residual variances, automatically estimating covariances among predictors) cfa() is meant for fitting confirmatory factor analysis (CFA) models, discussed in a later chapter. cfa() and sem() actually behave identically (i.e., they call lavaan() with the same defaults) growth() is meant for very simple latent growth curve models, also discussed in a later chapter In this chapter, we will use the sem() function similar to the way we use the lm() function, including how we obtain results from summary(). 2.2 Comparing 2 Group Means in GLM and SEM This section compares SEM with GLM in the simple case of comparing 2 group means. 2.2.1 The GLM Approach Recall that an independent-samples t test (assuming homoskedasticity across groups) is equivalent to testing the estimated slope of a dummy code in a simple regression model. t.test(ATT ~ mood.f, data = dat, var.equal = TRUE) ## ## Two Sample t-test ## ## data: ATT by mood.f ## t = -4.3889, df = 98, p-value = 2.876e-05 ## alternative hypothesis: true difference in means between group neutral and group positive is not equal to 0 ## 95 percent confidence interval: ## -19.670213 -7.420887 ## sample estimates: ## mean in group neutral mean in group positive ## -4.792052 8.753498 ## as a regression model mod.dummy &lt;- lm(ATT ~ mood.f, data = dat) summary(mod.dummy) # compare t test for slope to t.test() output ## ## Call: ## lm(formula = ATT ~ mood.f, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -52.818 -9.015 1.084 10.423 31.769 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4.792 2.182 -2.196 0.0305 * ## mood.fpositive 13.546 3.086 4.389 2.88e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.43 on 98 degrees of freedom ## Multiple R-squared: 0.1643, Adjusted R-squared: 0.1557 ## F-statistic: 19.26 on 1 and 98 DF, p-value: 2.876e-05 Recall also that the F test at the bottom of the summary.lm() output is an ANOVA comparing the fitted model to an intercept-only model. mod.int &lt;- lm(ATT ~ 1, data = dat) anova(mod.int, mod.dummy) ## Analysis of Variance Table ## ## Model 1: ATT ~ 1 ## Model 2: ATT ~ mood.f ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 99 27924 ## 2 98 23337 1 4587 19.263 2.876e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In the case of an F test with 1-df in the numerator, the test result is equivalent to a squared t statistic with the same df as the denominator of the F test. \\[ F_{1, df} = t^2_{df} \\] This makes it simpler to test individual parameters (single-df tests) without fitting a separate model that fixes the single parameter to 0 (by dropping it from the GLM). We will see the same relationship between statistics available from SEM. 2.2.2 The SEM Approach (single-group SEM) Fitting the same simple-regression model as an SEM is relatively simple: Replace the lm() function with the sem() function, and embed the formula in quotation marks. However, lavaan will not automatically create dummy codes for factor variables as lm() will, so we must first make a dummy code for positive mood. Recall: mod.dummy &lt;- lm(ATT ~ mood.f, data = dat) dat$pos.mood &lt;- ifelse(dat$mood.f == &quot;positive&quot;, yes = 1, no = 0) ## as an SEM fit.dummy &lt;- sem(&#39; ATT ~ pos.mood &#39;, data = dat) summary(fit.dummy) # compare SE and z test for slope to lm() result ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT ~ ## pos.mood 13.546 3.055 4.433 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ATT 233.369 33.003 7.071 0.000 The SEM’s ML estimate of the group mean difference is 13.546, which is identical to the lm() result. However, we will focus on some differences. 2.2.2.1 Why Does SEM Have a Smaller SE The SEM has a smaller SE estimate, which in turn makes its Wald z test statistic larger than the t statistic. Note that both statistics are calculated identically as the ratio of the estimate to its SE (i.e., a Wald test). More generally, any \\(H_0\\) can be tested about the parameter \\(\\beta\\), where the null-hypothesized value is represented by \\(\\beta_0\\): \\[t \\text{ or } z = \\frac{\\hat{\\beta} - \\beta_0}{SE}\\] The summary() methods simply set each \\(\\beta_0=0\\) by default, so testing a different \\(H_0\\) requires calculating the test and its p value manually. So, if they are calculated the same way, why are they z instead of t tests? SEM estimators are based on asymptotic (infinite-N) theory, which means MLE assumes \\(N\\) is sufficiently large that the sample covariance matrix \\(S\\) is approximately equivalent to the population covariance matrix \\(\\Sigma\\). The asymptotic assumption yields more power, but inflated Type I error rates when sample size is low (relative to number of estimated parameters). So it would be more robust to interpret the Wald z statistic as a t statistic in small samples; unfortunately, there is no straight-forward way to derive an appropriate df parameter for the t distribution. 2.2.2.2 Why Do Residual Variance Estimates Differ? The “Residual standard error” in the lower summary.lm() output is the SD of the residuals, so its square is the estimated variance of the residuals (238.131). The SEM estimate is smaller (233.369), which also follows from using asymptotic theory. The formula for a variance divides the sum of squared residuals by N when the population mean is known, but GLM divides by the model’s df (in this case, \\(N-2\\)). If we rescaled the GLM estimate by \\(\\frac{N-2}{N}\\), we would obtain the same asymptotic estimate that MLE provides from our SEM result: sigma(mod.dummy)^2 * (N - 2) / N ## [1] 233.3687 The same rescaling by \\(\\frac{N-2}{N}\\) is responsible for the smaller SEs in the SEM result, although it is not the SE itself that is rescaled (see previous section). 2.2.2.3 Where Is the Intercept in SEM? The SEM result had no intercept. This is because we did not specify one in our syntax. Whereas a formula object for lm() automatically adds an intercept (implicitly regressing on a constant: ATT ~ 1 + mood.f), the sem() function will not do so in simple models like this. The previous chapter (section Linear Regression Models) explains why we can omit mean-structure parameters when data are mean-centered (i.e., intercept would be 0 anyway). But SEM doesn’t actually require us mean-center the data to obtain such results, which is convenient when we have no hypotheses about the intercepts. To add intercepts to the model, we can simply add the argument meanstructure=TRUE, which would be set automatically whenever we explicitly add any intercept parameter to the model syntax. fit.dummy &lt;- sem(&#39; ATT ~ 1 + pos.mood &#39;, data = dat) parameterEstimates(fit.dummy, output = &quot;pretty&quot;, ci = FALSE) ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT ~ ## pos.mood 13.546 3.055 4.433 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ATT -4.792 2.160 -2.218 0.027 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ATT 233.369 33.003 7.071 0.000 As with the estimated slope, the estimated intercept is identical between GLM and SEM, but SEM has a smaller SE, resulting in a larger Wald z statistic. 2.2.2.4 Model-Comparison Approach (Analogous to F Test) Comparing nested GLMs provides an \\(F\\) statistic. Analogously, comparing nested SEMs provides a \\(\\chi^2\\) statistic, which is also follows from using asymptotic theory. As the denominator df of the F statistic approaches \\(\\infty\\), the F statistic (multiplied by its numerator df) more closely follows a \\(\\chi^2\\) distribution with the same (numerator) df. However, an important caveat follows from the criterion used to find the “best” parameters in SEM. Whereas GLM minimizes casewise residuals, SEM minimizes residuals of summary statistics (review Types of Data Used in SEM for details). In a GLM, it does not matter if we remove a predictor \\(x\\) from a model because the only data we try to reproduce is the outcome \\(y\\) (i.e., both nested models are fitted to the same data). But in SEM, we are fitting models to reproduce the sample means \\(\\bar{y}\\) and covariance matrix \\(\\mathbf{S}\\), which include both ATTitude and the positive-MOOD dummy code: lavInspect(fit.dummy, &quot;sampstat&quot;) # observed sample statistics ## $cov ## ATT pos.md ## ATT 279.239 ## pos.mood 3.386 0.250 ## ## $mean ## ATT pos.mood ## 1.981 0.500 If we were to “remove” the positive-MOOD dummy code from the SEM, the sample covariance matrix would no longer be a 2 \\(\\times\\) 2 matrix, but a 1 \\(\\times\\) 1 matrix containing only the variance of the outcome ATTitude. fit.int &lt;- sem(&#39; ATT ~ 1 &#39;, data = dat) lavInspect(fit.int, &quot;sampstat&quot;) ## $cov ## ATT ## ATT 279.239 ## ## $mean ## ATT ## 1.981 Thus, we would not be fitting both nested SEMs to (all of) the same data. The anova() method would warn us about this if we tried it: anova(fit.int, fit.dummy) ## Warning: lavaan-&gt;lavTestLRT(): ## some models are based on a different set of observed variables ## Warning: lavaan-&gt;lavTestLRT(): ## some models have the same degrees of freedom ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit.int 0 850.99 856.20 0 ## fit.dummy 0 835.05 842.87 0 -8.8818e-14 0 0 Instead, we need to keep both variables in the model—any models we want to compare must include all the same variables. To represent the \\(H_0: \\beta_0=0\\), we must fix it to 0 instead of freely estimating it (which represents the \\(H_A: \\beta_0 \\ne 0\\)). This is accomplished in the model syntax by placing a zero in front of the predictor, with an asterisk between the value and the variable (0*pos.mood): fit.int &lt;- sem(&#39; ATT ~ 1 + 0*pos.mood &#39;, data = dat) anova(fit.int, fit.dummy) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit.dummy 0 835.05 842.87 0.000 ## fit.int 1 850.99 856.20 17.945 17.945 0.41164 1 2.274e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Although we can use the generic model-comparing anova() method in R, this is not an analysis of variance (ANOVA), but rather an analysis of deviance, more commonly called a likelihood ratio test (LRT). 2.2.3 Multigroup SEM Approach The previous section demonstrated how to test the \\(H_0\\) that 2 groups have identical means, using either GLM (t test) or an analogous simple-regression in single-group SEM. Like a GLM, this makes the simplifying assumption of homoskedasticity (same residual variance within each group), represented earlier by setting the t.test() argument var.equal=TRUE. An alternative SEM approach is to fit models separately in each group, using the group= argument. In this case, we would fit an intercept-only model for ATTitude, estimating the parameters separately in each MOOD group: not only the intercept, but also the variance! mg.int &lt;- sem(&#39; ATT ~ 1 &#39;, data = dat, group = &quot;mood.f&quot;) summary(mg.int, header = FALSE) ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [neutral]: ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT -4.792 2.191 -2.187 0.029 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT 240.120 48.024 5.000 0.000 ## ## ## Group 2 [positive]: ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT 8.753 2.129 4.112 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT 226.617 45.323 5.000 0.000 There is an analogous t test that does not assume equal variances (which differ in the output above): t.test(ATT ~ mood.f, data = dat) # var.equal = FALSE by default ## ## Welch Two Sample t-test ## ## data: ATT by mood.f ## t = -4.3889, df = 97.918, p-value = 2.878e-05 ## alternative hypothesis: true difference in means between group neutral and group positive is not equal to 0 ## 95 percent confidence interval: ## -19.670277 -7.420823 ## sample estimates: ## mean in group neutral mean in group positive ## -4.792052 8.753498 But now that the group-mean-difference is not a distinct SEM parameter (like the slope was in the single-group approach), how do we test the \\(H_0\\) of equivalent means? In SEM, there are two approaches. 2.2.3.1 Compare Nested MG-SEMs To fit a MG-SEM in which the \\(H_0\\) must be true, we must constrain the 2 group means to be the same value. We can do this by giving them the same label in the model syntax. The label is arbitrary (below, we use mu for \\(\\mu\\)), as long as the same label is used for the parameter in both groups. As shown in the table above (the lavaan Syntax section), labeling a single parameter works like fixing (or freeing) a parameter to a particular value, but using a character string instead of a number (or NA). &#39; ATT ~ mu*1 &#39; ## [1] &quot; ATT ~ mu*1 &quot; In multiple groups, we use the c() function to make a vector of labels, where the first label applies to Group 1’s parameter, the second applies to Group 2, etc. mg.eq &lt;- sem(&#39; ATT ~ c(mu, mu)*1 &#39;, data = dat, group = &quot;mood.f&quot;) # grouping variable here, not in model summary(mg.eq, header = FALSE) ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [neutral]: ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT (mu) 2.225 1.670 1.332 0.183 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT 289.353 57.871 5.000 0.000 ## ## ## Group 2 [positive]: ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT (mu) 2.225 1.670 1.332 0.183 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT 269.244 53.849 5.000 0.000 Notice that the estimated mean is the same in both groups. We can compare these nested models because they were fit to the same data (ATT is the only variable in both cases). anova(mg.eq, mg.int) # LRT statistic ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## mg.int 0 837.01 847.43 0.000 ## mg.eq 1 852.95 860.77 17.943 17.943 0.58212 1 2.276e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.2.3.2 Define Parameters to Obtain Wald Test Another way to test the same \\(H_0\\) would be to define a new parameter that is a function of estimated parameters. In our case, we want to freely estimate the mean in each group (i.e., no equality constraint), but calculate the difference between means as a user-defined parameter. This is possible using the := operator in lavaan syntax, which requires labeling the parameter. In this case, the labels must differ so that they are not equal. Because we will have more than one line of model syntax, the example below saves the syntax as an object first, which is the recommended way of specifying a model in lavaan. mod &lt;- &#39; ATT ~ c(mu1, mu2)*1 # freely estimate 2 means mean_difference := mu2 - mu1 # calculate difference &#39; fit &lt;- sem(mod, data = dat, group = &quot;mood.f&quot;) summary(fit, header = FALSE) ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [neutral]: ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT (mu1) -4.792 2.191 -2.187 0.029 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT 240.120 48.024 5.000 0.000 ## ## ## Group 2 [positive]: ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT (mu2) 8.753 2.129 4.112 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT 226.617 45.323 5.000 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## mean_differenc 13.546 3.055 4.433 0.000 This model is equivalent to mg.int in the previous section, but the means are labeled and a mean_difference parameter is defined. lavaan uses the to estimate the SE of a function of parameters (here, difference between 2 intercepts) from the SEs of the original parameter estimates. Thus, we can obtain a Wald z statistic in the summary() output. We could also obtain an equivalent Wald \\(\\chi^2\\) statistic, which \\(=z^2\\) when testing a single parameter (i.e., 1 df). lavTestWald(fit, constraints = &#39;mu1 == mu2&#39;) ## $stat ## [1] 19.6558 ## ## $df ## [1] 1 ## ## $p.value ## [1] 9.272142e-06 ## ## $se ## [1] &quot;standard&quot; But the Wald \\(\\chi^2\\) test generalizes to the situation where multiple parameters are constrained. So it is useful for the same reason model-comparison with a LRT statistic is useful, but it does not require actually fitting the \\(H_0\\) model. 2.2.3.3 Summary of Advantages of Multigroup SEM Less restrictive assumptions parameters differ by default could be disadvantageous in small groups (asymptotic/large-N assumption applies to each group) More interpretable parameters each group has their own intercept and slopes Intuitive to specify \\(H_0\\) as user-defined parameter e.g., the difference between the intercepts in the treatment group (b2) and control group (b1) is zero Intuitive to represent assumptions about equality constraints by using the same labels across groups testable by comparing models with(out) constraints Can easily test \\(H_0\\) about parameters other than means Are variances or correlations equal across groups? 2.3 Fit an SEM to Summary Statistics All of the models above were fitted to raw data=. When the data are complete (no missing observations: NA), lavaan automatically calculates summary statistics from data=. Alternatively, summary statistics can be passed directly via the sample.cov= and sample.mean= arguments, which also requires specifying the sample size via the sample.nobs= argument. When assuming normality for complete data, results are identical across data formats: ## Raw Data sem(&#39;ATT ~ MOOD + NFC + POS&#39;, data = dat, meanstructure = TRUE) # explicitly request intercept ## Summary Data sem(&#39;ATT ~ MOOD + NFC + POS&#39;, sample.nobs = N, sample.cov = S, sample.mean = M) When omitting the mean structure (meanstructure=FALSE), also omit the sample.mean= argument. When fitting a multigroup SEM, you must pass a list of (means and) covariance matrices and a vector of sample sizes gN # vector of sample sizes gM # mean vectors gS # list of covariance matrices sem(&#39;ATT ~ NFC + POS&#39;, sample.nobs = gN, # &quot;group=&quot; is implied by lists sample.mean = gM, sample.cov = gS) 2.3.1 Advantages of Analyzing Summary Statistics Maintain privacy: They do not compromise the privacy of the research participants. Promote open-science practices: Summary statistics are easily reported in published empirical research without risking privacy, facilitating replication of results. This enables us to use many published results for instruction in this book. Facilitate replication: Research consumers can fit different models (e.g., that represent a competing theories) to the same summary statistics. However, it is unrealistic to assume data are perfectly normally distributed, and data are frequently incomplete in practice. Raw data= are required to: analyze incomplete data (using full information MLE rather than listwise deletion) obtain robust statistics (e.g., to account for nonnormality of continuous outcomes) model discrete (binary or ordinal) outcomes (which require a threshold model, explained later in a chapter about categorical data) 2.4 Moderation in SEM When evaluating moderation using a product term, that product term becomes a new variable in \\(\\bar{y}\\) and \\(S\\). Thus, adding an interaction to an SEM typically requires raw data (see Boker et al., 2023, for an exception). Consider an example analogous to ANCOVA: We want to test MOOD’s effect on POSitive thoughts, controlling for NFC. Before comparing adjusted group means, we should evaluate the homogeneity-of-slopes assumption. As in formula objects, lavaan syntax recognizes the colon (:) operator; however, there are caveats: It only applies to a product between 2 numeric variables (which may be dummy codes, but not factor variables), so no 3-way interactions. It is not possible to specify how the product term covaries with other variables, so it is actually safer to manually calculate the product term as a new variable in your data= so that you can specify parameters flexibly in syntax. The asterisk (*) is reserved for assigning labels or values to parameters, so we cannot use a formula object’s shortcut to automatically include the interaction and main effects (i.e., POS ~ mood.f * NFC). Instead, we must specify each term explicitly in the lavaan model syntax. fit.het &lt;- sem(&#39;POS ~ 1 + pos.mood + NFC + pos.mood:NFC&#39;, data = dat) Recall from the simple-regression example above that we could not test the \\(H_0\\) that positive MOOD’s slope = 0 by dropping that dummy code from the SEM. If we did, we would not be fitting both SEMs to the same summary statistics. The same principle applies here to the product-term, which must stay in the nested SEM. The \\(H_0\\) can be represented in the nested model by fixing the parameter to zero. fit.hom &lt;- sem(&#39;POS ~ 1 + pos.mood + NFC + 0*pos.mood:NFC&#39;, data = dat) anova(fit.hom, fit.het) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit.het 0 678.01 691.04 0.0000 ## fit.hom 1 682.08 692.50 6.0629 6.0629 0.22501 1 0.0138 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can reject \\(H_0\\) of homogeneous NFC slopes across MOOD groups 2.4.1 Moderation by Groups Using MG-SEM Earlier examples used MG-SEM to estimate means in each group, then test equivalence with model-comparison (LRT) or a Wald test. That was a test of the effect of the grouping variable (MOOD) on the outcome (POS). When a MG-SEM freely estimates slopes (the effect of one variable on another), that represents moderation by the grouping variable. The \\(H_0\\) of no moderation would be represented by equality constraints (e.g., same label) on NFC’s slope across groups. Even when the focal predictor is the grouping variable, we can capitalize on the “moderation by group” principle in MG-SEM to test the homogeneity-of-slopes assumption. The syntax below uses model comparison (LRT) to test the assumption. ## Heterogeneous slopes mg.het &lt;- sem(&#39; POS ~ 1 + NFC &#39;, data = dat, group = &quot;mood.f&quot;) ## Homogenous slopes mod.hom &lt;- &#39; POS ~ c(b1, b2)*1 # different intercepts POS ~ c(b3, b3)*NFC # same covariate slopes &#39; mg.hom &lt;- sem(mod.hom, data = dat, group = &quot;mood.f&quot;) ## Compare nested models anova(mg.hom, mg.het) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## mg.het 0 680.01 695.64 0.0000 ## mg.hom 1 684.05 697.07 6.0369 6.0369 0.31739 1 0.01401 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Again, because MG-SEM does not assume residual homoskedasticity, this test may be more robust, as long as there is no small-sample bias to cancel out that advantage. In this case, the residual variances are nearly identical, so we can expect tests of group-mean differences to be quite similar between single- and multigroup SEM approaches. ## ## ## Group 1 []: ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## POS 46.134 9.227 5.000 0.000 ## ## ## Group 2 []: ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## POS 47.128 9.426 5.000 0.000 2.4.2 The emmeans Package The emmeans package greatly simplifies conducting complex pairwise comparisons on lm() output (also glm() or lmer(), etc.), both controlling for covariates and stratifying across moderators to probe interactions, with many options to adjust for multiple testing. Rather than defining new parameters in model syntax, the same tools in emmeans are made available for lavaan results by the semTools package. install.packages(c(&quot;emmeans&quot;,&quot;semTools&quot;)) library(emmeans) # load first, so semTools knows what to do with it library(semTools) The functionality is available for single-group SEMs that are specified the same way as regressions in lm(). em1 &lt;- emmeans(fit.het, specs = ~ pos.mood | NFC, # focal predictor | moderator lavaan.DV = &quot;POS&quot;, # name of outcome ## probe at the M +/- 1 SD of the moderator at = list(NFC = c(-1.4, 0, 1.4))) probe1 &lt;- pairs(em1, rev = TRUE) # so group &quot;1&quot; minus group &quot;0&quot; rbind(probe1, adjust = &quot;sidak&quot;) # Sidak-adjusted p values ## NFC contrast estimate SE df z.ratio p.value ## -1.4 pos.mood1 - pos.mood0 5.15 1.96 Inf 2.635 0.0250 ## 0 pos.mood1 - pos.mood0 8.67 1.37 Inf 6.348 &lt;.0001 ## 1.4 pos.mood1 - pos.mood0 12.19 1.97 Inf 6.198 &lt;.0001 ## ## P value adjustment: sidak method for 3 tests The functionality is also available for multigroup SEMs, in which case the grouping variable is automatically treated as another predictor that can be specified in the specs= argument. Note that the grouping variable will be the name we passed to the group= argument when we fitted the MG-SEM (i.e., the factor variable mood.f rather than the dummy-coded integer variable pos.mood). When using emmeans() on a multigroup lavaan object, the argument nesting=NULL must be specified. em2 &lt;- emmeans(mg.het, specs = ~ mood.f | NFC, # focal predictor | moderator lavaan.DV = &quot;POS&quot;, # name of outcome nesting = NULL, # necessary for MG-SEMs ## probe at the M +/- 1 SD of the moderator at = list(NFC = c(-1.4, 0, 1.4))) probe2 &lt;- pairs(em2, rev = TRUE) # so group &quot;1&quot; minus group &quot;0&quot; rbind(probe2, adjust = &quot;sidak&quot;) # Sidak-adjusted p values ## NFC contrast estimate SE df z.ratio p.value ## -1.4 positive - neutral 5.15 1.96 Inf 2.633 0.0251 ## 0 positive - neutral 8.67 1.37 Inf 6.348 &lt;.0001 ## 1.4 positive - neutral 12.19 1.97 Inf 6.193 &lt;.0001 ## ## P value adjustment: sidak method for 3 tests As expected, the test statistics are quite similar between single- and multigroup SEM approaches, differing only in the 3rd or 4th decimal place. 2.5 Summary This chapter compared GLM and SEM approaches to testing a mean-difference between 2 groups, comparing output to reveal how statistics can differ between GLM and SEM. Both single- and multigroup SEM approaches were used, the latter providing the advantage of robustness to heteroskedasticity across groups. Adding a covariance facilitated demonstrating how to include an interaction term in a SEM, and why it is necessary to fix a variable’s parameter to 0 rather than drop it from the model when testing that \\(H_0\\). Models were fitted to both raw data= and summary statistics, which can provide some data-sharing advantages but is equivalent under restrictive conditions. The review and comparison both serve as a foundation for upcoming chapters that show how path analysis generalizes normal regression models. References Rosseel, Y. (2012). lavaan: An R package for structural equation modeling. Journal of Statistical Software, 48(2), 1–36. http://dx.doi.org/10.18637/jss.v048.i02 "],["ch3.html", "3 Path Models 3.1 Illustrative example 3.2 Conceptual explanation 3.3 Matrix explanation 3.4 Path analysis using lavaan References Appendix", " 3 Path Models Path analysis is one of the families of statistical analyses within the structural equation modeling (SEM) framework. Path analysis is used to describe the dependencies between a set of observed variables, where a structural model defines the directional relations between the variables. Path analysis builds on regression analysis principles, but can be used for more complex models that include multiple dependent variables or (multiple) mediator variables. We will first introduce the illustrative example that is used throughout this and subsequent chapters on path models. Then, we will explain the path model both conceptually and technically. Finally, we will illustrate how to fit a path model with an empirical data example using the lavaan program. 3.1 Illustrative example To illustrate path analysis we will use data from a study by Affrunti and Woodruff-Borden (2014) who investigated the development of child anxiety. They hypothesized that perfectionistic parents will engage in behaviors characterized by overcontrol, which then will increase child anxiety. In addition, parent anxiety was thought to influence child anxiety. In order to test their hypothesized model the variables parent perfectionism, parental overcontrol, parent anxiety and child anxiety were measured in 77 families (see Affrunti &amp; Woodruff-Borden, 2014 for more information on data collection and operationalization of the variables). In this chapter we will use a slightly adapted version of the model on the development of child anxiety. 3.2 Conceptual explanation Figure 3.1 is a graphical display of the path diagram of the structural model for the development of child anxiety that serves our illustrative purposes. A path diagram is a graphical representation of the path model in which the directional relationships between observed variables are defined. The four squares represent the observed variables parental anxiety (PA), parental perfectionism (PP), parental overcontrol (PO) and child anxiety (CA). The effects between the observed variables are represented by one sided arrows (→). In our example, the model consists of direct effects from parent anxiety and parent perfectionism on parental overcontrol, and a direct effect of parental overcontrol on child anxiety. Parent anxiety and parent perfectionism are so-called “exogenous” variables. The states or values of exogenous variables are not influenced by other variables in the model. They are sometimes also referred to as independent variables or predictor variables. Parental overcontrol and child anxiety are so-called “endogenous” variables, as they are assumed to be influenced by the states of the other variables in the model. An endogenous variable is sometimes referred to as a dependent variable. However, an endogenous variable can also have an effect on another endogenous variable in the model. In our example, parental overcontrol is influenced by parent anxiety and parent perfectionism (i.e., parental overcontrol is an endogenous variable). Parental overcontrol, in turn, also has a direct effect on child anxiety. This path model therefore represents a mediation model, where the effects of parent anxiety and parent perfectionism on child anxiety are fully mediated through parental overcontrol. Figure 3.1: A simple path diagram of the development of child anxiety. Figure 3.1 not only gives a graphical representation of the set of directional relations between the observed variables, but also includes the circles \\({\\zeta}_{PA}\\), \\({\\zeta}_{PF}\\), \\({\\zeta}_{PO}\\), and \\({\\zeta}_{CA}\\) that represent the so-called residual factors. Residual factors are unobserved, latent variables that represent all factors that fall outside the model but may influence the states of the corresponding observed variables. The directional effects from the residual factors to the corresponding observed variables are accompanied by the numeral ‘1’. This indicates that these effects are fixed to ‘1’, which is a so-called scaling constant (which will be explained in more detail in Chapter 12). Because these scaling constants for residual factors apply to almost all models, they are often not displayed in path diagrams. For endogenous variables, the residual factor can be viewed as a kind of ‘container’ variable, that contains all variables that also affect the specific endogenous variable, but that were not included in the model. The residual factors therefore symbolize the probabilistic causality of path analysis, as they indicate that endogenous variables are not only influenced by other variables in the model but also by (unobserved) variables that are outside the model (i.e., unmeasured causes). For example, in the model for the development of child anxiety, it would be unrealistic to assume that the anxiety of a child is only determined by parents’ behavior of overcontrol. It might be that there are also other factors, e.g. past experiences, contact with peers, or genetic predisposition, that have an effect on the anxiety of a child. To enable a model where child anxiety is only partially influenced by parental overcontrol, the unmeasured causes of child anxiety are incorporated in the model through the residual factor. The residual factors of endogenous variables are therefore sometimes also referred to as disturbance factors. The residual factors of exogenous variables can also be viewed as a container variable that contains all (unobserved) variables that are outside the model (i.e., unmeasured causes) that influence the corresponding exogenous variable. However, because exogenous variables are not influenced by other variables in the model, the residual factor of an exogenous variable represents the corresponding variable. In addition, the residual factors of different exogenous variables covary. For example, in the path diagram of Figure 3.1 there is a covariance between the two residual factors of parent anxiety and parent perfectionism, as reflected by the double headed arrow (&lt;–&gt;). This reflects the assumption that the unmeasured causes of the corresponding exogenous variables may covary, although the model does not provide an explanation for this association (i.e., they are outside the model). For example, parental neuroticism may be a common cause of parental anxiety and parental perfectionism, leading to a covariance between the two variables. Because the common causes are not modelled, and we may not even know all possible sources of shared variance between exogenous variables, it is very unrealistic to assume that the exogenous variables would not be correlated. For both exogenous and endogenous variables, the residual factor also reflects measurement error. The variance of a residual factor therefore partly consists of variance of the corresponding variable due to random error fluctuations. Thus, one cannot distinguish residual variance due to measurement error (i.e., unsystematic variance) and residual variance due to unmeasured causes (i.e., systematic variance). When the measure of the observed variable is unreliable this will inflate the variance of the corresponding residual factor and can be confounded with variance due to unmeasured causes of the variable. 3.3 Matrix explanation In general, the aim of path analysis is to describe the dependencies between a set of observed variables, based on some theory. In order to do this, we try to define a theoretically sensible path model that can accurately describe the variances and covariances of the observed variables in the population and formulate the following hypothesis: \\(\\mathbf{\\Sigma}_{\\text{population}} = \\mathbf{\\Sigma}_{\\text{model}}\\), where \\(\\mathbf{\\Sigma}_{\\text{population}}\\) is the matrix of population variances and covariances of the observed variables, and \\(\\mathbf{\\Sigma}_{\\text{model}}\\) is the matrix of variances and covariances of the observed variables as implied by the path model. The population variances and covariances are unknown, as data are usually only collected in a sample that was drawn from the population. Therefore, we estimate the population variances and covariances based on the sample variances and covariances: \\(\\mathbf{\\Sigma}_{\\text{population}} \\approx \\mathbf{\\hat\\Sigma}_{\\text{population}}\\) , where \\(\\mathbf{\\hat\\Sigma}_{\\text{population}} = \\mathbf{\\Sigma}_{\\text{sample}}\\). As a covariance matrix is a symmetric matrix, usually the upper triangle of the matrix is not provided: \\[ \\mathbf{\\Sigma}_{\\text{population}} = \\begin{bmatrix} \\sigma_{11} &amp; &amp; \\\\ \\sigma_{21} &amp; \\sigma_{22} &amp; \\\\ \\sigma_{31} &amp; \\sigma_{32} &amp; \\sigma_{33} \\\\ \\sigma_{41} &amp; \\sigma_{42} &amp; \\sigma_{43} &amp; \\sigma_{44} \\end{bmatrix} \\approx \\begin{bmatrix} \\hat\\sigma_{11} &amp; &amp; \\\\ \\hat\\sigma_{21} &amp; \\hat\\sigma_{22} &amp; \\\\ \\hat\\sigma_{31} &amp; \\hat\\sigma_{32} &amp; \\hat\\sigma_{33} \\\\ \\hat\\sigma_{41} &amp; \\hat\\sigma_{42} &amp; \\hat\\sigma_{43} &amp; \\hat\\sigma_{44} \\end{bmatrix}. \\] The variances of the variables are given on the diagonal of the matrix (\\(\\sigma_{11}\\) to \\(\\sigma_{44}\\)) and the covariances are given on the lower triangle of the matrix (e.g., \\(\\sigma_{21}\\) represents the covariance between variable \\(\\mathrm{y}_2\\) and variable \\(\\mathrm{y}_1\\)). The values of the upper triangular are equal to the lower triangular (e.g., \\(\\sigma_{21}\\) is equal to \\(\\sigma_{12}\\)). The population variances and covariances are estimated using the sample variances and covariances, where: \\[ \\mathbf{\\Sigma}_{\\text{sample}} = \\begin{bmatrix} s_{11} &amp; &amp; \\\\ s_{21} &amp; s_{22} &amp; \\\\ s_{31} &amp; s_{32} &amp; s_{33} \\\\ s_{41} &amp; s_{42} &amp; s_{43} &amp; s_{44} \\end{bmatrix}. \\] Here, the elements of \\(\\mathbf{\\Sigma}_{\\text{sample}}\\) are denoted with ‘s’. As an example, the observed sample variance of the first variable, \\(s_{11}\\), serves as an estimate of the population variance of the first variable, \\(\\hat\\sigma_{11}\\). The sample covariance matrix of our illustrative example of child anxiety is given by: \\[ \\mathbf{\\Sigma}_{\\text{sample}} = \\begin{bmatrix} 91.58 &amp; &amp; \\\\ 53.36 &amp; 194.32 &amp; \\\\ 28.39 &amp; 50.90 &amp; 130.19 \\\\ 9.21 &amp; 4.98 &amp; 9.41 &amp; 7.56 \\end{bmatrix}. \\] Thus, the variance of the variable parent anxiety is 91.58, and the covariance between the variables parent anxiety and parent perfectionism is 53.36. Similarly, we do not know the ‘true’ variances and covariances of the observed variables in the population as implied by the ‘true’ model parameters in the path model. Instead, we derive an estimated variance-covariance matrix as implied by the model: \\(\\mathbf{\\Sigma}_{\\text{model}} \\approx \\mathbf{\\hat\\Sigma}_{\\text{model}}\\), where \\(\\mathbf{\\hat\\Sigma}_{\\text{model}}\\) is a function of sample estimates of the unknown model parameters. Thus, to enable calculation of \\(\\mathbf{\\hat\\Sigma}_{\\text{model}}\\) we first need to derive estimates of all model parameters that feature in the path model. Below, we will describe the relationships between the observed variables in terms of model parameters, and explain how they can be used to find expressions for the variances and covariances. Figure 3.2 shows the Greek symbols that represent the variables and parameters that feature in the path model. The observed variables parental anxiety, parental perfectionism, parental overcontrol and child anxiety are represented by the squares \\(\\mathrm{y}_1\\), \\(\\mathrm{y}_2\\), \\(\\mathrm{y}_3\\), and \\(\\mathrm{y}_4\\) respectively. The direct effects between the observed variables are denoted \\(\\beta_{31}\\), \\(\\beta_{32}\\), and \\(\\beta_{43}\\). These direct effects are also called path coefficients and can be interpreted as regression coefficients. In general, \\(\\beta_{ij}\\) is the regression of variable \\(\\mathrm{y}_{i}\\) on \\(\\mathrm{y}_{j}\\), or, equivalently, the effect of \\(\\mathrm{y}_{j}\\) on \\(\\mathrm{y}_{i}\\). In addition, the circles are residual factors \\(\\zeta_{1}\\), \\(\\zeta_{2}\\), \\(\\zeta_{3}\\), and \\(\\zeta_{4}\\) that represent all factors that fall outside the model, i.e., unmeasured causes. Figure 3.2: Path diagram of the development of child anxiety including all path coefficients. Using the symbols described above, the relations between the variables can be represented by the following equations: \\[\\begin{equation} \\mathrm{y}_1 = \\zeta_1 \\tag{3.1} \\end{equation}\\] \\[\\begin{equation} \\mathrm{y}_2 = \\zeta_2 \\tag{3.2} \\end{equation}\\] \\[\\begin{equation} \\mathrm{y}_3=\\beta_{31}\\mathrm{y}_1+\\beta_{32}\\mathrm{y}_2 + \\zeta_3 \\tag{3.3} \\end{equation}\\] \\[\\begin{equation} \\mathrm{y}_4 = \\beta_{43} \\mathrm{y}_3 + \\zeta_4 \\tag{3.4} \\end{equation}\\] Here, we can see that exogenous variables \\(\\mathrm{y}_1\\) and \\(\\mathrm{y}_2\\) are only affected by factors that fall outside the model (\\(\\zeta_1\\) and \\(\\zeta_2\\)), whereas endogenous variable \\(\\mathrm{y}_3\\) and \\(\\mathrm{y}_4\\) are affected also by the other variables in the model. Note that the effects of the residual factors are left out of these Equations because they are constrained to ‘1’ (i.e., we could write \\(\\mathrm{y}_1 = (\\text{direct effect})\\zeta_1\\), where (direct effect) = 1, which thus simplifies to \\(\\mathrm{y}_1\\) = \\(\\zeta_1\\)). Instead of writing down the equation for each observed variable, the equations for the observed variables \\(\\mathrm{y}_1\\), \\(\\mathrm{y}_2\\), \\(\\mathrm{y}_3\\), and \\(\\mathrm{y}_4\\) can also be written in matrix form: \\[\\begin{equation} \\mathbf{y} = \\mathbf{B} \\mathbf{y} + \\boldsymbol{\\zeta} \\tag{3.5} \\end{equation}\\] where \\(\\mathbf{y}\\) is a vector of all observed variables, \\(\\boldsymbol{\\zeta}\\) is a vector of all residual factors, and \\(\\mathbf{B}\\) is a matrix of regression coefficients: \\[ \\mathbf{y} = \\begin{bmatrix} \\mathrm{y}_1 \\\\ \\mathrm{y}_2 \\\\ \\mathrm{y}_3 \\\\ \\mathrm{y}_4 \\end{bmatrix} , \\boldsymbol{\\zeta} = \\begin{bmatrix} \\zeta_1 \\\\ \\zeta_2 \\\\ \\zeta_3 \\\\ \\zeta_4 \\end{bmatrix}, \\mathrm{and} \\hspace{1mm} \\mathbf{B} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\beta_{31} &amp; \\beta_{32} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\beta_{43} &amp; 0 \\end{bmatrix}. \\] Matrix \\(\\mathbf{B}\\) contains three non-zero elements: \\(\\beta_{31}\\), \\(\\beta_{32}\\), \\(\\beta_{43}\\). The regression coefficient \\(\\beta_{31}\\) represent the effect ofvariable \\(\\mathrm{y}_1\\) on variable \\(\\mathrm{y}_3\\), the regression coefficient \\(\\beta_{32}\\) represent the effect of variable \\(\\mathrm{y}_2\\) on variable \\(\\mathrm{y}_3\\), and the regression coefficient \\(\\beta_{43}\\) represent the effect of variable \\(\\mathrm{y}_3\\) on variable \\(\\mathrm{y}_4\\). Substituting these matrices into Equation (3.5) gives: \\[\\begin{equation} \\begin{bmatrix} \\mathrm{y}_1 \\\\ \\mathrm{y}_2 \\\\ \\mathrm{y}_3 \\\\ \\mathrm{y}_4 \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\beta_{31} &amp; \\beta_{32} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\beta_{43} &amp; 0 \\end{bmatrix} \\times \\begin{bmatrix} \\mathrm{y}_1 \\\\ \\mathrm{y}_2 \\\\ \\mathrm{y}_3 \\\\ \\mathrm{y}_4 \\end{bmatrix} + \\begin{bmatrix} \\zeta_1 \\\\ \\zeta_2 \\\\ \\zeta_3 \\\\ \\zeta_4 \\end{bmatrix}, \\tag{3.6} \\end{equation}\\] which yields: \\[\\begin{equation} \\begin{bmatrix} \\mathrm{y}_1 \\\\ \\mathrm{y}_2 \\\\ \\mathrm{y}_3 \\\\ \\mathrm{y}_4 \\end{bmatrix} = \\begin{bmatrix} &amp; &amp; \\zeta_1 &amp; &amp; \\\\ &amp; &amp; \\zeta_2 &amp; &amp; \\\\ \\beta_{31} \\mathrm{y}_1 &amp; + &amp; \\beta_{32} \\mathrm{y}_2 &amp; + &amp; \\zeta_3 \\\\ &amp; &amp; \\beta_{43} \\mathrm{y}_3 + \\zeta_4 &amp; \\end{bmatrix}. \\tag{3.7} \\end{equation}\\] Here, we can see that the equations for variables \\(\\mathrm{y}_1\\), \\(\\mathrm{y}_2\\), \\(\\mathrm{y}_3\\), and \\(\\mathrm{y}_4\\) are the same as separate Equations (3.1) through (3.4). The path model as described by Equation (3.7) is used to describe the relationships between the observed variables. In order to find the model for the variances and covariances of the observed variables, we have to re-write Equation (3.5) as a function of model parameters: \\[\\mathrm{y} = \\mathbf{B} \\mathrm{y} + \\zeta \\Leftrightarrow\\] \\[\\begin{equation} \\mathrm{y} = (\\mathbf{I} - \\mathbf{B})^{-1} \\zeta \\tag{3.8} \\end{equation}\\] where \\(\\mathbf{I}\\) is an identity matrix that needs to be introduced to come to the end result, and \\((\\mathbf{I} - \\mathbf{B})^{-1}\\) denotes the inverse of the matrix \\((\\mathbf{I} - \\mathbf{B})\\). Derivations of Equation (3.8) are given in this chapters Appendix. We now have an expression for the scores on the variables. However, in standard SEM, we do not model the observed scores directly, but the variances and covariance of the observed scores. Therefore, we need to find an expression for the model implied covariance matrix. Using (3.8) and some covariance algebra, we obtain the expression for the variances and covariances of \\(\\mathrm{y}\\), called \\(\\mathbf{\\Sigma}_{\\text{model}}\\) = COV\\((\\mathbf{y},\\mathbf{y})\\): \\[\\begin{equation} \\mathbf{\\Sigma}_{\\text{model}} = (\\mathbf{I} - \\mathbf{B})^{-1} \\boldsymbol{\\Psi} (\\mathbf{I} - \\mathbf{B})^{-1\\mathrm{T}} \\tag{3.9} \\end{equation}\\] where \\(\\boldsymbol{\\Psi}\\) is written for COV(\\(\\boldsymbol\\zeta\\),\\(\\boldsymbol\\zeta\\)), and \\((\\mathbf{I} - \\mathbf{B})^{-1\\mathrm{T}}\\) denotes the transpose of the matrix \\((\\mathbf{I} - \\mathbf{B})^{-1}\\). Derivations of Equation (3.9) are given this chapters Appendix. The symmetric matrix \\(\\boldsymbol{\\Psi}\\) contains the variances and the covariances of the residual factors \\(\\boldsymbol\\zeta\\). For the model given in Equation (3.7), matrix \\(\\boldsymbol{\\Psi}\\) is \\[ \\boldsymbol{\\Psi} = \\begin{bmatrix} \\psi_{11} &amp; \\psi_{12} &amp; 0 &amp; 0 \\\\ \\psi_{21} &amp; \\psi_{22} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\psi_{33} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\psi_{44} \\end{bmatrix} \\] where \\(\\psi_{11}\\) and \\(\\psi_{22}\\) represent the variances of \\(\\zeta_1\\) and \\(\\zeta_2\\) and are thus equivalent with the variances of the exogenous variables \\(\\mathrm{y}_1\\) and \\(\\mathrm{y}_2\\). The covariance of \\(\\zeta_{1}\\) and \\(\\zeta_{2}\\) is represented by \\(\\psi_{12}\\) and is thus equivalent with the covariance of \\(\\mathrm{y}_1\\) and \\(\\mathrm{y}_2\\). Because a covariance matrix is a symmetric matrix, \\(\\psi_{12}\\) is equal to \\(\\psi_{21}\\). Parameters \\(\\psi_{33}\\) and \\(\\psi_{44}\\) are the variances of \\(\\zeta_3\\) and \\(\\zeta_4\\), equivalent with the residual variances (or disturbance variances) of \\(\\mathrm{y}_3\\) and \\(\\mathrm{y}_4\\), that is, that part of the variances of \\(\\mathrm{y}_3\\) and \\(\\mathrm{y}_4\\) that are not explained by the model.Note that the \\(\\zeta\\) variances associated with endogenous variables \\(\\mathrm{y}_3\\) and \\(\\mathrm{y}_4\\) have the same interpretation as the \\(\\zeta\\) variances associated with exogenous variables \\(\\mathrm{y}_1\\) and \\(\\mathrm{y}_2\\), but whereas all variance of \\(\\mathrm{y}_1\\) and \\(\\mathrm{y}_2\\) is unexplained by the model (and thus \\(\\psi_{11}\\) and \\(\\psi_{22}\\) are equivalent with the variances of \\(\\mathrm{y}_1\\) and \\(\\mathrm{y}_2\\)), only part of the variances of \\(\\mathrm{y}_3\\) and \\(\\mathrm{y}_4\\) is unexplained by the model. Now that we have found the general expression for the variances and covariances as a function of model parameters, we can evaluate Equation (3.9) of our example. Substituting \\(\\mathbf{B}\\) and \\(\\boldsymbol{\\Psi}\\) of our example we obtain: \\(\\mathbf{\\Sigma}_{\\text{model}} = (\\mathbf{I} - \\mathbf{B})^{-1} \\boldsymbol{\\Psi} (\\mathbf{I} - \\mathbf{B})^{-1\\mathrm{T}}\\), where: \\[ (\\mathbf{I} - \\mathbf{B})^{-1} = \\Bigg( \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} - \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\beta_{31} &amp; \\beta_{32} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\beta_{43} &amp; 0 \\end{bmatrix} \\Bigg) ^{-1} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ \\beta_{31} &amp; \\beta_{32} &amp; 1 &amp; 0 \\\\ \\beta_{31}\\beta_{43} &amp; \\beta_{32}\\beta_{43} &amp; \\beta_{43} &amp; 1 \\end{bmatrix}, \\] \\[ \\boldsymbol{\\Psi} = \\begin{bmatrix} \\psi_{11} &amp; \\psi_{21} &amp; 0 &amp; 0 \\\\ \\psi_{21} &amp; \\psi_{22} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\psi_{33} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\psi_{44} \\end{bmatrix}, \\mathrm{and} \\] \\[ (\\mathbf{I} - \\mathbf{B})^{-1\\mathrm{T}} = \\Bigg( \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} - \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\beta_{31} &amp; \\beta_{32} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\beta_{43} &amp; 0 \\end{bmatrix} \\Bigg)^{-1\\mathrm{T}} = \\begin{bmatrix} 1 &amp; 0 &amp; \\beta_{31} &amp; \\beta_{31}\\beta_{43} \\\\ 0 &amp; 1 &amp; \\beta_{32} &amp; \\beta_{32}\\beta_{43} \\\\ 0 &amp; 0 &amp; 1 &amp; \\beta_{43} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}. \\] Which yields: \\[\\begin{equation} \\Sigma_{\\text{model}} = \\begin{bmatrix} \\\\ \\psi_{11} &amp; &amp; &amp; \\\\ \\\\ \\psi_{21} &amp; \\psi_{22} &amp; &amp; \\\\ \\\\ \\beta_{31} \\psi_{11} + &amp; \\beta_{31} \\psi_{21} + &amp; (\\beta_{31}\\psi_{11}+\\beta_{32}\\psi_{31}) \\beta_{31} + &amp; \\\\ \\beta_{32} \\psi_{21}&amp;\\beta_{32} \\psi_{22}&amp;(\\beta_{31}\\psi_{21}+\\beta_{32}\\psi_{22}) \\beta_{32}\\psi_{33}&amp; \\\\ \\\\ \\beta_{31}\\beta_{43}\\psi_{11} + &amp; \\beta_{31}\\beta_{43}\\psi_{21} + &amp; (\\beta_{31}\\beta_{43}\\psi_{11} + \\beta_{32}\\beta_{43}\\psi_{21}) \\beta_{31} + &amp; (\\beta_{31}\\beta_{43}\\psi_{11} + \\beta_{32}\\beta_{43}\\psi_{21})\\beta_{31}\\beta_{43} + \\\\ \\beta_{32}\\beta_{43}\\psi_{21} &amp; \\beta_{32}\\beta_{43}\\psi_{22} &amp; (\\beta_{31}\\beta_{43}\\psi_{21} + \\beta_{32}\\beta_{43}\\psi_{22}) \\beta_{32} + &amp; (\\beta_{31}\\beta_{43}\\psi_{21} + \\beta_{32}\\beta_{43} \\psi_{22})\\beta_{32}\\beta_{43} + \\\\ &amp;&amp;\\beta_{43}\\psi_{33} &amp; {\\beta_{32}}^2 \\psi_{33} + \\psi_{44} \\\\ &amp;&amp;&amp;\\\\ \\end{bmatrix} \\tag{3.10} \\end{equation}\\] Now that we have found the expression of \\(\\mathbf{\\Sigma}_{\\text{model}}\\) as a function of model parameters, this enables the estimation of the model parameters, by choosing the values for each model parameter in such a way, that the resulting model implied variances and covariances of \\(\\mathbf{\\hat\\Sigma}_{\\text{model}}\\) are as close as possible to the sample variances and covariances, \\(\\mathbf{\\hat\\Sigma}_{\\text{population}}\\). A discrepancy function can be used to obtain parameter estimates, where an iterative procedure yields model parameters that keep the discrepancy between \\(\\mathbf{\\hat\\Sigma}_{\\text{population}}\\) and \\(\\mathbf{\\hat\\Sigma}_{\\text{model}}\\) to a minimum. In general, smaller values of discrepancy functions indicate better fit of the model to the data, and a value of zero indicates the fit is perfect, i.e., if the parameter estimates can perfectly reproduce the sample covariance matrix. Several discrepancy functions exist, but maximum likelihood estimation is most commonly applied. The resulting discrepancy value can be used for the assessment of overall goodness-of-fit using the so-called chi-square test of exact fit, where a significant chi-square value indicates a significant deviation between model and data (i.e., implying that \\(\\mathbf{\\hat\\Sigma}_{\\text{population}} \\ne \\mathbf{\\Sigma}_{\\text{model}}\\)). See also Chapters 10 and 11, where the topics of Estimation and Evaluation of Model Fit are explained in more detail. In our illustrative example of child anxiety, maximum likelihood estimation leads to the following model parameter estimates: \\[ \\hat{\\mathbf{B}} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\hat\\beta_{31} &amp; \\hat\\beta_{32} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\hat\\beta_{43} &amp; 0 \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0.19 &amp; 0.21 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0.07 &amp; 0 \\end{bmatrix}, \\] and \\[ \\hat{\\boldsymbol{\\Psi}} = \\begin{bmatrix} \\hat\\psi_{11} &amp; \\hat\\psi_{21} &amp; 0 &amp; 0 \\\\ \\hat\\psi_{21} &amp; \\hat\\psi_{22} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\hat\\psi_{33} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\hat\\psi_{44} \\end{bmatrix} = \\begin{bmatrix} 92.58 &amp; 53.36 &amp; 0 &amp; 0 \\\\ 53.36 &amp; 194.32 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 114.16 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 6.88 \\end{bmatrix}. \\] Matrix \\(\\hat{\\mathbf{B}}\\) contains the estimated regression coefficients \\(\\hat\\beta_{31}\\), \\(\\hat\\beta_{32}\\) and \\(\\hat\\beta_{43}\\). The estimated regression of parental overcontrol on parent anxiety (\\(\\hat\\beta_{31}\\)) is 0.19. As the parameter estimate is unstandardized, this indicates that with 1 point increase in parent anxiety there will be 0.19 point increase in parental overcontrol, holding parental perfectionism constant. The estimated effect of parent perfectionism on parental overcontrol (\\(\\hat\\beta_{32}\\)) is 0.21, indicating that controlled for parental anxiety, 1 point increase in parent perfectionism will lead to 0.21 point increase in parental overcontrol. Lastly, the estimated effect of parental overcontrol on child anxiety is 0.07, where 1 point increase in parental overcontrol will result in a 0.07 increase in child anxiety. All estimated effects between the variables are positive, and they support the hypothesis that parent anxiety and perfectionism increase parental overcontrol, which then increases child anxiety. However, the unstandardized parameter estimates do not give a direct interpretation of the size of the effects, and additional information is needed to judge the significance of the effects (see also Chapters 5 and 6). Matrix \\(\\hat{\\boldsymbol{\\Psi}}\\) contains the estimated variances and covariance of the residual factors. Here, we can see that the variance of the residual factor of parent anxiety (\\(\\psi_{11}\\)) is 91.58 and the variance of the residual factor of parent perfectionism (\\(\\psi_{22}\\)) is 194.32. Remember that the variances of exogenous variables are not explained by any observed variables, and thus all variance in parent anxiety and parent perfectionism is represented by the variances of their corresponding residual factors. In addition, the covariance between parent anxiety and parent perfectionism is equal to the covariance between their corresponding residual factors (\\(\\psi_{21}\\)). The variance of the residual factor of overcontrol (\\(\\psi_{33}\\)) can be interpreted as the variance of overcontrol that is unexplained by the model. The same is true for the estimated variance of the residual factor of child anxiety (\\(\\psi_{44}\\)). As the estimated model parameters of the psi-matrix provide information about the amount of variance that is unexplained by the model, we can also calculate the amount of variance that is explained by the model. The variance explained by the model is a result that is often reported in ordinary regression analysis as an indication of how well the model fits the data. Therefore, just as in regression analysis, it is informative to calculate the proportion of explained variance by using the estimated residual factor variance (i.e., the unexplained variance). In our example, the unexplained variance of the observed variable child anxiety is 6.88. We can calculate the proportion of explained variance of child anxiety using the following formula: \\(R^2 = \\frac{\\text{unexplained, residual variance}}{\\text{total variance}}\\). In our example the proportion of explained variance of child anxiety is 0.09, indicating that only 9\\(\\%\\) of the variance of child anxiety is explained by the path model that was specified (see also Chapter 5 on standardized parameters). 3.4 Path analysis using lavaan 3.4.1 Installing lavaan The software that we will use to run our structural equation modeling analyses is lavaan (Rosseel, 2012), which is free open-source software that is available as a package in R. To install the lavaan package you can type the following command in the R console: install.packages(&quot;lavaan&quot;, dependencies = TRUE) This will open a window where you have to select a CRAN mirror (select \"[your country], [closest city]\") and will install the package lavaan, including all the packages that it is dependent upon. You only need to install the package once (on a specific computer), to add the package to the R library. Once the package is installed, you can activate all the functionalities that are available in the package by using the command: library(lavaan) Every time you start R you need to use this command to activate the lavaan package into the current R workspace. Therefore, it is advisable to start every script with this command. 3.4.2 Fitting a path model Script 3.1 fits the path model of Figure 3.2 to the covariance matrix that is given in Affrunti and Woodruff-Borden (2014). All commands will be explained below. Script 3.1 # names observed variables obsnames &lt;- c(&quot;parent_anx&quot;, &quot;perfect&quot;, &quot;overcontrol&quot;, &quot;child_anx&quot;) # covariance matrix as given by Affrunti and Woodruff-Borden (2014) AWcov &lt;- matrix(data = c(91.58, 53.36, 28.39, 9.21, 53.36, 194.32, 50.90, 4.98, 28.39, 50.90, 130.19, 9.41, 9.21, 4.98, 9.41, 7.56), nrow = 4, ncol = 4, dimnames = list(obsnames,obsnames)) # specify the path model AWmodel &lt;- &#39;# regression equations overcontrol ~ b31*parent_anx + b32*perfect child_anx ~ b43*overcontrol # (residual) variance parent_anx ~~ p11*parent_anx perfect ~~ p22*perfect overcontrol ~~ p33*overcontrol child_anx ~~ p44*child_anx # covariance exogenous variables parent_anx ~~ p21*perfect &#39; # build the model AWmodelOut &lt;- lavaan( model = AWmodel, sample.cov = AWcov, sample.nobs = 77, likelihood = &quot;wishart&quot;, fixed.x = FALSE) We start by defining the observed covariance matrix and the names of the associated observed variables. It is required to provide these names with the input matrix. First we created the object obsnames that contains the names of the variables. Note that the order of the variables corresponds to the labels \\(\\mathrm{y}_1\\) to \\(\\mathrm{y}_4\\) in Figure 3.2. obsnames &lt;- c(&quot;parent_anx&quot;, &quot;perfect&quot;, &quot;overcontrol&quot;, &quot;child_anx&quot;) The names are given as a list with two elements, one vector of row names and one vector of column names. As a covariance matrix is a symmetric matrix, row and column names are the same, and we can use the command list(obsnames, obsnames) to provide the labels for the observed covariance matrix. The observed covariance matrix is stored in the object AWcov, by creating a matrix with the values of the elements, number of rows, number of columns, and the name vectors of the two dimensions. AWcov = matrix(...) To check whether you successfully specified the observed covariance matrix, check the results by typing AWcov in the R console. And check, for example, whether the matrix is indeed symmetrical by typing AWcov == t(AWcov) or isSymmetric(AWcov). The next step is to specify the model that has to be fitted to the observed data. We create the object AWmodel where the model specifications are given, encapsulated by single quotes. We need to specify all free parameters that need to be estimated: regression coefficients and (residual) variances and covariances. The structural part of the model is specified using regression equations: AWmodel &lt;- &#39; # regression equations overcontrol ~ b31*parent_anx + b32*perfect child_anx ~ b43*overcontrol The tilde sign, “~”, is the regression operator. On the left hand of this operator we have the dependent variable, and on the right hand side of this operator we have the independent variables, separated by the “+” operator. The regression coefficients are named after their position in the \\(\\mathbf{B}\\) matrix. For example, the regression of overcontrol on parent anxiety is labeled with “b31”, which corresponds to the position of the estimate of the regression coefficient (\\(\\beta_{31}\\)) in the \\(\\mathbf{B}\\) matrix. As such, the names “b31”, “b32”, “b43” are chosen to represent \\(\\beta_{31}\\), \\(\\beta_{32}\\), and\\(\\beta_{43}\\). The residual terms are not explicitly included in the formulas. These formulas therefore only specify the structural part of the model. The (residual) variances are specified using double tilde’s (“\\(\\sim \\sim\\)”), where the same variable name is given both left and right of this operator. Covariances are specified similarly. The estimates of the (co)variances can be named by providing a label before the variable name that is to the right from the “\\(\\sim \\sim\\)” operator. Here, we used the names “p11” to “p44” and “p21” to refer to the position of the parameter estimates in the \\(\\boldsymbol{\\Psi}\\) matrix. # (residual) variance parent_anx ~~ p11*parent_anx perfect ~~ p22*perfect overcontrol ~~ p33*overcontrol child_anx ~~ p44*child_anx # covariance exogenous variables parent_anx ~~ p21*perfect &#39; When all separate elements of the model are created, we can fit (“run”) the model using the lavaan() function and storing the output in AWmodelOut: AWmodelOut &lt;- lavaan( model = AWmodel, sample.cov = AWcov, sample.nobs = 77, likelihood = &quot;wishart&quot;, fixed.x = FALSE) The lavaan() function takes as arguments the specified model (model = AWmodel), the specified covariance matrix (sample.cov = AWcov), and the total number of observations (sample.nobs = 77). The final two arguments are used to turn off two default settings of lavaan. That is, we use Wishart likelihood (likelihood = \"wishart\") because we are only analyzing covariance structure (when we add mean structure later in the semester, we will use “normal” likelihood). We also specify that we want to freely estimate (fixed.x = FALSE) rather than fix the (co)variances of the exogenous variables to their sample values. The output is stored in AWmodelOut, and we can inspect the result using the summary() function: summary(AWmodelOut) This will show you some fit results of the model and give you the parameter estimates and their associated standard errors. The model has 2 degrees of freedom, and the chi-square value is 7.333. The summary of the output is given below: ## lavaan 0.6-19 ended normally after 28 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 8 ## ## Number of observations 77 ## ## Model Test User Model: ## ## Test statistic 7.333 ## Degrees of freedom 2 ## P-value (Chi-square) 0.026 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## overcontrol ~ ## parnt_nx (b31) 0.187 0.140 1.341 0.180 ## perfect (b32) 0.210 0.096 2.194 0.028 ## child_anx ~ ## ovrcntrl (b43) 0.072 0.026 2.741 0.006 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## parent_anx ~~ ## perfect (p21) 53.360 16.481 3.238 0.001 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## parnt_nx (p11) 91.580 14.856 6.164 0.000 ## perfect (p22) 194.320 31.523 6.164 0.000 ## .ovrcntrl (p33) 114.157 18.519 6.164 0.000 ## .child_nx (p44) 6.880 1.116 6.164 0.000 Here we see the result for the regression coefficients \\(\\beta_{31}\\), \\(\\beta_{32}\\), and \\(\\beta_{43}\\). lavaan also provides the associated standard error of the estimate (0.140, for \\(\\beta_{31}\\)). This gives an indication of the precision of the parameter estimate and can be used to judge whether the parameter estimate differs significantly from zero (see also Chapter 5). Especially when parameters are labeled, lavaan will have to shorten some of the longer variable names (only in the printed output, not internally!), so that the output conforms to a certain format. You may also notice that some variances are preceded by a period (.). This indicates that it is a residual variance for an endogenous variable, rather than a variance for an exogenous variable. If you run models with residual correlations between endogenous variables, those residual covariances will also use the (.) prefix. You can also request to see \\(R^2\\) for each endogenous variable: summary(AWmodelOut, rsquare = TRUE) ## lavaan 0.6-19 ended normally after 28 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 8 ## ## Number of observations 77 ## ## Model Test User Model: ## ## Test statistic 7.333 ## Degrees of freedom 2 ## P-value (Chi-square) 0.026 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## overcontrol ~ ## parnt_nx (b31) 0.187 0.140 1.341 0.180 ## perfect (b32) 0.210 0.096 2.194 0.028 ## child_anx ~ ## ovrcntrl (b43) 0.072 0.026 2.741 0.006 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## parent_anx ~~ ## perfect (p21) 53.360 16.481 3.238 0.001 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## parnt_nx (p11) 91.580 14.856 6.164 0.000 ## perfect (p22) 194.320 31.523 6.164 0.000 ## .ovrcntrl (p33) 114.157 18.519 6.164 0.000 ## .child_nx (p44) 6.880 1.116 6.164 0.000 ## ## R-Square: ## Estimate ## overcontrol 0.123 ## child_anx 0.090 3.4.3 Syntax shortcuts Script 3.1 specifies every single nonzero parameter depicted in the path model of Figure 3.2. In relatively small models, and for users who are learning SEM, it may be safe to specify each parameter explicitly in the syntax. In larger models, this can become quite cumbersome, increase the chance of making an error, and make the model syntax more difficult to read (e.g., to find mistakes). Some parameters can be specified automatically in the lavaan() call. For example, setting the option auto.var = TRUE will tell lavaan to freely estimate all (residual) variances of variables included in the model syntax, and the option fixed.x = FALSE already tells lavaan to freely estimate covariances among exogenous variables. Thus, adding these options to the lavaan() call means that the model syntax requires only the specification of regression parameters, which is quite easy to read: ## shorter model specification AWmodel &lt;- &#39; # regression equations overcontrol ~ b31*parent_anx + b32*perfect child_anx ~ b43*overcontrol &#39; ## free all (residual) variances using auto.var = TRUE AWmodelOut &lt;- lavaan( model = AWmodel, auto.var = TRUE, sample.cov = AWcov, sample.nobs = 77, likelihood = &quot;wishart&quot;, fixed.x = FALSE) In fact, the auto.var = TRUE option is set by default in lavaan’s shortcut function, sem(), which sets several other default options that are typically desired in a path analysis (or structural regression among latent variables, which you will learn about later). AWmodelOut &lt;- sem( model = AWmodel, sample.cov = AWcov, sample.nobs = 77, likelihood = &quot;wishart&quot;, fixed.x = FALSE) 3.4.4 Extracting results from lavaan output in matrix form To be able to inspect the parameter estimates of a path model in matrix form (namely the \\(\\mathbf{B}\\) and \\(\\boldsymbol{\\Psi}\\) matrices), you can use the lavInspect() function, which can be used to extract many kinds of information about the fitted lavaan model (see a complete list on the help page: ?lavInspect). The lavInspect() function takes two arguments: (1) the lavaan “object” (in this case, AWmodelOut) and (2) a character string naming what specific information you want to inspect (in this case, the estimated coefficients: “coef”). SEM involves more than just the \\(\\mathbf{B}\\) and \\(\\boldsymbol{\\Psi}\\) matrices, and the output will always include them even if they are empty (e.g., full of zeros, or an identity matrix). The following code can be used to store the \\(\\mathbf{B}\\) and \\(\\boldsymbol{\\Psi}\\) matrices in the objects “BETA” and “PSI” to control what is displayed. Estimates &lt;- lavInspect(AWmodelOut, &quot;est&quot;) BETA &lt;- Estimates$beta[obsnames, obsnames] PSI &lt;- Estimates$psi[obsnames, obsnames] The resulting BETA and PSI matrices are shown below. Because lavaan ignores the order of the variables in the input covariance matrix, its matrices correspond to variables in the order that they appeared in the model syntax. The order is arbitrary, but to make them easier to read (e.g., to compare this output to the matrices described in the previous sections of this chapter), the above syntax used the square-bracket operators to specify that the order of [rows, columns] should be the same order as our input matrix. ## [1] &quot;BETA&quot; ## parent_anx perfect overcontrol child_anx ## parent_anx 0.0000000 0.000000 0.00000000 0 ## perfect 0.0000000 0.000000 0.00000000 0 ## overcontrol 0.1873575 0.210491 0.00000000 0 ## child_anx 0.0000000 0.000000 0.07227898 0 ## [1] &quot;PSI&quot; ## parent_anx perfect overcontrol child_anx ## parent_anx 91.58 53.36 0.0000 0.000000 ## perfect 53.36 194.32 0.0000 0.000000 ## overcontrol 0.00 0.00 114.1569 0.000000 ## child_anx 0.00 0.00 0.0000 6.879855 Here, we can see that the variance of the residual factor of parent anxiety (\\(\\psi_{11}\\)) is 91.580 and the variance of the residual factor of parent perfectionism (\\(\\psi_{22}\\)) is 194.320. References Rosseel, Y. (2012). lavaan: An R package for structural equation modeling. Journal of Statistical Software, 48(2), 1-36. Appendix Derivations of Equation (3.8) \\(\\mathbf{y} = \\mathbf{B} \\mathbf{y} + \\boldsymbol{\\zeta} \\Leftrightarrow\\) \\(\\mathbf{y} - \\mathbf{B} \\mathbf{y} = \\boldsymbol{\\zeta} \\Leftrightarrow\\) \\(\\mathbf{I} \\mathbf{y} - \\mathbf{B} \\mathbf{y} = \\boldsymbol{\\zeta} \\Leftrightarrow\\) \\((\\mathbf{I} - \\mathbf{B}) \\mathbf{y} = \\boldsymbol{\\zeta} \\Leftrightarrow\\) (premultiply both sides by \\((\\mathbf{I} - \\mathbf{B})^{-1}\\) \\((\\mathbf{I} - \\mathbf{B})^{-1} (\\mathbf{I} - \\mathbf{B}) \\mathbf{y} = (\\mathbf{I} - \\mathbf{B})^{-1} \\boldsymbol{\\zeta} \\Leftrightarrow\\) \\(\\mathbf{y} = (\\mathbf{I} - \\mathbf{B})^{-1} \\zeta\\) Derivations of Equation (3.9) \\(\\mathbf{\\Sigma} = \\mathrm{COV}(\\mathbf{y},\\mathbf{y}) \\Leftrightarrow\\) (substitute Equation 3.08) \\(\\mathbf{\\Sigma} = \\mathrm{COV}( ( \\mathbf{I} - \\mathbf{B})^{-1} \\boldsymbol{\\zeta}, (\\mathbf{I} - \\mathbf{B})^{-1} \\boldsymbol{\\zeta}) \\Leftrightarrow\\) \\(\\mathbf{\\Sigma} = ( \\mathbf{I} - \\mathbf{B})^{-1} \\mathrm{COV}(\\boldsymbol{\\zeta}, \\boldsymbol{\\zeta}) ( \\mathbf{I} - \\mathbf{B}) ^{-1\\mathrm{T}} \\Leftrightarrow\\) (variances and covariances of \\(\\boldsymbol{\\zeta}\\) are denoted \\(\\boldsymbol{\\Psi}\\)) \\(\\mathbf{\\Sigma} = ( \\mathbf{I} - \\mathbf{B})^{-1} \\boldsymbol{\\Psi} ( \\mathbf{I} - \\mathbf{B})^{-1\\mathrm{T}}\\) "],["ch4.html", "4 Standard Errors and Confidence Intervals 4.1 Standard Errors 4.2 Confidence Intervals 4.3 Obtaining standard errors and confidence intervals in lavaan References", " 4 Standard Errors and Confidence Intervals 4.1 Standard Errors When the estimates of the parameter in a path model are obtained, and one assumes that the model is correct, researchers usually want to know whether the model parameters are statistically significantly different from zero. One way to judge the significance of a parameter estimate is to look at the associated standard error (\\(SE\\)). For example, we found that the effect of over-control on child anxiety was 0.072, with associated \\(SE\\) of 0.026. Although the interpretation of \\(SE\\)s and using them for judging statistical significance in structural equation modelling is no different than in any other statistical procedures (e.g., testing the difference between means in a \\(t\\)-test, or testing the significance of a regression coefficient in regression analysis), we shortly explain the procedure here. The \\(SE\\) reflects the standard deviation (\\(SD\\)) of the sampling distribution of the estimate. We obtained the parameter estimate of 0.072 based on a sample of 77 child–parent dyads. These 77 child–parent dyads are assumed to be a random sample from the much larger population of child–parent dyads. If we would have drawn another randomly selected sample of \\(N\\) = 77 from the same population, we would have probably obtained a slightly different estimate of the same effect. Imagine that we would draw all possible random samples of \\(N\\) = 77 from the population, fit the path model to each sample, and collect the estimated effect of interest. The obtained estimates would follow a normal distribution, called the sampling distribution. The mean of this distribution is assumed to be equal to the population value. The smaller the \\(SD\\), the smaller the range of the estimates from the sampling distribution and the closer a sample estimate is expected to be to the population value (i.e., the estimate is more precise). With larger samples, the estimates are assumed to vary less across samples, and the \\(SD\\) of the sampling distribution will be smaller. Of course, it is impossible to draw all possible samples and observe the sampling distribution directly. Instead, we rely on estimates of the sampling distribution. The \\(SE\\) of an estimated direct effect in one sample, is an estimate of the \\(SD\\) of the sampling distribution of that direct effect. The \\(SE\\)s are often given in the output of SEM programs by default. For example, the parameter estimates with SEs for the anxiety example are given in Table 1. Table 1. Parameter estimates, \\(SE\\)s, Wald \\(z\\) statistics, and \\(p\\) values for the path model of our illustrative example. Parameter Estimate SE z p (&lt;|z|) b11 0.187 0.140 1.341 .180 b32 0.210 0.096 2.194 .028 b43 0.072 0.026 2.741 .006 p21 53.360 16.481 3.238 .001 p11 91.580 14.856 6.164 &lt; .001 p22 194.320 31.523 6.164 &lt; .001 p33 114.157 18.519 6.164 &lt; .001 p44 6.880 1.116 6.164 &lt; .001 \\(SE\\)s can be used to judge the statistical significance of parameter estimates. This is done by taking the ratio of the parameter estimate over its estimated \\(SE\\), which asymptotically follows a standard normal (\\(z\\)) distribution (with small samples a t distribution, but we assume sufficiently large samples). The z values can be tested against critical values associated with a given \\(α\\) level. For example, to test them against an \\(α\\) level of .05 two-sided, you would compare them to the critical value of 1.96. If the ratio is larger than 1.96 or smaller than -1.96, the parameter estimate is significantly different from zero, at an \\(α\\) level of .05. The last column of Table 1 gives the associated probability of finding the \\(z\\) value or larger, under the null-hypothesis that the parameter is zero. Using an \\(α\\) level of .05, the effect of Parental Anxiety on over-control is not significantly larger than zero, but the effects of Perfectionism on over-control, and the effect of over-control on child anxiety are significantly larger than zero. Also, the association between parental anxiety and perfectionism is statistically significant. 4.2 Confidence Intervals The \\(SE\\)s can be used to calculate confidence intervals (CIs), which can also be used to judge significance of the unstandardized parameter estimates. The lower and upper bound of a CI around some parameter estimate is given by \\(Est\\) ± \\(Z_{\\text{crit}}\\) × \\(SE\\), where \\(Est\\) is the parameter estimate, \\(Z_{\\text{crit}}\\) is the critical z value given the desired significance level, and SE is the standard error of the parameter estimate. If the CI around a parameter estimate does not include 0, we can conclude that this parameter differs significantly from 0. When 0 is included in the interval, the parameter is not significantly different from 0. Suppose you want to calculate 95% CIs for the effect of over-control on child anxiety. The lower confidence limit is given by \\(0.072 − 1.96 × 0.026 = 0.021\\), and the upper confidence limit is given by \\(0.072 + 1.96 × 0.026 = 0.123\\). As zero is not in between 0.021 and 0.123, the parameter is considered statistically significant. Using CIs in this way to judge the statistical significance of parameters leads to the same conclusion as evaluating the p value against the \\(α\\) level. However, CIs are more informative than \\(p\\) values, and are recommended over \\(p\\) values (Cumming, 2013). Specifically, the size of the CI gives more descriptive information of the effect, as it can be gives an indication of the precision of the estimated effect. The interpretation of a 95% CI is that if you would calculate the CI for all random samples from the sampling distribution, 95% of those intervals will contain the population value. So, given a CI obtained from one sample, there is a 95% chance that it includes the population value, and a 5% chance that it doesn’t include the population value. Although the semantic difference seems subtle, it would be incorrect to say that the probability of the population value lying within a given confidence interval is 95%, because the population value is a fixed value, so we should not speak of the probability of a population value (unless speaking about posterior probabilities in Bayesian analyses). Rather, it is the method of calculating the CI that has a 95% probability of capturing a parameter. 4.2.1 Likelihood-based confidence intervals Likelihood-based CIs are another type of CI. They do not rely on the \\(SE\\)s, but are obtained through the likelihood of the model. After parameter estimates are obtained, for each parameter separately, the parameter is moved up (all other parameters held fixed) until the \\(χ^2\\) statistic is increased to exactly the critical \\(χ^2\\) value associated with the chosen α level (e.g., 3.84 with \\(α\\) = .05). This value is the upper confidence limit. Next, the parameter is moved in the negative direction until the \\(χ^2\\) is increased with the same critical value. This is, the lower confidence limit. Two large benefits of likelihood-based CIs are that they do not necessarily have to be symmetrical around the parameter estimate (which \\(SE\\)-based confidence intervals are), and that they can be obtained from functions of transformed parameters or functions of parameters as well (Neale &amp; Miller, 1997). Likelihood-based confidence are available in OpenMx but not in lavaan. 4.2.2 Bootstrapped confidence intervals Another type of CI can be obtained using bootstrapping. In our path model example, the sample size is 77. Bootstrapping involves resampling (with replacement) samples of size 77 from the original sample. This treats the observed data as though they are an infinite population, so each original observation can be included multiple times in a resampled sample (i.e., bootstrapping mimics the process of repeatedly drawing samples from the same population). By fitting the path model to each bootstrapped sample, and saving the parameter estimate of interest from each sample, one obtains a sampling distribution of the parameter estimate, which can be used for statistical inference. Bootstrap CIs are particularly useful in situations where obtaining the correct \\(SE\\)s analytically is difficult, such as with small samples or when the sampling distribution of a parameter is unknown, or known to be nonnormal. Bootstrapping is only possible when analyzing the raw data instead of the covariance matrix. 4.3 Obtaining standard errors and confidence intervals in lavaan In the standard summary output of lavaan, the \\(SE\\)s of parameter estimates are given in the column after the parameter estimates, and the ratios of the parameter estimates over their \\(SE\\)’s (Wald \\(z\\) value) is given in the next column. To request confidence intervals from the summary, use the argument ci = TRUE. The regression parameter output look like this: summary(AWmodelOut, ci = TRUE) ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## overcontrol ~ ## parnt_nx (b31) 0.187 0.140 1.341 0.180 -0.087 0.461 ## perfect (b32) 0.210 0.096 2.194 0.028 0.022 0.399 ## child_anx ~ ## ovrcntrl (b43) 0.072 0.026 2.741 0.006 0.021 0.124 One can also obtain this information from the parameterEstimates() function, which provides more flexibility. For example, we can ask for any width of the interval (although 99%, 95% and 90% are most common), and we can specify particular types of bootstrap CIs. The format is similar to the summary() output, but it is a data.frame, so the parameters are indicated by the left-hand side (lhs), operator (op), and right-hand side (rhs) of the equation used to specify a parameter in lavaan model syntax. For example, to calculate a 90% CI: parameterEstimates(AWmodelOut, level = .90) ## lhs op rhs label est se z pvalue ci.lower ci.upper ## 1 overcontrol ~ parent_anx b31 0.187 0.140 1.341 0.180 -0.042 0.417 ## 2 overcontrol ~ perfect b32 0.210 0.096 2.194 0.028 0.053 0.368 ## 3 child_anx ~ overcontrol b43 0.072 0.026 2.741 0.006 0.029 0.116 ## 4 parent_anx ~~ parent_anx p11 91.580 14.856 6.164 0.000 67.144 116.016 ## 5 perfect ~~ perfect p22 194.320 31.523 6.164 0.000 142.469 246.171 ## 6 overcontrol ~~ overcontrol p33 114.157 18.519 6.164 0.000 83.696 144.617 ## 7 child_anx ~~ child_anx p44 6.880 1.116 6.164 0.000 5.044 8.716 ## 8 parent_anx ~~ perfect p21 53.360 16.481 3.238 0.001 26.251 80.469 References Cumming, G. (2013). Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. New York, NY: Routledge. Neale, M. C., &amp; Miller, M. B. (1997). The use of likelihood based confidence intervals in genetic models. Behavior Genetics, 27, 113–120. "],["ch5.html", "5 Direct, Indirect, and Total Effects 5.1 Testing significance of indirect effects 5.2 Higher order indirect effects 5.3 Using matrix algebra to calculate total, total indirect and specific indirect effects 5.4 Calculating total, total indirect and specific indirect effects using lavaan output 5.5 Calculating specific indirect effects in lavaan", " 5 Direct, Indirect, and Total Effects In the path model from our illustrative example (see Figure 5.1), there is no arrow pointing from Parental Anxiety (PA) to Child anxiety (CA). This does not mean that the model implies that there is no effect of PA on CA. The effect runs through Parental Overcontrol (PO). PA has a direct effect on PO, which in turn has a direct effect on CA. PA thus has an indirect effect on CA, reflecting that the effect of PA on CA is mediated by PO. The size of the indirect effect equals the product of the direct effects that constitute the indirect effect. So, in this example, the indirect effect of PA on CA through PO is equal to .187 (\\(β_{31}\\)) times .072 (\\(β_{43}\\)) = .013. Note that it makes sense that the indirect effect equals the product of the direct effects. Holding PP constant, if PA increases with one point, PO is expected to increase with .187 point. If PO increases with 1 point, CA is expected to increase with .072 point. So if PO increases with .187 points instead of 1 point, CA is expected to increase with \\(.187 \\times .072 = .013\\) points. Similarly, the indirect effect of Parental Perfectionism (PP) on CA is \\(.210 \\times .072 = .015\\), indicating that 1 point increase in PP is expected to result in .015 point increase of CA. Figure 5.1: Full Mediation Model. If an effect of one variable on the other is only indirect, this reflects full mediation. Very often, there is also a direct effect next to the indirect effect, reflecting that the effect is not fully mediated, but partially mediated. Figure 5.2 shows the path model example of the partial mediation model (i.e., with direct effects of PA and PP on CA) and the associated parameter estimates. The direct effect of PA on CA is .091. This is the part of the total effect that is not mediated by PO. The total effect of PA on CA is the sum of the indirect effect(s) and the direct effect: \\(.091 + .187 \\times .058 = .102\\). Total effects thus are the sum of all indirect and direct effects of one variable on another. This is an example of consistent mediation, i.e., the direct effect and the indirect have the same sign (they are both positive in this case). It could also be that there is inconsistent mediation, where the direct effect and indirect have opposite signs. In our example, there is inconsistent mediation of the effect of PP on CA as the direct effect is negative while the indirect effect is positive. Inconsistent mediation could therefore lead to the situation in which the direct effect and indirect effect cancel each other out. Figure 5.2: Partial Mediation Model. 5.1 Testing significance of indirect effects Testing the significance of indirect effects can be done in the same way as for testing the significance of direct effects, using the standard error (\\(SE\\)) of the estimated effect. However, because the indirect effect is the product of two direct effects, the sampling distribution of the estimated indirect effects are complex and the associated SE’s are unknown. Sobel (1982) suggested to use the so-called delta-method (Rao, 1973; Oehlert, 1992) to obtain an approximation of the standard errors for unstandardized indirect effects. Suppose a is the effect of the predictor on the mediator, and b is the effect of the mediator on the outcome variable, then the estimated standard error for the indirect effect \\(ab\\) is: \\[\\begin{equation} SE_{ab} = \\sqrt{b^2SE^2_a + a^2SE^2_b} \\tag{5.1} \\end{equation}\\] When the sample size is large, the ratio \\(ab / SE_{ab}\\) can be used as the \\(z\\) test of the unstandardized indirect effect. This is called the Sobel-test (Sobel, 1982). With small samples, if the raw data is available, it is preferred to bootstrap confidence intervals around indirect effects (Preacher &amp; Hayes, 2008). If raw data is not available, bootstrapping is not an option. In this case one could use likelihood based confidence intervals (Cheung, 2008). Likelihood based confidence intervals are not available in lavaan. lavaan will provide standard errors based on the delta-method. Table 1 gives an overview of the direct, indirect and total effects of PA and PP on CA. In our example, none of the indirect effects are significant. Table 1. Direct, total indirect and total effects on Child Anxiety with standard errors, z-values and p-values and standardized values for the model from Figure 2. Parameter Estimate SE Z-value p(&gt;|z|) LB 95%CI UB 95%CI Std. Effects from PA on CA Direct .091 .033 2.771 .006 .027 .155 .317 Total indirect .011 .009 1.148 .251 -.008 .029 .038 Total .102 .033 3.047 .002 .036 .168 .355 Effects from PP on CA Direct -.015 .023 -.635 .525 -.060 .030 -.074 Total indirect .012 .008 1.552 .121 -.003 .028 .062 Total -.002 .023 -.103 .918 -.047 .043 -.012 5.2 Higher order indirect effects In our example there are only two indirect effects, but there may be more complex indirect effects. Consider for example the model that was hypothesized by Affrunti and Woodruff-Borden (2014) in Figure 5.3. In the model of Figure 5.3, there are two indirect effects from PA on CA. One path goes from PA to PO and then from PO to CA, and is equal to \\(β_{31} \\times β_{43}\\). The other indirect effect goes from PA to PP, from PP to PO, and from PO to CA, and is calculated by \\(β_{21} \\times β_{32} \\times β_{43}\\). Because this effect is build up of three direct effects, this is called a third order effect. The sum of all specific indirect effects is the total indirect effect. The total effect of PA on CA equals the sum of all indirect effects plus the direct effect (\\(β_{41}\\)). This model also contains an indirect effect of PA on PO, which equals \\(β_{21} \\times β_{32}\\). Figure 5.3: The hypothesized model of Affrunti and Woodruff-Borden (2014). Judging the significance of higher order indirect effects can also be done using the delta-method and Sobel test described earlier, but the calculations quickly become more difficult. For example, the standard error of indirect effect abc can be calculated using \\(SE_{abc} = SE_{ab} \\times SE_{c}\\) using Equation (5.1). lavaan will provide standard errors based on the delta-method for all requested functions of parameters. Table 2 shows a decomposition of effects of PA on PO and of PA on CA. As can be seen in Table 2, none of the individual indirect effects, or the total indirect effects in the model are significantly larger than zero. The unstandardized total effect of PA on CA is estimated to be .101, and is statistically significant at \\(α\\) = .05. As can be seen, the total effect can be attributed to the direct effect of PA on CA. The total effect of PA on PO is also statistically significant, although both the direct and the total indirect effects are not significant individually. Their combined effect leads to a total effect that is large enough to lead to statistical significance. Table 2. Direct, total indirect and total effects on CA and PO with standard errors, z-values and p-values and standardized values for path model from Figure 3. Parameter Estimate SE Z-value p(&gt;|z|) LB 95%CI UB 95%CI Std. Effects from PA on CA Direct .084 .031 2.271 .007 .023 .144 .292 Indirect via PP and PO .007 .005 1.409 .159 -.003 .016 .023 Indirect via PO .010 .009 1.133 .257 -.007 .028 .035 Total indirect .017 .011 1.563 .118 -.004 .038 .058 Total .101 .031 3.279 .001 .040 .161 .350 Effects from PA on PO Direct .187 .139 1.350 .177 -.085 .459 .157 Indirect via PP .123 .064 1.913 .056 -.003 .248 .103 Total indirect .123 .064 1.913 .056 -.003 .248 .103 Total .310 .131 2.363 .018 .053 .567 .260 After fitting a model, the estimated direct effects can be used to calculate the specific indirect effects, the total indirect effects and the total effects by hand. However, this is a tedious job. Therefore, it is often more attractive to use matrix algebra to obtain the indirect and total effects. 5.3 Using matrix algebra to calculate total, total indirect and specific indirect effects Instead of calculating all total effects by hand, one can use the model matrix \\(\\mathbf{B}\\) to calculate the total effects. In recursive models, the total effects in matrix \\(\\mathbf{T}\\) are given by: \\[\\begin{equation} \\mathbf{T}=\\sum _{k=1}^{p-1}{\\mathbf{B}}^{k} \\tag{5.2} \\end{equation}\\] where \\(p\\) is the number of variables. Thus, the total effects are calculated using the sum of powers of the matrix with regression coefficients (\\(\\mathbf{B}\\)), where the highest number of powers (\\(k\\)) is equal to the number of variables minus one (\\(p - 1\\)). For example, with four variables the total effects can be calculated using: \\(\\mathbf{T} = \\mathbf{B}^1 + \\mathbf{B}^2 + \\mathbf{B}^3\\). As \\(\\mathbf{B}^1 = \\mathbf{B}\\), the total effects can be decomposed into matrix B that contains all direct effects, and the sum of the powers of the \\(\\mathbf{B}\\) matrix that contain all indirect effects. Thus, the matrix with all indirect effects can be calculated by \\(\\mathbf{T} - \\mathbf{B}\\). In the anxiety example path model with higher order indirect effects the \\(\\mathbf{B}\\) matrix is: \\[ \\mathbf{B}^1 = \\begin{bmatrix} 0 &amp;0 &amp;0&amp;0 \\\\ \\beta_{21} &amp; 0 &amp; 0&amp;0\\\\ \\beta_{31} &amp; \\beta_{32} &amp; 0&amp;0 \\\\ \\beta_{41} &amp; 0 &amp; \\beta_{43} &amp; 0 \\end{bmatrix}. \\] which contains all direct effects (i.e., first-order effects). Multiplying matrix \\(\\mathbf{B}\\) with itself gives \\(\\mathbf{B}^2\\), which contains all second-order indirect effects: \\[ \\mathbf{B}^2 = \\begin{bmatrix} 0 &amp;0 &amp;0&amp;0 \\\\ 0 &amp; 0 &amp; 0&amp;0\\\\ \\beta_{21}\\beta_{32} &amp; 0 &amp; 0&amp;0 \\\\ \\beta_{31}\\beta_{43} &amp; \\beta_{32}\\beta_{43} &amp; 0 &amp; 0 \\end{bmatrix}. \\] Multiplying matrix \\(\\mathbf{B}\\) with itself three times gives the third-order indirect effects: \\[ \\mathbf{B}^3 = \\begin{bmatrix} 0 &amp;0 &amp;0&amp;0 \\\\ 0 &amp; 0 &amp; 0&amp;0\\\\ 0 &amp; 0 &amp; 0&amp;0 \\\\ \\beta_{21}\\beta_{32}\\beta_{43} &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix}. \\] If we would continue and calculate \\(\\mathbf{B}^4\\) we will see that it contains only zeros (indicating that there cannot exist fourth-order indirect effects in the model with four variables). Similarly, if we would calculate the matrices of indirect effects for the example in Figure 5.2, matrix \\(\\mathbf{B}^3\\) would already be zero, because there are no third or higher order effects in this model. The sum of the direct effects and the indirect effects is equal to the total effects. For nonrecursive models (discussed in a later chapter), Equation (5.2) can often still be used to calculate total effects, but it is not necessarily adequate. That is, the number of times that the power of the matrix with regression coefficients has to be calculated (and summed) is not defined. The total effects are only defined when the power of the matrix with regression coefficients (\\(\\mathbf{B}^k\\)) converges to zero. 5.4 Calculating total, total indirect and specific indirect effects using lavaan output We will use the output of the anxiety model to compute a matrix that contains the total effects (\\(\\mathbf{T}\\)), a matrix that contains the total indirect effects (\\(\\mathbf{U}\\)) and illustrate the calculation of a specific indirect effects (I1). In recursive models, matrix \\(\\mathbf{T}\\) is calculated by addition of matrix B with multiplications of matrix \\(\\mathbf{B}\\), as often as the number of variables minus one. So, if there are 4 observed variables, the expression for \\(\\mathbf{T}\\) stops after \\(\\mathbf{B}\\) is multiplied with itself 3 times. \\(\\mathbf{T}\\) contains the total effects. Estimates &lt;- lavInspect(AWmodelOut, &quot;est&quot;) B &lt;- Estimates$beta[obsnames, obsnames] Tot &lt;- B + B %*% B + B %*% B %*% B Matrix \\(\\mathbf{U}\\) is calculated as the matrix with total effects, minus the matrix with direct effects. The result is a matrix with the total indirect effects. Please notice that if there are multiple indirect effects between two variables, matrix \\(\\mathbf{U}\\) has the sum of the indirect effects. U &lt;- Tot - B A single indirect effect is calculated by multiplying specific elements from matrix \\(\\mathbf{B}\\). For example, B[3,1] selects the element in row 3, column 1 from the \\(\\mathbf{B}\\) matrix, and this element is multiplied with element B[4,3]. This is the indirect effect of Parental anxiety on Child anxiety via Overcontrol (see Figure 5.1). We gave this effect the name I1, because you may want to calculate more indirect effects, which could then be named I2, I3, I4 etc. I1 &lt;- B[3,1] * B[4,3] The resulting matrices are shown by asking for the result: Tot ## parent_anx perfect overcontrol child_anx ## parent_anx 0.00000000 0.00000000 0.00000000 0 ## perfect 0.00000000 0.00000000 0.00000000 0 ## overcontrol 0.18735753 0.21049095 0.00000000 0 ## child_anx 0.01354201 0.01521407 0.07227898 0 U ## parent_anx perfect overcontrol child_anx ## parent_anx 0.00000000 0.00000000 0 0 ## perfect 0.00000000 0.00000000 0 0 ## overcontrol 0.00000000 0.00000000 0 0 ## child_anx 0.01354201 0.01521407 0 0 I1 ## [1] 0.01354201 5.5 Calculating specific indirect effects in lavaan In lavaan we can also calculate total, total indirect and specific indirect effects. However, we cannot use matrix algebra but have to specify each effect individually. The script below shows how to calculate the specific indirect effect, total indirect effect and total effect of Parental Anxiety and Perfectionism on Child anxiety. In order to refer to the direct effects that make up the indirect effects, we have labelled the specific direct effects in the lavaan model, using [label]\\*[variable]. # specify the path model AWmodel &lt;- &#39;# regression equations overcontrol ~ b31*parent_anx + b32*perfect child_anx ~ b43*overcontrol + b41*parent_anx + b42*perfect # (residual) variance parent_anx ~~ p11*parent_anx perfect ~~ p22*perfect overcontrol ~~ p33*overcontrol child_anx ~~ p44*child_anx # covariance exogenous variables parent_anx ~~ p21*perfect # specific, total indirect and total effects of PA on CA I1_PA := b31*b43 total_ind_PA := I1_PA total_PA := total_ind_PA + b41 # specific, total indirect and total effects of PE on CA I1_PE := b32*b43 total_ind_PE := I1_PE total_PE := total_ind_PE + b42 &#39; We can define new variables that are a function of free parameter estimates by using the operator “:=”. We name the indirect effect of PA on CA I1_PA. If there would have been more mediators than Overcontrol, we could name other indirect effects I2_PA, I3_PA etc. The total indirect effect is calculated by summing the specific indirect effects. In this example there is just one specific indirect effect, so the total indirect effect is equal to the specific indirect effect. We used similar code for the indirect, total indirect and total effect of PE on CA. I1_PA := b31*b43 total_ind_PA := I1_PA total_PA := total_ind_PA + b41 The summary output of lavaan will give the result of the calculations, including a standard error of the estimate (using the delta-method) and the associated \\(z\\)-statistic. This provides a test of significance for the indirect ant total effects. When you request standardized output these are also given for the indirect effects. The results are added at the end of the output under “Defined parameters”: Defined Parameters: Estimate Std.Err z-value P(&gt;|z|) I1_PA 0.011 0.010 1.140 0.254 total_ind_PA 0.011 0.010 1.140 0.254 total_PA 0.102 0.034 3.027 0.002 I1_PE 0.012 0.008 1.542 0.123 total_ind_PE 0.012 0.008 1.542 0.123 total_PE -0.002 0.023 -0.102 0.918 "],["ch6.html", "6 Calculating Standardized Parameter Estimates 6.1 Standardized regression coefficients 6.2 Standardized residual factor variances and covariances 6.3 Calculating standardized coefficients in R using lavaan results 6.4 Request standardized output with lavaan 6.5 Standardizing indirect and total effects", " 6 Calculating Standardized Parameter Estimates 6.1 Standardized regression coefficients The \\(\\mathbf{B}\\) matrix from the path analysis model in Chapter 3 contains unstandardized parameter estimates. Unstandardized parameters are dependent on the units in which the variables are scaled. When predictor variables are measured on the same scale, comparison of unstandardized coefficients can provide information on their relative influence on the outcome. For example, when we would estimate the effect of the anxiety of the father and the anxiety of the mother on the anxiety of the child, the unstandardized effects can be directly compared to give an indication of the relative influence of mother’s and father’s anxiety. However, comparison of effects is complicated when variables are measured on different scales. In our illustrative example, a meaningful comparison of the effects of parent anxiety and parent perfectionism on parental over-control is complicated by the fact that the interpretation of units on the scales of these variables are not equivalent (e.g., how does one unit on parent anxiety relate to one unit on parent perfectionism?). In such a case, it would be helpful to obtain standardized parameter estimates that are independent on the units in which the variables are scaled. The standardized \\(β\\) is the regression coefficient that is scaled with respect to the \\(SD\\) of each variable. For example, \\(\\hat{\\beta}_{21}\\) is the estimated regression coefficient representing the direct effect of variable 1 on variable 2. The standardized version of \\(\\hat{\\beta}_{21}\\), \\(\\hat{\\beta}^*_{21}\\), is given as: \\[\\begin{equation} \\hat{\\beta}^*_{21} = \\hat{\\beta}_{21} \\times \\frac{\\hat{\\sigma}_1}{\\hat{\\sigma}_2}, \\tag{6.1} \\end{equation}\\] where \\(\\hat{\\sigma}_1\\) and \\(\\hat{\\sigma}_2\\) are the estimated \\(SD\\)s of variable 1 and variable 2 as predicted by the model.The standardized parameter can be interpreted in terms of standardized units, where a single SD increase in the predictor variable (variable 1) would result in a change of \\(\\hat{\\beta}^*_{21}\\) \\(SD\\)s in the outcome variable (variable 2). Substituting the parameter estimate \\(\\hat{\\beta}_{31}\\) and model-implied \\(SD\\)s \\({\\hat{\\sigma}_1}\\) and \\({\\hat{\\sigma}_3}\\) from our illustrative example yields: \\[ \\hat{\\beta}^*_{31} = 0.19 \\times \\frac{\\sqrt{91.58}}{\\sqrt{130.19}} = .16 . \\] Thus, controlling for the other variables in the model, a 1-SD increase in parent anxiety is expected to result in parental over-control increasing 0.16 SDs. In comparison, the standardized regression coefficient for the regression of parental over-control on parent perfectionism is: \\[ \\hat{\\beta}^*_{32} = \\hat{\\beta}_{32} \\times \\frac{\\hat{\\sigma}_2}{\\hat{\\sigma}_3} = 0.21 \\times \\frac{\\sqrt{194.32}}{\\sqrt{130.19}} = .26 . \\] The relative influence of parent perfectionism on parental over-control is thus larger than the influence of parent anxiety. In addition, standardized regression coefficients can be used to interpret the size of the effect (in terms of effect size \\(r\\)), where values between .10–.30 indicate small effects, values between .30–.50 indicate intermediate effect, and values larger than .50 indicate strong effects (Bollen, 1988). In our example both effects can be considered small. The calculation of standardized regression coefficients can be done for the complete matrix of estimated regression coefficients that are represented in matrix \\(\\hat{\\mathbf{B}}\\). The matrix expression for the standardized \\(\\hat{\\mathbf{B}}\\) matrix, \\(\\hat{\\mathbf{B}}^*\\), is the following: \\[\\begin{equation} \\hat{\\mathbf{B}}^* = \\text{diag}(\\hat{\\mathbf\\Sigma})^{-\\frac{1}{2}} \\hat{\\mathbf{B}} \\hspace{1mm} \\text{diag}(\\hat{\\mathbf\\Sigma})^\\frac{1}{2} \\tag{6.2} \\end{equation}\\] In this expression, \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) is the matrix containing the model-implied variances and covariances. As an alternative, the sample matrix of (co)variances could be used. Often, the sample variances and the model-implied variances are equal. However, in some situations the constraints imposed on the model can cause differences between the model-implied and sample variances. For reasons of consistency, we will always use the variances as implied by the model. In our example, the matrix of standardized regression coefficients is: \\[ \\hat{\\mathbf{B}}^* = \\begin{bmatrix} 0&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;0\\\\ \\hat{\\beta}_{31}^* &amp; \\hat{\\beta}_{32}^* &amp;0&amp;0\\\\ 0&amp;0&amp;\\hat{\\beta}_{43}^* &amp;0\\\\ \\end{bmatrix} = \\begin{bmatrix} 0&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;0\\\\ 0.16 &amp; 0.26 &amp;0&amp;0\\\\ 0&amp;0&amp; 0.30 &amp;0\\\\ \\end{bmatrix}, \\] where it can be seen that the standardized coefficient of the regression of over-control on parental anxiety is relatively small compared to the other coefficients. 6.2 Standardized residual factor variances and covariances Similarly, the matrix of residual factor variances and covariances can be standardized to obtain parameter estimates that are independent on the units in which the variables are measured. A standardized covariance is a correlation. If \\(COV_{21}\\) is the covariance between variable 2 and variable 1, the correlation \\(COR_{21}\\) is calculated as: \\[\\begin{equation} COR_{21} = \\frac{COV_{21}}{\\hat{\\sigma}_1 \\hat{\\sigma}_2} \\tag{6.3} \\end{equation}\\] For example, the correlation between the variables parent anxiety and parent perfectionism is: \\[ COR_{21} = \\frac{COV_{21}}{\\hat{\\sigma}_1 \\hat{\\sigma}_2} = \\frac{53.36}{\\sqrt{91.58 \\times 194.32}} = .40. \\] Like standardized regression slopes, correlation coefficients can be interpreted as effect size \\(r\\) (Bollen, 1988). Thus, in our illustrative example there is an intermediate correlation between the two exogenous variables. The matrix expression for standardized variances and covariances in the \\(\\hat{Ψ}\\) matrix is: \\[\\begin{equation} \\hat{\\mathbf\\Psi}^* = \\text{diag}(\\hat{\\mathbf\\Sigma}_{\\text{model}})^{-\\frac{1}{2}} \\hat{Ψ} \\hspace{1mm} \\text{diag}(\\hat{\\mathbf\\Sigma}_{\\text{model}})^\\frac{1}{2} \\tag{6.4} \\end{equation}\\] In our example, the matrix of standardized residual variances and covariances is: \\[ \\hat{\\mathbf\\Psi}^* = \\begin{bmatrix} \\hat{\\psi}_{11}^* &amp; \\hat{\\psi}_{21}^*&amp;0&amp;0\\\\ \\hat{\\psi}_{12}^* &amp; \\hat{\\psi}_{22}^*&amp;0&amp;0\\\\ 0&amp;0 &amp;\\hat{\\psi}_{33}^*&amp;0\\\\ 0&amp;0&amp;0 &amp;\\hat{\\psi}_{44}^*\\\\ \\end{bmatrix} = \\begin{bmatrix} 1 &amp;0.40 &amp; 0 &amp; 0\\\\ 0.40 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0.88 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0.91\\\\ \\end{bmatrix}. \\] The standardized variances of the residual factors can be interpreted as the proportion of unexplained variance. As the variances of the residual factors of exogenous variables are equal to the variances of the observed variables, their standardized value is 1, i.e., 100% of the variance of exogenous variables is unexplained by the model. For endogenous variables, the residual factor contains only that part of the variance of the observed variable that is not explained by the model. In our example, the proportion of unexplained variance of child anxiety is .91. This indicates that 91% of the variance of child anxiety cannot be explained by the specified model. Or, in other words, the model explains only 9% of the variance of child anxiety. Other variables, not included in the model, determine the remaining variance of child anxiety. 6.3 Calculating standardized coefficients in R using lavaan results There are several ways to obtain standardized parameter estimates from a path model. Here, we will show how to manually calculate standardized parameter estimates from the estimated (\\(\\hat{\\mathbf{B}}\\) \\(\\hat{\\mathbf\\Psi}\\)) and model-implied (\\(\\hat{\\mathbf\\Sigma}\\)) matrices. Script 6.1 shows the syntax that standardizes the \\(\\hat{\\mathbf{B}}\\) and \\(\\hat{\\mathbf{\\Psi}}\\)matrices (\\(\\hat{\\mathbf{B}}^*\\) and \\(\\hat{\\mathbf{\\Psi}}^*\\)) from the output of the Affrunti &amp; Woodruff-Borden model that was saved in the object AWmodelOut. Script 6.1 # parameter estimates from the model Estimates &lt;- lavInspect(AWmodelOut, &quot;est&quot;) BETA &lt;- Estimates$beta[obsnames, obsnames] PSI &lt;- Estimates$psi[obsnames, obsnames] # calculate model-implied covariance matrix IDEN &lt;- diag(1, nrow = 4) SIGMA &lt;- solve(IDEN - BETA) %*% PSI %*% t(solve(IDEN - BETA)) # calculate standard deviations of model-implied variances SD &lt;- diag(sqrt(diag(SIGMA))) # calculate standardized parameter estimates BETAstar &lt;- solve(SD) %*% BETA %*% SD PSIstar &lt;- solve(SD) %*% PSI %*% solve(SD) # give labels to the new matrices dimnames(BETAstar) &lt;- list(obsnames, obsnames) dimnames(PSIstar) &lt;- list(obsnames, obsnames) First, the unstandardized estimates for the \\(β\\) and \\(ψ\\) parameters are collected in the objects BETA and PSI, respectively, with the commands: Estimates &lt;- lavInspect(AWmodelOut, &quot;est&quot;) BETA &lt;- Estimates$beta[obsnames, obsnames] PSI &lt;- Estimates$psi[obsnames, obsnames] We also need the model-implied covariance matrix, \\(\\hatΣ\\) model, which we can calculate with the parameter estimates, using \\(\\hat{\\mathbf\\Sigma}_{\\text{model}} = (\\mathbf{I}-\\hat{\\mathbf{B}})^{-1} \\hat{\\mathbf\\Psi}[(\\mathbf{I}-\\hat{\\mathbf{B}})^{-1}]^\\mathbf{T}\\). We already extracted the parameter estimates for the \\(\\hat{\\mathbf{B}}\\) and \\(\\hat{\\mathbf{\\Psi}}\\) matrices (into the objects BETA and PSI), so now we create an identity matrix IDEN with dimensions 4 × 4 and then calculate \\(\\hat{\\mathbf\\Sigma}_{\\text{model}}\\) using: SIGMA &lt;- solve(IDEN - BETA) %*% PSI %*% t(solve(IDEN - BETA)) Note, however, that you can also request the model-implied covariance matrix directly from lavaan: SIGMA &lt;- lavInspect(AWmodelOut, &quot;cov.ov&quot;)[obsnames, obsnames] For our calculations we only need the \\(SD\\)s, which we obtain by extracting the diagonal of SIGMA using the diag() function, then take the square-root of each element using diag(). Notice that the diag() function can also create a diagonal matrix, such as when we used it to create an identity matrix IDEN, in which case it needs the value to put on the diagonal and the number of rows (or columns). In the case of \\(SD\\), sqrt(diag(SIGMA)) is a vector with 4 elements, so diag() creates a matrix of 4 rows and columns with sqrt(diag(SIGMA)) on its diagonal. SD &lt;- diag(sqrt(diag(SIGMA))) The \\(\\hat{\\mathbf{B}}\\) matrix is standardized by pre-multiplying \\(\\hat{\\mathbf{B}}\\) with a diagonal matrix with the inverse of the \\(SD\\)s, and post-multiplying it with a diagonal matrix with the \\(SD\\)s: BETAstar &lt;- solve(SD) %*% BETA %*% SD The matrix \\(\\hat{\\mathbf\\Sigma}\\) is standardized by pre- and post-multiplying \\(\\hat{\\mathbf\\Sigma}\\) with a diagonal matrix with the inverse of the standard deviations. PSIstar &lt;- solve(SD) %*% PSI %*% solve(SD) The standardized variances and covariances (correlations) are collected in the object PSIstar. The standardized direct effects are in the object BETAstar. The same labels that were given to the matrices with unstandardized estimates, can also be used for the standardized parameter estimates: dimnames(BETAstar) &lt;- list(obsnames, obsnames) dimnames(PSIstar) &lt;- list(obsnames, obsnames) To view the standardized \\(\\hat{\\mathbf{B}}^*\\) and \\(\\hat{\\mathbf\\Sigma}^*\\) matrices, type: BETAstar ## parent_anx perfect overcontrol child_anx ## parent_anx 0.0000000 0.00000 0.0000000 0 ## perfect 0.0000000 0.00000 0.0000000 0 ## overcontrol 0.1571385 0.25716 0.0000000 0 ## child_anx 0.0000000 0.00000 0.2999438 0 PSIstar ## parent_anx perfect overcontrol child_anx ## parent_anx 1.000000 0.399997 0.0000000 0.0000000 ## perfect 0.399997 1.000000 0.0000000 0.0000000 ## overcontrol 0.000000 0.000000 0.8768487 0.0000000 ## child_anx 0.000000 0.000000 0.0000000 0.9100337 6.4 Request standardized output with lavaan The same standardized matrices can be extracted using lavaan’s build-in functions: lavInspect(AWmodelOut, &quot;std.all&quot;) ## $lambda ## ovrcnt chld_n prnt_n perfct ## overcontrol 1 0 0 0 ## child_anx 0 1 0 0 ## parent_anx 0 0 1 0 ## perfect 0 0 0 1 ## ## $theta ## ovrcnt chld_n prnt_n perfct ## overcontrol 0 ## child_anx 0 0 ## parent_anx 0 0 0 ## perfect 0 0 0 0 ## ## $psi ## ovrcnt chld_n prnt_n perfct ## overcontrol 0.877 ## child_anx 0.000 0.910 ## parent_anx 0.000 0.000 1.000 ## perfect 0.000 0.000 0.400 1.000 ## ## $beta ## ovrcnt chld_n prnt_n perfct ## overcontrol 0.0 0 0.157 0.257 ## child_anx 0.3 0 0.000 0.000 ## parent_anx 0.0 0 0.000 0.000 ## perfect 0.0 0 0.000 0.000 You can also request standardized estimates when you use the summary() or parameterEstimates() functions with the argument standardized = TRUE: summary(AWmodelOut, standardized = TRUE) ## lavaan 0.6-19 ended normally after 28 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 8 ## ## Number of observations 77 ## ## Model Test User Model: ## ## Test statistic 7.333 ## Degrees of freedom 2 ## P-value (Chi-square) 0.026 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## overcontrol ~ ## parnt_nx (b31) 0.187 0.140 1.341 0.180 0.187 0.157 ## perfect (b32) 0.210 0.096 2.194 0.028 0.210 0.257 ## child_anx ~ ## ovrcntrl (b43) 0.072 0.026 2.741 0.006 0.072 0.300 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## parent_anx ~~ ## perfect (p21) 53.360 16.481 3.238 0.001 53.360 0.400 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## parnt_nx (p11) 91.580 14.856 6.164 0.000 91.580 1.000 ## perfect (p22) 194.320 31.523 6.164 0.000 194.320 1.000 ## .ovrcntrl (p33) 114.157 18.519 6.164 0.000 114.157 0.877 ## .child_nx (p44) 6.880 1.116 6.164 0.000 6.880 0.910 parameterEstimates(AWmodelOut, standardized = TRUE) ## lhs op rhs label est se z pvalue ci.lower ci.upper std.lv ## 1 overcontrol ~ parent_anx b31 0.187 0.140 1.341 0.180 -0.087 0.461 0.187 ## 2 overcontrol ~ perfect b32 0.210 0.096 2.194 0.028 0.022 0.399 0.210 ## 3 child_anx ~ overcontrol b43 0.072 0.026 2.741 0.006 0.021 0.124 0.072 ## 4 parent_anx ~~ parent_anx p11 91.580 14.856 6.164 0.000 62.462 120.698 91.580 ## 5 perfect ~~ perfect p22 194.320 31.523 6.164 0.000 132.536 256.104 194.320 ## 6 overcontrol ~~ overcontrol p33 114.157 18.519 6.164 0.000 77.861 150.453 114.157 ## 7 child_anx ~~ child_anx p44 6.880 1.116 6.164 0.000 4.692 9.067 6.880 ## 8 parent_anx ~~ perfect p21 53.360 16.481 3.238 0.001 21.058 85.662 53.360 ## std.all ## 1 0.157 ## 2 0.257 ## 3 0.300 ## 4 1.000 ## 5 1.000 ## 6 0.877 ## 7 0.910 ## 8 0.400 This will add two columns to the output, the column std.lv gives standardized parameters when only the exogenous variables are standardized, and the column std.all gives standardized parameters when both exogenous and endogenous variables are standardized. The latter one will give equivalent output as calculated above. You can also request standardized estimates using the standardizedSolution() function, which also provides \\(SE\\)s for the standardized estimates themselves. However, we recommend only testing the unstandardized estimates for making inferences about population parameters (e.g., null-hypothesis significance tests), and using standardized estimates only as a standardized measure of effect size. 6.5 Standardizing indirect and total effects Standardized indirect effects are obtained by multiplying the standardized direct effects instead of the unstandardized direct effects. Alternatively, one can standardize an indirect effect using formulas (6.1) and (6.2) replacing the estimated regression coefficient with the calculated indirect or total effect of interest. Note that the standard deviations of the mediating variables do not play a role in standardizing indirect or total effects. "],["ch7.html", "7 Identification 7.1 Assessment of identification using the elements of \\(\\mathbf\\Sigma_{\\text{population}}\\) and \\(\\mathbf\\Sigma_{\\text{model}}\\) 7.2 Assessing identification through heuristics 7.3 Assessment of empirical model identification using lavaan Appendix", " 7 Identification The problem of identification considers the issue of whether there is enough “known” information to obtain unique estimates of the model that is specified (i.e., the “unknown” information). In structural equation modeling, the known pieces of information are the sample variances and covariances of the observed variables, and the unknown pieces of information are the model parameters. When the model is “underidentified”, this means that there is not enough known information to yield unique parameter estimates. When there are just as many knowns as unknowns, the model is “just identified”. However, usually we are interested in so called “overidentified” models, where there are more knowns than unknowns. Identification is an important but rather difficult topic of structural equation modeling, and there are many different ways to evaluate the identification status of a model. The first, and easiest way to evaluate whether a model might be identified is to evaluate whether the number of model parameters to be estimated is equal to or smaller than the number of nonredundant elements in the observed covariance matrix: \\[\\begin{equation} q \\le (p(p+1)) ½, \\tag{7.1} \\end{equation}\\] where \\(p\\) is the number of observed variables, and \\(q\\) is the number of free parameters in the model. This is a general rule that can be applied to all structural equation models. However, it is a ‘necessary but not sufficient’ condition for identification. This means that models that have a negative number of degrees of freedom are surely not identified. Models that have at least zero degrees of freedom might be identified. Evaluation of Equation (7.1) for our illustrative example of child anxiety yields a total of 10 knowns (i.e., \\(p = 4\\)), and 8 unknowns (i.e., \\(\\beta_{31}\\), \\(\\beta_{32}\\), \\(\\beta_{43}\\), \\(\\psi_{11}\\), \\(\\psi_{22}\\), \\(\\psi_{33}\\), \\(\\psi_{44}\\) and \\(\\psi_{21}\\)). The difference between the number or nonredundant elements in the covariance matrix and the number of free parameters in the model are the ‘degrees of freedom’. The model of our example thus has 2 degrees of freedom. There are different approaches to further assess whether a model is identified. In this chapter we will first discuss the symbolic or theoretical identification of model parameters. In addition, we will explain some rules of thumb that can be applied in order to facilitate the evaluation of model identification. We only discuss identification of path models, identification of factor models will be discussed in a later chapter. Some conditions related to identification are sufficient, which means that if the condition holds, the model is surely identified (at least theoretically), but there may be other identified models for which the condition does not hold. Other conditions are necessary, which means that if the condition holds, the model might be identified. If a necessary condition doesn’t hold, the model is surely not identified. 7.1 Assessment of identification using the elements of \\(\\mathbf\\Sigma_{\\text{population}}\\) and \\(\\mathbf\\Sigma_{\\text{model}}\\) A model is identified only when all unknown parameters of the model are identified. Identification of model parameters can be demonstrated by showing that the unknown parameters are functions of known parameters, i.e., that we can give a description of the free parameters in the model in terms of population variances and covariances (\\(\\mathbf\\Sigma_{\\text{population}}\\)). The population variances and covariances are known-to-be-identified (i.e., known information) because the observed sample variances and covariances (\\(\\mathbf\\Sigma_{\\text{sample}}\\)) are direct estimates of \\(\\mathbf\\Sigma_{\\text{population}}\\). Therefore, if an unknown parameter can be written as a function of one or more elements of \\(\\mathbf\\Sigma_{\\text{population}}\\), then that parameter is identified. As an example, we take \\(\\mathbf\\Sigma_{\\text{model}}\\) from Equation (3.10). Here, the elements of the covariance matrix are written as a function of model parameters. In order to evaluate the identification status of a parameter, we need to write the equation the other way around, so that the model parameter is a function of population variances and covariances. If each unknown model parameter can be written as a function of known parameters, then the model of Equation (3.10) is identified. For example, the first three elements of the model implied covariance matrix are a function of single model parameters \\(ψ_{11}\\), \\(ψ_{22}\\), and \\(ψ_{21}\\). These parameters can therefore be represented by the population variances \\(\\sigma_{11}\\), \\(\\sigma_{22}\\), and covariance \\(\\sigma_{21}\\): \\[\\begin{equation} \\psi_{11} = \\sigma_{11} \\tag{7.2} \\end{equation}\\] \\[\\begin{equation} \\psi_{22} = \\sigma_{22} \\tag{7.3} \\end{equation}\\] \\[\\begin{equation} \\psi_{21} = \\sigma_{21} \\tag{7.4} \\end{equation}\\] These equations thus have the same number of “knowns” as “unknowns’, which leads to a unique expression for each model parameter. The parameters \\(ψ_{11}\\), \\(ψ_{22}\\), and \\(ψ_{21}\\) are thus identified. The equations for the population covariances \\(\\sigma_{31}\\) and \\(\\sigma_{32}\\) are: \\[\\begin{equation} \\sigma_{31} = \\beta_{31}\\psi_{11} + \\beta_{32}\\psi_{21} \\tag{7.5} \\end{equation}\\] \\[\\begin{equation} \\sigma_{32} = \\beta_{32}\\psi_{22} + \\beta_{31}\\psi_{21} \\tag{7.6} \\end{equation}\\] Given Equations (7.2) – (7.4), both equations have two unknowns, \\(\\beta_{31}\\) and \\(\\beta_{32}\\). Because both equations share the same two unknowns, we can rewrite the equations such that the model parameters \\(\\beta_{31}\\) and \\(\\beta_{32}\\) are on the left side of the equations and use this information to yield unique functions for each model parameter in terms population parameters. First, we rewrite Equations (7.5) and (7.6): \\[\\begin{equation} \\beta_{31} = \\frac{\\sigma_{31}-\\beta_{32}\\psi_{21}}{\\psi_{11}} \\tag{7.7} \\end{equation}\\] \\[\\begin{equation} \\beta_{32} = \\frac{\\sigma_{32}-\\beta_{31}\\psi_{21}}{\\psi_{22}} \\tag{7.8} \\end{equation}\\] Substituting Equation (7.8) into Equation (7.7) gives an equation with only one unknown: \\[\\begin{equation} \\beta_{31} = \\frac{\\sigma_{31}-\\frac{\\sigma_{32}-\\beta_{31}\\psi_{21}}{\\psi_{22}}\\psi_{21}}{\\psi_{11}} \\tag{7.9} \\end{equation}\\] Rewriting gives (for intermediate steps, see this chapters Appendix: \\[\\begin{equation} \\beta_{31} = \\frac{\\sigma_{31}\\psi_{22}-\\sigma_{32}\\psi_{21}}{\\psi_{11}\\psi_{22}-{\\psi_{21}}^2} \\tag{7.10} \\end{equation}\\] The expression for \\(β_{31}\\) contains the already known to be identified parameters \\(ψ_{11}\\), \\(ψ_{22}\\), and \\(ψ_{21}\\). Substituting Equations (7.2), (7.2) and (7.4) into Equation (7.10) gives: \\[\\begin{equation} \\beta_{31} = \\frac{\\sigma_{31}\\sigma_{22}-\\sigma_{32}\\sigma_{21}}{\\sigma_{11}\\sigma_{22}-{\\sigma_{21}}^2} \\tag{7.11} \\end{equation}\\] This shows that the parameter \\(β_{31}\\) can be written as a function of population variances and covariances, and thus \\(β_{31}\\) is identified. Similarly, substituting Equation (7.7) into (7.8) and rewriting gives: \\[\\begin{equation} \\beta_{32} = \\frac{\\sigma_{32}\\psi_{22}-\\sigma_{31}\\psi_{21}}{\\psi_{11}\\psi_{22}-{\\psi_{21}}^2} \\tag{7.12} \\end{equation}\\] and substituting Equations (7.2), (7.3) and (7.4) into Equation (7.12) gives: \\[\\begin{equation} \\beta_{32} = \\frac{\\sigma_{32}\\sigma_{22}-\\sigma_{31}\\sigma_{21}}{\\sigma_{11}\\sigma_{22}-{\\sigma_{21}}^2} \\tag{7.13} \\end{equation}\\] Therefore, using the equations for the population covariances \\(\\sigma_{31}\\) and \\(\\sigma_{32}\\), both \\(\\beta_{31}\\) and \\(\\beta_{32}\\) are identified. The \\(\\sigma_{33}\\), \\(\\sigma_{41}\\) and \\(\\sigma_{44}\\) equations then have just a single unknown each (\\(\\psi_{33}\\), \\(\\beta_{43}\\) and \\(\\psi_{44}\\)) which indicates that these model parameters are also identified. In this chapters Appendix I we demonstrate that the unknown parameters \\(\\psi_{33}\\), \\(\\beta_{43}\\) and \\(\\psi_{44}\\) can indeed be written as a function of known parameters. All model parameters of Equation (3.10) are identified and therefore the model of Equation (3.10) is identified. Moreover, we did not use the \\(\\sigma_{42}\\) and \\(\\sigma_{43}\\) equations yet, which shows that the model given by Equation (3.10) is over-identified. Specifically, we have two more nonredundant elements in the population covariance matrix than the number of unknown model parameters (i.e., the model has two degrees of freedom). The equations for \\(\\sigma_{41}\\),\\(\\sigma_{42}\\) and \\(\\sigma_{43}\\) can all be used to express \\(\\beta_{43}\\) in terms of population variances and covariances. To illustrate this over identification of \\(\\beta_{43}\\) these different equations are given in the Appendix. The expression of model parameters in terms of population variances and covariances can be used to arrive at a theoretical assessment of identification. However, a model that is theoretically identified might not necessarily be empirically identified. The theoretical identification of model parameter rests on the assumption that for each population parameter there is at least one estimate in terms of sample parameters. However, this assumption might be violated when some of the observed variables in the model exhibit very large or very small correlations. For example, when the sample covariance between two variables is zero, then the equations for the unknown parameters might involve division by zero, which is not possible. Therefore, researchers should always be aware of identification problems, even if the model is theoretically identified. 7.2 Assessing identification through heuristics Because the symbolic assessment of identification quickly becomes very complex as the model grows, researchers have developed a number of rules of thumb to assess identification. The most well-known rules of thumb for path models are the “Recursive Rule”, the “Order Condition”, and the “Rank Condition”. These rules are explained in detail on pages 98-104 of Bollen (1988), but below we give a brief description of each of these rules. 7.2.1 The recursive rule The recursive rule is a ‘sufficient, but not necessary condition’ for model identification. The rule entails that all recursive models are identified. Recursive models contain only unidirectional causal effects and have uncorrelated residual factors of endogenous variables. This means that there are no feedback-loops in the model. Because the recursive rule is a sufficient rule, it is possible that the model is still identified even though not all causal effects are unidirectional or there exist correlations between the residual factors of the endogenous variables. 7.2.2 The order condition For identification of nonrecursive models we need additional rules. Where the previous rules apply the model as a whole, the order condition (and the rank condition) apply to the separate equations of the endogenous variables in the model (i.e., Equations (3.3) and (3.4) from our illustrative example). Each equation has to meet the condition for the model to be identified. One other difference with the previous conditions, is that for the order and rank conditions it is assumed that all residual covariances between the residual factors of endogenous variables are free to be estimated. The advantage of this assumption is that when all the equations of a model meet the rank and order conditions, than all the elements in \\(\\mathbf\\Psi\\) that correspond to the residual factors of endogenous variables are identified. However, usually we know that some of these elements of \\(\\mathbf\\Psi\\) are restricted to zero, and such restrictions may help in the identification of model parameters. This knowledge is not taken into account with the rank and order conditions. The order condition entails that for each equation of an endogenous variable, the number of endogenous variables excluded from the equation needs to be at least one less than the total number of endogenous variables (\\(g – 1\\)). The order condition is a necessary but not sufficient condition. In order to evaluate the order condition, one can calculate matrix \\(\\mathbf{C}\\), which is \\((\\mathbf{I} – \\mathbf{B}_g | -\\mathbf{B}_x)\\). \\(\\mathbf{B}_g\\) refers to the part of the \\(\\mathbf{B}\\) matrix that contains the regression coefficients between the endogenous variables, and \\(\\mathbf{B}_x\\) refers to the part of the \\(\\mathbf{B}\\) matrix that contains the regression coefficients between the exogenous and endogenous variables. For example, the \\(\\mathbf{C}\\) matrix for our illustrative example of the development of child anxiety is: \\[ \\mathbf{C} = \\begin{bmatrix} 1&amp;0&amp; -\\beta_{31} &amp; -\\beta_{32}\\\\ -\\beta_{43} &amp; 1 &amp; 0&amp;0 \\end{bmatrix} \\] In order to evaluate the order condition, we need to count the number of zero elements for each row. If a row has more zeros than \\(g – 1\\), then the associated equation meets the order condition. In our example, the row corresponding to the equation for \\(\\mathrm{y}_3\\) (parental overcontrol) has one zero, and the row corresponding to the equation for variable \\(\\mathrm{y}_4\\) (child anxiety) has two zeros. Our model contains a total of two endogenous variables, i.e. \\(g – 1 = 1\\). Thus, the equations are identified. The order condition is a necessary but not sufficient condition, which means that even when each equation meets the condition it does not guarantee identification of the model. 7.2.3 The rank condition The rank condition is a necessary and sufficient condition, indicating that if each equation meets the criteria than the model is identified. If the equations do not meet the condition, than the model is surely not identified. To evaluate the rank condition we again look at the \\(\\mathbf{C}\\) matrix, but now delete all columns of \\(\\mathbf{C}\\) that do not have zeros in the row of the equation of interest. Using the remaining columns to form a new matrix, \\(\\mathbf{C}_i\\), we know that equation \\(i\\) is identified when the rank of \\(\\mathbf{C}_i\\) equals \\(g – 1\\). When we calculate the \\(\\mathbf{C}_3\\) matrix for the equation that refers to the \\(\\mathrm{y}_3\\) variable from our illustrative example, we get: \\[ \\mathbf{C}_3 = \\begin{bmatrix} 0\\\\ 1 \\end{bmatrix}. \\] The rank of a matrix or vector is the number of independent rows (or columns). A row is independent when it contains nonzero elements, and is linearly independent from other rows in the matrix (e.g., when a row is the sum of two other rows of the same matrix, it is not linearly independent from the other rows). For \\(\\mathbf{C}_3\\) the rank is 1. Therefore, the equation for parental overcontrol is identified. The \\(\\mathbf{C}_4\\) matrix of our illustrative example is: \\[ \\mathbf{C}_4 = \\begin{bmatrix} -\\beta_{31}&amp;-\\beta_{32}\\\\ 0&amp;0 \\end{bmatrix}. \\] The rank of this matrix is also 1 and thus this equation is also identified. 7.3 Assessment of empirical model identification using lavaan The methods for assessment of identification as described above are all methods that cannot be readily evaluated with a computer program such as lavaan. One method that can be evaluated with software is the so-called “empirical check”, where the model of interest is fitted to the (user defined) population covariance matrix of the specified model. When the ‘empirical’ solution is equal to the model in the population, the model may be identified. When the parameter estimates of the empirical solution are different from the parameters specified in the population, the model is surely not identified (i.e., the condition is necessary but not sufficient). The empirical check has two steps. Step 1: Calculate a model implied covariance matrix for the model of interest. Step 2: Fit the model to the model implied covariance matrix from Step 1. If the parameter estimates you obtain in Step 2 are identical to the parameter values you chose in Step 1, the model may be identified. If you obtain different parameter estimates in Step 2, your model is surely not identified. Below, we will show two examples of the empirical check. In Script 7.1 we will check identification of the path model depicted in Figure 7.1. First we will check identification if we add a covariance between the residual factors of \\(\\mathrm{y}_3\\) and \\(\\mathrm{y}_4\\) (Model 1), and subsequently we will check identification when we additionally add a reciprocal effect from \\(\\mathrm{y}_4\\) to \\(\\mathrm{y}_3\\) (Model 2). Script 7.1 ## STEP 1: calculate the model implied covariance matrix BETA &lt;- matrix(c( 0, 0, 0,0, 0, 0, 0,0, .5,.5, 0,0, 0, 0,.5,0), nrow=4,ncol=4,byrow=TRUE) PSI &lt;- matrix(c( 1,.5, 0, 0, .5, 1, 0, 0, 0, 0,.8,.5, 0, 0,.5,.7), nrow=4,ncol=4,byrow=TRUE) IDEN &lt;- diag(1,4,4) SIGMA &lt;- solve(IDEN-BETA) %*% PSI %*% t(solve(IDEN-BETA)) obsnames = c(&quot;y1&quot;,&quot;y2&quot;,&quot;y3&quot;,&quot;y4&quot;) dimnames(SIGMA) &lt;- list(obsnames,obsnames) Figure 7.1: Path model for which identification is assessed in the situation when effects \\(ψ_{43}\\) (Model 1) and both \\(ψ_{43}\\) and \\(ß_{34}\\) (Model 2) are added. ## STEP 2: fit model to the covariance matrix from step 1 EmpiricalCheck &lt;- &#39; # regressions y4 ~ b43*y3 y3 ~ b32*y2 + b31*y1 # residual (co)variances y1 ~~ p11*y1 y2 ~~ p22*y2 y3 ~~ p33*y3 y4 ~~ p44*y4 y3 ~~ p43*y4 # covariance exogenous variables y1 ~~ p21*y2 &#39; EmpiricalCheckOut &lt;- lavaan(EmpiricalCheck, sample.cov=SIGMA, sample.nobs=100, likelihood = &quot;wishart&quot;, fixed.x=FALSE) summary(EmpiricalCheckOut) ## lavaan 0.6-19 ended normally after 20 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 100 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 1 ## P-value (Chi-square) 1.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y4 ~ ## y3 (b43) 0.500 0.097 5.150 0.000 ## y3 ~ ## y2 (b32) 0.500 0.085 5.906 0.000 ## y1 (b31) 0.500 0.085 5.906 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y4 ~~ ## .y3 (p43) 0.500 0.119 4.194 0.000 ## y2 ~~ ## y1 (p21) 0.500 0.112 4.450 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## y1 (p11) 1.000 0.142 7.036 0.000 ## y2 (p22) 1.000 0.142 7.036 0.000 ## .y3 (p33) 0.800 0.114 7.036 0.000 ## .y4 (p44) 0.700 0.139 5.035 0.000 When you run the script for Model 1, you will notice that the parameter estimates are exactly equal to our chosen values from Step 1. Thus, this indicates that the model may be identified. As this empirical check is a necessary requirement for identification, but not sufficient, we are not completely sure that the model is truly identified. In the next script we show the empirical check of Model 2, where we also add the effect from \\(\\mathrm{y}_4\\) to \\(\\mathrm{y}_3\\). Script 7.2 ## STEP 1: calculate the model implied covariance matrix BETA &lt;- matrix(c(0, 0, 0, 0, 0, 0, 0, 0, .5,.5, 0,.5, 0, 0,.5, 0), nrow=4,ncol=4,byrow=TRUE) PSI &lt;- matrix(c( 1,.5, 0, 0, .5, 1, 0, 0, 0, 0,.8,.5, 0, 0,.5,.7), nrow=4,ncol=4,byrow=TRUE) IDEN &lt;- diag(1,4,4) SIGMA &lt;- solve(IDEN-BETA) %*% PSI %*% t(solve(IDEN-BETA)) obsnames = c(&quot;y1&quot;,&quot;y2&quot;,&quot;y3&quot;,&quot;y4&quot;) dimnames(SIGMA) &lt;- list(obsnames,obsnames) ## STEP 2: fit model to the covariance matrix from step 1 EmpiricalCheck &lt;- &#39; # regressions y4 ~ b43*y3 y3 ~ b32*y2 + b31*y1 + b34*y4 # residual (co)variances y1 ~~ p11*y1 y2 ~~ p22*y2 y3 ~~ p33*y3 y4 ~~ p44*y4 y3 ~~ p43*y4 # covariance exogenous variables y1 ~~ p21*y2 &#39; EmpiricalCheckOut &lt;- lavaan(EmpiricalCheck, sample.cov=SIGMA, sample.nobs=100, likelihood = &quot;wishart&quot;, fixed.x=FALSE) ## Warning: lavaan-&gt;lav_model_vcov(): ## Could not compute standard errors! The information matrix could not be inverted. This may ## be a symptom that the model is not identified. summary(EmpiricalCheckOut) ## lavaan 0.6-19 ended normally after 21 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 100 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y4 ~ ## y3 (b43) 0.500 NA ## y3 ~ ## y2 (b32) 0.383 NA ## y1 (b31) 0.383 NA ## y4 (b34) 0.850 NA ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y4 ~~ ## .y3 (p43) 0.056 NA ## y2 ~~ ## y1 (p21) 0.500 NA ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## y1 (p11) 1.000 NA ## y2 (p22) 1.000 NA ## .y3 (p33) 0.265 NA ## .y4 (p44) 0.700 NA The output for the empirical check of Model 2 does not lead to the same parameter estimates as we used in Step 1. Therefore, we can be sure that this model is not identified. Appendix Algebraic assessment of identification using elements of \\(\\mathbf\\Sigma_{\\text{population}}\\) and \\(\\mathbf\\Sigma_{\\text{model}}\\) \\[\\begin{equation} \\beta_{31} = \\frac{\\sigma_{31}-\\frac{\\sigma_{32}-\\beta_{31}\\psi_{21}}{\\psi_{22}}\\psi_{21}}{\\psi_{11}} \\tag{7.9} \\end{equation}\\] \\[\\begin{align} \\beta_{31}\\psi_{11} &amp; = \\sigma_{31}-\\frac{\\sigma_{32}\\beta_{31}\\psi_{21}}{\\psi_{22}}\\psi_{21} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (7.09a)\\\\ \\\\ \\beta_{31}\\psi_{11}\\psi_{22} &amp; = \\sigma_{31}\\psi_{22} - (\\sigma_{32}-\\beta_{31} \\psi_{21})\\psi_{21} \\ \\ \\ \\ \\ \\ \\ \\ (7.09b)\\\\ \\\\ \\beta_{31}\\psi_{11}\\psi_{22} &amp; = \\sigma_{31}\\psi_{22} - \\sigma_{32}\\psi_{21} + \\beta_{31}\\psi^2_{21} \\ \\ \\ \\ \\ \\ \\ \\ (7.09c)\\\\ \\\\ \\beta_{31}\\psi_{11}\\psi_{22} - \\beta_{31}\\psi^2_{21} &amp; = \\sigma_{31}\\psi_{22} - \\sigma_{32}\\psi_{21} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (7.09d)\\\\ \\\\ \\beta_{31}(\\psi_{11}\\psi_{22} -\\psi^2_{21}) &amp; = \\sigma_{31}\\psi_{22} - \\sigma_{32}\\psi_{21} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (7.09e) \\end{align}\\] \\[\\begin{equation} \\beta_{31} = \\frac{\\sigma_{31}\\psi_{22}-\\sigma_{32}\\psi_{21}}{\\psi_{11}\\psi_{22}-{\\psi_{21}}^2} \\tag{7.10} \\end{equation}\\] \\[ \\begin{align} \\sigma_{33} = \\dots \\ \\ \\Longleftrightarrow \\ \\ \\psi_{33} = \\dots \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (7.13) \\end{align} \\] Substituting Equations (7.2), (7.3), (7.4), (7.11) and (7.13) into Equation (7.13) gives: \\[\\begin{equation} \\sigma_{33} = \\frac{\\sigma_{11}\\sigma_{22}\\sigma_{33}-2\\sigma_{21}\\sigma_{31}\\sigma_{32}-\\sigma_{11}\\sigma^2_{32}-\\sigma_{22}\\sigma^2_{31}\\sigma_{33}\\sigma^2_{21}}{\\sigma_{11}\\sigma_{22}\\sigma^2_{21}} \\tag{7.14} \\end{equation}\\] \\[\\begin{equation} \\sigma_{41} = \\dots 🡘 \\beta_{43} = \\frac{\\sigma_{41}}{\\beta_{31}\\psi{11} + \\beta_{32}\\psi_{21}} \\tag{7.15} \\end{equation}\\] Substituting Equations (7.2), (7.4), (7.11) and (7.13) into Equation (7.15) gives: \\[\\begin{equation} \\beta_{43} = \\frac{\\sigma_{41}}{\\sigma_{31}} \\tag{7.16} \\end{equation}\\] Although, to identify \\(\\beta_{43}\\), we can also use: \\[\\begin{equation} \\sigma_{42} \\Longleftrightarrow \\beta_{43} = \\frac{\\sigma_{42}}{\\beta_{31}\\psi_{21} + \\beta_{32}\\psi_{22}} \\tag{7.17} \\end{equation}\\] Substituting Equations (7.2), (7.3), (7.11) and (7.12) into Equation (7.17) gives: \\[\\begin{equation} \\beta_{43} = \\frac{\\sigma_{42}}{\\sigma_{31}} \\tag{7.18} \\end{equation}\\] So, now we already have two identifications of \\(\\beta_{43}\\), and we can also use: \\[ \\sigma_{43} = \\dots \\ \\ \\Longleftrightarrow \\ \\ \\beta_{43} = \\dots \\ \\ \\ , \\] yielding: \\[\\begin{equation} \\beta_{43} = \\frac{\\sigma_{43}}{\\sigma_{33}} \\tag{7.19} \\end{equation}\\] Equations (7.16), (7.17) and (7.19) show three identifications of \\(\\beta_{43}\\). \\(\\sigma_{44}\\) identifies \\(\\psi_{44}\\), through: \\[ \\sigma_{44} = \\dots \\ \\ \\Longleftrightarrow \\ \\ \\psi_{44} = \\dots \\ , \\] and substitution: \\[\\begin{equation} \\psi_{44} = \\sigma_{44} - \\sigma_{33}\\beta^2_{43} \\tag{7.20} \\end{equation}\\] Which is identified after substituting either Equation (7.16), (7.18) or (7.19). "],["ch8.html", "8 Autoregression 8.1 Autoregression models with predictors 8.2 Cross-lagged panel models References", " 8 Autoregression In an autoregression (or autoregressive) model, the observed variables are the same variable, measured at different time points. Each observed variable regresses on the same variable at the previous measurement occasion. Hence the term “autoregression”. An autoregression model allows us to study interindividual change. The direct effects between subsequent timepoints indicate how stable the ordering of individuals is across time. Therefore, the direct effects are also called “stability coefficients”. A simple autoregression model with four measurement occasions (collected in four years) is depicted in Figure 8.1. This example is taken from Duncan and Duncan (1996), who conducted a longitudinal study of alcohol use among adolescents. A sample of 321 adolescents were surveyed annually over a 4-year period, in which they indicated their alcohol consumption. Figure 8.1: Simple autoregression model. Script 8.1 fits this model to the data of Duncan and Duncan (1996). Script 8.1 ## observed data obsnames &lt;- c(&quot;year1&quot;,&quot;year2&quot;,&quot;year3&quot;,&quot;year4&quot;,&quot;gender&quot;,&quot;famstat&quot;) values &lt;- c(1.000, .640, 1.000, .586, .670, 1.000, .454, .566, .621, 1.000, .001, .038, .118, .091, 1.000, -.214, -.149, -.135, -.163, -.025, 1.000) SD &lt;- c(1.002,.960,.912,.920,.504,.498) duncancov &lt;- getCov(x=values, names = obsnames, sds = SD) names(duncanmeans) &lt;- obsnames ## define model duncanmodel &lt;- &#39; # COVARIANCES # regression equations year4 ~ b43*year3 year3 ~ b32*year2 year2 ~ b21*year1 # residual variances year4 ~~ p44*year4 year3 ~~ p33*year3 year2 ~~ p22*year2 # variance exogenous variable year1 ~~ p11*year1 &#39; ## run model duncanmodelOut &lt;- lavaan(duncanmodel, sample.cov=duncancov, sample.nobs=321, likelihood = &quot;wishart&quot;, fixed.x=FALSE) ## output summary(duncanmodelOut, fit = TRUE) The autoregression model is actually a simple path model. For the covariance structure we define the direct effects between the observed variables (matrix \\(\\mathbf{B}\\)) and the (residual) variances (matrix \\(\\mathbf{\\Psi}\\)). If an autoregressive model doesn’t explain the correlations between measurements well enough, one could add ‘second order autoregressive effects’. In Figure 8.1 this would be a direct effect of Year 1 on Year 3, and a direct effect of Year 2 on Year 4. A common practice in autoregression models is to constrain the autoregression effects (i.e., the direct effects between the measurements) to be equal. This is done by providing equal labels for these effects in the \\(\\mathbf{B}\\) matrix: # regression equations year4 ~ Beq*year3 year3 ~ Beq*year2 year2 ~ Beq*year1 The difference in model fit between the model without equality constraints on the regression coefficients and the model with the equality constraints on the regression coefficients, can be used to determine whether this equality constraint is tenable. It is only theoretically justifiable to make this constraint if the lag (time between measurements) is equal. Because causal effects take time to occur, the size of the effect depends on the lag between measurements. For example, effects typically grow stronger for a short duration after the first measurement, but then the effect grows weaker over time. So when you report estimated autoregressive effects, make sure to be clear that the estimate applies only to the lag between those occasions (in this example, 1 year). 8.1 Autoregression models with predictors If an autoregression model fits the data well, predictors can be added to the model. These predictors are usually entered as exogenous variables, with a direct effect on the first measurement. When the predictor variable represents an intervention that took place after the first measurement, one would only add direct effects of that predictor on timepoints after the intervention. Script 8.2 fits an autoregression model, with second order autoregression effects, and ‘gender’ and ‘family status’ as predictors to the same data of Duncan and Duncan (1996) as in Script 8.1. This model is depicted in Figure 8.2. Figure 8.2: Simple autoregression model, including predictor variables. Script 8.2 ## define model duncanmodel &lt;- &#39; # COVARIANCES # regression equations year4 ~ b43*year3 + b42*year2 year3 ~ b32*year2 + b31*year1 year2 ~ b21*year1 year1 ~ b15*gender + b16*famstat # residual variances year4 ~~ p44*year4 year3 ~~ p33*year3 year2 ~~ p22*year2 year1 ~~ p11*year1 # (co)variance exogenous variable gender ~~ p55*gender famstat ~~ p66*famstat gender ~~ p65*famstat&#39; ## run model duncanmodelOut &lt;- lavaan(duncanmodel, sample.cov=duncancov, sample.nobs=321, likelihood = &quot;wishart&quot;, fixed.x=FALSE) ## output summary(duncanmodelOut, fit = TRUE) If the fit of a model where only the first measurement is regressed on the predictors is not satisfactory, one might consider adding direct effects of the predictors on later measurements as well. The conceptual difference between those two models would be their theoretical interpretation. In the example above, the predictors only affect later outcomes indirectly, so this model represents the hypothesis that any sex or family differences that existed at Time 1 do not change over time. A model with additional direct effects of predictors on later outcomes would represent the hypothesis that group differences change over time. The \\(\\Delta\\chi^2\\) statistic allows you test the null hypothesis of no change in sex or family differences over time by comparing nested models with and without those additional effects. 8.2 Cross-lagged panel models If more than one variable are measured at several time points, one could also evaluate so called ‘cross-lagged effects’ in a cross-lagged panel model. These are the effects of one variable on the other at a later time point. Suppose that in the earlier example the researchers did not only have measures of alcohol consumption (\\(x\\)) across four years, but also of depression (\\(\\mathrm{y}\\)). The model in Figure 8.2 can be used to evaluate the effect of alcohol consumption in year 1 on depression in year 2, controlled for depression in year 1 (and the effect of depression in year 2 on alcohol consumption in year 3, controlled for alcohol use in year 2, and so on for later time points). The residual factors (\\(ζ\\)) of different variables at the same time point are often correlated, representing that the same unobserved variables may affect the responses on the two variables. For more information on cross-lagged panel models see Biesanz (2012). Figure 8.3: Cross-lagged panels. References Biesanz, J.C. (2012). Autoregressive longitudinal models. In Hoyle, R.H. (Ed.), Handbook of Structural Equation Modeling (pp. 459-471). New York: Guilford Press. Duncan, S. C. &amp; Duncan, T. E. (1996). A multivariate latent growth curve analysis of adolescent substance use. Structural Equation Modeling, 3, 323-347. "],["ch9.html", "9 Model Specification and Model Identification 9.1 From theory to model 9.2 Model parsimony 9.3 A priori model specification 9.4 Post hoc model modification 9.5 Backward and forward specification searches 9.6 Correlation residuals 9.7 Modification indices 9.8 Cross-validation 9.9 Calculating correlation residuals in lavaan References", " 9 Model Specification and Model Identification 9.1 From theory to model Structural equation modelling is a confirmatory technique, i.e., we specify a model that we believe to be true in the population and test whether the specified model fits the data that we have obtained. In principle, the hypothesized model that will be fitted to the data is formulated before the data are collected. Following the stages of the in the empirical cycle as formulated by A. D. de Groot (1961), one starts with observation (the researcher observes something that deserves investigation, for example, that perfectionistic parents often have anxious children), followed by induction (reflection on, or formulation of, theories that may explain the observed phenomena), followed by deduction (the formulation of testable research hypotheses that would be implied by theory, for example, that perfectionism of parents leads to over-controlling parenting behaviour, which in turn leads to anxiety in their children). The next stage is testing the hypothesis using data. This is the phase in which the structural model that represents the research hypotheses is tested against reality (i.e., data). The last phase is evaluation, which may possibly lead to new hypotheses or revision of the theory. Figure 9.1: Empirical Cycle. If there are competing theories, that each postulate a different model based on the same variables, researchers may use SEM to test the models corresponding to the different theories and select the model that fits the data best. 9.2 Model parsimony As a researcher, you want to end up with a model that is “simple,” but that is still a good reflection of reality. In SEM, one indication of the simplicity or parsimony of a model is the degrees of freedom. For a given number of observed variables, the more degrees of freedom a model has, the more parsimonious the model (i.e., the less parameters it has, and thus the less complex the model). However, complex models with more parameters generally fit the data better. Unfortunately, this is not necessarily because the model is a more accurate description of reality; rather, freeing parameters in a data-driven way often leads to a model that is fit to sample-specific nuances. Finding the balance between parsimony and accuracy is a difficult issue. A famous principle that refers to this issue is Ockham’s razor, or the “law of parsimony” which Albert Einstein translated into the advice: “Everything should be kept as simple as possible, but no simpler”. 9.3 A priori model specification Very often, researchers plan to fit several models. For example, if the goal is to test a mediation hypothesis, one may first fit a model with an indirect effect only, and subsequently add the direct effect to test partial mediation. Or in a full SEM model, it is common to use “two-step modeling”, which means that one first tests the measurement model, without imposing a structure on the correlations between latent variables. Only if the measurement model is accepted, one continues with specifying a path model or factor model on the latent variables. Sometimes, the hypotheses that the researchers want to tests aren’t only about the overall fit of the model, but about specific parameters in a model. For example, researchers may want to test whether certain parameters in the model are equal. This can be tested by fitting a model with and without equality constraints on these parameters, and investigate whether the fit of the model with the equality constraint is significantly worse than the fit of the model without the constraint. As long as the models that will be fitted, and the hypotheses that will be answered by these models, are formulated before looking at the data, this practice can still be called confirmatory. This is not the case if the model modifications are purely based on statistics, as will be described next. 9.4 Post hoc model modification Often, researchers just test one theoretical model. When the model does not fit the data well, we might need to reject the notion that the model (i.e., the theory) is a true reflection of reality. When this model does not fit the data well, the model is usually modified in order to obtain better model fit. The process of sequential model modification is also called a specification search. As post-hoc model modifications (modifications to the model based on information obtained after fitting the model to the data) are inherently data-driven, they are exploratory by nature. They should be executed with great care, as they often do not lead to a model that generalizes to other samples (MacCallum, 1986). To reduce the risk of ending up with a completely sample-specific model, the specification search should always be guided by theoretically meaningful modifications. Additional strategies to reduce the risk of meaningless data-driven model modifications are to formulate a pre-specified set of parameters that are candidates for modification, to fit the model on data from large samples, and formulate the initial model very carefully. Post-hoc model modification is a data-based approach, so any final model should be evaluated as stemming from an exploratory analysis strategy, which needs to be validated in other samples. It is also important to realize that by adding parameters to the model, the discrepancies between \\(\\mathbf{\\Sigma}_{\\text{population}}\\) and \\(\\mathbf\\Sigma_{\\text{model}}\\) will decrease, and thus the \\(χ^2\\) value will become closer to zero. However, models with more parameters are also more complex and can lead to unnecessary parameters that take on meaningless values. We should strive for models that are parsimonious and can be clearly understood. So, both with the originally hypothesized model and with modified models, one needs to balance trying to find a simple and interpretable model, and arriving at good model fit. 9.5 Backward and forward specification searches When altering a model post-hoc, there are basically two different strategies, and these strategies should not be mixed. The backward specification search involves fitting a model with many parameters, more than expected based on the theory, and then removing parameters one by one if they are not considered statistically significant. This is also called model trimming. The more popular strategy is the forward specification search, called model building. With model building one starts with a parsimonious model that only includes the parameters that are expected by theory, and add parameters when the model does not fit. The researcher can get information about which parameters will likely improve the fit of a model by inspection of correlation residuals or modification indices. If a model doesn’t fit the data, it means that the model isn’t explaining the variances and covariances of the variables well; that is, the discrepancy between \\(\\hat{\\mathbf{\\Sigma}}_{\\text{population}}\\) and \\(\\hat{\\mathbf\\Sigma}_{\\text{model}}\\) is substantial according to the fit criteria. It may be that all covariances are very different, but it could also be that the model appropriately models the relations between some variables, but doesn’t sufficiently account for the covariances between other variables. In this case, adding parameters specifically to model the unexplained covariance may be sensible. Correlation residuals and modification indices can be used to find out from which part of the model the largest misfit arises. 9.6 Correlation residuals Covariance residuals are the differences between the observed and model-implied covariances. That is, the matrix of covariance residuals equals the matrix of observed sample variances and covariances minus the estimated model implied matrix of variances and covariances (i.e., \\(\\mathbfΣ_{\\text{sample}} - \\hat{\\mathbf\\Sigma}_{\\text{model}}\\)). Covariance residuals have no common scale, which makes them difficult to interpret. Therefore, it may be helpful to consider the correlation residuals instead. Correlation residuals are calculated by standardizing the observed and model-implied covariance matrices, then subtracting the model-implied from the sample correlation matrix (i.e., \\(\\mathbfΣ^*_{\\text{sample}} - \\hat{\\mathbf\\Sigma}^*_{\\text{model}}\\)). Table 1 shows the correlation residuals for the full mediation model of child anxiety (i.e., the model without direct effects of Parent Anxiety and Parent Perfectionism on Child Anxiety). It can be seen that some correlations are fully explained by the model, leading to a correlation residual of zero. The correlation residual between Parental Anxiety and Child Anxiety is the largest. If a correlation residual for two variables is large, there is unmodeled dependency. As a general rule of thumb, correlation residuals with an absolute value larger than .10 are often regarded as being large. Thus, the correlation residual between Parent Anxiety and Child Anxiety lies outside the cut-off value of .10 and therefore can be considered large. Now, the researchers has to think about which parameter could be added to explain the dependency between these variables better. Here, one can choose between a direct effect or a covariance. If there are no clear ideas about the directionality of the effect, adding a covariance may be the best option. In the current example, a direct effect of PA on CA seems to make the most sense, as we already included an indirect effect of PA on CA in the model. Adding a direct effect would mean that the effect of PA and CA is not fully, but partially mediated by over-control. If a parameter is added to the model, the correlation residuals will change. Therefore, one should recalculate the correlation residuals after each model modification. Table 1. Correlation residuals for the full mediation model of child anxiety model Parental Anxiety Perfectionism Overcontrol Child Anxiety Parental Anxiety .000 Perfectionism .000 .000 Overcontrol .000 .000 .000 Child Anxiety .272 .034 .000 .000 9.7 Modification indices Another option to investigate which possible modifications to the model could improve model fit is to look at so-called Modification Indices (MIs). MIs provide a rough estimate of how much the \\(χ^2\\) test statistic of a model would decrease if a particular fixed (or constrained) parameter were freely estimated. The size of a MI can be evaluated relative to a \\(χ^2\\) distribution with 1 \\(df\\). So, with a significance level of .05, one could call a MI larger than 3.84 significant. To control the inflation of Type I error rates due to multiple testing, it is recommended to (a) plan a priori which parameters’ modification indices you will inspect and (b) use a Bonferroni adjusted \\(α\\) level to select your critical value. For instance, the full mediation model for child anxiety only has df = 2, so you should choose no more than two modification indices to inspect. A Bonferroni-adjusted \\(α = .05 / 2 = .025\\) would yield a \\(χ^2\\) critical value of 5.02 (for a 1-\\(df\\) test). This is analogous to using a post hoc method (e.g., Tukey, Bonferroni, or Scheffé) to compare pairs of group means following a significant omnibus \\(F\\) test in ANOVA. MIs depend on sample size. The larger the sample, the larger the modification indices. So, with large sample sizes, small misfit may already lead to large MIs. Therefore, it is useful to inspect the expected parameter change (EPC) as well. The EPC gives an indication of how a specific parameter would change if it were freely estimated. If a MI is high, but the EPC is very low, addition of the parameter would not add much to the model substantively. In addition, to enable comparison of EPCs it is often convenient to inspect the standardized version of the EPC (SEPC), where values larger than .10 are considered to be substantial (Saris &amp; Stronkhorst, 1984). Note that MIs are univariate indices. As soon as parameter is added to (or removed from) the model, all MIs might change. Therefore, one should inspect MIs after each model modification. Table 2 shows the MIs and SEPCs for the full mediation model of child anxiety. As you can see, the MIs are given for every parameter that is not in the model, even for parameters that do not really make sense or are mathematically not possible to add. For example, you see a MI for the direct effect of Child Anxiety on Overcontrol, as well as a covariance between these two variables. It would be strange to add one of these parameters to the model, because we already specified a direct effect from Overcontrol on Child Anxiety. Both in terms of interpretation and in terms of estimation (i.e., the model would become nonrecursive), it would be difficult to add these parameters to the model. So, as a researcher, you have to make sure to evaluate the appropriateness of parameters to be added. In the current example, the highest MI is for a covariance between CA and PA, while the MI of a direct effect of PA on CA is very similar. This is because freeing either one of these parameters would lead to an equivalent model (not equivalent in interpretation, but statistically equivalent because both models would result in the same model-implied covariance matrix). Theoretically, it makes more sense to assume that Parental Anxiety affects Child Anxiety than the other way around. Therefore, a direct effect of PA on CA seems to be the most sensible parameter to add. Table 2. Modification indices for the full mediation model of child anxiety. Parameter MI SEPC Covariance: child_anx \\(↔\\) parent_anx 6.871 .264 Direct effect: child_anx \\(\\leftarrow\\) parent_anx 6.716 .292 Direct effect: parent_anx \\(\\leftarrow\\) child_anx 6.871 .290 Direct effect: overcontrol \\(\\leftarrow\\) child_anx 2.076 −.459 Covariance: child_anx \\(↔\\) overcontrol 2.076 −.418 Direct effect: perfectionism \\(\\leftarrow\\) child_anx .598 −.087 Direct effect: child_anx \\(\\leftarrow\\) perfectionism .109 .038 Covariance: perfectionism \\(↔\\) child_anx .598 −.079 The lavaan Script 9.0 below demonstrates how to make a minor model adjustment, such as adding a single parameter. Note that the model syntax does not need to be a single character string, but can be a vector of character strings, so we do not need to write out the whole model again. The new model can be fit to the data using all the same lavaan() arguments in Script 3.1, or we can use the update() function as a shortcut. Any specified arguments will replace the original model-fit arguments found in the object AWmodelOut. The first argument to lavaan() is called model), so we provide our new model syntax. All other (unspecified) arguments will be the same when the new model is fit, saving the results in the object AWmodel2Out. 9.7.1 Script 9.0 # add a direct effect of Parent Anxiety on Child Anxiety to the path model AWmodel2 &lt;- c(AWmodel, &#39; child_anx ~ b41* parent_anx &#39;) # fit the new model by &quot;updating&quot; the original model AWmodel2Out &lt;- update(AWmodelOut, model = AWmodel2) In our illustrative example of child anxiety, the partial mediation model (where the regression of child anxiety on parent anxiety is added to the model) yields the following test result: \\(χ^2(1) = 0.397\\), \\(p = .53\\). Thus, the \\(χ^2\\) value is no longer significant (at \\(α = .05\\)), so the null hypothesis of exact fit cannot be rejected. This gives support to the notion that the model gives a true description of reality. However, one could question the parsimony of this model with a single degree of freedom. The size of the direct effect in standardized metric is estimated to be .292, which is substantial. Note that the actual value matches the SEPC in Table 2 to the third decimal place. Expected and actual estimated values will not always correspond so perfectly, but they will typically be very close. 9.8 Cross-validation When post hoc model modification is used, one is actually not testing hypotheses anymore, but one is generating hypotheses based on the data under consideration. That is, it falls under exploratory research, and its results carry less scientific certainty than the results of confirmatory research. Future research could focus on trying to replicate the findings based on the final model from exploratory research. 9.9 Calculating correlation residuals in lavaan The residual() function (or resid() for short) provides covariance residuals by default, but you can request correlation residuals with an additional argument: resid(AWmodelOut, type = &quot;cor&quot;) ## the default standardization method is Bollen&#39;s (1989) formula resid(AWmodelOut, type = &quot;cor.bollen&quot;) ## optionally, arrange rows &amp; columns to match input order resid(AWmodelOut, type = &quot;cor&quot;)$cor[obsnames, obsnames] First, we created two objects that contain the sample (ssam) and model-implied (smod) covariance matrices. Although the sample covariance matrix is available as the object AWcov that was used as input data, this would not be the case if raw data were analysed. And although we could calculate the sample covariance matrix for complete data using the cov() function, when there are missing data, covariance and correlation residuals must be calculated using the estimated covariance matrix (also called the EM matrix) that is obtained by fitting the saturated model to the partially observed data. Thus, the most error-free way to extract this information from lavaan is to use the lavInspect() function to extract the sample statistics, or “sampstat” for short. Likewise, the model-implied covariance matrix can be extracted by requesting “cov.ov” (i.e., the model-implied covariance between observed variables). # extract the sample covariance matrix ssam &lt;- lavInspect(AWmodelOut, &quot;sampstat&quot;)$cov[obsnames, obsnames] # extract the model-implied covariance matrix smod &lt;- lavInspect(AWmodelOut, &quot;cov.ov&quot;)[obsnames, obsnames] These matrices need to be standardized. This is done with the R function cov2cor(), which transforms a covariance matrix to a correlation matrix. The model-implied correlation matrix is then subtracted from the observed correlation matrix, and we print the result rounded to the third decimal place: corres &lt;- cov2cor(ssam) - cov2cor(smod) round(corres, 3) The last two lines are optional, but may help you find the large (&gt; .10) and largest residuals, respectively, indicated by cells saying TRUE. abs(corres) &gt;= .10 abs(corres) == max(abs(corres)) The matrix of correlation residuals for the AW-model is given below. parent_anx perfect overcontrol child_anx parent_anx 0.000 0.000 0.000 0.272 perfect 0.000 0.000 0.001 0.034 overcontrol 0.000 0.001 0.000 0.001 child_anx 0.272 0.034 0.001 0.000 Note that there is also a slightly different formula available, which is implemented in Bentler’s (1995) EQS software. Rather than standardizing each matrix with respect to their own \\(SD\\)s, then subtracting them, Bentler proposed subtracting the unstandardized covariance matrices, then standardizing the differences with respect to the observed-variable \\(SD\\)s only. Script 8.2 shows how to request these correlation residuals from lavaan, as well as how the procedure to calculate them differs. ### Script 9.2 ### ## request Bentler&#39;s (1995) formula round(resid(AWmodelOut, type = &quot;cor.bentler&quot;)$cor[obsnames, obsnames], 3) ## MANUAL PROCEDURE: ## calculate covariance residuals covres &lt;- ssam - smod ## standardize covariance residuals to make correlation residuals SDs &lt;- diag(sqrt(diag(ssam))) corres &lt;- solve(SDs) %*% covres %*% solve(SDs) dimnames(corres) &lt;- list(obsnames, obsnames) round(corres, 3) n this case, you will not notice any difference between the two procedures. The reason is that when no constraints are placed on the (residual) variance estimates, the estimated values will be chosen such that the model-implied total variance will exactly reproduce the observed total variance. In such situations, there is no practical difference between the two formulae. In situations where the variances are constrained (see, for example, later chapters on strict measurement invariance), the two formulae will diverge, and neither is “right” or “wrong” because they are both standardized, but with respect to different criteria. Because Bollen’s (1989) formula standardizes the observed and model-implied matrices first, the diagonals will always be 1 by definition, so diagonal elements of the correlation-residual matrix will always be \\(1 – 1 = 0\\). Bentler’s (1995) formula, on the other hand, might be more helpful to identify invalid constraints on (residual) variances because the differences between observed and model-implied variances are calculated first, then standardized with respect to how large the “true” observed variances are. 9.9.1 Requesting MIs and (S)EPCs in lavaan In lavaan, MIs and EPCs can be inspected using the modificationIndices() function. This function returns a data frame with the complete list of model parameters that are fixed to a specific value (i.e., not for equality constraints), and prints each associated MI and (standardized and unstandardized) EPC. Using the following commands, the data frame is sorted with the highest MIs printed first. Also, we can specify a minimum value (i.e., a critical value, crit) to display only MIs that might be considered significant. Here, we define it as a \\(1-df\\) \\(χ^2\\) value corresponding to \\(α = .05\\): crit &lt;- qchisq(.05, df = 1, lower.tail = FALSE) modificationIndices(AWmodelOut, sort. = TRUE, minimum.value = crit) The output for all nonzero MIs from the model are given below. lhs op rhs mi epc sepc.lv sepc.all sepc.nox 12 child_anx ~~ parent_anx 6.871 6.945 6.945 0.264 0.264 18 parent_anx ~ child_anx 6.871 1.009 1.009 0.290 0.290 15 child_anx ~ parent_anx 6.716 0.084 0.084 0.292 0.292 You can also request that MIs be printed at the bottom of the summary() output, but you have no options to sort or subset them: summary(AWmodelOut, modindices = TRUE) References Bentler, P. M. (1995). EQS structural equations program manual. Encino, CA: Multivariate Software. Bollen, K. A. (1989). Structural equations with latent variables. Hoboken, NJ: Wiley. MacCallum, R. C. (1986). Specification searches in covariance structure modelling. Psychological Bulletin, 100(1), 107–120. doi:10.1037/0033-2909.100.1.107 Saris, W. E., &amp; Stronkhorst, H. (1984). Causal modelling in nonexperimental research: An introduction to the LISREL approach. Amsterdam, NL: Sociometric Research Foundation. "],["ch10.html", "10 Estimation 10.1 Improper Solutions 10.2 Specifying starting values in lavaan 10.3 Alternative estimators 10.4 Robust estimators 10.5 Requesting alternative and robust estimators in lavaan 10.6 Alternative calculation of the ML discrepancy function when analysing raw data 10.7 Using FIML to analyse raw data with missing values in lavaan References", " 10 Estimation In the chapter on identification we saw that model parameters can be written as a function of elements from \\(\\mathbf{\\Sigma}_\\text{population}\\). Subsequently, we can use these equations to estimate model parameters derived from the sample variances and covariances (\\(\\mathbf{\\Sigma}_\\text{sample}\\)). For just-identified models, the number of known elements in \\(\\mathbf{\\Sigma}_\\text{sample}\\) equals the number of unknown model parameters, and one can derive parameter estimates by solving the equations that satisfy \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) = \\(\\mathbf{\\Sigma}_\\text{sample}\\). For models that are over identified (i.e., that have positive \\(df\\)) the estimation of model parameters is more complicated. In our illustrative example of child anxiety, we can derive three different equations in terms of population variances and covariances (i.e., by rewriting the equations of \\(\\sigma_{41}\\), \\(\\sigma_{42}\\) and \\(\\sigma_{43}\\)) for the expression of the single model parameter \\(\\beta_{43}\\). When we subsequently want to use these equations to estimate the model parameter \\(\\hat\\beta_{43}\\) we can never derive an estimate so that all three elements \\(\\hat\\sigma_{41}\\), \\(\\hat\\sigma_{42}\\) and \\(\\hat\\sigma_{43}\\) of \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) are equal to the corresponding elements of \\(\\mathbf{\\Sigma}_\\text{sample}\\). Therefore, for over-identified models there will always be a certain amount of discrepancy between \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) and \\(\\mathbf{\\Sigma}_\\text{sample}\\). In such cases, the estimation of model parameters requires an iterative procedure to minimize the discrepancy between \\(\\mathbf{\\Sigma}_\\text{sample}\\) and \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) (i.e., What value of \\(\\hat\\beta_{43}\\)will lead to expressions of \\(\\hat\\sigma_{41}\\), \\(\\hat\\sigma_{42}\\) and \\(\\hat\\sigma_{43}\\) that are as close as possible to the corresponding elements in \\(\\mathbf{\\Sigma}_\\text{sample}\\)?). The estimation procedures are iterative because the initial solution (i.e., the first attempt to estimate model parameters and evaluate the discrepancy between \\(\\mathbf{\\Sigma}_\\text{sample}\\) and \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\)) is improved through subsequent cycles of calculations until the improvement in model fit falls below a predefined minimum value (i.e., the decrease in discrepancy between \\(\\mathbf{\\Sigma}_\\text{sample}\\) and \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) is very small). When this happens, the estimation process has converged. Convergence may be achieved more quickly when the initial solution, or the initial estimates of the parameters (i.e., start values) are reasonably accurate. If these initial estimates are completely inaccurate, then iterative estimation may even fail to converge. Most computer programs automatically generate reasonable start values and will give a warning if a solution has not converged. However, sometimes it may be necessary to provide user-specified start values in order for the solution to converge, especially for more complex models. Several discrepancy functions exist that can be used for the estimation of model parameters. Three desirable qualities of a good estimation procedure are unbiasedness, consistency and efficiency. Suppose we repeat the estimation procedure for a given model an infinite number of times on an infinite number of datasets. The estimator is unbiased when the expected parameter values (i.e., means of the sampling distributions of parameter estimates) are equal to the population values, i.e., they are not systematically biased upwards or downwards. The estimator is consistent when parameter estimates are closer to the population parameters with increased sample size, i.e., the larger the sample size, the closer the estimated values are to the population values (given that the sample is representative of the population). Efficiency refers to the variance of the sampling distribution of parameter estimates, where the most efficient estimator has a sampling distribution with the smallest variance (and thus the smallest \\(SE\\)s). The most intuitive method that could be used to minimize the discrepancies between \\(\\mathbf{\\Sigma}_\\text{sample}\\) and \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) is to simply calculate the difference between the two matrices and try to minimize the values within the resulting residual covariance matrix. This is what is commonly referred to as the unweighted least squares (ULS) discrepancy function1: \\[\\begin{equation} \\text{F}_\\text{ULS}(\\mathbf\\Sigma_{\\text{sample}}, \\hat{\\mathbf{\\Sigma}}_{\\text{model}}) = ½ \\text{trace}((\\mathbf\\Sigma_{\\text{sample}}, \\hat{\\mathbf{\\Sigma}}_{\\text{model}})^2), \\tag{10.1} \\end{equation}\\] which minimizes the squared deviations between the observed sample variances and covariances and the corresponding elements predicted by the model. If the deviations are zero (i.e., observed and model-implied matrices are identical), then \\(F_\\text{ULS}=0\\), indicating perfect fit. Any nonzero discrepancies yield a positive \\(F_\\text{ULS}\\). Minimizing \\(F_\\text{ULS}\\) yields unweighted least squares (ULS) estimates of all the model parameters given by Equations (3.9) and (3.10), under the assumption that the model is valid and identified. It leads to unbiased and consistent estimates of model parameters, and does not require that the observed variables have a particular distribution. However, it is not the most efficient estimator. A particularly attractive discrepancy function is given by: \\[\\begin{equation} \\text{F}_{\\text{ML}}(\\mathbf\\Sigma_{\\text{sample}}, \\hat{\\mathbf{\\Sigma}}_{\\text{model}}) = \\log|\\hat{\\mathbf{\\Sigma}}_{\\text{model}}|-\\log|\\mathbf{\\Sigma}_{\\text{sample}}| + \\text{trace}(\\mathbf{\\Sigma}_{\\text{sample}}\\hat{\\mathbf{\\Sigma}}^{-1}_{\\text{model}})-p, \\tag{10.2} \\end{equation}\\] which gives so-called maximum likelihood (ML) estimates of all model parameters, assuming that the distribution of the scores of the observed variables (\\(p\\)) is multivariate normal and that the model is valid and identified. It is the most widely used fitting function for general structural equation models, and the estimator is unbiased, consistent and more efficient than ULS. Although it is a more complex nonlinear function, it has additional important properties. First, it allows for tests of statistical significance of parameter estimates as the estimators are asymptotically normally distributed. Second, unlike \\(F_\\text{ULS}\\), \\(F_\\text{ML}\\) is scale invariant and scale free. These properties refer to the dependency of the fitting function on the units of measurement of the observed variables. When the fitting function is scale invariant, the value of the fit function is independent of the measurement scales of the variables, i.e., the value of the fit function will be the same for different scales of measurement. In addition, scale-freeness refers to the property that when the scales of the observed variables are linearly transformed (i.e., multiplied by and/or added to a constant), the relationship between the parameter estimates of the transformed and untransformed solution can be derived too (i.e., they are linearly transformed in a similar fashion). In general, smaller values of discrepancy functions indicate better fit of the model to the data. A value of zero indicates the fit is perfect, i.e., the parameter estimates can perfectly reproduce the sample covariance matrix (\\(\\hat{\\mathbf{\\Sigma}}_\\text{model}=\\mathbf{\\Sigma}_\\text{sample}\\)). Using Equation (10.2) to arrive at ML estimates of model parameter of the path model from our illustrative example, yields: \\[ \\hat{\\mathbf{\\Sigma}}_\\text{model} = \\begin{bmatrix} 91.58 &amp; \\\\ 53.36 &amp; 194.32 \\\\ 28.39 &amp; 50.90 &amp; 130.19 \\\\ 2.05 &amp; 3.68 &amp; 9.41 &amp; 7.56 \\end{bmatrix} \\] whereas the observed variances and covariances of the sample are given by: \\[ \\mathbf{\\Sigma}_\\text{sample} = \\begin{bmatrix} 91.58 &amp; \\\\ 53.36 &amp; 194.32 \\\\ 28.39 &amp; 50.90 &amp; 130.19 \\\\ 9.21 &amp; 4.98 &amp; 9.41 &amp; 7.56 \\end{bmatrix} \\] When we compare \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) and \\(\\mathbf{\\Sigma}_\\text{sample}\\) from our illustrative example, we can see that there are some discrepancies between the two matrices. Specifically, the elements \\(\\hat{\\sigma}_{41}\\) and \\(\\hat{\\sigma}_{42}\\) of \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) are different from the corresponding sample covariance. These two elements featured in the equations for the over-identified model parameter \\(\\hat{\\beta}_{43}\\). As can be seen, the model parameter was estimated so that the element \\(\\hat{\\beta}_{43}\\) of \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\) equals the corresponding element of the sample covariance matrix, which thus leads to a misfit for the elements \\(\\hat{\\sigma}_{41}\\) and \\(\\hat{\\sigma}_{42}\\). The residual covariance matrix (i.e., \\(\\mathbf{\\Sigma}_\\text{sample} - \\hat{\\mathbf{\\Sigma}}_\\text{model}\\)) is: \\[ \\mathbf{\\Sigma}_{\\text{residual}} = \\begin{bmatrix} 0\\\\ 0&amp;0\\\\ 0&amp;0&amp;0\\\\ 7.2 &amp; 1.3 &amp; 0 &amp; 0 \\end{bmatrix} \\] This shows that the covariance between variable 4 (child anxiety) and variables 1 and 2 (parent anxiety and parent perfectionism) are underestimated by the model. When the residual values would be negative, this would indicate that the covariances are overestimated by the model. Model fit evaluation (which is the topic of Chapter 11) is used to evaluate whether the amount of misfit in these elements is substantial enough to reject the model, i.e., concluding that the specified model is not an adequate representation of the developmental process of child anxiety. It is important to note that models should only be fit to covariance matrices. Fitting a model to a correlation matrix without additional constraints yields incorrect \\(SE\\)s (Cudeck, 1989), so Wald \\(z\\) tests do not have nominal Type I error rates. 10.1 Improper Solutions Even when the estimation procedure has reached convergence, a researcher should always be aware of inadmissible solutions and so-called Heywood cases. Heywood cases refer to parameter estimates with an illogical value, like for example negative variance estimates, or estimated correlations with absolute values larger than 1.02. These kind of estimates have no plausible interpretations, and therefore such solutions are inadmissible. Sometimes the associated SEs of parameter estimates are very large (e.g., 999,999.99), which usually indicates that there is a problem with the model solution. Inadmissible solutions may be caused by several factors, including underidentification, misspecification, or bad starting values. Some computer programs give warnings that parameter estimates take on illogical values, but it is important to always carefully inspect all parameter estimates, unstandardized and standardized, to ensure that the solution is indeed admissible. Chen, Bollen, Paxton, Curran and Kirby (2001) describe the possible causes of, consequences of, and possible strategies to handle improper solutions in more detail. For instance, a Heywood case could result from either (a) model misspecification or (b) sampling error. So before trying to “fix” a Heywood case, one should first test the null hypothesis that the parameter is an admissible solution. For example, if the 95% CI for a residual variance includes positive values, then you cannot reject the null hypothesis (using α = .05) that the true population value is indeed positive; in this case, if the model fits well and there are no other signs of misspecification, you could conclude that the true parameter is simply close enough to zero that sampling error occasionally yields a negative estimate. 10.2 Specifying starting values in lavaan Methods for choosing default start values are quite excellent in modern SEM software such as Mplus and lavaan, so it is rarely necessary for a user to provide start values manually. However, it may be useful to know how to do so, particularly when having difficulty converging on a proper (or any) solution. There are three ways to provide non-default starting values in lavaan. The first two involve specifying them in the lavaan model syntax, either using the start() modifier: AWmodel &lt;- &#39; child_anx ~ start(0.666)*overcontrol &#39; Or you may use the ? operator: AWmodel &lt;- &#39; child_anx ~ 0.666?overcontrol &#39; Note that if you want to provide both a starting value and use other modifiers/operators (e.g., to fix a parameter or label it) on the same parameter, then you have to specify that parameter twice on the same line of syntax: AWmodel &lt;- &#39; child_anx ~ b43*overcontrol + start(0.666)*overcontrol &#39; 10.3 Alternative estimators Additional estimators are available, but are less often used with continuous data. For categorical data, however, covariance structure analysis is not appropriate, so some version of the weighted least-squares (WLS) estimator is typically used. WLS estimation is available for continuous data as well, although this special case of WLS is referred to in the SEM literature as the asymptotical distribution-free (ADF; Browne, 1984) estimator. The WLS fit function is: \\[\\begin{equation} \\text{F}_{\\text{WLS}}(\\mathbf{\\Sigma}_\\text{sample},\\hat{\\mathbf{\\Sigma}}_\\text{model}) = \\text{vech}(\\mathbf{\\Sigma}_\\text{sample} - \\hat{\\mathbf{\\Sigma}}_\\text{model})^{T} W^{-1} \\text{vech}(\\mathbf{\\Sigma}_\\text{sample} - \\hat{\\mathbf{\\Sigma}}_\\text{model}), \\tag{10.3} \\end{equation}\\] where vech() vectorizes the unique elements of its argument. The WLS fit function essentially incorporates higher-order information beyond the covariance matrix (specifically, kurtosis) into a weight matrix (the \\(W\\) matrix in Equation (10.3)). It is usually chosen to be the sampling covariance matrix of the elements in \\(\\mathbf{\\Sigma}_\\text{sample}\\). Equation (10.3) is a very general fit function, because in principle, any weight matrix can be used. If an identity matrix is used as the weight matrix, this yields the ULS estimator. The ML fit function (using Wishart likelihood for analyses of covariance structure only) can actually be conceived of as WLS where the weight matrix is derived from \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\). Likewise, there is also a “generalized” least-squares estimator (GLS), which can be conceived as WLS if the weight matrix would be derived from \\(\\mathbf{\\Sigma}_\\text{sample}\\). GLS also requires multivariate normality, but it is not as efficient as MLE, so there is no advantage in using GLS. Computers did not always have such great hardware (processing and memory) and software (optimization techniques to find ML solutions) that we are used to today. Therefore, GLS was popular 20 years ago when it was more common that SEM programs would fail to converge on a ML solution. Nowadays, most of the above estimators (ULS, GLS, ADF) are rarely, if ever, used. Not only is the ML estimator the most efficient (i.e., the smallest SEs), but being based on likelihoods comes with other advantages, such as being able to calculate likelihood-based information criteria (e.g., AIC and BIC) to compare models. Also, ADF requires extremely large sample sizes to be stable (i.e., \\(N\\) &gt; 2000 or 5000). Although MLE is based on asymptotic (“large-sample”) theory, sample sizes in the hundreds are often sufficient for stable solutions (or even ~120 for smaller models). 10.4 Robust estimators If data are not drawn from a multivariate normal population, then ML estimates are still consistent (and effectively unbiased, as sample size increases). However, the \\(SE\\)s tend to be underestimated and fit statistic inflated, both leading to inflated Type I error rates. If you have a sample size in the thousands, you could just use ADF. However, such large samples are rare for practicing behavioral researchers. A more practical solution is to “correct” the SEs and fit statistic so that they do yield nominal Type I error rates. The most often used correction for \\(SE\\)s is to use a “sandwich-type” estimator. The asymptotic covariance matrix of model parameters, \\(A\\), estimates how much model parameters would (co)vary from sample to sample. \\(SE\\)s are the square-roots of the diagonal elements of \\(A\\) (i.e., the sampling variances). If the normality assumption does not hold, then \\(A\\) is incorrect, but it can be corrected using a weight matrix, \\(W\\), calculated from the observed kurtosis. Without getting into the technical details, the term “sandwich” refers to the basic form of the matrix-algebra equation, in which \\(A\\) is the outer “break” and \\(W\\) is the “meat” (see Savalei, 2014, for more information). Several robust corrections for the fit statistic have been proposed. The Satorra–Bentler (2001) scaled test statistic is the most popular, but it requires complete data, whereas the Yuan–Bentler (2000) scaled test statistic (T2*) can be used with partially observed data (i.e., using full-information maximum likelihood)—they are asymptotically equivalent to each other (i.e., in large samples). These methods “scale” the actual distribution of the test statistic to have a mean that equals the df, which is the actual mean of the \\(\\chi^2\\) distribution. Satterthwaite-type methods also adjust the variance of the test statistic, so that its variance is approximately equal to the \\(\\chi^2\\) distribution’s (i.e., \\(2 \\times df\\)). Scaling and shifting the observed statistic will yield Type I error rates that are closer to the nominal \\(α\\) level. These scaled–shifted statistics are sometimes referred to as mean- and variance-adjusted statistics (e.g., in Mplus). Because the unadjusted \\(\\chi^2\\) fit statistic will have inflated Type I errors when the normality assumption is not met, a scaled test statistic usually indicates better fit. 10.5 Requesting alternative and robust estimators in lavaan The lavaan() function (and the cfa() and sem() wrappers) accept arguments to specify the desired estimator, type of test statistic, and method for calculating \\(SE\\)s. In the examples up until now, we have been using the defaults for normally distributed data. Below, we explicitly request those default arguments: AWmodelOut &lt;- lavaan(model = AWmodel, sample.cov = AWcov, sample.nobs = 77, likelihood = &quot;wishart&quot;, fixed.x = FALSE, estimator = &quot;ML&quot;, se = &quot;standard&quot;, test = &quot;standard&quot;) Alternative estimators can be requested easily; for example, to request GLS, simply use the argument estimator = \"GLS\". When analyzing categorical outcomes (see Chapter 23), the default will be switched to estimator = \"DWLS\" (diagonally weighted least squares). If you are analyzing raw data instead of summary statistics, robust \\(SE\\)s and fit statistics can be requested just as easily. For example, to request sandwich-type \\(SE\\)s, use the argument se = \"robust.sem\" with complete data or se = \"robust.huber.white\" with missing data (in combination with missing = \"FIML\"). To request a scaled test statistic, use the argument test = \"Satorra.Bentler\" with complete data or test = \"Yuan.Bentler\" with missing data (in combination with missing = “FIML”; see the following section for more information). Bootstrapping can be used to calculate \\(SE\\)s and the \\(p\\) value for the fit statistic by requesting both se = \"boot\" and test = \"boot\" (in addition to setting the number of bootstrap samples to use in the boot argument); bootstrapping the fit statistics is currently only available with complete data, although the semTools package includes a function (bsBootMiss()) to bootstrap fit with missing data. Because the popular SEM software Mplus uses a single shortcut to specify the choice of estimator, \\(SE\\)s, and fit statistic, many of those shortcuts are being used by applied researchers as though they are the names of the estimator itself (e.g., “MLR” for robust ML). Even if robust \\(SE\\)s and fit statistic are used, ML is still the estimation method use to obtain point estimates of parameters (i.e., assuming normality)—only the \\(SE\\)s and fit statistic are adjusted after parameters are estimated. Still, lavaan allows some of these shortcuts, which you can read about on the ?lavaan help page, in the description of the estimator argument. Likewise, the help page describes all other available estimators (e.g., \"PML\" for pairwise maximum likelihood), \\(SE\\)s (e.g., based on first-order derivatives), and test statistics (e.g., scaled and shifted, or mean- and variance-adjusted). 10.6 Alternative calculation of the ML discrepancy function when analysing raw data Equation (10.2) shows how to calculate \\(F_\\text{ML}\\) from summary statistics (i.e., observed (\\(\\mathbf{\\Sigma}_\\text{sample}\\)) and model-implied (\\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\)) covariance matrices). This equation only applies when analysing complete data. In practice, data are often partially observed. When some data are missing, it is still possible to use full-information maximum likelihood (FIML) estimation, where the likelihood of each individual is calculated using only the parameters relevant to the variables on which they have observed data. Individual \\(i\\)’s likelihood is calculated by plugging their vector of observed values (\\(\\mathrm{y}_i\\)) into the multivariate normal probability density function: \\[\\begin{equation} \\text{likelihood}(\\textbf{y}_i) = \\frac{1}{(2\\pi)^{p/2|\\mathbf{\\Sigma}|1/2}}\\mathrm{e}^{-\\frac{1}{2}(y_i-\\mu)&#39;\\mathbf{\\Sigma}^{-1}(y_i-\\mu)} \\tag{10.4} \\end{equation}\\] using the model-implied mean vector3 as \\(μ\\) and the model-implied covariance matrix as \\(\\mathbf\\Sigma\\), where \\(p\\) is the number of variables in \\(\\mathrm{y}_i\\). After calculating the likelihood for each row of data, the joint likelihood of observing the entire sample is the product4 of all the individual likelihoods. Because likelihoods are bound between 0 and 1, the joint likelihood becomes very small—too small even for computers to calculate with enough precision5. It is easier to work with log-likelihoods because the log of numbers ranging from 0 to 1 will range from \\(−\\infty\\) to 0 (so not as much precision is needed). Because the log of a product is equal to the sum of the individual logs—\\(\\log(a \\times b) = \\log(a) + \\log(b)\\)—we can simply add together all the individual log-likelihoods to calculate the log-likelihood of the sample. The log of equation (10.4) is: \\[\\begin{equation} \\ell_i = \\frac{p}{2}\\log(2\\pi) - \\log(|\\mathbf{\\Sigma}|) - \\frac{1}{2}(y_i-\\mu)&#39;\\mathbf{\\Sigma}^{-1}(y_i-\\mu) \\tag{10.5} \\end{equation}\\] In a model with 5 variables, person \\(i\\)’s vector \\(\\mathrm{y}_i\\) would have 5 observed values in it, the model-implied mean vector6 μ would have 5 means in it, and the model-implied covariance matrix \\(\\mathbf\\Sigma\\) would have 5 rows and 5 columns. If person \\(i\\) has complete data, all this information would be included in the calculation of equation (10.5): \\[ y_i = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ y_5 \\end{bmatrix} \\mu_i = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2\\\\ \\mu_3\\\\ \\mu_4\\\\ \\mu_5 \\end{bmatrix} \\mathbf{\\Sigma}_i = \\begin{bmatrix} \\sigma^2_1 &amp; \\sigma_{12} &amp; \\sigma_{13} &amp; \\sigma_{14} &amp; \\sigma_{15} \\\\ \\sigma_{21} &amp; \\sigma^2_2 &amp; \\sigma_{23} &amp; \\sigma_{24} &amp; \\sigma_{25} \\\\ \\sigma_{31} &amp; \\sigma_{32} &amp; \\sigma^2_3 &amp; \\sigma_{34} &amp; \\sigma_{35} \\\\ \\sigma_{41} &amp; \\sigma_{42} &amp; \\sigma_{43} &amp; \\sigma^2_4 &amp; \\sigma_{45} \\\\ \\sigma_{51} &amp; \\sigma_{52} &amp; \\sigma_{53} &amp; \\sigma_{54} &amp; \\sigma^2_5 \\end{bmatrix} \\] However, if person \\(i\\) was only observed on \\(\\mathrm{y}_1\\), \\(\\mathrm{y}_2\\), and \\(\\mathrm{y}_5\\): \\[ y_i = \\begin{bmatrix} y_1 \\\\ y_2 \\\\. \\\\ . \\\\ y_5 \\end{bmatrix} \\mu_i = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2\\\\ \\color{lightgrey}{\\mu_3} \\\\ \\color{lightgrey}{\\mu_4}\\\\ \\mu_5 \\end{bmatrix} \\mathbf{\\Sigma}_i = \\begin{bmatrix} \\sigma^2_1 &amp; \\sigma_{12} &amp; \\color{lightgrey}{\\sigma_{13}} &amp; \\color{lightgrey}{\\sigma_{14}} &amp; \\sigma_{15} \\\\ \\sigma_{21} &amp; \\sigma^2_2 &amp; \\color{lightgrey}{\\sigma_{23}} &amp; \\color{lightgrey}{\\sigma_{24}} &amp; \\sigma_{25} \\\\ \\color{lightgrey}{\\sigma_{31}} &amp; \\color{lightgrey}{\\sigma_{32}} &amp; \\color{lightgrey}{\\sigma^2_3} &amp; \\color{lightgrey}{\\sigma_{34}} &amp; \\color{lightgrey}{\\sigma_{35}} \\\\ \\color{lightgrey}{\\sigma_{41}} &amp; \\color{lightgrey}{\\sigma_{42}} &amp; \\color{lightgrey}{\\sigma_{43}} &amp; \\color{lightgrey}{\\sigma^2_4} &amp; \\color{lightgrey}{\\sigma_{45}} \\\\ \\sigma_{51} &amp; \\sigma_{52} &amp; \\color{lightgrey}{\\sigma_{53}} &amp; \\color{lightgrey}{\\sigma_{54}} &amp; \\sigma^2_5 \\end{bmatrix} \\] Only use parameters involving those variables to calculate her/his \\(\\ell_i\\): \\[ y_i = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_5 \\end{bmatrix} \\mu_i = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2\\\\ \\mu_5 \\end{bmatrix} \\mathbf{\\Sigma}_i = \\begin{bmatrix} \\sigma^2_1 &amp; \\sigma_{12} &amp; \\sigma_{15} \\\\ \\sigma_{21} &amp; \\sigma^2_2 &amp; \\sigma_{25} \\\\ \\sigma_{51} &amp; \\sigma_{52} &amp; \\sigma^2_5 \\end{bmatrix} \\] Thus, an individual’s likelihood is calculated using all available information. The log-likelihood \\(\\ell\\) for a sample is the sum of all the individual log-likelihoods (\\(\\ell = \\mathbf\\Sigma\\ell_i\\)), so FIML estimation utilizes each person’s available information when choosing the best parameter estimates that maximize the likelihood of the entire sample. We discuss tests statistics for model fit and model comparison in Chapter 11. However, in order to understand how \\(\\ell\\) is related to \\(F_\\text{ML}\\), we must first introduce the likelihood-ratio test (LRT). The ratio of two likelihoods tells you how much more (or less) likely you are to observe the sample data if the model in the numerator (A) is true than if the model in the denominator (B) is true: \\(\\frac{\\text{likelihood under model A}}{\\text{likelihood under model B}}\\). Recall that we work with log-likelihoods for greater precision. Furthermore, we multiply \\(\\ell\\) by −2 so that the resulting statistics are distributed as \\(\\chi^2\\) random variables (see Chapter 11 for details). Because the log of a ratio is equal to the difference in each log—i.e., \\(log(a / b) = log(a) − log(b)\\)—we can calculate the log of the likelihood-ratio as a difference between the log-likelihoods \\(\\ell\\): \\[\\begin{equation} LRT = -2\\ell_A - (-2\\ell_B) = -2 \\times (\\ell_A - \\ell_B) \\tag{10.6} \\end{equation}\\] Suppose we label our hypothesized (target) model as Model A, and we compare it to a perfectly fitting saturated model (labelled Model B) whose estimates are therefore identical to the observed sample statistics (\\(\\mathbf{\\Sigma}_\\text{sample}\\)). If the hypothesized model is the true data-generating model, then there should be little or no difference between \\(\\ell_{\\text{Target}}\\) and \\(\\ell_{\\text{Saturated}}\\), so the LRT should be small (close to zero). You might notice how equation (10.2) incorporates this concept into the calculation of \\(F_\\text{ML}\\), by taking the difference between the \\(\\log\\)s (of the determinants) of the target-model-implied \\(\\Sigma\\) (i.e., \\(\\hat{\\mathbf{\\Sigma}}_\\text{model}\\)) and the saturated-model-implied \\(\\mathbf\\Sigma\\) (i.e., \\(\\mathbf{\\Sigma}_\\text{sample}\\)), which would be Models A and B in equation (10.6). Having established the concept of a LRT, we can show how to calculate the same \\(F_\\text{ML}\\) from equation (10.2) using \\(\\ell\\). Notice that a mean (\\(\\overline{X}\\)) is simply a sum of values divided by the number of values: \\(\\overline{X} = \\frac{1}{N} \\Sigma x_i = \\frac{\\Sigma x_i}{N}\\). If we calculate equation (10.6) using the average log-likelihood (\\(\\overline{\\ell} = \\frac{1}{N} \\Sigma\\ell_i = \\frac{\\ell}{N}\\)) instead of the sum \\(\\ell\\), then the result would be \\(\\frac{LRT}{N} = F_{\\text{ML}}\\). So \\(F_\\text{ML}}\\) can be interpreted as the average person’s log-likelihood-ratio in the sample. As you will see in Chapter 11, the \\(\\chi^2\\) statistic is used to test whether the model fits the entire sample, so we simply convert the mean (\\(F_\\text{ML}\\)) back to a sum (LRT, or \\(\\chi^2\\)) by multiplying the mean by the sample size7 (\\(N \\times F_{\\text{ML}}\\)). 10.7 Using FIML to analyse raw data with missing values in lavaan In lavaan, the default way to handle missing values is to apply listwise deletion. FIML estimation will be invoked by adding the argument missing = \"ML\" to the model. The missing values in the raw data (here stored in the object AWdata) should be specified as NA. Since using FIML requires the analysis of the means of the variables, one should also include the model for the means in the model syntax. To specify an unrestricted mean structure one would freely estimate an intercept for each observed variable. The lavaan syntax to specify the intercept for a variable involves regressing the variable on the constant 1. For example, the intercept of variable \\(\\mathrm{y}_1\\) would be estimated by including the syntax: y1 ~ 1. AWmodelOut &lt;- lavaan(model = AWmodel, data = AWdata, missing = &quot;ML&quot;) References Browne, M. W. (1984). Asymptotic distribution free methods in the analysis of covariance structures. British Journal of Mathematical and Statistical Psychology, 37, 62–83. doi:10.1111/j.2044-8317.1984.tb00789.x Chen, F., Bollen, K. A., Paxton, P., Curran, P. J., &amp; Kirby, J. B. (2001). Improper solutions in structural equation models. Sociological Methods &amp; Research, 29, 468–508. doi:10.1177/0049124101029004003 Cudeck, R. (1989). Analysis of correlation matrices using covariance structure models. Psychological Bulletin, 105(2), 317–327. doi:10.1037/0033-2909.105.2.317 Heywood, H. B. (1931). On finite sequences of real numbers. Proceedings of the Royal Society of London, 134, 486–501. Jöreskog, K. G. (1973). A general method for estimating a linear structural equation system. In A. S. Goldberger &amp; O. D. Duncan (Eds.). Structural equation models in the social sciences (pp. 85–112). New York: Academic Press. Myung, J. (2003). Tutorial on maximum likelihood estimation. Journal of Mathematical Psychology, 47, 90–100. doi:10.1016/S0022-2496(02)00028-7 Satorra, A., &amp; Bentler, P. M. (2001). A scaled difference chi-square test statistic for moment structure analysis. Psychometrika, 66(4), 507–514. doi:10.1007/BF02296192 Savalei, V. (2014). Understanding robust corrections in structural equation modeling. Structural Equation Modeling, 21(1), 149–160. doi:10.1080/10705511.2013.824793 Yuan, K.-H., &amp; Bentler, P. M. (2000). Three likelihood-based methods for mean and covariance structure analysis with nonnormal missing data. Sociological Methodology, 30(1), 165–200. doi:10.1111/0081-1750.00078 In a later chapter we will introduce mean structures, where we will give versions of Equations (10.1) and (10.2) that incorporate observed and model-implied means↩︎ If the estimated parameter is a covariance, then it would be necessary to check the standardized solution to see whether the correlation is greater than 1 in absolute value. Calculating a 95% CI for the correlation would in that case require standardizing the upper and lower confidence limits of the covariance, using the model-implied \\(SD\\)s (i.e., square-roots of estimated variances).↩︎ When mean structure is excluded from the model, μ can be set to a vector of zeros, and each variable in the data set should be mean-centered.↩︎ This is the same as calculating the probability of flipping a coin twice and getting “heads” both times. The probability of “heads” is 50% for each coin-toss, so the probability of 2 “heads” is \\(0.5 \\times 0.5 = 0.25\\) (or 25%).↩︎ R, for instance, only keeps track to the 16th decimal place, although it might only be very precise to the 12th decimal place in practice.↩︎ When mean structure is excluded from the model, \\(μ\\) can be set to zero and data should be mean-centered.↩︎ Or by \\(N − 1\\) when analysing only covariance structure based on complete-data summary statistics.↩︎ "],["ch11.html", "11 Measures of Model Fit 11.1 The chi-squared test of exact fit 11.2 Root Mean Square Error of Approximation (RMSEA) 11.3 Other descriptive fit indices 11.4 A note on using available fit indices 11.5 Difference in model fit 11.6 Request fit measures in lavaan References", " 11 Measures of Model Fit When the model is identified, then \\(\\mathbf{\\Sigma}_\\text{sample}\\) can be used to derive parameter estimates that yield a covariance matrix (\\(\\hat{\\mathbf{\\Sigma}}_{\\text{model}}\\)) that is as close as possible to the observed sample covariance matrix. In general, when the discrepancies between \\(\\mathbf{\\Sigma}_\\text{sample}\\) and \\(\\hat{\\mathbf{\\Sigma}}_{\\text{model}}\\) are large, this indicates that the specified model cannot give a good description of the data and therefore one might question whether the model is true in the population, i.e., whether the model is misspecified. For just-identified models, the model parameters can usually be estimated so that \\(\\hat{\\mathbf{\\Sigma}}_{\\text{model}}\\) equals \\(\\mathbf{\\Sigma}_\\text{sample}\\). Evaluation of model fit is therefore uninformative. The model that is specified might not necessarily be the ‘true’ model, but there is not enough information to evaluate possible misspecification of the model as a whole. For models that are over identified (i.e., that have positive degrees of freedom) the evaluation of model fit may be informative as it can give an indication as to what extent the discrepancies between \\(\\mathbf{\\Sigma}_\\text{sample}\\) and \\(\\hat{\\mathbf{\\Sigma}}_{\\text{model}}\\) can be attributed to misspecification of the model. Below we first discuss the \\(\\chi^2\\) test of ‘exact fit’, then we explain the evaluation of ‘approximate fit’, and give a short overview of other descriptive measures of model fit. We also discuss the evaluation of differences in model fit, and finally show how to obtain all these measures of model fit in lavaan. 11.1 The chi-squared test of exact fit The \\(\\chi^2\\) test of exact fit is the basic statistical evaluation of overall model fit for over-identified SEMs. It is used to evaluate the following hypothesis: \\[ \\mathbf{\\Sigma}_{\\text{population}} = \\mathbf{\\Sigma}_{\\text{model}}, \\hspace{50mm} (\\text{11.01}) \\] where \\(\\mathbf\\Sigma_{\\text{population}}\\) refers to the matrix of population variances and covariances of the observed variables, and \\(\\mathbf\\Sigma_{\\text{model}}\\) refers to the population matrix of variances and covariances as implied by the path model. \\(\\mathbf\\Sigma_{\\text{model}}\\) is a function of model parameters (following Equations (3.9) and (3.10). If the model gives a true description of reality then \\(\\mathbf\\Sigma_{\\text{model}}\\) is equal to the population variances and covariances \\(\\mathbf\\Sigma_{\\text{population}}\\). However, these population matrices cannot be directly observed and therefore their values are unknown. Instead, the matrix of observed covariances \\(\\mathbf\\Sigma_{\\text{sample}}\\) is taken as an estimate of the population covariance matrix, and \\(\\hat{\\mathbf\\Sigma}_{\\text{model}}\\) is the covariance matrix as implied by model parameters derived from the sample estimates. Because the sample covariance matrix and estimated model-implied covariance matrix are only estimates of their corresponding population covariance matrices, it is possible that \\(\\hat{\\mathbf\\Sigma}_{\\text{population}} ≠ \\hat{\\mathbf\\Sigma}_{\\text{model}}\\), even if \\(\\mathbf\\Sigma_{\\text{population}} = \\mathbf\\Sigma_{\\text{model}}\\). Figure 11.1 gives a graphical representation of the population covariance matrices (\\(\\mathbf\\Sigma_{\\text{population}}\\) and \\(\\mathbf\\Sigma_{\\text{model}}\\)) and the sample covariance matrices (\\(\\mathbf\\Sigma_{\\text{sample}}\\) and \\(\\hat{\\mathbf\\Sigma}_{\\text{model}}\\)), and the different types of discrepancies that play a role in model fit evaluation. The term ‘sample discrepancy’ refers to the observed differences between the sample covariance matrix and the model-implied covariance matrix as derived from model parameter estimates. The term ‘population discrepancy’ refers to the differences between the population covariance matrix and the population model-implied covariance matrix. Figure 11.1: Population and sample covariance matrices that play a role in model fit evaluation. The \\(\\chi^2\\) test of exact fit is based on the assumption that exact fit holds in the population, i.e., the population discrepancy is zero (\\(\\mathbf{\\Sigma}_{\\text{population}} = \\mathbf{\\Sigma}_{\\text{model}}\\)). Under this null hypothesis, the \\(p\\) value associated with the observed \\(\\chi^2\\) fit statistic gives the probability of observing a sample discrepancy (i.e., the difference between \\(\\hat{\\mathbf\\Sigma}_{\\text{population}}\\) and \\(\\hat{\\mathbf\\Sigma}_{\\text{model}}\\)) at least as large as the observed one, when any discrepancy is due solely to random sampling error. When this probability is very low (e.g., lower than \\(\\alpha = .05\\)), then we reject the null hypothesis of exact fit and conclude that the model does not hold in the population. In other words, we conclude that the model is misspecified (i.e., the population discrepancy is not zero but contains discrepancy due to misspecification). The \\(\\chi^2\\) test of exact fit is based on the maximum likelihood (ML) discrepancy function. When all assumptions are satisfied, \\((N − 1) \\times \\text{F}_{\\text{ML}}\\) has a central \\(\\chi^2\\) distribution: \\[\\begin{equation} \\chi^2 = (N-1) \\times \\text{F}_\\text{ML} \\tag{11.1} \\end{equation}\\] with degrees of freedom equal to \\[\\begin{equation} df = ½ \\hspace{1mm}(p \\hspace{1mm} (p + 1)) - q \\tag{11.2} \\end{equation}\\] where \\(p\\) is the number of observed variables and \\(q\\) is the number of free model parameters to be estimated. If the \\(p\\) value associated with the \\(\\chi^2\\) value is smaller than the significance level \\(\\alpha\\), the null hypothesis of exact fit (i.e., \\(\\mathbf{\\Sigma}_{\\text{population}} = \\mathbf{\\Sigma}_{\\text{model}}\\)) is rejected. Otherwise, the model is regarded as compatible with the population covariance matrix \\(\\mathbf{\\Sigma}_{\\text{population}}\\). Note that when only the covariance structure is analysed, we use Wishart likelihood, so we multiply \\(\\text{F}_{\\text{ML}}\\) by \\(N - 1\\), but when both mean and covariance structure are analysed (e.g., when analysing raw data, or when using any robust correction), we use normal likelihood, so we multiply \\(\\text{F}_{\\text{ML}}\\) by \\(N\\). The full mediation model of child anxiety from our illustrative example yields the following \\(\\chi^2\\) test result: \\(\\chi^2 = 7.429\\), with \\(df = 2\\), and associated \\(p\\) value \\(= .024\\). Thus, the \\(\\chi^2\\) value is significant (at \\(\\alpha = .05\\)), so we reject the null hypothesis of exact fit. 11.1.1 Alternative basis for calculating the test statistic when analysing raw data Equation (11.1) shows how to calculate \\(\\chi^2\\) from summary statistics (i.e., observed and model-implied covariance matrices, and optionally mean vectors). This equation only applies when analysing complete data. In practice, data are often partially observed. When some data are missing, you can use full-information maximum likelihood (FIML) estimation (review the last section of Chapter 10 for details). We use a the log-likelihood (\\(\\ell\\))8 of the partially observed sample data, given the model parameters, to calculate the \\(\\chi^2\\) test statistic for the model. We can also use \\(\\ell\\) with complete data, in which case the \\(\\chi^2\\) value is the same as it would be using equation (11.1). Although we discuss model comparison more thoroughly later in the chapter, calculating \\(\\chi^2\\) using \\(\\ell\\) implicitly involves a model comparison via a likelihood-ratio test (LRT; review the last section of Chapter 10 for details): \\[\\begin{equation} \\chi^2 = -2 \\times (\\ell_{\\text{A}} - \\ell_{\\text{B}}) = -2 \\ell_{\\text{A}}(-2\\ell_{\\text{B}}) \\tag{11.3} \\end{equation}\\] Notice that the \\(\\chi^2\\) statistic in equation (11.3) is the same quantity as the LRT in equation (10.6) in the previous chapter. An individual model’s \\(\\chi^2\\) statistic is calculated by considering the target model as Model A, and the perfectly fitting saturated model as Model B. If the hypothesized model is the true data-generating model, then there should be little or no difference between \\(\\ell_{\\text{Target}}\\) and \\(\\ell_{\\text{Saturated}}\\), so the \\(\\chi^2\\) statistic should be small (relative to its \\(df\\)). 11.1.2 Testing exact fit vs. describing the degree of approximate fit In general, a researcher usually specifies a model that he or she thinks is the ‘true’ model, and therefore is interested in obtaining a non-significant \\(\\chi^2\\) value. However, is it realistic to assume that there is an exactly ‘true’ model that satisfies the assumption of exact fit, i.e., \\(\\mathbf{\\Sigma}_{\\text{population}} = \\mathbf{\\Sigma}_{\\text{model}}\\)? It has been argued that it is implausible that any model that we specify is anything more than an approximation to reality (Brown &amp; Cudeck, 1992). When we assume that the models that we specify are only an approximation of a real data-generating process, then the null hypothesis that a model fits exactly in the population is known to be false a priori. Even if the discrepancy is small enough to be ignored in practice (i.e., because the model is approximately correct enough to be useful), small differences between \\(\\mathbf\\Sigma_{\\text{sample}}\\) and \\(\\hat{\\mathbf\\Sigma}_{\\text{model}}\\) may become statistically significant in large samples (e.g., see Equation (11.1)). It has been argued that models that approximate the population covariance matrix will almost certainly be rejected under the null hypothesis of exact fit if sample size is sufficiently large (see for example Marsh, Balla, &amp; McDonald, 1988). Therefore, rather than testing whether the model fits exactly in the population (when we already know the answer is no), it might be more sensible to assess the degree to which the model fits in the population. Numerous descriptive fit indices have been developed as an alternative to the \\(\\chi^2\\) test of exact fit. These descriptive fit indices do not provide a statistical significance test to assess model fit, but rather provide a descriptive evaluation of fit. Such indices are based on the idea that models are simplifications of reality and will never exactly hold in the population. Some of these fit indices take into account sample size, model parsimony, or compare the fit of the model to a baseline model. Fit indices typically have unknown sampling distributions, so they cannot be used as actual test statistics because there is no analytical way to derive a critical value9 . However, this has not stopped some researchers from proposing ‘rules of thumb’ to delineate poor and good fit—these are typically treated as critical values by applied researchers, which is not how we recommend they be used. Rather, we recommend viewing descriptive fit indices as complementing the exact fit test in a way that is analogous to any statistical test being accompanied by a measure of effect size. In the case of statistically significant model misfit, fit indices can be used to assess whether the degree of misfit is of practical importance. Below we explain how a number of descriptive fit indices can be derived and interpreted. 11.2 Root Mean Square Error of Approximation (RMSEA) One of the earliest and most popular descriptive fit indices is the Root Mean Square Error of Approximation (RMSEA; Steiger &amp; Lind, 1980). The rationale behind the RMSEA is that the null hypothesis of exact fit (i.e., \\(\\mathbf{\\Sigma}_{\\text{population}} = \\mathbf{\\Sigma}_{\\text{model}}\\)) is invariably false in practical situations. Therefore, the hypothesis of exact fit is replaced by the hypothesis of approximate fit: \\[\\begin{equation} \\mathbf{\\Sigma}_{\\text{population}} \\approx \\mathbf{\\Sigma}_{\\text{model}}, \\tag{11.4} \\end{equation}\\] where it assumed that the specified model will only be an approximation to reality and thus some specification error should be allowed such that \\(\\mathbf\\Sigma_{\\text{model}}\\) will never be exactly equal to \\(\\mathbf\\Sigma_{\\text{population}}\\). However, a question that then comes up is: when do we decide that the model is a close enough approximation to reality? When we look at Figure 11.1, the population discrepancy is not assumed to be zero under the hypothesis of approximate fit. But how large can the specification error be before a model should be rejected? To accommodate approximate fit within the context of model fit evaluation, an additional error term is introduced: the ‘error of approximation’. The error of approximation concerns the questions of how well the model with unknown but optimally chosen parameters can be expected to fit the population covariance matrix. Assuming that the model is not expected to hold exactly in the population there will always be a certain amount of approximation error. Given that the model holds approximately, the \\((N − 1) \\times \\text{F}_{\\text{ML}}\\) from Equation (11.1) follows a noncentral \\(\\chi^2\\) distribution, with noncentrality parameter \\(\\lambda\\). Therefore, if you think that the model is an approximation of reality, you should evaluate \\((N − 1) \\times \\text{F}_{\\text{ML}}\\) against a noncentral \\(\\chi^2\\) distribution instead of a central \\(\\chi^2\\) distribution. The noncentrality parameter (\\(\\lambda\\)) can be estimated using10: \\[\\begin{equation} \\lambda = (N-1)\\varphi_{\\text{A}}, \\tag{11.5} \\end{equation}\\] where \\(\\varphi_{\\text{A}}\\) refers to the discrepancy due to approximation. Cudeck and Henly (1991) proposed that the approximation discrepancy, in turn, can be estimated with: \\[\\begin{equation} \\hat{\\varphi}_{\\text{A}} = \\text{F}_{\\text{ML}} - df / (N-1) \\tag{11.6} \\end{equation}\\] Substituting Equation 11.06 into Equation 11.05 gives an estimate of \\(λ\\): \\[\\begin{equation} \\hat{\\lambda} = (N-1) \\times \\text{F}_{\\text{ML}} - df, \\hspace{3mm} \\text{or, equivalently,} \\hspace{3mm} \\hat{\\lambda} = \\chi^2 - df. \\tag{11.7} \\end{equation}\\] The RMSEA is a measure of approximate fit, and is computed based on the sample size, the noncentrality parameter, and \\(df\\) of the model. The noncentrality parameter is divided by \\(df \\times (N − 1)\\), which makes it less sensitive to changes in sample size, and produces a measure of misspecification per \\(df\\). It therefore also takes model parsimony into account. The point estimate of the RMSEA is calculated as follows: \\[\\begin{equation} \\text{RMSEA} = \\sqrt{\\frac{\\text{max}((\\chi^2 - df), 0)}{df(N-1)}} = \\sqrt{\\frac{\\text{max}\\hat{\\lambda},0)}{df(N-1)}} \\tag{11.8} \\end{equation}\\] Notice that if \\(\\chi^2 &lt; df\\), then the RMSEA is set to zero. An RMSEA of zero indicates the model fits at least as well as would be expected if the null hypothesis of exact fit were true. In evaluating the value of the RMSEA, we accept some error of approximation. Browne and Cudeck (1992) suggested that an \\(\\text{RMSEA} &lt; .05\\) indicates “close fit”, an RMSEA between 0.05–0.08 is thought to indicate a “reasonable error of approximation”, and that models with an RMSEA \\(&gt; 0.10\\) have poor fit. MacCallum, Browne, and Sugawara (1996) suggested that RMSEA between 0.08–0.10 indicates “mediocre” fit. A confidence interval (CI) can be computed for RMSEA. Ideally the lower value of the 90% CI includes or is very near zero and the upper value is not very large, i.e., less than 0.08. However, this is only typically achieved in practice when both of two conditions hold: large sample size and large \\(df\\). Kenny, Kaniskan, and McCoach (2015) show that when either of the terms in the denominator of RMSEA (\\(N\\) or \\(df\\); see equation (11.8) above) are small, the sampling variability of RMSEA is very erratic, so it is nearly impossible to trust the estimated RMSEA in any single sample when either \\(N\\) or \\(df\\) are small. Unfortunately, this will almost always be the case with a path model, which typically have very small \\(df\\) even when there are many variables, regardless of how large the sample is. So in practice, RMSEA may only be informative in latent variable models, in which many observed variables are modeled as being associated (often indirectly) via many fewer common factors. In our illustrative example, the RMSEA value of the full mediation model is 0.189, with a 90% CI of 0.058–0.343. Thus, the point estimate of the RMSEA indicates poor model fit, and the CI is very wide. The CI therefore gives an indication of the imprecision of the estimated point estimate of the RMSEA. As a comparison, the RMSEA value of the partial mediation model is 0, with a 90% CI of 0.000–0.259. The RMSEA indicates exact fit (because this model is saturated, it fits perfectly by definition, so \\(\\chi^2 = 0\\); however, \\(\\text{RMSEA} = 0\\) in over-identified models whenever \\(\\chi^2 &lt; df\\)), but the CI shows (again) that the point estimate of RMSEA is not very precise. Browne and Cudeck (1992) proposed the ‘test of close fit’ where it is tested whether RMSEA is significantly greater than .05 (i.e., the null hypothesis is that if we fit our model to the population covariance matrix, RMSEA ). We conduct the test by constructing a CI, using a confidence level that is \\(2 \\times \\alpha\\) (so that we can conduct a one-sided test of our directional hypothesis using the CI). For example, using \\(α = .05\\) as criterion, we use a 90% CI for RMSEA. When the lower confidence limit &gt; 0.05, we can reject the null hypothesis of close fit (because the entire CI is above the 0.05 threshold). MacCallum et al. (1996) extended this idea by ‘flipping’ the null hypothesis (i.e., that the population \\(\\text{RMSEA} \\ge 0.05\\)), which they called a “test of not-close fit”. When the upper confidence limit of the \\(\\text{RMSEA} &lt; 0.05\\), we can reject the null hypothesis of not-close fit (because the entire CI is below the 0.05 threshold). Different thresholds could also be used—for example, 0.08 can be used to provide a ‘test of approximate fit’ or ‘not-approximate fit’. The only distinction between tests of close vs. not-close fit is which one you use as the null hypothesis. Recall that one very useful interpretation of a CI is that it is a range of null hypothesized values that could not be rejected using the sample data. In our example from chapter 7, the partial mediation model has exact fit (\\(\\chi^2\\) and \\(\\text{RMSEA} = 0\\)), but the 90% CI ranges from 0.000–0.259, so we could not reject a null hypothesis of exact fit (\\(\\text{RMSEA} = 0\\)), of close fit (\\(\\text{RMSEA} \\le 0.05\\)), a null hypothesis of approximate fit (\\(\\text{RMSEA} \\le 0.08\\)), a null hypothesis of mediocre fit (\\(\\text{RMSEA} \\le 0.10\\)), or a null hypothesis of poor fit (\\(\\text{RMSEA} &gt; 0.10\\)). Because no possible null hypothesis could be rejected (i.e., no theory could be falsified), the RMSEA in this example is effectively useless (i.e., it is uninformative in any practical sense). As Kenny et al. (2015) indicated, this is to be expected whenever \\(N\\) or \\(df\\) are small. 11.3 Other descriptive fit indices Below, we give a short description of other popular descriptive fit indices. We limit our discussion to the fit indices that are provided by lavaan’s summary() output (which are also the indices provided by Mplus), although many additional indices are available from lavaan’s fitMeasures() function, as well as the moreFitIndices() function in the semTools package. The information on the different fit indices is kept as concise as possible, but more detailed overviews of these (and other) fit indices can be found in other sources (e.g., Bollen, 1989; Schermelleh-Engel, Moosbrugger, &amp; Müller, 2003; West, Taylor, &amp; Wu, 2012). 11.3.1 The Tucker–Lewis Index (TLI) and the Comparative Fit Index (CFI) The Tucker–Lewis Index (TLI; Tucker &amp; Lewis, 1973) and the Comparative Fit Index (CFI; Bentler, 1990) are so-called incremental fit indices (also called relative or comparative fit indices). Incremental fit indices compare the fit of the model of interest with a baseline or null model. Tucker and Lewis (1973) original developed TLI as a sort of reliability coefficient for extracting the correct number of factors in exploratory factor analysis. However, Bentler and Bonett (1980) developed a framework for different types of incremental fit indices and illuminated their particular advantage in comparing models, which we will discuss later in this chapter. Conceptually, incremental fit indices place a target model somewhere on a continuum between the best fitting (i.e., perfectly fitting saturated) model and the worst fitting (but still theoretically plausible) model. Figure 11.2 depicts this conceptual continuum, which is anchored on the left by zero because a model cannot fit better than perfectly (i.e., zero discrepancy). On the right, the null model is as poorly fitting as we can conceive being plausible (e.g., without constraining variances to equal one million for 7-point Likert scales), although greater discrepancies are possible. If our target model is a good approximation of the true data-generating model (i.e., the “population”), then our target model should be much closer to the left-hand side of the continuum than to the right-hand side. In general, incremental fit indices range from 0 to 1, so they could be interpreted as a proportion of the continuum in Figure 11.2, with higher values indicating better fit. Figure 11.2: Continuum between poor and perfect fit. The most common choice for the baseline model is the so-called independence model, where all covariances in \\(\\mathbf\\Sigma_{\\text{population}}\\) are assumed zero. Although other baseline models could be used, this is not often seen in practice11. There are several incremental fit indices, but here we limit the discussion to the TLI and CFI because they have shown the most favourable properties in simulation research (e.g., insensitivity to sample size, sensitivity to model misspecification). The TLI, also referred to as the non-normed fit index (NNFI) by Bentler and Bonett (1980), is calculated using the \\(\\chi^2\\) and \\(df\\) of the independence (null) and target (model) models: \\[\\begin{equation} \\text{TLI} = \\frac{\\frac{\\chi^2_{\\text{null}}}{df_{\\text{null}}}-\\frac{\\chi^2_{\\text{model}}}{df_{\\text{model}}}}{\\frac{\\chi^2_{\\text{null}}}{df_{\\text{null}}}-1} \\tag{11.9} \\end{equation}\\] Because TLI is not normed (i.e., not forced to be within the bounds of 0 and 1), the values of the TLI will be larger than 1 whenever the target model’s \\(\\chi^2 &lt; df\\), or may even be slightly below 0 if the target model’s \\(\\chi^2\\)-to-\\(df\\) ratio is greater than the null model’s ratio. The CFI is calculated in a very similar way as the TLI, but uses the differences between \\(\\chi^2\\) and \\(df\\) of the null and target models (recall from equation (11.7) that this difference is an estimate of the noncentrality parameter \\(\\hat{\\lambda}\\)): \\[\\begin{equation} \\text{CFI} = \\frac{\\text{max}[0,(\\chi^2_{\\text{null}}-df_{\\text{null}})]-\\text{max}[0,(\\chi^2_{\\text{model}}-df_{\\text{model}})]}{\\text{max}[0,(\\chi^2_{\\text{null}}-df_{\\text{null}})]} = 1-\\frac{\\text{max}[0,(\\chi^2_{\\text{model}}-df_{\\text{model}})]}{\\text{max}[0,(\\chi^2_{\\text{null}}-df_{\\text{null}}),(\\chi^2_{\\text{model}}-df_{\\text{model}})]} \\tag{11.10} \\end{equation}\\] In this formula, the numerator is 0 if the target model’s \\(\\chi^2 &lt; df\\), and the denominator is equal to the numerator if the target model’s \\(\\chi^2 &lt; df\\) or if the null model fits at least as well as the target model. This ensures that the CFI will range between 0 and 1. As a rule of thumb, TLI or \\(\\text{CFI} &gt; .90\\) (Bentler &amp; Bonett, 1980) or \\(&gt; .95\\) (Hu &amp; Bentler, 1999) may be interpreted as indicative of good fit relative to the null model. TLI and CFI take model complexity into account and are relatively unaffected by samples size (Bollen, 1990; Hu &amp; Bentler, 1998; Marsh, Balla, &amp; McDonald, 1988; West et al., 2012). However, they are sensitive to the size of the observed covariances. The closer the observed covariances are to zero (especially a majority), the more \\(\\mathbf\\Sigma_{\\text{sample}}\\) resembles the independence model, which makes it more difficult for a target model to cross the divide between the null and saturated models. 11.3.2 The Root Mean Square Residual (RMR) and Standardized RMR (SRMR) RMR (Jöreskog &amp; Sörbom, 1981) and SRMR (Bentler, 1995) are overall badness-of-fit measures that are based on the fitted residuals (i.e., difference between model-implied and sample covariance matrices). \\[\\begin{equation} \\text{RMR} = \\sqrt{\\frac{\\mathbf{\\Sigma}^p_{i=1}\\mathbf{\\Sigma}^i_{j=1}(s_{ij}-\\hat\\sigma_{ij})^2}{p(p+1)/2}} \\tag{11.11} \\end{equation}\\] RMR is defined as the square-root of the mean of the squared fitted residuals. In principle, RMR values close to zero suggest a good fit. But as the elements of \\(\\mathbf{S}\\) and \\(\\mathbf\\Sigma\\) are scale dependent, the fitted residuals are scale dependent, too, which implies that RMR depends on the sizes of the variances and covariances of the observed variables. In other words, without taking the scales of the variables into account, it is virtually impossible to say whether a given RMR value indicates good or bad fit. To overcome this problem, the standardized RMR was been introduced, where the residuals \\(s_{ij}\\) and \\(\\hat\\sigma_{ij}\\) are standardized using the standard deviations of the observed variables \\(i\\) and \\(j\\) from the sample covariance matrix12. \\[\\begin{equation} \\text{SRMR} = \\sqrt{\\frac{\\mathbf{\\Sigma}^p_{i=1}\\mathbf{\\Sigma}^i_{j=1}(s_{ij}-\\hat\\sigma_{ij})/(s_{ii}-s{jj})^2}{p(p+1)/2}} \\tag{11.12} \\end{equation}\\] SRMR continues to be popular despite its limitations. Interpreting SRMR is complicated by the fact that its expected value varies with sample size, but as a rule of thumb SRMR values lower than .05 are taken as indicative of good fit, and SRMR lower than .10 may be interpreted as acceptable fit. However, we do not recommend paying attention to SRMR as a global measure of overall model fit; rather, we recommend paying attention to individual correlation residuals, as described in chapter 8 on model modification. In that example, the average correlation residual was \\(\\text{SRMR} = .087\\), which would indicate acceptable (but not good) global fit. However, most of the correlation residuals were zero, so the average (SRMR) masked the fact that the largest correlation residual (.272) was unacceptably large, indicating a severe local source of model misspecification. 11.3.3 Information Criteria The Akaike Information Criterion (AIC; Akaike, 1987) and so-called “Bayesian”13 Information Criterion (BIC; Raftery, 1986, 1995) are fit indices that were developed specifically to compare models fit to the same data. In general, lower values indicate a better fit, so the model with the lowest value is the best fitting model after adjusting for model complexity (as measured by the number of free parameters in the model). However, the absolute value is irrelevant; only the AIC (or BIC) of one model relative to the AIC (or BIC) of another model can be meaningfully interpreted. An advantage of these fit indices is that the competing models do not need to be nested. A disadvantage is that they are based on likelihoods, so they are only available when using ML estimation (e.g., not using WLS for modelling categorical outcomes). The values of information criteria can differ across software even when the model parameters and fit statistics are the same. The differences are not really meaningful as they all lead to the same ordering of competing models, but they differ because there are different formulas for AIC. One formula is based on the log-likelihood of the model (\\(\\ell\\)): \\[\\begin{equation} \\text{AIC} = \\ell − q \\tag{11.13} \\end{equation}\\] where \\(q\\) is the number of free parameters in the model. Another formula is based on \\(−2\\ell\\) (which is the one reported in lavaan): \\[\\begin{equation} \\text{AIC} = -2\\ell + 2q \\tag{11.14} \\end{equation}\\] which is simple \\(−2\\) times the formula in (11.13). Finally, AIC can also be calculated using the \\(\\chi^2\\) statistic instead of \\(−2\\ell\\) in (11.14), which yields the same rank-order of candidate models because each competing model’s \\(\\chi^2\\) is calculated relative to the same saturated model (see equation (11.3)). Regardless of which formula is used, AIC penalizes models that have more free parameters (i.e., are more complex). The rationale behind information criteria is that a model with more estimated parameters (some of which may be near zero in the population) should not be favoured over a model that may be slightly simplified but provides similar predictions as the more complex model. AIC was developed specifically to identify which among a set of models would be expected to have the least prediction error when fitted to new samples (i.e., to identify which model generalizes best). The BIC was derived based on Bayesian theory (an alternative to classical “frequentist” hypothesis testing) as a rough approximation of the log of a Bayes factor (the Bayesian analogue of a LRT) comparing the target model to the saturated model. The resulting index is similar to the AIC, but the penalty against complex models increases as sample size increases: \\[\\begin{equation} \\text{BIC} = -2\\ell + \\log(N) \\times q \\tag{11.15} \\end{equation}\\] where \\(\\log(N)\\) is the natural logarithm of the number of cases in the sample. Similar to AIC, an alternative calculation of BIC would be to use \\(\\chi^2\\) instead of \\(−2\\ell\\) in equation (11.15), which provides identical rank-ordering of competing models. Simulations have shown that BIC tends to select the true model if it is in the set of competing models (which may never be true in practice), whereas the AIC tends to select the model that makes the most accurate predictions about new samples, regardless of whether the true model is in the candidate set. They both perform better with larger samples, so small-sample adjustments have been proposed. The Sample-Size Adjusted BIC (SABIC; Sclove, 1987) uses \\(\\log(\\frac{N+2}{24})\\)) instead of \\(\\log(N)\\) in equation(11.14), which places a smaller emphasis on parsimony. In contrast, the corrected AIC (AICc; Burnham &amp; Anderson, 2003) adds \\(\\frac{2q(q+1)}{(N-q-1)}\\) to AIC (as defined in equation (11.14)), placing even greater emphasis on parsimony. This is necessary because in small samples, AIC is more likely to select a model that overfits to sample nuances, reducing its generalizability. 11.4 A note on using available fit indices There exists considerable controversy concerning the use of fit indices. Some researchers do not believe that descriptive fit indices are of much added value, and that the \\(\\chi^2\\) test of exact fit should be the only substantive test of model fit applied (e.g., Barrett, 2007). Another problem is that with so many different alternative fit indices to choose from, one might be tempted to choose to report only those indices that support your model, based on arbitrary rules-of-thumb. This might result in too many misspecified models being reported as ‘acceptable’ models. Also, some argue that cutoffs for a descriptive fit index can be misleading as these descriptive fit indices are then wrongfully treated as actual test statistics (e.g., Hayduk, Cummings, Boadu, Pazderka-Robinson, &amp; Boulianne, 2007). Some researchers have argued that a specific combination of descriptive fit indices should be preferred for model evaluation (e.g., Hu &amp; Bentler, 1999). In general, it could be recommended to inspect and report several descriptive fit indices, in addition to the \\(\\chi^2\\) test, but that the researcher should be aware that choice of the specific fit index might depend on the specifics of the data (e.g., sample size) or model (e.g., complexity) and the specific goal of model evaluation (e.g., confirmatory versus exploratory, comparing competing (non)nested models, model parsimony, explanatory power, etc.). Several papers discuss recommendations for the use of the different fit indices described above (and several others) and their potential problems (e.g., see Schermelleh-Engel, Moosbrugger &amp; Müller, 2003; Hu &amp; Bentler, 1999; Marsh, Hau &amp; Wen, 2004). Most importantly, as a researcher one should not forget that substantive theory-relevant criteria can (and should always) play a major role in the evaluation of model fit (e.g., Barret, 2007; Hayduk, et al., 2007). 11.5 Difference in model fit In applications of covariance structure analysis, researchers often face the problem of choosing among two or more alternative models. The choice of which measure to use for selecting one of several competing models depends on whether or not the models are nested. A specific model (Model A) is said to be nested within a less restricted model (Model B) with more parameters (i.e., fewer \\(df\\)) than Model A, if Model A can be derived from Model B only by introducing restrictions. For example, by fixing free parameters in Model B or by constraining a free parameter to equal to one or more other parameters. This is known as parameter nesting14: any two models are nested when the free parameters in the more restrictive model are a subset of the free parameters in the less restrictive model. Additionally, if A and B have the same \\(df\\), then they are equivalent models, which is a special case of nesting. As the test statistic of each of the nested models follows a \\(\\chi^2\\) distribution, the difference in \\(\\chi^2\\) values between two nested models is also \\(\\chi^2\\) distributed: \\[\\begin{equation} \\Delta\\chi^2= \\chi_A^2 - \\chi_B^2 , \\tag{11.16} \\end{equation}\\] with df for the difference equal to the difference in df for the two models: \\[\\begin{equation} \\Delta df = df_A - df_B \\tag{11.17} \\end{equation}\\] Thus, testing the difference in model fit can be tested comparing \\(\\Delta\\chi^2\\) to a \\(\\chi^2\\) distribution with \\(\\Delta df\\), which is called the \\(\\chi^2\\) difference test. If \\(\\Delta\\chi^2\\) is significant, the null hypothesis of equal fit for both models is rejected, so the less restrictive Model B should be retained. But if \\(\\Delta\\chi^2\\) is not significant, the fit of the restricted model (Model A) is not significantly worse than the fit of the unrestricted model (Model B), so the null hypothesis of equal fit cannot be rejected. On the parsimony principle (Occam’s razor), we should favour the more restrictive (i.e., simpler) Model A. In our illustrative example of child anxiety, the difference in model fit between the full mediation model (Model A) and the partial mediation model (Model B) is: \\[ \\Delta\\chi^2= \\chi_A^2-\\chi_B^2 = 7.429 - 0.402 = 7.027, \\] \\[ \\text{with} \\hspace{2mm} \\Delta df = df_A - df_B = 2 - 1 = 1 . \\] The associated \\(p\\) value is .008, indicating that the difference in model fit is significant at \\(α = .05\\). The fit of the full mediation model is significantly worse than the fit of the partial mediation model, so we would favour the latter model. Likewise, a single target model’s \\(\\chi^2\\) statistic can be thought of as a \\(\\Delta\\chi^2\\) statistic using equations (11.16) and (11.17), where Model B is replaced with the saturated Model S. In our illustrative example of child anxiety the overall \\(\\chi^2\\) is then obtained by: \\[ \\Delta\\chi^2 = \\chi_A^2 - \\chi_S^2 = \\chi_A^2 - 0 = 7.429 - 0 = 7.429 , \\] \\[ \\text{with} \\hspace{2mm} \\Delta df = df_A - df_S = df_A - 0 = 2 - 0 = 2. \\] 11.5.1 \\(\\Delta\\chi^2\\) as a likelihood ratio test Recall from equation 11.03 that a model’s \\(\\chi^2\\) statistic is the LRT from equation 9.06, treating the target model as Model A and the saturated model as Model B. The \\(\\Delta\\chi^2\\) test is also a log-likelihood ratio, so equation 11.15 could equivalently be calculated using equation 11.03. The reason the two equations yield the same result is that each model’s \\(\\chi^2\\) statistic is calculated using the same saturated model’s log-likelihood (\\(\\ell_S\\)), so they cancel out. Labelling the saturated model as Model S instead of B in equation 11.03, the LRT for two nested hypothetical Models A (in ) and B (in ) could be calculated using each of their LRT statistics: \\[\\begin{align*} \\Delta\\chi^2 &amp; = \\color{green}{[-2\\ell_A-(-2\\ell_S )]}-\\color{blue}{[-2\\ell_B-(-2\\ell_S )]} \\\\ &amp; =\\color{green}{-2\\ell_A}+\\color{red}{2\\ell_S}+\\color{blue}{2\\ell_B}-\\color{red}{2\\ell_S} \\\\ &amp; =\\color{green}{-2\\ell_A}+\\color{blue}{2\\ell_B} \\\\ &amp; =\\color{green}{-2\\ell_A}-\\color{blue}{(-2\\ell_B )} \\end{align*}\\] 11.5.2 Describing differences in fit The \\(\\chi^2\\) difference test applied to nested models has essentially the same strengths and weaknesses as the \\(\\chi^2\\) test applied to any single model; namely, trivial differences can be detected as statistically significant in large samples. Thus, a researcher may supplement the significance test for difference in fit by reporting a difference in a descriptive fit index. In the case of RMSEA, equation (11.8) can actually be applied to \\(\\Delta\\chi^2\\) and \\(\\Delta df\\) instead of \\(\\chi^2\\) and \\(df\\). This was proposed as the Root Deterioration per Restriction (RDR), but it never became popular because it behaved so erratically. Recall that the RMSEA itself performs very poorly when either \\(N\\) or \\(df\\) are small, which explains why RDR performs so poorly: rarely will two models be compared that have a very large difference in \\(df\\) (\\(\\Delta df\\)). Instead, \\(\\Delta\\text{CFI}\\) has become very popular, particularly when testing measurement equivalence across groups or occasions (we will discuss this later in the course). However, these fit indices have unknown sampling distributions, they should not be used as test statistics15, but rather as a kind of effect size that would typically accompany a significance test. Analogously, when using a t test to compare means, small differences might be statistically significant in large samples, so Cohen’s \\(d\\) is used to indicate whether the observed difference is of practical importance. Unfortunately, there are few guidelines for what would constitute a meaningful difference in CFIs between models, and the few proposed rules-of-thumb have been made for very specific situations (e.g., measurement invariance). Incremental fit indices in general have the advantage of being able to compare models regardless of whether they are nested (Bentler &amp; Bonett, 1980). This is because all possible competing models are nested within the same saturated model, by definition. So as long as a single null model is specified that is nested within each candidate model16, calculating the CFI for each candidate models allows us to see where each competing model lies on the same continuum between poor and perfect fit. Supposing we have three candidate models, the one with the largest CFI is the one furthest to the left in Figure 11.3 (i.e., Target Model 3): Figure 11.3: Placing competing models on the same continuum. Because CFI and TLI implicitly account for model complexity by using the model’s \\(df\\) to adjust the model’s fit (using the noncentrality parameter and the \\(\\chi^2\\)-to-\\(df\\) ratio, respectively), the continuum in Figure 11.3 represents complexity-adjusted fit. The model with the lowest AIC (or BIC) could also be selected as the model that best balances fit and parsimony. This model-selection procedure has typically been used in place of a \\(\\chi^2\\) difference test when the models are not nested; however, this procedure does not take sampling variability into account, so it is not truly a test of (comparative) model fit. Furthermore, simply choosing the lowest AIC suffers the same limitation as choosing the highest CFI—it is unclear what constitutes a meaningful difference in values between two models. 11.5.3 Testing differences in fit between non-nested models Test statistics have also been developed for non-nested models (Merkle, You, &amp; Preacher, 2016). If each individual log-likelihood \\(\\ell_i\\) is calculated under Model A and under Model B, then the difference between individual \\(i\\)’s log-likelihoods (\\(\\Delta\\ell_i\\)) reveals which model most likely “generated” this person’s observed data. A weighted sum of these \\(\\Delta\\ell_i\\) is an asymptotically normally distributed statistic, with a \\(\\mu = 0\\) if the null hypothesis of equal fit is true, so it can be used to conduct a \\(z\\) test. A significant test indicates that Model A fits better than Model B (if the statistic is positive) or vice versa (if the statistic is negative); otherwise there is not enough evidence to prefer one model over another. This is called the Vuong test after its developer (Vuong, 1989, as cited in Merkle et al., 2016). We can also use the variability of \\(\\Delta\\ell_i\\) to calculate a 95% CI (assuming \\(α = .05\\)) for the difference between two model’s AICs (or BICs). This provides a test of fit that takes model parsimony into account. Assuming the null hypothesis of equal complexity-adjusted fit is true, \\(\\Delta\\text{AIC}\\) (or \\(\\Delta\\text{BIC}\\)) is zero in the population. Testing this null hypothesis is as simple as checking whether the 95% CI for \\(\\Delta\\text{AIC}\\) (or \\(\\ \\)$ includes zero. If so, you cannot reject the null hypothesis. Otherwise, the model with the lower AIC (or BIC) should be preferred. Because the Vuong test and CIs for information criteria area calculated from individual \\(\\Delta\\ell_i\\), they can only be calculated when using MLE to fit the model to complete data that are multivariate normally distributed. Furthermore, they cannot be used if you only have access to summary statistics (like most of our teaching examples), which is rarely a problem in practice. Although it is theoretically possible to extend the Vuong test to least-squares estimators (e.g., WLS for categorical outcomes), this extension has yet to be developed (Merkle et al., 2016). Because these tests have only recently begun being investigated in an SEM framework, more research is needed to see how robust they are when data deviate from multivariate normality (i.e., when \\(\\ell_i\\) are calculated using equation (10.5) even though data do not follow the distribution described by (10.4)). 11.6 Request fit measures in lavaan The summary() function has an argument to request information about model fit from the lavaan output: summary(AWmodelOut, fit.measures = TRUE) Notice that lavaan will print the \\(\\chi^2\\) test for both the target model and the default baseline model (i.e., the independence model), as well as RMSEA (including a 90% CI), CFI and TLI, SRMR (and WRMR when outcomes are categorical), and information criteria when using MLE (specifically, AIC, BIC, and SABIC). Several other fit indices are available from two different functions. The first is lavaan’s function fitMeasures(). The default is to print all available fit measures: fitMeasures(AWmodelOut) But there are too many to easily read. It is better to request only the fit measures you want to see (e.g., when you want to calculate changes such as \\(\\Delta\\text{CFI}\\)): myFitIndices &lt;- c(&quot;chisq&quot;,&quot;df&quot;,&quot;pvalue&quot;,&quot;cfi&quot;,&quot;aic&quot;) fitMeasures(AWmodelOut, fit.measures = myFitIndices) The function moreFitIndices() is available in the semTools package, and it provides a few other options, such as AICc (labelled “aic.smallN”): library(semTools) moreFitIndices(AWmodelOut, fit.measures = &quot;aic.smallN&quot;) 11.6.1 Compare fit of lavaan models Consider the difference in fit between the original path model for the development of child anxiety from Chapter 3 and the less constrained model with the additional direct effect from Parent Anxiety to Child Anxiety from Chapter 8. You can use the anova() function, providing both models as arguments. The order of models does not matter because lavaan will sort them in order of increasing df automatically. anova(AWmodelOut, AWmodel2Out) The function lavTestLRT() is used the same way as anova(), but it has some more options (mainly, what adjustment to use if data are not normally distributed). In fact the anova() function merely calls lavTestLRT() with all its default arguments. Using either function, the output would be: Chi Square Difference Test Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) AWmodel2Out 1 2138.5 2159.6 0.3972 AWmodelOut 2 2143.5 2162.3 7.3327 6.9355 1 0.00845 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Notice that the actual \\(\\Delta\\chi^2\\) (6.9355) is very similar to the expected \\(\\Delta\\chi^2\\) indicated by the modification index for this additional parameter (6.716) in Chapter 8, Table 2. Also, the AIC and BIC for each model are displayed. The anova() function is not suitable for comparing non-nested models, so if your models are not nested, you can simply use a function to request AIC or BIC: AIC(AWmodelOut, AWmodel2Out) BIC(AWmodelOut, AWmodel2Out) Note that these functions output a column labeled df, which is actually the number of free model parameters, not the model’s \\(df\\). In order to actually test differences in fit of non-nested models, use functions that are available in the R package nonnest2. Suppose that in our examples, we had actually fit our models to raw data. The following functions would allow us to run the Vuong test (analogous to \\(\\Delta\\chi^2\\) test for non-nested models): library(nonnest2) vuongtest(AWmodelOut, AWmodel2Out) Or we could test differences in parsimony-adjusted fit using CIs for \\(\\Delta\\text{AIC}\\) or \\(\\Delta\\text{BIC}\\): icci(AWmodelOut, AWmodel2Out, conf.level = 0.95) CIs for both \\(\\Delta\\text{AIC}\\) and \\(\\Delta\\text{BIC}\\) would be provided, but you should only use one or the other, based upon whether you can assume one of the models is “correct” (BIC) or whether you merely wish to find the most generalizable model (AIC). Note, again, that these tests require analysing the raw data, not summary statistics. 11.6.2 Fit measures in lavaan when adjusting for non-normal data When correcting for non-normality, lavTestLRT() and anova() automatically calculate the correct adjusted \\(\\Delta\\chi^2\\) test. However, the default method (\"satorra.bentler.2001\") can sometimes yield a negative test statistic, in which case it is impossible to compute a \\(p\\) value. If this happens, you can use a version of the test that will always yield a positive scaled test statistic: lavTestLRT(AWmodelOut, AWmodel2Out, method = &quot;satorra.bentler.2010&quot;) When correcting for non-normality, the summary(..., fit.measures = TRUE) output includes a second column labelled “Robust” that contains the scaled \\(\\chi^2\\) test results, as well as robust versions of RMSEA, CFI, and TLI that incorporate the scaling factor to adjust for non-normality. The other fit measures (AIC, BIC, and SRMR) are unaffected by the adjustment, so those values are identical in the two columns. The left column of unadjusted measures can be ignored, but it is included for the sake of comparison. However, when you use the fitMeasures() function, you will see not only the unadjusted fit measures, but also two different copies of any measure based on the \\(\\chi^2\\) statistic. The first set are labelled with a suffix “.scaled”, which corresponds to the corrected \\(\\chi^2\\) statistic. For RMSEA, TLI, and CFI (which are based on \\(\\chi^2\\)), “.scaled” indicates that they were calculated naïvely by simply plugging the scaled \\(\\chi^2\\) statistic (“chisq.scaled”) into equations (11.8), (11.9), and (11.10), respectively. However, using those formulas with simple substitutions would yield fit measures that do not, on average, equal their population-level counterparts (i.e., if models were fit to \\(\\mathbfΣ_{\\text{population}}\\) and adjusted for non-normality using population information). Instead, special formulas were developed by Brosseau-Liard and colleagues (2012, 2014) to yield consistent sample values of these three fit indices. These are labelled with a suffix “.robust”, they are the ones displayed in the summary() output, and they are the ones you should request from fitMeasures(): myFitIndices &lt;- c(&quot;chisq.scaled&quot;,&quot;df&quot;,&quot;pvalue.scaled&quot;,&quot;cfi.robust&quot;,&quot;aic&quot;) fitMeasures(AWmodelOut, fit.measures = myFitIndices) Likewise, the output of modificationindices() will contain a column “mi.scaled”. If you are comparing MIs to a critical value, this is the column you should pay attention to. 11.6.3 Test statistic adjusted for small sample size One last issue is that the \\((\\Delta)\\chi^2\\) statistic is only asymptotically (i.e., as \\(N \\rightarrow \\infty\\)) distributed as a \\(\\chi^2\\) random variable. In finite samples, it is approximately distributed as a \\(\\chi^2\\) random variable, but in small samples the approximation is poor. In this case, your p values will be incorrect because the \\((\\Delta)\\chi^2\\) statistic will be too big, suggesting that the model fits worse than it actually does. It is simple to correct for this by multiplying the observed \\((\\Delta)\\chi^2\\) statistic by a correction factor \\(c\\)17: \\[\\begin{equation} c=1-\\frac{2p+4k+5}{6N} , \\tag{11.18} \\end{equation}\\] where \\(p\\) is the number of observed variables, \\(k\\) is the number of factors, and \\(N\\) is the sample size (Nevitt &amp; Hancock, 2004). Note that in a path model, \\(k = 0\\), reducing the numerator to \\(2p + 5\\). The multiplicative correction will typically be , so it will usually make \\(\\chi^2\\) smaller, reducing the inflated Type I error rate in small samples. This correction will be small whenever the denominator in (11.18) (\\(N\\)) is large, although how large depends on the size of the model. For example, models with more variables (\\(p\\) and \\(k\\)) have a larger numerator, requiring larger \\(N\\) to overcome the inflation of \\(\\chi^2\\). When data are normal, you simply multiply the \\(\\chi^2\\) statistic by \\(c\\) and calculate a \\(p\\) value for the corrected statistic: N &lt;- lavInspect(fit, &quot;ntotal&quot;) # subtract 1 if likelihood = &quot;wishart&quot; P &lt;- length(lavNames(AWmodelOut, type = &quot;ov&quot;)) # count observed variables K &lt;- length(lavNames(AWmodelOut, type = &quot;lv&quot;)) # count latent factors cc &lt;- 1 - ((2*P + 4*K + 5) / (6*N)) # correction factor (chi &lt;- fitMeasures(AWmodelOut, &quot;chisq&quot;)) (DF &lt;- fitMeasures(AWmodelOut, &quot;df&quot;)) (pValue &lt;- pchisq(chi*cc, DF, lower.tail = FALSE)) When adjusting for non-normality (in which case the model must be fit to raw data instead of summary statistics), you simply multiply the scaled \\(\\chi^2\\) statistic by \\(c\\) and calculate a \\(p\\) value for the corrected statistic. chi &lt;- fitMeasures(AWmodelOut, &quot;chisq.scaled&quot;) # nothing else changes When correcting the \\(\\Delta\\chi^2\\) statistic for model comparison, you can extract the \\(\\Delta\\chi^2\\) statistic from the anova() output, which will already be the scaled \\(\\Delta\\chi^2\\) when adjusting for non-normality. The \\(\\Delta df\\) can also be extracted from the output. AOV &lt;- anova(AWmodelOut, AWmodel2Out) chi &lt;- AOV[[&quot;Chisq diff&quot;]][2] DF &lt;- AOV[[&quot;Df diff&quot;]][2] Although the calculation of cc will not be affected by sample size or number of variables (because both models must be fit to the same sample people and variables), the number of factors \\(k\\) may differ between nested models. In this case, it is probably best to choose the larger \\(k\\) between the two models, because the model with fewer factors is statistically equivalent to the model with more factors if the factor variances were constrained to equality and factor correlations were constrained to 1 (i.e., if the factors are the same variable). This typically works in our favour because choosing the larger \\(k\\) will also decrease the \\(\\chi^2\\) more, so the model will appear to fit better. References Akaike, H. (1987). Factor analysis and AIC. Psychometrika, 52, 317–332. doi:10.1007/BF02294359 Barret, P. (2007). Structural equation modelling: Adjudging model fit. Personality and Individual Differences, 42(5), 815–824. doi:10.1016/j.paid.2006.09.018 Bentler, P. M. (1990). Comparative fit indexes in structural models. Psychological Bulletin, 107(2), 238–246. doi:10.1037/0033-2909.107.2.238 Bentler, P. M. (1995). EQS structural equations program manual. Encino, CA: Multivariate Software. Bentler, P. M., &amp; Bonett, D. G. (1980). Significance tests and goodness of fit in the analysis of covariance structures. Psychological Bulletin, 88(3), 588–606. doi:10.1037/0033-2909.88.3.588 Bollen, K. A. (1989). Structural equations with latent variables. Hoboken, NJ: Wiley Bollen, K. A. (1990). Overall fit in covariance structure models: Two types of sample size effects. Psychological Bulletin, 107(2), 256–259. doi:10.1037/0033-2909.107.2.256 Brosseau-Liard, P. E., Savalei, V., &amp; Li, L. (2012). An investigation of the sample performance of two nonnormality corrections for RMSEA. Multivariate Behavioral Research, 47(6), 904–930. doi:10.1080/00273171.2012.715252 Brosseau-Liard, P. E., &amp; Savalei, V. (2014). Adjusting incremental fit indices for nonnormality. Multivariate Behavioral Research, 49(5), 460–470. doi:10.1080/00273171.2014.933697 Browne, M. W., &amp; Cudeck, R. (1989). Single sample cross-validation indices for covariance structures. Multivariate Behavioral Research, 24(4), 445–455. doi:10.1207/s15327906mbr2404_4 Browne, M. W., &amp; Cudeck, R. (1992). Alternative ways of assessing model fit. Sociological Methods &amp; Research, 21, 230–258. doi:10.1177/0049124192021002005 Burnham, K., &amp; Anderson, D. (2003). Model selection and multimodel inference: A practical-theoretic approach. New York, NY: Springer-Verlag. Cudeck, R., &amp; Henly, S. J. (1991). Model selection in covariance structures analysis and the “problem” of sample size: A clarification. Psychological Bulletin, 109(3), 512–519. doi:10.1037/0033-2909.109.3.512 Hayduk, L., Cummings, G., Boada, K., Pazderka-Robinson, H., &amp; Boulianne, S. (2007). Testing! testing! one, two, three—Testing the theory in structural equation models! Personality and Individual Differences, 42, 841–850. doi:10.1016/j.paid.2006.10.001 Hu, L.-t., &amp; Bentler, P. M. (1998). Fit indices in covariance structure modeling: Sensitivity to underparameterized model misspecification. Psychological Methods, 3(4), 424–453. doi:10.1037/1082-989X.3.4.424 Hu, L.-t., &amp; Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. Structural Equation Modeling, 6(1), 1–55. doi:10.1080/10705519909540118 Jöreskog, K. G., &amp; Sörbom, D. (1981). LISREL V: Analysis of linear structural relationships by maximum likelihood. Chicago: National Educational Resources. Kenny, D. A., Kaniskan, B., &amp; McCoach, D. B. (2015). The performance of RMSEA in models with small degrees of freedom. Sociological Methods &amp; Research, 44(3), 486–507. doi:10.1177/0049124114543236 MacCallum, R. C., Browne, M. W., &amp; Sugawara, H. M. (1996). Power analysis and determination of sample size for covariance structure modeling. Psychological Methods, 1(2), 130–149. doi:10.1037//1082-989X.1.2.130 Marsh, H. W., Balla, J. R., &amp; McDonald, R. P. (1988). Goodness of fit indexes in confirmatory factor analysis: The effect of sample size. Psychological Bulletin, 103, 391–410. doi:10.1037/0033-2909.103.3.391 Marsh, H. W., Hau, K.-T., &amp; Wen, Z. (2004). In search of golden rules: Comment on hypothesis-testing approaches to setting cutoff values for fit indexes and dangers in overgeneralizing Hu &amp; Bentlers’ (1999) findings. Structural Equation Modeling, 11, 320–341. doi:10.1207/s15328007sem1103_2 Merkle, E. C., You, D., &amp; Preacher, K. J. (2016). Testing nonnested structural equation models. Psychological Methods, 21(2), 151–163. Advance online publication. doi:10.1037/met0000038 Millsap, R. E. (2007). Structural equation modeling made difficult. Personality and Individual Differences, 42(5), 875–881. doi:10.1016/j.paid.2006.09.021 Nevitt, J., &amp; Hancock, G. R. (2004). Evaluating small sample approaches for model test statistics in structural equation modelling. Multivariate Behavioral Research, 39(3) 439–478. doi:10.1207/S15327906MBR3903_3 Pornprasertmanit, S., Wu, W., &amp; Little, T. D. (2013). A Monte Carlo approach for nested model comparisons in structural equation modeling. In R. E. Millsap, L. A. van der Ark, D. M. Bolt, &amp; C. M. Woods (Eds.), New developments in quantitative psychology (Vol. 66, pp. 187–197). New York, NY: Springer. doi:10.1007/978-1-4614-9348-8_12 Raftery, A. E. (1986). Choosing models for cross-classification. American Sociological Review, 51(1), 145–146. Raftery, A. E. (1995). Bayesian model selection in social research. Sociological Methodology, 25, 111–163. Schermelleh-Engel, K., Moosbrugger, H., &amp; Müller, H. (2003). Evaluating the fit of structural equation models: Tests of significance and descriptive goodness-of-fit measures. Methods of Psychological Research Online, 8(2), 23–74. Sclove, S. L. (1987). Application of model-selection criteria to some problems in multivariate analysis. Psychometrika, 52, 333–343. doi:10.1007/BF02294360 Steiger, J. H., &amp; Lind, J. (1980). Statistically based tests fort the number of common factors. Paper presented at the annual meeting of the Psychometric Society, Iowa City. Tucker, L. R., &amp; Lewis, C. (1973). A reliability coefficient for maximum likelihood factor analysis. Psychometrika, 38, 1–10. doi:10.1007/BF02291170 West, S. G., Taylor, A. B., &amp; Wu, W. (2012). Model fit and model selection in structural equation modeling. In R. H. Hoyle (Ed.), Handbook of structural equation modeling (pp. 209–231). New York, NY: Guilford. Widaman, K. F., &amp; Thompson, J. S. (2003). On specifying the null model for incremental fit indices in structural equation modeling. Psychological Methods, 8(1), 16–37. doi:10.1037/1082-989X.8.1.16 Recall that the log-likelihood \\(\\ell\\) for a sample is the sum of all the individual log-likelihoods (\\(\\ell = \\mathbf\\Sigma\\ell_i\\)).↩︎ It is possible to use simulation-based methods to generate an empirical sampling distribution with which to derive critical values and p values (see, e.g., Millsap, 2007; Pornprasertmanit, Wu, &amp; Little, 2013).↩︎ For all calculations in the RMSEA section, replace N − 1 with N when using normal likelihood instead of Wishart likelihood, which is only used to analyze complete-data covariance structure.↩︎ The most common requirements for specifying an alternative baseline model would be when comparing models with different levels of measurement equivalence across groups or occasions (see chapters on invariance in multiple-group and longitudinal CFA models) or when evaluating homogeneity of residual variances in a latent growth curve model (see Widamin &amp; Thompson, 2003, for discussion).↩︎ This is the formula used by Bentler’s (1995) EQS program. Bollen (1989) proposed calculating SRMR from actual correlation residuals, by first standardizing the observed covariance matrix using observed variances, then standardizing the model-implied covariance matrix using model-implied variances, and taking the differences. When the observed and model-implied variances are equal (which is typically the case), these methods produce the same result. Currently, Mplus uses Bollen’s method for means and for off-diagonal elements (correlations, as well as for means when a mean-structure is modeled) and uses Bentler’s method for diagonal elements (variances). All three versions are available in lavaan, with Bentler’s method being the default output.↩︎ The BIC is also known as Akaike’s Bayesian Information Criterion (ABIC), or as the Schwarz (1978) Bayesian Criterion (SBC) after its developer. BIC is calculated only from information about the data, without using any information from a posterior distribution, so despite its name it is not really a Bayesian quantity. It is also not derived from information theory, so it is not really an “information” criterion either.↩︎ There is also a more general concept of covariance matrix nesting (Bentler &amp; Bonett, 1980), which simply states that if a less restrictive model (B) can fit perfectly to the same (or larger) set of covariance matrices than a more restrictive model (A) can, then A is nested within B. Covariance matrix nesting includes the special case of parameter nesting, but also includes situations where nested models have very different forms, so they do not have an equivalent set of parameters to estimate.↩︎ Unless an empirical sampling distribution can be derived, for example, using bootstrapping, permutation, or Monte Carlo simulation.↩︎ The default independence model might not be nested within each competing model (Widamin &amp; Thompson, 2003).↩︎ Replace the \\(N\\) in the denominator with \\(N − 1\\) when using Wishart likelihood for modelling covariance structure only.↩︎ "],["ch12.html", "12 Path Analysis with Categorical Outcomes 12.1 Prepare Data and Workspace 12.2 Regression Models for Binary Variables 12.3 Latent Response Variable 12.4 Mediation Model with Categorical Outcomes References", " 12 Path Analysis with Categorical Outcomes Structural equation modeling is a technique designed for continuous variables. In practice, variables are often not continuous but categorical, such as variables scored on discrete Likert scales (i.e., ordinal data) or correct/incorrect responses on test items (i.e., binary data). If endogenous variables in a path model (or in any SEM) are categorical, the SEM-method to deal with the categorical variables is to assume that there exists a latent (unobserved) continuous variable that underlies the observed categorical variable. The underlying variable is called a latent response variable (LRV). Categorical SEM fits the model to the LRVs instead of to the categorical variables. The observed categorical scores can be linked to the LRV using so-called thresholds that represent the value on the LRV beyond which individuals who score higher would get an observed categorical score in the higher category. For example, for a test item that asks ‘How many degrees of freedom does this path model have?’, the students could give the incorrect (scored 0) or the correct (scored 1) answer. The LRV here represents the ability (LRV) to calculate \\(df\\) for this path model on a continuous scale. Students whose ability is high enough would give the correct response; otherwise, the response would be incorrect. The threshold would reflect the minimum required ability to indicate the correct response. Fitting path models to categorical data thus involves linking the LRV to the observed categorical variables. In this chapter we first import example data, then we show how one can use probit and logit link functions in a generalized linear model (GLM). Next, we discuss the concept of the LRV for one ordinal variable, for multiple ordinal variables, and then we illustrate fitting a path model to ordinal variables. 12.1 Prepare Data and Workspace library(lavaan) 12.1.1 Import Example Data We will use example data reported by MacKinnon et al. (2007), which are available to download from the Mplus} website} as supplementary materials for a technical report (Muthén, 2011, p. 24). The example data can be downloaded directly from the URL using read.table(file=), as shown below. Note that the data are in summary format (i.e., a table with frequencies for each combination of categories for the 3 variables). The read.table() output is therefore transformed into a standard data.frame with 1 row per subject. dd &lt;- read.table(file = &quot;http://www.statmodel.com/examples/shortform/4cat%20m.dat&quot;, col.names = c(&quot;intention&quot;, &quot;intervention&quot;, &quot;ciguse&quot;, &quot;w&quot;)) dd$intention &lt;- dd$intention - 1L # make the lowest category 0, not 1 ## transform frequency table to casewise data myData &lt;- do.call(rbind, lapply(1:nrow(dd), function(RR) { data.frame(rep(1, dd$w[RR]) %*% as.matrix(dd[RR, 1:3])) })) Predictor: intervention (1 = treatment, 0 = control) Mediator: intention to smoke in the following 2 months (measured 6 months after intervention) 0 = No, 1 = I don’t think so, 2 = Probably, 3 = Yes Outcome: ciguse in previous month (1 = smoked, 0 = not), measured a 1-year follow-up 12.1.2 Summarize Data The resulting data.frame looks like this: ## intention intervention ciguse ## 415 0 1 0 ## 463 0 1 0 ## 179 1 0 1 ## 526 0 1 0 ## 195 1 0 0 The marginal frequencies for each variable are: ## table for each variable lapply(myData, table) ## $intention ## ## 0 1 2 3 ## 644 103 60 57 ## ## $intervention ## ## 0 1 ## 371 493 ## ## $ciguse ## ## 0 1 ## 708 156 Let’s begin with a frequency table to estimate the proportion of subjects who smoke cigarettes (i.e., the estimated probability of smoking: \\(\\widehat{\\pi}\\)) in each combination of categories for the predictors. tab3way &lt;- table(myData) probs &lt;- prop.table(tab3way, 1:2)[,,2] addmargins(probs, FUN = mean) ## Margins computed over dimensions ## in the following order: ## 1: intention ## 2: intervention ## intervention ## intention 0 1 mean ## 0 0.11583012 0.08311688 0.09947350 ## 1 0.26530612 0.20370370 0.23450491 ## 2 0.58823529 0.42307692 0.50565611 ## 3 0.68965517 0.67857143 0.68411330 ## mean 0.41475668 0.34711723 0.38093696 The treatment group (intervention == 1) smokes less, both on average and within each intention group. Smoking also increases with intent to smoke (both on average and within treatment/control groups). Treatment appears least effective among those who were certain they would continue smoking (row 4). 12.2 Regression Models for Binary Variables Suppose we used a linear model to predict the probability of smoking, treating intention as a continuous predictor to estimate only its linear effect. mod.lin &lt;- lm(ciguse ~ intervention + intention, data = myData) coef(mod.lin) ## (Intercept) intervention intention ## 0.1177588 -0.0439528 0.1927033 The estimated intercept indicates the predicted probability of smoking when predictors are zero (i.e., those in the control group with no intent to smoke). The estimated slopes reflect what we saw in the table: treatment reduces the probability of smoking (given the intent to smoke), and intent to smoke is associated with more smoking (given treatment). Note: No interaction is included here, but you can test for yourself that it was not significant. It would be problematic if the model predicted any probabilities outside the natural 0–1 range. We do not observed that problem in this specific sample: summary(fitted(mod.lin)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.07381 0.07381 0.11776 0.18056 0.26651 0.69587 This limitation of linear probability models is resolved with a link function in a GLM that allows for predicted values along the entire real-number line. Two such transformations are in frequent use: The probit (probability unit) transformation dates back to Bliss (1934). A probability can be transformed to a corresponding quantile in a cumulative distribution function (CDF), such as the standard-normal distribution. In other words, any probability \\(p\\) between 0–1 has a corresponding \\(z\\) score, such as can be requested from qnorm(p). Likewise, any predicted value on the probit scale can be transformed back into a probability using pnorm(probit). The GLM takes the form below, where \\(\\Phi()\\) is the standard-normal CDF, \\(\\Phi^{-1}()\\) is its inverse, and \\(\\mathbf{XB}\\) is the linear predictor (\\(\\widehat{y}\\)): \\[ \\text{Probit}(y=1) = \\Phi(\\pi) = z = \\mathbf{XB} \\] \\[ \\text{Pr}(y=1) = \\pi = \\Phi^{-1}(z) \\] The logit (logistic unit) transformation is often favored because its coefficients can be interpreted on the (natural-)log-odds scale. Recall the odds of an outcome is a ratio of its probability (\\(\\pi\\)) to its complement (\\(1-\\pi\\)), so its range is 0 to \\(+\\infty\\) (i.e., it is merely bound to nonnegative numbers). The natural (i.e., base-\\(e\\)) log of a nonnegative number can take any real number. The formulas below show how probabilities, odds, and logits are related. \\[ \\text{Logit}(\\pi) = \\ln(\\text{odds}) = \\ln \\Bigg(\\frac{\\pi}{1 - \\pi} \\Bigg) = \\mathbf{XB} \\] \\[ \\text{odds} = \\frac{\\pi}{1 - \\pi} = \\mathrm{e}^{\\text{Logit}(\\pi)} \\text{ , where } \\; \\; \\mathrm{e} = 2.7182818 \\] \\[ \\pi = \\frac{\\text{odds}}{1 + \\text{odds}} = \\frac{\\mathrm{e}^\\text{Logit}}{1 + \\mathrm{e}^\\text{Logit}} \\] There is a logit() function in the psych package, but it is simple enough to calculate the transformation (and its inverse): logit &lt;- log( p / (1-p) ) # odds &lt;- p / (1-p) p &lt;- exp(logit) / (1 + exp(logit)) # odds &lt;- exp(logit) Both probit and logistic regression models can be estimated using the glm() function, demonstrated below. 12.2.1 Fit a Logistic Regression Model In order to compare the results of fitting the logistic and the probit regression models, we first fit the GLM with the logit link. We continue to treat the ordinal mediator intention as continuous for now. mod.logit &lt;- glm(ciguse ~ intervention + intention, data = myData, family = binomial(&quot;logit&quot;)) coef(mod.logit) ## (Intercept) intervention intention ## -2.0177349 -0.3771387 1.0379733 12.2.2 Fit a Probit Regression Model mod.probit &lt;- glm(ciguse ~ intervention + intention, data = myData, family = binomial(&quot;probit&quot;)) coef(mod.probit) ## (Intercept) intervention intention ## -1.1894765 -0.2030216 0.6081512 12.2.3 Compare Models The GLMs make very similar predictions. We can compare all 3 models’ (linear, logit and probit) predictions to the observed probabilities in each group. ## intention intervention p.obs p.linear p.logit p.probit ## 1 3 1 0.67857143 0.65191604 0.67239696 0.66711311 ## 3 3 0 0.68965517 0.69586883 0.74954459 0.73727830 ## 5 2 1 0.42307692 0.45921270 0.42093726 0.43007009 ## 7 2 0 0.58823529 0.50316549 0.51454880 0.51070069 ## 9 1 1 0.20370370 0.26650936 0.20474455 0.21641830 ## 11 1 0 0.26530612 0.31046215 0.27293908 0.28051061 ## 13 0 1 0.08311688 0.07380601 0.08356445 0.08188581 ## 15 0 0 0.11583012 0.11775881 0.11735341 0.11712611 Notice how similar the predicted probabilities are across models, and how close they are to the observed proportions in each group. Each of these models estimates the same number of parameters, but their functional form differs (identity, logit, and probit link functions, with different models for error). So we can only compare the fit of each model to the data descriptively. Here are two examples: (1) sum the squared differences between each model’s predicted probabilities and the observed probabilities, summarized by Pearson’s \\(\\chi^2\\) statistic (lower fits better): ## p.linear p.logit p.probit ## 0.04094642 0.01564608 0.01676192 Or compare their Tjur’s pseudo-\\(R^2\\) values (higher fits better): ## linear logit probit ## 0.2042811 0.2074272 0.2063500 In both cases, the logit model performs slightly better than probit, both of which perform better than the linear model. But the discrepancies are small. 12.3 Latent Response Variable In SEM, the probit model is often preferred because predicted values are \\(z\\) scores that can be transformed into probabilities. This lends itself easily to a latent-response interpretation, which can be stated as follows for the cigarette-use example. Each subject has a latent propensity to smoke. This propensity is a continuous, normally distributed trait. Subjects whose propensity exceeds a threshold succumb to smoking, whereas those whose propensity does not exceed the threshold refrain from smoking. The probit model above can therefore be reframed in terms of this LRV, \\(\\mathrm{y}^*\\). \\[\\mathrm{y}^* = \\mathbf{XB} + \\varepsilon ,\\] where \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma)\\) and the observed binary response \\(\\mathrm{y}\\) is linked to the LRV by a threshold model: \\[\\mathrm{y} = I(y^* &gt; \\tau),\\] where the indicator function \\(I()\\) assigns 1 when its argument is TRUE and 0 when it is FALSE. Because the LRV is unobserved (i.e., latent), its distributional parameters cannot be estimated from the data. GLM software like the glm() function typically identify the model by fixing the residual variance \\(\\sigma=1\\) and the threshold \\(\\tau=0\\). For simplicity, consider an intercept-only model for cigarette use. mod0 &lt;- glm(ciguse ~ 1, data = myData, family = binomial(&quot;probit&quot;)) coef(mod0) ## (Intercept) ## -0.9132499 In lavaan the default is instead to fix the intercept to 0 and estimate the threshold. The model syntax below shows how thresholds are specified with the “pipe” (vertical bar: |) followed by t1 indicating the first threshold. mod0.ciguse &lt;- &#39;ciguse | t1&#39; # specify first (and only) threshold fit0.ciguse &lt;- sem(mod0.ciguse, data = myData) summary(fit0.ciguse, header = FALSE, nd = 7) ## ## Parameter Estimates: ## ## Parameterization Delta ## Standard errors Robust.sem ## Information Expected ## Information saturated (h1) model Unstructured ## ## Thresholds: ## Estimate Std.Err z-value P(&gt;|z|) ## ciguse|t1 0.9132499 0.0498031 18.3372246 0.0000000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## ciguse 1.0000000 Binary variables have only 1 threshold that splits a normal distribution into 2 categories. Notice that it is arbitrary whether the intercept (mean) or threshold is fixed to 0. In the output of glm() the threshold was fixed at zero and intercept was estimated to be \\(-0.913\\). In the output of lavaan the intercept is fixed at zero and the threshold was estimated to be \\(+0.913\\). In either case, the threshold is the same distance from the LRV’s mean, as depicted in Figure 12.1 below. Figure 12.1: One threshold divides a normal distribution into two categories. Notice that the distributions are identical. Only the \\(x\\)-axis differs, reflecting the change in (arbitrary) identification constraint. 12.3.1 Ordinal Outcomes The LRV interpretation is easily extended to polytomous ordinal variables, such as intent to smoke. This is called the cumulative probit model (and link function). Any ordinal variable with categories \\(c=0, \\ldots, C\\) can be interpreted as a crude discretization of an underlying LRV, whose \\(C\\) thresholds divide the latent distribution into \\(C+1\\) categories. \\[\\mathrm{y}=c \\ \\ \\ \\text{ if } \\ \\ \\ \\tau_c &lt; y^* \\le \\tau_{c+1} \\] Because the normal distribution is unbounded, the first category “starts” at \\(\\tau_0 = -\\infty\\), and the last category “ends” at \\(\\tau_{C+1} = +\\infty\\). For example, intent to smoke has 4 categories, so there are \\(C=3\\) thresholds. We do not have to specify thresholds in lavaan model syntax if we tell lavaan which variables are ordinal using the argument ordered=. When all modeled variables are ordinal, one can use TRUE as a shortcut. fit2 &lt;- sem(&#39;ciguse ~~ intention&#39;, data = myData, ordered = TRUE) summary(fit2, header = FALSE, standardized = TRUE) ## ## Parameter Estimates: ## ## Parameterization Delta ## Standard errors Robust.sem ## Information Expected ## Information saturated (h1) model Unstructured ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ciguse ~~ ## intention 0.637 0.041 15.496 0.000 0.637 0.637 ## ## Thresholds: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ciguse|t1 0.913 0.050 18.337 0.000 0.913 0.913 ## intention|t1 0.660 0.046 14.280 0.000 0.660 0.660 ## intention|t2 1.101 0.054 20.570 0.000 1.101 1.101 ## intention|t3 1.506 0.066 22.867 0.000 1.506 1.506 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ciguse 1.000 1.000 1.000 ## intention 1.000 1.000 1.000 Notice that intent has 3 thresholds, labeled with sequential integers following the letter t. This is how they would be specified in lavaan model syntax, e.g., &#39; intention | NA*t1 + NA*t2 + NA*t3 &#39; Alternatively, set the argument auto.th=TRUE to automatically estimate all thresholds. The LRV for intention can be interpreted as the degree to which someone intends to smoke—similar to the observed variable, but the degree increases continuously rather than in discrete increments. Subjects in Category 0 do not have a latent intent to smoke that exceeds the first threshold (\\(\\hat\\tau_1\\)), so they do not indicate that they intend to smoke. Subjects will only respond that they “don’t know” when their latent intent exceeds \\(\\hat\\tau_1=\\) 0.66 \\(SD\\)s above the mean of that distribution. Subjects must exceed \\(\\hat\\tau_2=\\) 1.101 \\(SD\\) above the mean before they begin indicating “probably”. Only those whose latent intent exceeds \\(\\hat\\tau_3=\\) 1.506 \\(SD\\)s above the mean do they respond firmly “yes”. Figure 12.2 below visualizes the “classification rules” above. Figure 12.2: Three thresholds divide a normal distribution into four categories. 12.3.2 Estimating Thresholds Thresholds are univariate statistics (like means). Threshold estimates are based on the frequency distribution of a categorical variable. Recall that the probit function merely transforms a (predicted) probability (\\(\\pi\\)) into a corresponding \\(z\\) score. The (standardized) thresholds are these \\(z\\) scores. We can estimate them by plugging into qnorm() the cumulative proportions (\\(\\widehat\\pi_c\\)) up to each category \\(c\\). For example, here are the (cumulative) proportions in each category of intention. p.intent &lt;- prop.table(table(myData$intention)) # proportions per category cumsum(p.intent) # cumulative proportions (up to and including each category) ## 0 1 2 3 ## 0.7453704 0.8645833 0.9340278 1.0000000 By definition, 100% of the sample was observed in any of the categories up to (and including) the highest category, so the final cumulative proportion is 1. Likewise, no one in the sample was observed in a category lower than the lowest category (by definition), so we can append a zero as the first number in this vector of cumulative proportions. Then we can find the corresponding \\(z\\) scores in a normal distribution, which are the thresholds between categories: qnorm(c(0, cumsum(p.intent))) ## 0 1 2 3 ## -Inf 0.6599915 1.1011455 1.5064783 Inf The upper and lower thresholds are \\(+/-\\infty\\) by definition, corresponding to 0 and 100%. Those never need to be estimated because they are fixed by design. The remaining 3 thresholds are actual borders between observed categories, showing how far above/below the mean a subject must be in order to indicate a particular response category. 12.3.3 Estimating Polychoric Correlations With multiple ordinal variables, we can estimate the correlations between their associated LRVs by relying on the assumption that the LRVs are normally distributed (Olsson, 1979, 1982). These correlations are called polychoric correlations (Olsson, 1979), which are bivariate statistics (like the covariance matrix). If the model also includes a continuous variable, its correlation with an ordinal variable’s LRV is called the polyserial correlation (Olsson, 1982). Special names for 2-category variables are tetrachoric correlation (between 2 binary variables) or biserial correlation (between a binary and continuous variable). For example, the estimated covariance between cigarette use and intent to smoke in the model above is a polychoric correlation because each LRV’s \\(SD\\) was fixed to 1 in that unrestricted (saturated) model. The reason that the probit model is so popular in SEM is that the standard SEM matrices and interpretations still apply to normal data, except those normal variables are latent. All we need to do is append the SEM with a threshold model in order to link these normal LRVs to their observed discrete counterparts. The default saturated model in lavaan estimates all thresholds and polychoric (and polyserial, if applicable) correlations, along with means and (co)variances among any continuous variables. This is used as input data when fitting any hypothesized model (even when fitting a regression model with \\(df=0\\)). We can see the estimated sample statistics for the model above: lavInspect(fit2, &quot;sampstat&quot;) ## $cov ## ciguse intntn ## ciguse 1.000 ## intention 0.637 1.000 ## ## $mean ## ciguse intention ## 0 0 ## ## $th ## ciguse|t1 intention|t1 intention|t2 intention|t3 ## 0.913 0.660 1.101 1.506 Notice that the means are 0 and variances are 1, consistent with the correlation metric and the assumption that the underlying LRV is a \\(z\\) score. These values are actually fixed to identify the saturated model. We will discuss scaling constraints and identification of latent variables more when we introduce the common-factor model. 12.3.4 Estimating an SEM with Estimated Input The problem with treating thresholds and polychoric correlations as observed data is that they were not observed. They are estimates of population parameters, based on the data. They each have an associated \\(SE\\) and 95% CI. In order to trust the \\(SE\\)s, 95% CIs, and test statistics in our hypothesized model, we need to take the uncertainty of the “data” into account. This is often accomplished using weighted least-squares estimation, where the weight matrix \\(\\mathbf{W}\\) is the sampling covariance matrix of the estimated thresholds and polychoric correlations. Note: Do not confuse the sampling covariance matrix of estimated parameters with the covariance matrix of variables. The latter is used as input data, and it is what we want our SEM to explain. The sampling covariance of parameter estimates is how we quantify their uncertainty: its diagonal contains sampling variances, the square-roots of which are the \\(SE\\)s that we use to calculate Wald \\(z\\) tests and CIs. The more variables (and categories) there are, the larger \\(\\mathbf{W}\\) becomes: there is one row/column for every estimated threshold and correlation. Even in samples as large as 1000, this makes estimation unstable. An alternative is to simply ignore the sampling covariances during estimation, so \\(\\text{diag}(\\mathbf{W})\\) is the weight matrix to obtain point estimates of parameters. This is called diagonally weighted least squares (estimator = \"DWLS\"), which is the default in lavaan. Even with DWLS, the full weight matrix is still needed to calculate \\(SE\\)s and the \\(\\chi^2\\) statistic. The \\(\\chi^2\\) statistic needs to be robust against the uncertainty of the input data, so it is adjusted by scaling it (a mean-adjusted statistic) and optionally shifting it (a mean- and variance-adjusted statistic). The default is both: estimator = \"WLSMV\" is a shortcut that implies lavaan(..., estimator = \"DWLS\", se = \"robust.sem\", test = \"scaled.shifted\") Another alternative is unweighted/ordinary least squares (ULS), where \\(\\mathbf{W}\\) is an identity matrix. This often yields good point estimates, but Type I error rates can differ from the \\(\\alpha\\) level, so it is still recommended to request a scaled/shifted \\(\\chi^2\\) statistic (e.g., estimator = \"ULSMV\"). There are also likelihood-based estimators. One option is marginal maximum likelihood (estimator = \"MML\"), which is currently disabled in lavaan because it was too computationally intensive and the developer is exploring better routines. A less computationally intensive alternative is pairwise maximum likelihood (estimator = \"PML\"), which maximizes only the (sum of) uni- and bivariate (log-)likelihoods. This is a quite robust procedure even in small samples, and because it is likelihood-based, information criteria (AIC and BIC) are available. Note: The “robust” statistics are only corrected for the two-stage estimation procedure (thresholds+pollychorics, followed by SEM parameters using DWLS or ULS) or for combining pairwise log-likelihoods (using PML). The LRV interpretation for categorical outcomes assumes a normal distribution for latent responses. Because LRVs are (by definition) unobserved, there is no way to estimate their degree of nonnormality, which would be necessary to correct for it. 12.3.4.1 Counting Degrees of Freedom For SEM with only continuous variables, the number of observed summary statistics \\(p^*\\) is a simply function of the number of variables \\(p\\): \\[p^* = \\frac{p(p+3)}{2} \\text{ (with mean structure) or } \\frac{p(p+1)}{2} \\text{ (without means)}\\] \\(p\\) means \\(p\\) variances \\(\\frac{p(p-1)}{2}\\) covariances The number of “observed” covariances does not differ between continuous and categorical variables, but some covariances are replaced by: polychoric correlations among LRVs (scaled) polyserial correlations between LRVs and observed variables But the number of univariate statistics can differ. Whereas continuous variables each contribute an observed mean and variance, categorical variables do not contribute either (i.e., those values are fixed to 0 and 1, respectively, to estimate thresholds and polychoric correlations). Instead, each categorical variable contributes \\(C\\) “observed” standardized thresholds for its \\(C+1\\) categories. So each binary variable contributes \\(C=1\\) threshold, each “ternary” (3-category) variable contributes \\(C=2\\) thresholds, and so on. Thus, the number summary statistics is a function of the number of observed continuous and discrete variables. Suppose we denote: \\(p_c\\) the number of continuous variables \\(p_d\\) the number of discrete variables so the total number of observed variables remains \\(p = p_c + p_d\\) the number of thresholds for discrete variables \\(d = 1, \\dots, D\\) is \\(C_d\\) the total number of thresholds is \\(K = \\sum_{d=1}^D C_d\\) Then the number summary statistics is \\(\\frac{p(p-1)}{2} + 2p_c + K\\). That is, both continuous and discrete variables contribute covariances/correlations (first term), only continuous variables contribute a mean and variance (second term), and only discrete variables contribute thresholds (third term). This has implications for determining the expected \\(df\\), which is an important part of verifying that you fit the model you intended to fit. Just as mean structures are typically saturated (e.g., for every observed mean, an intercept is estimated), each “observed” standardized threshold has a corresponding estimated threshold (not necessarily standardized, but is by default in lavaan). Likewise, intercepts and (residual or marginal) variances typically remain fixed for LRVs in hypothesized models, as they do in the default saturated model. Thresholds might be constrained (contributing \\(df\\)) in models for multiple groups or occasions—as might LRV intercepts or (residual or marginal) variances—which we discuss in later chapters. 12.3.4.2 Missing Data When multivariate-normal data are incomplete, all available information can be used to estimate parameters by setting missing = \"FIML\" (full-information ML estimation) to override the default listwise deletion method. Actually, FIML applies to nonnormal continuous data as well, since a robust correction for nonnormality is available with FIML results (estimator = \"MLR\"). FIML is also available for categorical outcome(s), but only when using (marginal) ML estimation. Until estimator = \"MML\" becomes available in lavaan, the FIML option is unfortunately unavailable. When at least 1 endogenous variable is binary/ordinal, missing = \"pairwise\" deletion retains as much information as possible, so it is still preferred over the default missing = \"listwise\" deletion. However, both deletion methods make the restrictive assumption that data are missing completely at random (MCAR). The reason pairwise deletion assumes MCAR data is that for each pair of variables, it estimates their covariance (or polychoric/polyserial correlation) using all jointly observed complete data for that pair of variables. So no information from other observed variables can be used to estimate the covariance/correlation. In contrast, FIML estimates parameters using each person’s entire vector of observed data, so missing data on Variable A can be compensated by observed data on Variable B. Thus, FIML makes the less restrictive assumption that data are missing at random (MAR)—that is, the missingness is still random conditional on the observed data (see Little et al., 2014, for more detailed conceptual explanations). Pairwise deletion is available with any (diagonally or un)weighted least-squares estimators, as well as with (P)ML. But with PML for categorical outcomes, a missing = \"doubly.robust\" estimation method is available that only requires assuming data are MAR (Katsikatsou et al., in press). It is computationally intensive, but it may be worth it if the MAR assumption is not feasible. 12.4 Mediation Model with Categorical Outcomes Consider the mediation model depicted in Figure 12.3 below. The dashed line is the direct effect of treatment on smoking behavior, given the intent to smoke. Figure 12.3: Mediation model for smoking-intervention data from Duncan and Duncan (1996). Because SEM treats an exogenous binary predictor as numeric (like dummy-coded predictors in standard OLS regression models), these \\(p=3\\) variables include \\(p_c=1\\) “continuous” predictor (intervention) and \\(p_d=2\\) discrete outcomes. These contribute \\(p^* = \\frac{p(p-1)}{2} = 3\\) “observed” covariances: The polyserial correlations of intervention with ciguse and intention The polychoric correlation between ciguse and intention The predictor also contributes \\(2p_c=2\\) observed values: a mean and a variance. The endogenous binary variable ciguse contributes 1 threshold, and the endogenous ordinal variable intention contributes 3 thresholds, so \\(K=4\\). Thus, there are 3 + 2 + 4 = 9 summary statistics in this 3-variable system. There are 3 possible conclusions: No mediation: the indirect effect \\(\\beta_{21} \\times \\beta_{32}=0\\) because either \\(\\beta_{21}=0\\) or \\(\\beta_{32}=0\\) Partial mediation: the indirect effect \\(\\beta_{21} \\times \\beta_{32} \\ne 0\\) and the direct effect \\(\\beta_{31} \\ne 0\\) Full mediation: the indirect effect \\(\\beta_{21} \\times \\beta_{32} \\ne 0\\) but the direct effect \\(\\beta_{31} = 0\\) Omitting the dashed line (by fixing \\(\\beta_{31}=0\\)) would imply full mediation. A full-mediation model would estimate 8 parameters: 2 regression slopes (\\(\\beta_{21}\\) and \\(\\beta_{32}\\)) 1 mean and 1 variance for the exogenous dummy coded intervention 3 thresholds for the mediator intention 1 threshold for the outcome ciguse Thus, the full-mediation model will have \\(df=1\\). The partial-mediation model would estimate the dashed line, reducing \\(df=0\\). No mediation could be represented by a model that estimates the dashed line but fixes either \\(\\beta_{21}=0\\) (a multiple-regression model for ciguse) or \\(\\beta_{32}=0\\) (a multivariate regression model for intention and ciguse). We will only fit the full and partial mediation models in the next section. 12.4.1 Estimate Mediation Models Begin by fitting the partial-mediation model to the data, to test \\(H_0: \\beta_{21} \\times \\beta_{32}=0\\) (no mediation). We will only specify the regression slopes and user-defined parameters because the residual variances are not estimated. The identification constraints require more explanation (see the following section). mod.part &lt;- &#39; ## regression paths intention ~ b21*intervention ciguse ~ b31*intervention + b32*intention ## define indirect and total effects ind := b21*b32 tot := ind + b31 &#39; fit.part &lt;- sem(mod.part, data = myData, ordered = TRUE) summary(fit.part, standardized = TRUE, rsquare = TRUE) ## lavaan 0.6-19 ended normally after 13 iterations ## ## Estimator DWLS ## Optimization method NLMINB ## Number of model parameters 7 ## ## Number of observations 864 ## ## Model Test User Model: ## Standard Scaled ## Test Statistic 0.000 0.000 ## Degrees of freedom 0 0 ## ## Parameter Estimates: ## ## Parameterization Delta ## Standard errors Robust.sem ## Information Expected ## Information saturated (h1) model Unstructured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## intention ~ ## intrvntn (b21) -0.246 0.089 -2.758 0.006 -0.246 -0.121 ## ciguse ~ ## intrvntn (b31) -0.130 0.093 -1.402 0.161 -0.130 -0.064 ## intentin (b32) 0.631 0.042 15.105 0.000 0.631 0.629 ## ## Thresholds: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## intention|t1 0.525 0.067 7.844 0.000 0.525 0.521 ## intention|t2 0.970 0.071 13.572 0.000 0.970 0.963 ## intention|t3 1.378 0.082 16.710 0.000 1.378 1.368 ## ciguse|t1 0.760 0.072 10.491 0.000 0.760 0.752 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .intention 1.000 1.000 0.985 ## .ciguse 0.602 0.602 0.591 ## ## R-Square: ## Estimate ## intention 0.015 ## ciguse 0.409 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ind -0.155 0.057 -2.713 0.007 -0.155 -0.076 ## tot -0.285 0.100 -2.845 0.004 -0.285 -0.140 Using the standard criterion \\(\\alpha=5\\%\\), the Wald \\(z\\) tests allow us to reject the \\(H_0\\) of no mediation: indirect effect \\(b\\) = \\(-0.155\\), \\(z = -2.713\\), p = 0.007, \\(\\beta = -0.076\\). We fail to reject the \\(H_0\\) of full mediation: direct effect b = \\(-0.13\\), \\(z = -1.402\\), p = 0.161, \\(\\beta = -0.064\\). Because the scales of the LRVs are arbitrary, it is safer to interpret the standardized slopes test a \\(H_0\\) using a \\(\\Delta \\chi^2\\) test We can fit a full-mediation model to the data to obtain the LRT. mod.full &lt;- &#39; ## regression paths intention ~ b21*intervention ciguse ~ b32*intention ## define indirect and total effects ind := b21*b32 &#39; fit.full &lt;- sem(mod.full, data = myData, ordered = TRUE) lavTestLRT(fit.full, fit.part) # or anova(), which then calls lavTestLRT() ## ## Scaled Chi-Squared Difference Test (method = &quot;satorra.2000&quot;) ## ## lavaan-&gt;lavTestLRT(): ## lavaan NOTE: The &quot;Chisq&quot; column contains standard test statistics, not the robust test ## that should be reported per model. A robust difference test is a function of two standard ## (not robust) statistics. ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## fit.part 0 0.0000 ## fit.full 1 1.2648 1.9567 1 0.1619 Notice that lavTestLRT() automatically detects the robust estimator and test statistic requested when fitting the models, so it appropriately uses the same robust correction (mean- and variance-adjustment) for the \\(\\Delta \\chi^2\\) statistic. This is why the Chisq Diff column does not match the difference between (uncorrected) \\(\\chi^2\\) values in the Chisq column. The \\(p\\) value is very close to the Wald test’s \\(p\\) value (also calculated using a robust \\(SE\\)), which is expected when \\(N\\) is large. 12.4.2 Interpreting Coefficients Notice that the glm() estimates from the probit regression for ciguse do not match those from the sem() function. There are noteworthy differences in parameterization: The GLM approach fixes the threshold to 0 and estimates the intercept. The SEM approach fixes the intercept to 0 and estimates the threshold. As shown in the figure above, this distinction is arbitrary because the LRV has no “location” that we can identify from the data. The intercept and threshold can only be said to be a certain distance apart, which is why they take the same absolute value. For example, we can free the ciguse intercept in lavaan syntax and fix its threshold instead: ## fixed intercept coef(fit.part, type = &quot;all&quot;)[c(&quot;ciguse|t1&quot;,&quot;ciguse~1&quot;)] ## ciguse|t1 ciguse~1 ## 0.7596909 0.0000000 ## fixed threshold mod.trade &lt;- &#39; ciguse | 0*t1 # fix threshold ciguse ~ NA*1 # estimate intercept &#39; coef(sem(c(mod.part, mod.trade), data = myData, ordered = TRUE), type = &quot;all&quot;)[c(&quot;ciguse|t1&quot;,&quot;ciguse~1&quot;)] ## ciguse|t1 ciguse~1 ## 0.0000000 -0.7596909 The GLM approach treats all predictors as fixed, and predictors are distinct from outcomes. Intent to smoke was treated as continuous. Although we could have used polynomial contrast codes to estimate linear, quadratic, and cubic effects, we still would have to take the observed category weights (0–3) as given. The SEM approach allows outcomes to predict other outcomes. So the LRV underlying intent to smoke was used as a predictor of smoking propensity (LRV underlying ciguse). This allows us to extrapolate from our results what we would expect if we had measured intent as a continuous variable (and it happened to be normally distributed). A final distinction has to do with the identification constraint on the LRV scale. 12.4.3 Delta vs. Theta Parameterizations The SEM approach in lavaan (by default) fixes the marginal (i.e., total) variance of the LRV to 1. This is called the “delta parameterization” in the SEM literature. The GLM approach fixes the residual/conditional variance to 1. This is called the “theta parameterization” in the SEM literature. Under the delta parameterization, the residual variance is fixed such that it equals 1 minus the explained variance (\\(1-R^2\\)). Under the theta parameterization, the LRV’s total variance is the sum of explained and unexplained variance (1 + explained variance). The total variances is not an explicit SEM parameter; instead, the scaling factors (Scales y* in the output) are the reciprocal of the total \\(SD\\) (i.e., \\(\\frac{1}{SD}\\)). Use the argument parameterization = \"theta\" to override the default delta parameterization, if there is a reason to do so (i.e., if you want to model residual variances). This will be discussed further in the chapter about item factor analysis (i.e., common-factor models for categorical indicators). This arbitrary distinction can have important consequences for the interpretation and decomposition of mediated effects. For example, the indirect effects would not be comparable between full- and partial-mediation models when fixing residual variances to 1, because doing so would change the scale of the LRV across the two models. That is, the relative amount of residual variance would be different for the full- and partial mediation models. The partial-mediation model explains less variance (lower \\(R^2\\), so its residual variance should be larger) than the full-mediation model, but residual variances are fixed to 1 in both cases, making the total variance appear smaller in the partial-mediation model. This change of scales changes the meaning of ‘one unit increase’ across the models. Luckily, when using the delta parameterization in single-group models, the outcome’s LRV scale (and any categorical mediator’s LRV scale) is already held constant by fixing the marginal variance to 1 (Breene et al., 2013). However, this good news would not apply in more complex situations that affect LRV scales, such as multigroup models. So when using path analysis with categorical outcomes, it is best to exercise caution. Use the delta parameterization, and do not use a multigroup models to compare paths across groups (i.e., moderated mediation) unless you understand how to equate the LRV scales across groups. 12.4.4 Decomposing Total Effects Furthermore, a common method of quantifying the size of an indirect effect is the proportion of the total effect: \\(\\frac{\\beta_{21} \\times \\beta_{32}}{(\\beta_{21} \\times \\beta_{32}) + \\beta_{31}}\\). This is already problematic when the direct and indirect effects have opposite signs (called inconsistent mediation). But when the scale of a LRV varies between models with(out) a mediator, then the sum of estimated direct and indirect effects would no longer match the total effect. For example, fit separate probit models for the mediator and outcome, as would be necessary using the GLM approach. For simplicity, only treat ciguse as categorical. ## simple regression to obtain the total effect (total &lt;- coef(sem(&#39;ciguse ~ total*intervention&#39;, data = myData, ordered = &#39;ciguse&#39;, parameterization = &quot;theta&quot;))[&quot;total&quot;]) ## total ## -0.2850428 ## model for mediator (b21 &lt;- coef(sem(&#39;intention ~ b21*intervention&#39;, data = myData))[&quot;b21&quot;]) ## b21 ## -0.1644697 ## model for outcome (b3 &lt;- coef(sem(&#39;ciguse ~ b31*intervention + b32*intention&#39;, data = myData, ordered = &#39;ciguse&#39;, parameterization = &quot;theta&quot;))[c(&quot;b31&quot;,&quot;b32&quot;)]) ## b31 b32 ## -0.2030216 0.6081512 ## estimate total effect from decomposition b3[[1]] + b21*b3[[2]] ## b21 ## -0.303044 This does not match the total effect from the simple probit regression because the LRV scales differ. That is, the simple regression has more residual variance (less explained variance without intention in the model), yet the residual variance is still fixed to 1. Imai et al. (2010) proposed a general solution to this problem, using the causal-modeling framework, implemented in the mediation (see their `vignette for examples). It is quite complicated, but here is how it would apply to our current example (see also Muthén, 2011, for corresponding Mplus syntax): mod.Imai &lt;- &#39; ciguse ~ c*intervention + b*intention intention ~ a*intervention # label threshold for ciguse ciguse | b0*t1 # biased SEs naive.indirect := a*b naive.direct := c # correct probit11 := (-b0+c+b*a)/sqrt(b^2+1) probit10 := (-b0+c )/sqrt(b^2+1) probit00 := (-b0 )/sqrt(b^2+1) indirect := pnorm(probit11) - pnorm(probit10) direct := pnorm(probit10) - pnorm(probit00) &#39; fit &lt;- sem(mod.Imai, data = myData, ordered = c(&quot;ciguse&quot;,&quot;intention&quot;)) summary(fit, std = TRUE) ## lavaan 0.6-19 ended normally after 13 iterations ## ## Estimator DWLS ## Optimization method NLMINB ## Number of model parameters 7 ## ## Number of observations 864 ## ## Model Test User Model: ## Standard Scaled ## Test Statistic 0.000 0.000 ## Degrees of freedom 0 0 ## ## Parameter Estimates: ## ## Parameterization Delta ## Standard errors Robust.sem ## Information Expected ## Information saturated (h1) model Unstructured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ciguse ~ ## interventn (c) -0.130 0.093 -1.402 0.161 -0.130 -0.064 ## intention (b) 0.631 0.042 15.105 0.000 0.631 0.629 ## intention ~ ## interventn (a) -0.246 0.089 -2.758 0.006 -0.246 -0.121 ## ## Thresholds: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ciguse|t1 (b0) 0.760 0.072 10.491 0.000 0.760 0.752 ## intntn|t1 0.525 0.067 7.844 0.000 0.525 0.521 ## intntn|t2 0.970 0.071 13.572 0.000 0.970 0.963 ## intntn|t3 1.378 0.082 16.710 0.000 1.378 1.368 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ciguse 0.602 0.602 0.591 ## .intention 1.000 1.000 0.985 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## naive.indirect -0.155 0.057 -2.713 0.007 -0.155 -0.076 ## naive.direct -0.130 0.093 -1.402 0.161 -0.130 -0.064 ## probit11 -0.884 0.062 -14.182 0.000 -0.884 -0.755 ## probit10 -0.752 0.070 -10.714 0.000 -0.752 -0.691 ## probit00 -0.643 0.063 -10.184 0.000 -0.643 -0.637 ## indirect -0.037 0.014 -2.647 0.008 -0.037 -0.020 ## direct -0.034 0.024 -1.403 0.161 -0.034 -0.017 However, Breen et al. (2013) proposed a simpler, less restrictive solution that holds the LRV scale consistent so that the decomposition holds. Their method is meant for researchers fitting separate regression models, and performed quite well in simulations (and similar to Imai et al.’s method). Luckily, when using the delta parameterization in single-group models, their method is unnecessary when simultaneously estimating the full/partial-mediation model as a path analysis. This is because the outcome’s LRV scale (and any categorical mediator’s LRV scale) is already held constant by fixing the marginal variance to 1. However, this good news would not apply in more complex situations that affect LRV scales, such as multigroup models. So when using path analysis with categorical outcomes, it is best to exercise caution. Use the delta parameterization, and do not use a multigroup models to compare paths across groups (i.e., moderated mediation) unless you understand how to equate the LRV scales across groups. References Bliss, C. I. (1934). The method of probits. Science, 79(2037), 38–39. https://doi.org/10.1126/science.79.2037.38 Breen, R., Karlson, K. B., &amp; Holm, A. (2013). Total, direct, and indirect effects in logit and probit models. Sociological Methods &amp; Research, 42(2), 164–191. https://doi.org/10.1177/0049124113494572 Katsikatsou, M., Moustaki, I., &amp; Jamil, H. (in press). Pairwise likelihood estimation for confirmatory factor analysis models with categorical variables and data that are missing at random. British Journal of Mathematical and Statistical Psychology. https://doi.org/10.1111/bmsp.12243 Little, T. D., Jorgensen, T. D., Lang, K. M., &amp; Moore, E. W. G. (2014). On the joys of missing data. Journal of Pediatric Psychology, 39(2), 151–162. https://doi.org/10.1093/jpepsy/jst048 Muthén, B. (2011). Applications of causally defined direct and indirect effects in mediation analysis using SEM in Mplus [Technical report]. Retrieved from http://www.statmodel.com/download/causalmediation.pdf Olsson, U. (1979). Maximum likelihood estimation of the polychoric correlation coefficient. Psychometrika, 44(4), 443–460. https://doi.org/10.1007/BF02296207 Olsson, U., Drasgow, F., &amp; Dorans, N. J. (1982). The polyserial correlation coefficient. Psychometrika, 47(3), 337–347. https://doi.org/10.1007/BF02294164 "],["ch13.html", "13 Fitting Path Models with Multilevel Data 13.1 Intraclass correlation 13.2 Multilevel structure as a nuisance: Correcting for the dependency 13.3 Two-level path models 13.4 Obtaining ICCs, and estimates of \\(\\Sigma_\\text{W}\\) and \\(\\Sigma_\\text{B}\\) 13.5 Fitting a two-level path model References", " 13 Fitting Path Models with Multilevel Data Research in the field of child development or education often involves nested observations. For example, data may be gathered by first selecting schools, and then selecting students within those schools, or researchers may select families and then children within those families. Such two-stage sampling schemes lead to individual observations that are not statistically independent. Two students from the same classroom have shared experiences (e.g. the same teacher, same classmates, same neighborhood where they live) that may make their responses more similar to each other than the responses obtained from two students from different classrooms. This dependency leads to structural differences across classrooms (for example, some classrooms have higher average math achievement because they have a better teacher). It is common to call the highest level of differences (the classroom-level in this example) the between level or Level 2, and the lowest level (the student-level here) the within level or Level 1. There exist several ways to evaluate path models with multilevel data, depending on the research question. All methods require analysis of raw data. Sometimes the research question involves all Level 1 variables, and the fact that the data have a nested structure are just the result of the sampling design. In such a case, the multilevel structure is regarded a nuisance that the researcher actually wants to get rid of. Alternatively, there may be research questions that involve variables that operate at both levels of analysis. For example, a researcher may be interested in the effect of students self-esteem on student achievement, and also in the effect of the average self-esteem in the classroom on the average student achievement. In such a situation the multilevel nature of the data is regarded as interesting, and one would analyse a model that features relations at multiple levels. 13.1 Intraclass correlation Intraclass correlations (ICCs) indicate what proportion of a variable’s variance exists at Level 1 and what part exists at Level 2. For example, if the ICC of some variable is 0.10, that indicates that 10% of the total variance is caused by differences between clusters (classrooms), and 90% is caused by differences between the individuals within those clusters. The ICC value can also be interpreted as the correlation that you would expect between the scores of two individuals that are part of the same cluster. When you see the multilevel structure as a nuisance, you hope that the ICCs of your variables are small. If you have research questions involving Level 2 variables, you hope that the ICCs of those variables are relatively high. Script 13.1 shows how to obtain the ICCs using lavaan. 13.2 Multilevel structure as a nuisance: Correcting for the dependency The ‘problem’ with multilevel data is that the individual observations are not independent. For example, when you observe scores from 100 individuals that are clustered in groups of 10 people, and the ICCs of the measured variables are not zero, that means that there is overlap in information that you obtain from individuals within clusters. The effective sample size is then actually smaller than 100. If you would ignore the multilevel structure, you are effectively overstating the information that you have. In practice, that means that the \\(SE\\)s will be too small, and that the \\(\\chi^2\\) statistic will be too large. One solution is to correct the \\(SE\\)s and fit statistics for the dependency in the data. If you specify a single-level model in lavaan, but you add the argument cluster = “clustervariable”, then lavaan will report cluster-robust \\(SE\\)s (Williams, 2000) and a corrected test statistic. This would be an acceptable approach when your hypotheses are about Level-1 processes, and you just want to correct for the nested data. 13.3 Two-level path models If a research question involves variables at Level 2 as well as at Level 1, one would conduct two-level path analysis. When fitting two-level models in lavaan, each observed variable is decomposed into a within component and a between-component. For example, Given the multivariate response vector \\(\\mathrm{y}_{ij}\\), with scores from subject i in cluster j, the scores are decomposed into means (\\(\\mu_j\\)), and individual deviations from the cluster means (\\(\\eta_{ij}\\)): \\[\\begin{equation} \\begin{split} \\mathrm{y}_{ij} &amp;= \\mu_j + (\\mathrm{y}_{ij} - \\mu_j) \\\\ &amp;= \\mu_j + \\eta_{ij} \\end{split} \\end{equation}\\] where \\(\\mu_j\\) and \\(\\eta_{ij}\\) are independent. The overall covariances of \\(\\mathrm{y}_{ij}\\) (\\(\\Sigma_{total}\\)) can be written as the sum of the covariances of these two components: \\[\\begin{equation} \\begin{split} \\Sigma_{total} &amp;= COV(\\mu_j, \\mu_j) + COV(\\eta_{ij}, \\eta_{ij}) \\\\ &amp;= \\Sigma_\\text{between} + \\Sigma_\\text{within} \\\\ &amp;= \\Sigma_\\text{B} + \\Sigma_\\text{W} \\end{split} \\end{equation}\\] One can postulate separate models for \\(\\Sigma_{B}\\) and \\(\\Sigma_{W}\\). This model specification is denoted the within/between formulation (Muthén, 1990, 1994; Schmidt, 1969), and implies random intercepts for all observed variables. The observed variables can have variance at one or both of the levels in two-level data. For example, in data from children in school classes, the variable ‘Teacher gender’ only has variance at Level 2, since all children in the same school class share the same teacher. The gender of the child varies within school classes, and will have variance at Level 1, but not at Level 2, in cases where the distribution of boys and girls is equal across classes. In practice, variables that have variance at Level 1, often also have variance at Level 2. For example, children’s scores on a mathematical ability test may differ across different children from the same school class (Level 1), while the classroom average test scores are also likely different (Level 2). As an example dataset we use scores on four variables, obtained from 1377 students in 58 schools (Schijf &amp; Dronkers, 1991; Hox, Moerbeek &amp; van de Schoot, 2017). The four variables we use are: Education of the father (Feduc), Education of the mother (Meduc), Teacher’s advice about secondary education (Advice), and the result on a school achievement test (Galo). We will fit the two-level model that is depicted below. Figure 13.1: A two-level path diagram. 13.4 Obtaining ICCs, and estimates of \\(\\Sigma_\\text{W}\\) and \\(\\Sigma_\\text{B}\\) In Script 13.1, we fit saturated models to Level 1 and Level 2, by letting all variables covary with each other at both levels. The means of the variables will be estimated only at Level 2 because Level-1 means are zero by definition. That is, Level-1 components of variables represent individual deviations from the cluster mean, and cluster-mean-centered variables have means of zero (both within clusters and across clusters). Fitting a saturated model will give us estimates of the within-level and between-level covariance matrices. The variance estimates from this model can be used to calculate ICCs. Fitting this model thus serves as a first step to obtain information about the variance distribution across levels. Script 13.1 library(lavaan) data &lt;- read.table(&quot;demoData/GaloComplete.dat&quot;, header = TRUE) head(data) ## school galo advice feduc meduc ## 1 1 78 1 1 1 ## 2 1 104 4 4 3 ## 3 1 93 2 1 1 ## 4 1 114 4 2 1 ## 5 1 95 2 2 2 ## 6 1 98 2 1 1 satmodel &lt;- &#39; level: 1 galo ~~ advice + feduc + meduc advice ~~ feduc + meduc feduc ~~ meduc level: 2 galo ~~ advice + feduc + meduc advice ~~ feduc + meduc feduc ~~ meduc galo ~ 1 advice ~ 1 feduc ~ 1 meduc ~ 1 &#39; fitsat &lt;- lavaan(model = satmodel, data = data, cluster = &quot;school&quot;, auto.var = TRUE) The clustering variable should be specified as an argument to the lavaan() function. The keywords level: 1 (not level 1:) and level:2 (not level 2:, which would return an error) identify blocks in the model syntax, notifying lavaan that we are specifying a model at each level of analysis. If the model syntax does not contain separate models for levels 1 and 2, but the clustering variable is still specified, then lavaan will fit a single-level model and report cluster-robust \\(SE\\)s and fit statistics. One can obtain the ICC estimates for each variable, and the estimated covariance matrices at Level 1 and Level 2 from the saturated (or any) multilevel model using the following code. # ICCs (ICCs &lt;- lavInspect(fitsat,&quot;icc&quot;)) ## galo advice feduc meduc ## 0.156 0.143 0.293 0.211 # Sigma_within (Sigma_w &lt;- lavInspect(fitsat, &quot;sampstat&quot;)$within$cov) ## galo advice feduc meduc ## galo 143.572 ## advice 12.802 1.730 ## feduc 6.935 0.767 4.425 ## meduc 5.901 0.704 2.265 3.764 # Sigma_between (Sigma_b &lt;- lavInspect(fitsat, &quot;sampstat&quot;)$school$cov) ## galo advice feduc meduc ## galo 26.464 ## advice 2.607 0.289 ## feduc 5.737 0.669 1.833 ## meduc 4.133 0.470 1.345 1.009 The ICC values show that a proportion 0.156 of the total variance in the GALO achievement test scores as attributable to between-school differences. This could also be calculated manually using the variance estimates at the two levels (26.491 / (26.491 + 143.595) = .156). Educational level of the father has the largest proportion of between-school variance with an ICC of 0.293. 13.5 Fitting a two-level path model In Script 13.2, we fit the two-level path model as depicted in Figure 13.1 to the data. Script 13.2 model2 &lt;- &#39; level: 1 advice ~ galo galo ~ feduc + meduc # covariance and variances feduc ~~ meduc advice ~~ advice galo ~~ galo feduc ~~ feduc meduc ~~ meduc level: 2 advice ~ galo galo ~ feduc + meduc # covariance and variances feduc ~~ meduc advice ~~ advice galo ~~ galo feduc ~~ feduc meduc ~~ meduc galo ~ 1 advice ~ 1 feduc ~ 1 meduc ~ 1 &#39; fitmod2 &lt;- lavaan(model = model2, data = data, cluster = &quot;school&quot;) Note that this two-level path model has \\(df=4\\). In two-level models, the number of observed statistics are twice as much as in single level models because we count the information at both levels. At the within level there are 4*(4+1)/2 = 10 elements in the within-level covariance matrix, and at the between level there are also 10 elements in the between-level covariance matrix (and there are four observed means). In this example, the number of parameters to be estimated is also doubled in comparison with a single level model, because all \\(\\beta\\) and \\(\\psi\\) parameters are estimated at the within as well as at the between-level. The number of parameters may also be different across levels, when a different model is fitted to the between level and to the within level. But in this model, we estimate three \\(\\beta\\) parameters and five \\(\\psi\\) parameters at each level, leading to \\(df=2\\) per level. At the between-level there are also four intercepts (\\(\\alpha\\)) estimated based on four observed means, so the mean structure is saturated and does not add any \\(df\\) to the model. summary(fitmod2, fit.measures = TRUE) ## lavaan 0.6-19 ended normally after 105 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 20 ## ## Number of observations 1377 ## Number of clusters [school] 58 ## ## Model Test User Model: ## ## Test statistic 38.935 ## Degrees of freedom 4 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 2349.154 ## Degrees of freedom 12 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.985 ## Tucker-Lewis Index (TLI) 0.955 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -12612.714 ## Loglikelihood unrestricted model (H1) -12593.247 ## ## Akaike (AIC) 25265.428 ## Bayesian (BIC) 25369.982 ## Sample-size adjusted Bayesian (SABIC) 25306.450 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.080 ## 90 Percent confidence interval - lower 0.058 ## 90 Percent confidence interval - upper 0.103 ## P-value H_0: RMSEA &lt;= 0.050 0.013 ## P-value H_0: RMSEA &gt;= 0.080 0.522 ## ## Standardized Root Mean Square Residual (corr metric): ## ## SRMR (within covariance matrix) 0.028 ## SRMR (between covariance matrix) 0.046 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## ## Level 1 [within]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## advice ~ ## galo 0.089 0.002 50.305 0.000 ## galo ~ ## feduc 1.092 0.180 6.060 0.000 ## meduc 0.918 0.195 4.706 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## feduc ~~ ## meduc 2.261 0.128 17.622 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .advice 0.589 0.023 25.680 0.000 ## .galo 131.155 5.125 25.589 0.000 ## feduc 4.425 0.172 25.687 0.000 ## meduc 3.768 0.146 25.744 0.000 ## ## ## Level 2 [school]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## advice ~ ## galo 0.104 0.007 14.958 0.000 ## galo ~ ## feduc 10.769 16.594 0.649 0.516 ## meduc -10.290 22.314 -0.461 0.645 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## feduc ~~ ## meduc 1.359 0.280 4.853 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .galo 89.913 2.300 39.093 0.000 ## .advice -7.489 0.711 -10.538 0.000 ## feduc 3.860 0.188 20.512 0.000 ## meduc 2.850 0.143 19.899 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .advice 0.028 0.010 2.667 0.008 ## .galo 5.620 5.141 1.093 0.274 ## feduc 1.843 0.380 4.845 0.000 ## meduc 1.015 0.218 4.665 0.000 In the output, lavaan reports an overall test statistic, and several fit measures that are based on the overall model. The SRMR is provided separately for the within and between levels. For the current model exact fit is rejected, the RMSEA is 0.08 with a 90% confidence interval ranging from 0.058 to 0.103, and the CFI (for which the baseline model is the independence model at both levels) is 0.985. The output for the parameter estimates is provided first for the within-level part of the model, and then for the between-level part. Interpretations depend on the level of analysis. For example: The effect of galo on advice is estimated to be .089 at the within-level. This means that when galo scores increase by 1 point among individuals from the same school (i.e., \\(\\eta_{ij} = \\mathrm{y}_{ij} - \\mu_j\\)), individuals are expected to receive 0.089 points higher advice on average. The effect of galo on advice at the between-level is estimated to be .104. This means that when a school’s average galo score (i.e., \\(\\mu_j\\)) increases by 1 point, the school is expected to receive 0.104 points higher advice on average. The difference between a variable’s between- and within-level effect (\\(\\beta_\\text{B} - \\beta_\\text{W}\\)) is called the contextual effect (see Marsh et al., 2012). In our example, this is the effect on received advice of being in a school with 1-unit higher average galo scores (\\(\\mu_j\\)), given an individual’s own galo score (\\(\\mathrm{y}_{ij}\\)). \\[\\begin{equation} \\begin{split} \\text{advice} &amp;= \\beta_\\text{W} (\\mathrm{y}_{ij} - \\mu_j) + \\beta_\\text{B} \\mu_j \\\\ &amp;= \\beta_\\text{W} \\mathrm{y}_{ij} - \\beta_\\text{W} \\mu_j + \\beta_\\text{B} \\mu_j \\\\ &amp;= \\beta_\\text{W} \\mathrm{y}_{ij} + (\\beta_\\text{B} - \\beta_\\text{W}) \\mu_j \\end{split} \\end{equation}\\] The equivalence of within- and between-level effects can be tested by comparing a model in which the effects are constrained to be equal to a model in which they are estimated freely. Alternatively, one could define the contextual effect as a new parameter by subtracting the two effects of interest, similar to how one defines specific indirect effects. &#39; level: 1 advice ~ b43.w*galo level: 2 advice ~ b43.b*galo b43.contextual := b43.b - b43.w # obtain Wald z test of equivalence v. contextual effect&#39; In standard multilevel regression, one may also include random slopes in the model. This way one could test whether the effect of some variable on another variable varies across clusters. Random slopes are not yet a feature in lavaan’s multilevel SEM, although the wide-format approach might be feasible in samples with many small clusters (Barendse &amp; Rosseel, 2020). References Barendse, M. T., &amp; Rosseel, Y. (2020). Multilevel modeling in the ‘wide format’ approach with discrete data: A solution for small cluster sizes. Structural Equation Modeling, 27(5), 696–721. https://doi.org/10.1080/10705511.2019.1689366 Hox, J. J., Moerbeek, M., &amp; Van de Schoot, R. (2017). Multilevel analysis: Techniques and applications. Routledge. Marsh, H. W., Ludtke, O., Nagengast, B., Trautwein, U., Morin, A. J. S., Abduljabbar, A. S., et al. (2012). Classroom climate and contextual effects: Conceptual and methodological issues in the evaluation of group-level effects. Educational Psychololgy, 47, 106–124. https://doi.org/10.1080/00461520.2012.670488 Muthén, B. (1990). Mean and covariance structure analysis of hierarchical data. Los Angeles, CA: UCLA. Muthén, B.O. (1994). Multilevel covariance structure analysis. Sociological Methods &amp; Research, 22(3), 376–398. https://doi.org/10.1177%2F0049124194022003006 Williams, R. L. (2000). A note on robust variance estimation for cluster‐correlated data. Biometrics, 56(2), 645–646. https://doi.org/10.1111/j.0006-341X.2000.00645.x Schijf, H., &amp; Dronkers, J. (1991). De invloed van richting en wijk op de loopbanen in de lagere scholen van de stad Groningen in 1971. IBH Abram, BPM Creemers &amp; A. van derLeij (red.), ORD, 91. Schmidt, W. H. (1969). Covariance structure analysis of the multivariate random effects model [Doctoral dissertation]. University of Chicago, Department of Education. "],["ch14.html", "14 Factor Models 14.1 Empirical example of a factor model 14.2 Conceptual explanation of a factor model 14.3 Symbolic explanation of a factor model 14.4 Identification of model parameters in a factor model 14.5 Fitting a factor model using lavaan References Appendix", " 14 Factor Models Factor analysis is the second family of statistical analyses within the structural equation modeling (SEM) framework. Factor analysis is used to describe the dependencies between a set of observed variables, by using a limited number of so-called underlying or common factors. These common factors are not directly observed (i.e., they are latent factors) and represent everything that the associated observed variables have in common. In this chapter we first introduce an empirical example that will be used to explain factor models in this and subsequent chapters, then we give a general explanation of the factor model—both conceptually and through symbols, and explain how to fit the factor model using lavaan. 14.1 Empirical example of a factor model The School Attitudes Questionnaire (SAQ) of Smits &amp; Vorst (1982) is a Dutch questionnaire that measures three components of educational attitudes: motivation for school tasks, satisfaction with school life, and self-confidence about ones scholastic capabilities. Each component is measured with three scales: -Motivation (for school tasks) is measured by: learning orientation, concentration on school work, and homework attitude; -Satisfaction (with school life) is measured by: fun at school, acceptance by classmates, and relationship with teacher; -Self-confidence (about ones scholastic capabilities) is measured by: self-expression, self-efficacy, and social skills. 14.2 Conceptual explanation of a factor model Figure 14.1 is a graphical display of the factor model of the SAQ. The nine squares represent the nine observed scale scores of the questionnaire: learning orientation (LO), concentration on school work (CO), homework attitude (HM), fun at school (FU), acceptance by classmates (AC), relationship with teacher (TE), self-expression (SE), self-efficacy (SF), and social skills (SK). In the context of factor models the observed variables are often referred to as indicator variables. The circles at the top are the common factors Motivation, Satisfaction and Self-confidence. The common factors are represented by circles to reflect the fact that they are latent factors, i.e., they are not directly observed. The relationships between the latent factors and the observed variables are represented by one-sided arrows (→) and are called factor loadings. In our example, the common factors Motivation, Satisfaction, and Self-confidence are each measured by three observed indicators. For example, Motivation is measured by the observed indicators LO, CO, and HM, as represented by the direct effects of the common factor on these three variables. There are no arrows pointing from the common factor Motivation to the other observed indicator variables. The common factor Motivation therefore represent everything that the associated observed indicator variables LO, CO, and HM have in common. Likewise, the common factor Satisfaction represents everything that the variables FU, AC, and TE have in common. The model that is represented in Figure 1 defines the measurement structure of the model (i.e., the relationships between the common factors and indicator variables) and is therefore called a measurement model. The underlying common factors in the measurement model are allowed to correlate, which is reflected by the double headed arrows (↔︎) between the common factors. The factor model thus provides a description of the relationships between the observed indicator variables using a limited number of underlying common factors. Figure 14.1: Factor model of the School Attitudes Questionnaire The circles \\(ε_{LO}\\) through \\(ε_{SK}\\) at the bottom of Figure 14.1 are so-called residual factors. Just as with path analysis, residual factors in factor analysis are unobserved, latent factors that represent all factors that fall outside the model but may influence the states of the corresponding observed indicator variables. In the context of factor analysis, these residual factors can be considered ‘container variables’ that represent everything that is specific to the associated observed indicator variable (as opposed to everything that the observed indicator variables have in common, as represented by the common factors). The residual factors also reflect measurement error. The variance of a residual factor therefore partly consists of variance due to random error fluctuations (i.e., measurement error; unsystematic variance) and partly of specific variable variance (i.e., due to unmeasured causes; systematic variance). The directional effects from the residual factors to the corresponding observed indicator variables are accompanied by the scaling constant ‘1’ for reasons of identification (which is explained in more detail in section 14.4). 14.3 Symbolic explanation of a factor model Figure 14.2 is again a graphical representation of the factor model of the SAQ, but now also includes the Greek symbols that are associated with the common factors (‘\\(ξ\\)’, or ‘ksi’) and the directional effects between the common factors and observed indicator variables (‘\\(λ\\)’, or ‘lambda’). Using these symbols, the relationships between the observed indicator variables and the underlying common factor as presented in Figure 2 can be given by the following equations: \\[\\begin{align} \\mathrm{x}_1 = \\lambda_{11}\\xi_1+\\varepsilon_1, \\tag{14.1} \\\\ \\mathrm{x}_2 = \\lambda_{21}\\xi_1+\\varepsilon_2, \\tag{14.2} \\\\ \\mathrm{x}_3 = \\lambda_{31}\\xi_1+\\varepsilon_3, \\tag{14.3} \\\\ \\mathrm{x}_4 = \\lambda_{42}\\xi_2+\\varepsilon_4, \\tag{14.4} \\\\ \\mathrm{x}_5 = \\lambda_{52}\\xi_2+\\varepsilon_5, \\tag{14.5} \\\\ \\mathrm{x}_6 = \\lambda_{62}\\xi_2+\\varepsilon_6, \\tag{14.6} \\\\ \\mathrm{x}_7 = \\lambda_{73}\\xi_3+\\varepsilon_7, \\tag{14.7} \\\\ \\mathrm{x}_8 = \\lambda_{83}\\xi_3+\\varepsilon_8, \\tag{14.8} \\\\ \\mathrm{x}_9 = \\lambda_{93}\\xi_3+\\varepsilon_9, \\tag{14.9} \\end{align}\\] where \\(\\mathrm{x}_1\\) through \\(\\mathrm{x}_9\\) are the nine observed indicator variables, \\(\\xi_1\\), \\(\\xi_2\\) and \\(\\xi_3\\) are the common factors Motivation, Satisfaction, and Self-Confidence respectively, and \\(\\varepsilon_1\\) through \\(\\varepsilon_9\\) are the residual factors of the associated \\(\\mathrm{x}_1\\) through \\(\\mathrm{x}_9\\). Parameters \\(\\lambda_{11}\\) through \\(\\lambda_{93}\\) are factor loadings. Using the equations, we can again see that each of the observed variables is only affected by one of the common factors. Note also that each of the observed variables is affected by its associated residual factor. Figure 14.2: Factor Model of the School Attitudes Quetsionnaire Instead of writing down the equation for each observed variable, the equations for the observed variables x1 through x9 can also be written in matrix form: \\[\\begin{equation} \\mathbf{x} = \\mathbf\\Lambda \\mathbf\\xi + \\mathbf{\\varepsilon}, \\tag{14.10} \\end{equation}\\] where \\(\\mathbf{x}\\) is a vector of all observed variables, \\(\\mathbf\\xi\\) is a vector of all common factors, \\(\\mathbf\\varepsilon\\) is a vector of all residual factors, and \\(\\mathbf\\Lambda\\) is a matrix of factor loadings. \\[ \\mathbf{x}= \\begin{bmatrix} x_1\\\\x_2\\\\x_3\\\\x_4\\\\x_5\\\\x_6\\\\x_7\\\\x_8\\\\x_9 \\end{bmatrix}, \\mathbf\\xi = \\begin{bmatrix} \\xi_1\\\\\\xi_2\\\\\\xi_3 \\end{bmatrix}, \\mathbf\\varepsilon = \\begin{bmatrix} \\varepsilon_1\\\\\\varepsilon_2\\\\\\varepsilon_3\\\\\\varepsilon_4\\\\\\varepsilon_5\\\\\\varepsilon_6\\\\\\varepsilon_7\\\\\\varepsilon_8\\\\\\varepsilon_9 \\end{bmatrix}, \\text{and } \\mathbf\\Lambda = \\begin{bmatrix} \\lambda_{11}&amp;0&amp;0\\\\\\lambda_{21}&amp;0&amp;0\\\\\\lambda_{31}&amp;0&amp;0\\\\0&amp;\\lambda_{42}&amp;0\\\\0&amp;\\lambda_{52}&amp;0\\\\0&amp;\\lambda_{62}&amp;0\\\\0&amp;0&amp;\\lambda_{73}\\\\0&amp;0&amp;\\lambda_{83}\\\\0&amp;0&amp;\\lambda_{93} \\end{bmatrix}. \\] Matrix \\(\\mathbf\\Lambda\\) contains nine nonzero elements: \\(\\lambda_{11}\\) through \\(\\lambda_{93}\\). Like the regression slopes in the Beta matrix (\\(\\mathbf{B}\\)), rows represent the outcomes (here, indicators) and columns represent the predictors (here, common factors). So the factor loading \\(\\lambda_{ij}\\) represents the regression of variable \\(i\\) on common factor \\(j\\). When the factor model is specified such that variable \\(i\\) does not load on common factor \\(j\\), then that specific element \\(\\lambda_{ij}\\) is fixed to zero. Specifically, the pattern of matrix \\(\\mathbf\\Lambda\\) specifies the measurement structure of the factor model. In our example, \\(\\mathbf\\Lambda\\) contains many elements that are fixed to zero because each indicator variable loads only on one of three common factors. Such a pattern of factor loadings is sometimes referred to as ‘simple structure’. Substituting these matrices into Equation (14.10) gives: \\[\\begin{equation} \\begin{bmatrix} x_1\\\\x_2\\\\x_3\\\\x_4\\\\x_5\\\\x_6\\\\x_7\\\\x_8\\\\x_9 \\end{bmatrix}=\\begin{bmatrix} \\lambda_{11} &amp; 0 &amp; 0 \\\\ \\lambda_{21} &amp; 0 &amp; 0 \\\\ \\lambda_{31} &amp; 0 &amp; 0 \\\\ 0 &amp; \\lambda_{42} &amp; 0 \\\\ 0 &amp; \\lambda_{52} &amp; 0 \\\\ 0 &amp; \\lambda_{62} &amp; 0 \\\\ 0 &amp; 0 &amp; \\lambda_{73} \\\\ 0 &amp; 0 &amp; \\lambda_{83} \\\\ 0 &amp; 0 &amp; \\lambda_{93} \\end{bmatrix}\\begin{bmatrix}\\xi_1\\\\\\xi_2\\\\\\xi_3 \\end{bmatrix}+\\begin{bmatrix}\\varepsilon_1\\\\\\varepsilon_2\\\\\\varepsilon_3\\\\\\varepsilon_4\\\\\\varepsilon_5\\\\\\varepsilon_6\\\\\\varepsilon_7\\\\\\varepsilon_8\\\\\\varepsilon_9 \\end{bmatrix} \\tag{14.11} \\end{equation}\\] and evaluation gives: \\[\\begin{equation} \\begin{bmatrix} x_1\\\\x_2\\\\x_3\\\\x_4\\\\x_5\\\\x_6\\\\x_7\\\\x_8\\\\x_9 \\end{bmatrix} = \\begin{bmatrix} \\lambda_{11}\\xi_1+\\varepsilon_1\\\\ \\lambda_{21}\\xi_1+\\varepsilon_2\\\\ \\lambda_{31}\\xi_1+\\varepsilon_3\\\\ \\lambda_{42}\\xi_2+\\varepsilon_4\\\\ \\lambda_{52}\\xi_2+\\varepsilon_5\\\\ \\lambda_{62}\\xi_2+\\varepsilon_6\\\\ \\lambda_{73}\\xi_3+\\varepsilon_7\\\\ \\lambda_{83}\\xi_3+\\varepsilon_8\\\\ \\lambda_{93}\\xi_3+\\varepsilon_9 \\end{bmatrix}. \\tag{14.12} \\end{equation}\\] Here, we can see that the equations for variables \\(\\mathrm{x}_1\\) through \\(\\mathrm{x}_9\\) are the same as separate Equations (14.1) through (14.9). We now have an expression for the scores on the observed indicator variables. However, in standard SEM we do not model the observed scores directly, but rather the variances and covariances of the observed scores. Therefore, we need to find an expression for the model-implied covariance matrix. Using Equation (14.10) and some covariance algebra, we obtain the expression for the variances and covariances of \\(\\mathbf{x}\\), called \\(\\mathbf\\Sigma_{\\text{model}} = \\text{COV}(\\mathbf{x},\\mathbf{x})\\): \\[\\begin{equation} \\mathbf\\Sigma_{\\text{model}} = \\mathbf\\Lambda \\mathbf\\Phi \\mathbf\\Lambda^\\text{T} + \\mathbf\\Theta, \\tag{14.13} \\end{equation}\\] where the variances and covariances of the common factors are represented by \\(\\text{COV}(\\mathbf\\xi,\\mathbf\\xi) = \\mathbf\\Phi\\), and the variances and covariances of the residual factors represented by \\(\\text{COV}(\\mathbf\\varepsilon,\\mathbf\\varepsilon) = \\mathbf\\Theta\\). The matrix \\(\\mathbf\\Lambda\\) contains the common factor loadings, and \\(\\mathbf\\Lambda^\\text{T}\\) denotes the transpose of the matrix \\(\\mathbf\\Lambda\\). Derivations of Equation (14.13) are given in the Appendix at the end of this chapter. Matrix \\(\\mathbf\\Phi\\) is a symmetric matrix and contains the variances and covariances of the common factors \\(\\mathbfξ\\). For the model given in Equation (14.12), matrix \\(\\mathbf\\Phi\\) is: \\[\\begin{equation} \\mathbf\\Phi = \\begin{bmatrix} \\phi_{11}\\\\\\phi_{21}&amp;\\phi_{22}\\\\\\phi_{31}&amp;\\phi_{32}&amp;\\phi_{33}\\\\ \\end{bmatrix}, \\tag{14.14} \\end{equation}\\] where the diagonal elements \\(φ_{11}\\), \\(φ_{22}\\), \\(φ_{33}\\) represent the variances of common factors \\(ξ_1\\), \\(ξ_2\\), and \\(ξ_3\\), respectively, and the off-diagonal elements represent the covariances between the common factors, e.g., the element \\(φ_{21}\\) represents the covariance between common factors \\(ξ_1\\) and \\(ξ_2\\). Matrix \\(\\mathbf\\Theta\\) is a symmetric matrix and contains the variances and covariances of the residual factors. It is often assumed that the residual factors do not covary with each other, so that matrix \\(\\mathbf\\Theta\\) is a diagonal matrix with residual variances only. However, in some applications covariances between (some) residual factors are allowed, which are then specified by nonzero off-diagonal elements of matrix \\(\\mathbf\\Theta\\). The \\(\\mathbf\\Theta\\) matrix for our illustrative example from the Figure 14.2 model is: \\[\\begin{equation} \\mathbf\\Theta = \\begin{bmatrix} \\theta_{11}\\\\ 0&amp;\\theta_{22}\\\\ 0&amp;0&amp;\\theta_{33}\\\\ 0&amp;0&amp;0&amp;\\theta_{44}\\\\ 0&amp;0&amp;0&amp;0&amp;\\theta_{55}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;\\theta_{66}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\\theta_{77}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\\theta_{88}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\\theta_{99} \\end{bmatrix}, \\tag{14.15} \\end{equation}\\] where \\(θ_{11}\\) through \\(θ_{99}\\) represent the variances of the residual factors of \\(\\mathrm{x}_1\\) through \\(\\mathrm{x}_9\\). These residual variances represent the variance of the associated indicator variable that is not represented by the underlying common factors. They can be interpreted as variance that is unexplained by the model. In Figure 3, the \\(\\mathbf\\Phi\\) and \\(\\mathbf\\Theta\\) parameters representing common factor variances and covariances and residual factor variances and covariances are added to the graphical display. Figure 14.3: Factor model of the School Attitudes Questionnaire including common factor and residual factor (co)variance parameters Now that we have found the general expression for the variances and covariances as a function of model parameters of a factor model, we can evaluate Equation (14.13) of our illustrative example. Substitution of the \\(\\mathbf\\Lambda\\), \\(\\mathbf\\Phi\\), and \\(\\mathbf\\Theta\\) of our example yields: \\(\\mathbf\\Sigma_{\\text{model}} = \\mathbf\\Lambda \\mathbf\\Phi \\mathbf\\Lambda^\\text{T} + \\mathbf\\Theta\\), where: \\[ \\mathbf\\Lambda \\mathbf\\Phi \\mathbf\\Lambda^\\text{T} = \\begin{bmatrix} \\lambda_{11}&amp;0&amp;0\\\\\\lambda_{21}&amp;0&amp;0\\\\\\lambda_{31}&amp;0&amp;0\\\\0&amp;\\lambda_{42}&amp;0\\\\0&amp;\\lambda_{52}&amp;0\\\\0&amp;\\lambda_{62}&amp;0\\\\0&amp;0&amp;\\lambda_{73}\\\\0&amp;0&amp;\\lambda_{83}\\\\0&amp;0&amp;\\lambda_{93} \\end{bmatrix} \\begin{bmatrix} \\phi_{11}\\\\\\phi_{21}&amp;\\phi_{22}\\\\\\phi_{31}&amp;\\phi_{32}&amp;\\phi_{33} \\end{bmatrix} \\begin{bmatrix} \\lambda_{11}&amp;\\lambda_{21}&amp;\\lambda_{31}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;\\lambda_{42}&amp;\\lambda_{52}&amp;\\lambda_{62}&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\\lambda_{73}&amp;\\lambda_{83}&amp;\\lambda_{93} \\end{bmatrix} \\] and thus \\(\\mathbf\\Sigma_{\\text{model}}\\) is given by: \\[\\begin{equation} \\mathbf\\Sigma_{\\text{model}} = \\begin{bmatrix} \\lambda^2_{11} \\varphi_{11} +\\theta_{11} \\\\ \\lambda_{11}\\lambda_{21}\\varphi_{11} &amp; \\lambda^2_{21}\\varphi_{11}+\\theta_{22} \\\\ \\lambda_{11}\\lambda_{31}\\varphi_{11} &amp; \\lambda_{21}\\lambda_{31}\\varphi_{11} &amp; \\lambda^2_{31}\\varphi_{11}+\\theta_{33}\\\\ \\lambda_{11}\\lambda_{42} \\varphi_{21} &amp; \\lambda_{21}\\lambda_{42}\\varphi_{21} &amp; \\lambda_{31}\\lambda_{42}\\varphi_{21} &amp; \\lambda^2_{42}\\varphi_{22}+\\theta_{44}\\\\ \\lambda_{11}\\lambda_{52} \\varphi_{21} &amp; \\lambda_{21}\\lambda_{52} \\varphi_{21} &amp; \\lambda_{31}\\lambda_{52}\\varphi_{21} &amp; \\lambda_{42}\\lambda_{52}\\varphi_{22} &amp; \\lambda^2_{52}\\varphi_{22}+\\theta_{55}\\\\ \\lambda_{11}\\lambda_{62}\\varphi_{21} &amp; \\lambda_{21}\\lambda_{62} \\varphi_{21} &amp; \\lambda_{31}\\lambda_{62}\\varphi_{21} &amp; \\lambda_{42}\\lambda_{62}\\varphi_{22} &amp; \\lambda_{52}\\lambda_{62}\\varphi_{22} &amp; \\lambda^2_{62}\\varphi_{22}+\\theta_{66}\\\\ \\lambda_{11}\\lambda_{73}\\varphi_{31} &amp; \\lambda_{21}\\lambda_{73}\\varphi_{31} &amp; \\lambda_{31}\\lambda_{73}\\varphi_{31} &amp; \\lambda_{42}\\lambda_{73}\\varphi_{32} &amp; \\lambda_{52}\\lambda_{73}\\varphi_{32} &amp;\\lambda_{62}\\lambda_{73}\\varphi_{32} &amp; \\lambda^2_{73} \\varphi_{33}+\\theta_{77}\\\\ \\lambda_{11}\\lambda_{83} \\varphi_{31} &amp; \\lambda_{21}\\lambda_{83}\\varphi_{31} &amp;\\lambda_{31}\\lambda_{83}\\varphi_{31} &amp; \\lambda_{42}\\lambda_{83}\\varphi_{32} &amp; \\lambda_{52}\\lambda_{83}\\varphi_{32} &amp; \\lambda_{62}\\lambda_{83}\\varphi_{32} &amp; \\lambda_{72}\\lambda_{83}\\varphi_{32} &amp; \\lambda^2_{83}\\varphi_{33}+\\theta_{88}\\\\ \\lambda_{11}\\lambda_{93} \\varphi_{31} &amp; \\lambda_{21}\\lambda_{93} \\varphi_{31} &amp; \\lambda_{31}\\lambda_{93}\\varphi_{31} &amp; \\lambda_{42}\\lambda_{93}\\varphi_{32} &amp; \\lambda_{52}\\lambda_{93}\\varphi_{32} &amp; \\lambda_{62}\\lambda_{93}\\varphi_{32} &amp; \\lambda_{73}\\lambda_{93}\\varphi_{32} &amp; \\lambda_{83}\\lambda_{93}\\varphi_{32} &amp; \\lambda^2_{93}\\varphi_{33}+\\theta_{99} \\end{bmatrix} \\tag{14.16} \\end{equation}\\] We can thus evaluate whether the factor model gives a good description of the linear dependencies between the observed variables by evaluating \\(\\mathbf\\Sigma_\\text{population} = \\mathbf\\Sigma_\\text{model}\\), where \\(\\mathbf\\Sigma_\\text{population}\\) is given by: \\[\\begin{equation} \\mathbf\\Sigma_\\text{population}= \\begin{bmatrix} \\sigma_{11} \\\\ \\sigma_{21} &amp; \\sigma_{22} \\\\ \\sigma_{31} &amp; \\sigma_{32} &amp; \\sigma_{33} \\\\ \\sigma_{41} &amp; \\sigma_{42} &amp; \\sigma_{43} &amp; \\sigma_{44} \\\\ \\sigma_{51} &amp; \\sigma_{52} &amp; \\sigma_{53} &amp; \\sigma_{54} &amp; \\sigma_{55} \\\\ \\sigma_{61} &amp; \\sigma_{62} &amp; \\sigma_{63} &amp; \\sigma_{64} &amp; \\sigma_{65} &amp; \\sigma_{66} \\\\ \\sigma_{71} &amp; \\sigma_{72} &amp; \\sigma_{73} &amp; \\sigma_{74} &amp; \\sigma_{75} &amp; \\sigma_{76} &amp; \\sigma_{77} \\\\ \\sigma_{81} &amp; \\sigma_{82} &amp; \\sigma_{83} &amp; \\sigma_{84} &amp; \\sigma_{85} &amp; \\sigma_{86} &amp; \\sigma_{87} &amp; \\sigma_{88} \\\\ \\sigma_{91} &amp; \\sigma_{92} &amp; \\sigma_{93} &amp; \\sigma_{94} &amp; \\sigma_{95} &amp; \\sigma_{96} &amp; \\sigma_{97} &amp; \\sigma_{98} &amp; \\sigma_{99} \\end{bmatrix}. \\tag{14.17} \\end{equation}\\] 14.4 Identification of model parameters in a factor model The population variances (\\(\\sigma_{ii}\\)), and covariances (\\(\\sigma_{ij}\\)) that feature in Equation (14.17) can be estimated with sample variances (\\(s_{ii}\\)), and covariances (\\(s_{ij}\\)). Similar to the identification of path models, the factor model is identified if it is possible to uniquely express each of the model parameters that feature in Equation (14.16) as functions of the variances and covariances of Equation (14.17). However, the identification of latent factors requires additional restrictions. Because latent factors are unobserved variables, we do not know the scales of measurements of these variables. Because the scales of the common factors are not defined, it is not possible to estimate both the variance and factor loading of a latent factor. To give scales to the latent factors, one can either fix the factor variance or one of the factor loadings at a nonzero value. The identification of residual factors—which also appear in path models—is usually done by using a scaling constant ‘1’ for the associated residual factor loading (i.e., the direct effect of the residual factor on the associated observed variable). These restrictions are applied by default by most computer programs. For the identification of common factors, the researcher can chose between the two types of identification restrictions: through restriction of common-factor variances or through restriction of factor loadings. For example, to identify the common factors from our illustrative example, one can fix either the factor variances at a nonzero value (e.g., \\(\\varphi_{11} = 1, \\varphi_{22} = 1, \\varphi_{33} = 1\\)) or one factor loading for each factor (e.g., \\(\\lambda_{11} = 1, \\lambda_{22} = 1\\), and \\(\\lambda_{33} = 1\\). As the scaling constant is usually ‘1’, these two types of identification constraints are referred to as: the ‘unit variance identification constraint’ (UVI constraint) and the ‘unit loading identification constraint’ (ULI constraint). The UVI method is also referred to as the ‘fixed-factor’ method, and the ULI method is referred to as the ‘marker-variable’ or ‘reference-variable’ method. A third method is related to ULI, but instead of constraining a single loading to 1, all loadings are estimated under the constraint that the mean of the loadings is 1—this is called the ‘effects-coding’ method. Traditionally, we would choose a “marker” or “reference” variable that is thought to best represent the latent construct (i.e., the perfect indicator, if it did not have measurement error), and we would fix the loading of that indicator to 1 (ULI constraint). The logic behind ULI was that fixing the factor loading to 1 implied a 1-unit increase in the reference indicator (on average) for each 1-unit increase in the common factor. Thus, the common factor was often said to “be on the same scale” as the reference indicator. However, that would only be true if the reference indicator had no measurement error (implying its residual variance could be fixed to zero). Holding the reliability of an indicator (i.e., the proportion of its variance that is common-factor variance ) constant, the more measurement error the indicator has, the greater its estimated residual variance and the lower its estimated factor loading would be. So when the reference indicator does have measurement error (which we assume implicitly, otherwise we wouldn’t need a common-factor model for the latent construct), the ULI method sets the scale of the common factor to the scale of the common-factor component of the reference indicator, not to its total (i.e., its observed) scale (Steiger, 2002). So although the ULI method has been most popular in SEM for decades, its popularity is based on a misconception. Latent variables have no implicit scale because they are unobserved by definition, and no statistical trick can give them a meaningful scale. Units of standard deviation are familiar because we often use standardized effect sizes in other contexts (e.g., Cohen’s d is a standardized mean difference, a correlation is a standardized simple regression slope). Standardized estimates are available regardless of the scaling constraint, so the UVI / fixed-factor method is not necessarily any better—both methods lead to identical model fit, and the estimated factor loadings are proportionally equivalent relative to the factor variance, whether it is fixed to 1 or set using the common-factor component of an indicator. However, the \\(SE\\)s of the factor loadings are sensitive to the different identification methods (Gonzalez &amp; Griffin, 2001), so Wald \\(z\\) tests of significance for factor loadings are affected. This may only lead to different conclusions about the null hypothesis that \\(λ_{ij} = 0\\) when indicators have much more measurement error than common-factor variance, or when \\(N\\) is quite low. However, it is troubling to think that an estimated \\(SE\\) depends on an arbitrary scaling constraint. The UVI / fixed-factor method may be preferable if only because the specified factor variance is arbitrary anyway, and ULI seems to imply that one of the factor loadings is a known quantity. The effects-coding method of identification has the benefit of estimating the factor variance without specifying a single variable as the ideal reference indicator. Instead of fixing one loading to 1, it estimates all loadings under the constraint that the average loading (per construct) is 1, or equivalently, that the factor loadings sum to the number of indicators (\\(N_i\\)). This is equivalent to constraining one loading to be \\(N_i\\) minus the remaining factor loadings. Thus, the indicator with the “average” amount of common-factor variance would have a factor loading of 1, and loadings above 1 belong to the indicators that have more common-factor variance than average (among the indicators used in the analysis). Although effects coding was originally conceived as a “non-arbitrary” method of scaling the latent construct (Little, Slegers, &amp; Card, 2006), that was based on the same misconception as believing the ULI sets the latent construct’s scale identical to the reference indicator’s scale. However, the effects-coding method is advantageous in scenarios when fixing the latent variance is suboptimal. For example, we can only scale the residual variance of an endogenous common factor, rather than the total variance, and fixing a residual variance to 1 may be intuitively unappealing (although it is as arbitrary as fixing the total variance). When a factor has fewer than three indicators, these scaling methods are not sufficient for identification. We devote a later chapter to single-indicator constructs, which can be used to model the effects of observed variables (e.g., sex or age) on latent common factors18. However, constructs with only two indicators have a complicated status. With only two indicators, there are three observed pieces of information: two variances and a single covariance, which represents the shared (common) variance between the indicators. That is not enough to identify the five pieces of information we could estimate (two residual variances, one factor variance, and two factor loadings), so we need to fix two pieces of information instead of just one. Using the ULI orientation is intuitively appealing in this situation, because when you fix both factor loadings to 1, the estimated common-factor variance is the observed covariance (i.e., the observed common variance). The UVI orientation would be to fix the factor variance to 1, but we still need another constraint for just-identification, which we can achieve by constraining the estimated factor loadings to equality (i.e., estimate one loading, but set both the loadings to that one value). Effects coding is not possible with only two indicators. To make the situation more complicated, you can estimate a two-indicator factor with only one constraint, but only when the factor has a nonzero covariance with another factor in the model. The covariances of the two indicators with other indicators in the other factor will be enough to empirically identify the factor loading(s) and/or factor variance of the two-indicator factor—but only if the factor covariance is substantial. If the factor covariance is close to zero, the model will still be empirically underidentified. It is therefore preferable to ensure identification, ideally by fixing both factor loadings to 1 so that the freely estimated factor variance represents what it literally is: the covariance between the indicators. 14.5 Fitting a factor model using lavaan The lavaan script for fitting a factor model resembles the script for fitting a path model. We again use equations to specify the model, but we now use the “=~” operator to define the common factors. Whereas the “~” operator specifies regression paths that point from predictor(s) on the right-hand side to outcome(s) on the left-hand side, the “=~” operator specifies regression paths (called factor loadings) that point from the predictor (common factor) on the left-hand side to the outcomes (indicators) on the right-hand side. Script 14.1 fits the three-factor model from Figure 14.3 to the covariance matrix from observed scores of the SAQ that was administered to 915 school pupils. Script 14.1 ## observed covariance matrix obsnames &lt;- c(&quot;learning&quot;,&quot;concentration&quot;,&quot;homework&quot;,&quot;fun&quot;, &quot;acceptance&quot;,&quot;teacher&quot;,&quot;selfexpr&quot;,&quot;selfeff&quot;,&quot;socialskill&quot;) values &lt;- c(30.6301, 26.9452, 56.8918, 24.1473, 31.6878, 53.2488, 16.3770, 18.4153, 16.8599, 27.9758, 7.8174, 9.6851, 12.0114, 12.8765, 47.0970, 13.6902, 16.9232, 12.9326, 17.2880, 12.3672, 29.0119, 15.3122, 24.2849, 21.4935, 12.9621, 13.9909, 11.6333, 59.5343, 13.4457, 21.8158, 18.8545, 7.3931, 12.2333, 7.1434, 29.7953, 49.2213, 6.6074, 12.7343, 12.5768, 6.4065, 13.4258, 6.1429, 26.0849, 23.6253, 40.0922) saqcov &lt;- getCov(values, names = obsnames) ## specify model saqmodel &lt;- &#39; # define latent common factors Motivation =~ L11*learning + L21*concentration + L31*homework Satisfaction =~ L42*fun + L52*acceptance + L62*teacher SelfConfidence =~ L73*selfexpr + L83*selfeff + L93*socialskill # indicator residual variances (or use &quot;auto.var = TRUE&quot;) learning ~~ TH11*learning concentration ~~ TH22*concentration homework ~~ TH33*homework fun ~~ TH44*fun acceptance ~~ TH55*acceptance teacher ~~ TH66*teacher selfexpr ~~ TH77*selfexpr selfeff ~~ TH88*selfeff socialskill ~~ TH99*socialskill # common factor variances (or use &quot;auto.var = TRUE&quot;) Motivation ~~ F11*Motivation Satisfaction ~~ F22*Satisfaction SelfConfidence ~~ F33*SelfConfidence # factor covariances (or use &quot;auto.cov.lv.x = TRUE&quot;) Motivation ~~ F21*Satisfaction Motivation ~~ F31*SelfConfidence Satisfaction ~~ F32*SelfConfidence # OPTIONAL: manually specify scaling constraints # UVI / fixed-factor method (or use &quot;std.lv = TRUE&quot;) # F11 == 1 # F22 == 1 # F33 == 1 # ULI / marker-variable / reference-variable method # (or use &quot;auto.fix.first = TRUE&quot;) # L11 == 1 # L42 == 1 # L73 == 1 # effects-coding method (MUST specify in syntax) # NOTE: 3 different ways yield the same solution (L11 + L21 + L31) / 3 == 1 # mean(Lambda) = 1 L42 + L52 + L62 == 3 # sum(Lambda) = number of indicators L73 == 3 – L83 – L93 # 1 lambda = difference between the sum and remaining loadings &#39; ## fit model saqmodelOut &lt;- lavaan(saqmodel, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;) ## results summary(saqmodelOut, fit = TRUE, standardized = TRUE, rsquare = TRUE) ## parameter matrices lavInspect(saqmodelOut, &quot;est&quot;) The first part of the script, where the observed covariance matrix is created, is not different from when fitting a path model. Differences are present in the model specification, where we need to define the common factors and additional parameters that are specific to the factor model. First, we define common factors by specify their factor loadings (\\(λ_{ij}\\), the regression paths pointing from a common factor to an observed indicator in Figure 14.3. saqmodel &lt;- &#39; # define latent common factors Motivation =~ L11*learning + L21*concentration + L31*homework Satisfaction =~ L42*fun + L52*acceptance + L62*teacher SelfConfidence =~ L73*selfexpr + L83*selfeff + L93*socialskill The operator (“=~”) defines the common factor, where the name on the left-hand side of the operator is the common factor. As far as the software is concerned, it is only an arbitrary label, so you can choose any name you want, but it should not be a variable name that exists in the input data. The names on the right-hand side of the operator are the observed variables that are its reflective indicators, and whose names must appear in the input data. Note that (just as with the path model) the residual error term is not explicitly included in the formula. These equations therefore refer to the pattern of factor loadings (\\(\\mathbfΛ\\)). We use labels for the estimates of the factor loadings, where the label refers to the position of the regression coefficient in the \\(\\mathbfΛ\\) matrix. For example, the factor loadings of the observed indicators of Motivation are positioned in the first column, rows one, two and three, and therefore we use the labels “L11”, “L21”, and “L31”: Motivation =~ L11*learning + L21*concentration + L31*homework The residual errors are specified in the same way as they are with the path model, using the double tildes (~~) to represent two-headed arrows. These are the residual terms that are represented in the theta matrix (\\(\\mathbfΘ\\)). As there are no covariances between residual factors specified in our model, this matrix is diagonal. That is, the diagonal elements of the symmetric \\(\\mathbfΘ\\) are the indicators’ residual variances, and all residual covariances are fixed to zero. We use labels “TH11” through “TH99” to represent the 1st-row/1st-column element through the 9th-row/9th-column element. # indicator residual variances (or use &quot;auto.var = TRUE&quot;) learning ~~ TH11*learning concentration ~~ TH22*concentration homework ~~ TH33*homework fun ~~ TH44*fun acceptance ~~ TH55*acceptance teacher ~~ TH66*teacher selfexpr ~~ TH77*selfexpr selfeff ~~ TH88*selfeff socialskill ~~ TH99*socialskill Note, however, that this syntax can be left out if you use an additional lavaan argument to automatically (auto.) estimate the variance (var): saqmodelOut &lt;- lavaan(saqmodel, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;, auto.var = TRUE) Next, we need to specify the variances and covariances between the common factors (\\(\\mathbfΦ\\))19. We use labels “F11” to “F33” for the variances, and the covariances are labeled with “F21”, “F31” and “F32”. # common factor variances (or use &quot;auto.var = TRUE&quot;) Motivation ~~ F11*Motivation Satisfaction ~~ F22*Satisfaction SelfConfidence ~~ F33*SelfConfidence # factor covariances (or use &quot;auto.cov.lv.x = TRUE&quot;) Motivation ~~ F21*Satisfaction Motivation ~~ F31*SelfConfidence Satisfaction ~~ F32*SelfConfidence Similar to residual variances, common-factor variances can be omitted from the model syntax if you use the argument “auto.var = TRUE”. Likewise, you can omit common-factor covariances from the model syntax if you use the argument “auto.cov.lv.x = TRUE”. Now we have specified all parameters of our factor model that are free to be estimated. However, although our model has positive degrees of freedom, it is still not identified. We must fix either the factor variances at a nonzero value or constrain at least one factor loading for each factor to give the factors a scale. Script 14.1 shows three ways to specify within the model syntax the scaling constraints necessary to identify the model. First we demonstrate the UVI (fixed-factor) constraint: # UVI / fixed-factor method (or use &quot;std.lv = TRUE&quot;) F11 == 1 F22 == 1 F33 == 1 Note that the “==” operator (translated: “is equal to”) can only have constants on the left- and right-hand sides. These can be explicit constants (e.g., “1”) or parameter labels (e.g., “F11”), but variables can never be part of an equality constraint20. Also note that you are not required to specify this constraint explicitly in the model syntax. Instead, you can tell lavaan to standardize (std.) each latent variable (lv): saqmodelOut &lt;- lavaan(saqmodel, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;, std.lv = TRUE) The alternative method to give scales to the common factors would be to fix one of the factor loadings of each common factor. Because software is ignorant of which variable might be preferred as a reference indicator, the default is typically to use the “first” indicator per factor as a reference indicator; however, if no indicator stands out as the ideal indicator, then there is little justification for use the ULI constraint. The ULI method can be specified explicitly in the model syntax: # ULI / marker-variable / reference variable method # (or use &quot;auto.fix.first = TRUE&quot;) # L11 == 1 # L42 == 1 # L73 == 1 Or, as noted in the syntax comment, you can omit constraints from the syntax by telling lavaan you want to automatically (auto.) fix the first loading to 1: saqmodelOut &lt;- lavaan(saqmodel, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;, auto.fix.first = TRUE) When there is not an ideal indicator to use as the reference variable, but the research wants to estimate factor variances, the effects-coding method can be used. # effects-coding method (MUST specify in syntax) # NOTE: 3 different ways yield the same solution (L11 + L21 + L31) / 3 == 1 # mean(Λ) = 1 L42 + L52 + L62 == 3 # sum(Λ) = number of indicators L73 == 3 – L83 – L93 # 1 λ = difference between the # sum and remaining loadings Note the three equivalent ways of specifying the necessary constraint, each of which is demonstrated using a different factor’s indicators. Note also that effects coding does not have an argument in lavaan, so it must be specified in model syntax using parameter labels (which would not be required when using the auto.fix.first or std.lv arguments). Finally, we run the model with the lavaan function. The arguments are the model syntax (saqmodel), the covariance matrix as input data (saqcov), and the sample size (\\(N = 915\\)). We still use Wishart likelihood when we fit our model only to the sample covariance matrix, but unlike with path models, we no longer need to set the argument fixed.x = FALSE because all observed variables are endogenous . ## run model saqmodelOut &lt;- lavaan(saqmodel, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;) There is a dedicated “wrapper” function (i.e., a function that calls lavaan() with specific defaults turned on) called cfa(). Specifically, cfa() calls lavaan() with the arguments auto.fix.first, auto.var, and auto.cov.lv.x set to TRUE. To use UVI instead of ULI, you can implicitly set auto.fix.first back to FALSE by setting std.lv = TRUE. Effects coding, however, requires calling lavaan() directly. Script 14.2 yields the same results as Script 14.1 (specifically, using the UVI constraint) but with many fewer lines of syntax. ### Script 14.2 {-} ## observed covariance matrix obsnames &lt;- c(&quot;learning&quot;,&quot;concentration&quot;,&quot;homework&quot;,&quot;fun&quot;, &quot;acceptance&quot;,&quot;teacher&quot;,&quot;selfexpr&quot;,&quot;selfeff&quot;,&quot;socialskill&quot;) values &lt;- c(30.6301, 26.9452, 56.8918, 24.1473, 31.6878, 53.2488, 16.3770, 18.4153, 16.8599, 27.9758, 7.8174, 9.6851, 12.0114, 12.8765, 47.0970, 13.6902, 16.9232, 12.9326, 17.2880, 12.3672, 29.0119, 15.3122, 24.2849, 21.4935, 12.9621, 13.9909, 11.6333, 59.5343, 13.4457, 21.8158, 18.8545, 7.3931, 12.2333, 7.1434, 29.7953, 49.2213, 6.6074, 12.7343, 12.5768, 6.4065, 13.4258, 6.1429, 26.0849, 23.6253, 40.0922) saqcov &lt;- getCov(values, names = obsnames) ## specify model saqmodel &lt;- &#39;# define latent common factors Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill &#39; ## run model saqmodelOut &lt;- cfa(saqmodel, sample.cov = saqcov, sample.nobs = 915, std.lv = TRUE, likelihood = &quot;wishart&quot;) ## output summary(saqmodelOut, fit = TRUE, standardized = TRUE, rsquare = TRUE) ## parameter matrices lavInspect(saqmodelOut, &quot;est&quot;) We request results of the analysis along with the standardized solution, model fit measures, and R2 for the indicators (i.e., proportion of variance explained by factors): ## output summary(saqmodelOut, standardized = TRUE, fit = TRUE, rsquare = TRUE) The lavaan summary() output is split into several parts, with information about model fit appearing first (which can also be found in the fitMeasures() output). The remaining sections can all be found in the parameterEstimates() output. “Latent Variables” contains the results of the regression equations (i.e., factor loadings), “Covariances” contains the parameter estimates of the common-factor covariances, and “Variances” contains the variances of the common factors and residual variances of the observed indicators. The bottom section contains the estimated \\(R^2\\) for each endogenous variable (i.e., indicators). The standardized solution is discussed in more detail in the following chapter. To obtain the parameter estimates in matrix format (\\(\\mathbfΛ\\), \\(\\mathbfΦ\\), and \\(\\mathbfΘ\\)), use the lavInspect() function. Note, however, that lavaan refers to \\(\\mathbfΦ\\) as \\(\\mathbfΨ\\) (“Psi”). lavInspect(saqmodelOut, &quot;est&quot;) When we introduced path model notation in Chapter 3, we used Psi to represent the matrix of exogenous (co)variances and endogenous residual (co)variances. After we introduce the full SEM, which combines a path model with a factor model, lavaan’s use of \\(\\mathbfΨ\\) instead of \\(\\mathbfΦ\\) will make more sense. For now, think of them as arbitrary labels—either way, we are talking about the covariance matrix of latent variables. The use of Φ implies the latent variables are exogenous, and the use of Ψ implies at least one latent variable may be endogenous, but the formulas work the same either way. References Gonzalez, R., &amp; Griffin, D. (2001). Testing parameters in structural equation modeling: Every “one” matters. Psychological Methods, 6(3), 258–269. doi:10.1037//1082-989X.6.3.258 Little, T. D., Slegers, D. W., &amp; Card, N. A. (2006). A non-arbitrary method of identifying and scaling latent variables in SEM and MACS models. Structural Equation Modeling, 13(1), 59–72. doi:10.1207/s15328007sem1301_3 Smits, J. A., &amp; Vorst, H. C. M. (1982). Schoolvragenlijst voor basisonderwijs en voortgezet onderwijs (SVL). Handleiding voor gebruikers. Nijmegen: Berkhout Nijmegen. Steiger, J. H. (2002). When constraints interact: A caution about reference variables, identification constraints, and scale dependencies in structural equation modeling. Psychological Methods, 7(2), 210–227. doi:10.1037//1082-989X.7.2.210 Appendix Derivations of Equation 14.13 \\[ \\mathbf\\Sigma = \\text{COV}(\\mathbf{x},\\mathbf{x}) \\Leftrightarrow \\] (substitute Equation (14.13) \\[ \\mathbf\\Sigma = \\text{COV}(\\mathbf\\Lambda \\mathbf\\xi + \\mathbf\\varepsilon, \\mathbf\\Lambda \\mathbf\\xi + \\mathbf\\varepsilon) \\Leftrightarrow \\] (decompose) \\[ \\mathbf\\Sigma = \\text{COV}(\\mathbf\\Lambda \\mathbf\\xi,\\mathbf\\Lambda \\mathbf\\xi) + \\text{COV}(\\mathbf\\Lambda \\mathbf\\xi,\\mathbf\\varepsilon)+ \\text{COV}(\\mathbf\\varepsilon,\\mathbf\\Lambda \\mathbf\\xi)+ \\text{COV}(\\mathbf\\varepsilon,\\mathbf\\varepsilon) \\Leftrightarrow \\] (residual factors are assumed not to covary with the common factors, \\(COV(\\mathbf\\xi,\\mathbf\\varepsilon) = 0.\\)) \\[ \\mathbf\\Sigma = \\text{COV}(\\mathbf\\Lambda \\mathbf\\xi,\\mathbf\\Lambda \\mathbf\\xi) + 0 + 0 + \\text{COV}(\\mathbf\\varepsilon,\\mathbf\\varepsilon) \\Leftrightarrow \\] (place constants outside brackets). \\[ \\mathbf\\Sigma = \\mathbf\\Lambda \\text{COV}(\\mathbf\\xi,\\mathbf\\xi)\\mathbf\\Lambda^{\\text{T}} +\\text{COV}(\\mathbf\\varepsilon,\\mathbf\\varepsilon)\\Leftrightarrow \\] (variances and covariances of \\(\\mathbf\\xi\\) and \\(\\mathbf\\varepsilon\\) are denoted \\(\\mathbf\\Phi\\) and \\(\\mathbf\\Theta\\)) \\[ \\mathbf\\Sigma = \\mathbf\\Lambda \\mathbf\\Phi \\mathbf\\Lambda^\\text{T} + \\mathbf\\Theta \\] This is necessary because the SEM matrices of regression coefficients only allow for effects of latent factors on observed variables (Λ) or of latent variables on latent variables (B). In path models, we actually treat all observed variables as single-indicator constructs, allowing us to use B.↩︎ The Greek letter “Phi” can be pronounced like “fee” (typical in U.S. English) or like it rhymes with “eye” (typical in U.K. English). The Greeks pronounce \\(Φ\\) as “fee,” but they also pronounce \\(χ\\) as “key” and \\(π\\) as “pee.” Unless you are actually speaking Greek, you are not required to conform to these conventions. By analogy, English, Germans, French, and Dutch (among others) all have very different pronunciations for the same letters of the alphabet (for example, E, I, H, J, R, V, W, U, and Z can differ quite a lot from language to language).↩︎ Functions of parameters can also be specified (e.g., “F11 == log(F22)” or “sqrt(L11) == abs(L42)”). Inequality constraints can also be specified, which will not fix a parameter but will constrain the range of values it could be. This is most commonly used to constrain variances to be positive (e.g., “F11 &gt; 0”); however, such constrained estimation is not preferred because it can have unintended consequences (e.g., hides model misspecification, forces other parameter estimates to be biased, the model fit statistic is no longer distributed as a simple \\(χ^2\\) random variable under \\(\\text{H}_0\\)).↩︎ "],["ch15.html", "15 Standardized Parameter Estimates for the Factor Model 15.1 Standardized factor loadings 15.2 Standardized common-factor variances and covariances 15.3 Standardized unique-factor variances and covariances 15.4 Structure coefficients 15.5 Calculating standardized coefficients in lavaan 15.6 Request standardized output with lavaan References", " 15 Standardized Parameter Estimates for the Factor Model 15.1 Standardized factor loadings The matrix \\(\\mathbfΛ\\) from our illustrative factor model example from Chapter 14 contains unstandardized factor loadings. These unstandardized estimates of factor loading parameters are interpreted relative to the units of measurement of the latent and observed variables (i.e., a factor loading is a slope, representing the average number of units the indicator changes when the factor increases by one unit). Thus, higher loadings indicate stronger linear relationships between the factor and indicator. When the indicator variables of a common factor are measured on the same scale, comparison of unstandardized coefficients can indicate the relative magnitudes among indicators of the same common factor (i.e., the highest loading belongs to the indicator most strongly related to the construct). For example, when we would estimate the effect of Motivation for school tasks on learning orientation and concentration on school work—and these variables are measured on the same scale (e.g., a 7-point Likert scale)—the unstandardized effects can be directly compared to give an indication of the relative importance of learning orientation and concentration on school work for the measurement of Motivation. However, a meaningful comparison of effects may be complicated when the interpretation of units on the scales of the variables are not equivalent (e.g., if one indicator is measured on a 5-point scale and the other on a 7-point scale, how does one unit on learning orientation relate to one unit on concentration on school work?). In addition, unstandardized factor covariances must also be interpreted in the (unobserved) measurement scale of the common factors. Therefore, it would be helpful to obtain standardized parameter estimates that are independent of the units in which both the common factor variables and the indicator variables are scaled. Standardized factor loadings are the factor loadings that would be obtained if both the common factor and observed indicator had variances equal to 1. Consequently, standardized factor loadings can be calculated as a function of unstandardized factor loadings and the variances of the observed variables and the common factors. For example, the estimated unstandardized factor loading of learning orientation on Motivation, \\(\\hatλ_{11}\\), can be standardized through: \\[\\begin{equation} \\hat\\lambda^*_{11} = \\hat\\lambda_{11} \\sqrt{\\frac{\\hat\\varphi_{11}}{\\hat\\sigma_{11}}}, \\tag{15.1} \\end{equation}\\] where \\(\\hatφ_{11}\\) denotes the variance of the first factor (Motivation), \\(\\hatσ_{11}\\) denotes the model-implied variance of the first indicator (learning orientation), and \\(\\hatλ_{11}\\) denotes the unstandardized factor loading of the first indicator on the first factor. The standardized parameter can be interpreted in units of standard deviation, so a 1 \\(SD\\) increase in the common factor is associated with a change of \\(\\hatλ^*_{11}\\) \\(SD\\)s in the observed indicator variable. Substituting the parameter estimate \\(\\hatλ_{11}\\), the factor variance \\(\\hatφ_{11}\\), and the model-implied variance \\(\\hatσ_{11}\\) from our illustrative example yields: \\[ \\hatλ_{11}^* = 4.56 \\sqrt{\\frac{1}{30.63}}=0.82 . \\] Thus, a 1 \\(SD\\) increase in Motivation is expected to result in a 0.82 \\(SD\\) increase in learning orientation. In comparison, the standardized factor loading for the regression of concentration on school work on Motivation: \\[ \\hatλ_{21}^* = 5.95\\sqrt{\\frac{1}{56.89}} = 0.79 . \\] Although the unstandardized factor loading of concentration on school work was larger than the factor loading of learning orientation, the size of the standardized factor loading of concentration on school work is slightly smaller (due to the fact that the variance of this indicator variable is larger). The indicators in our example each load on only one factor, so each indicator’s factor loading is a simple regression slope. Thus, the standardized factor loadings can be interpreted as Pearson correlation coefficients (\\(r\\)), using the following guidelines for the size of the effect: negligible &lt; 0.1, ≤ small &lt; 0.3 ≤ moderate &lt; 0.5 ≤ large (Cohen, 1992). In our example, both effects can be considered strong. In matrix notation, the standardized factor loadings are given by: \\[\\begin{equation} \\hat{\\mathbf{\\Lambda}} = \\mathbf{D}^{-1}_\\mathbf\\Sigma \\hat{\\mathbf\\Lambda} \\mathbf{D}_\\mathbf\\Phi, \\tag{15.2} \\end{equation}\\] where \\(\\mathbf{D}_\\mathbfΣ\\) and \\(\\mathbf{D}_\\mathbfΦ\\) are diagonal matrices with elements \\(\\sqrt{\\text{diag}(\\hat{\\mathbfΣ}_\\text{model}})\\) and \\(\\sqrt{\\text{diag}(\\hat{\\mathbfΦ})}\\), respectively (i.e., the square roots of the diagonals of \\(\\hat{\\mathbf{Σ}}_{model}\\) and \\(\\hat{\\mathbf{Φ}}\\)). 15.2 Standardized common-factor variances and covariances A standardized matrix of common factor variances and covariances is a matrix where all common factor variances are 1. If identification of the common factors has been achieved by fixing the common factor variances at 1 (UVI constraint), then the matrix of common factor variances and covariances is already standardized. If this is not the case, a standardized matrix of common factor variances and covariances, i.e., a matrix of common factor correlations, can be calculated by: \\[\\begin{equation} \\hat{\\mathbf\\Phi}^* = \\mathbf{D}^{-1}_{\\mathbf\\Phi} \\hat{\\mathbf\\Phi} \\mathbf{D}^{-1}_\\mathbf\\Phi. \\tag{15.3} \\end{equation}\\] In our illustrative example the matrix of common factor correlations is: \\[ \\hat{\\mathbf\\Phi}^* = \\begin{bmatrix} \\hat\\phi^*_{11}\\\\ \\hat\\phi^*_{21}&amp;\\hat\\phi^*_{22}\\\\ \\hat\\phi^*_{31}&amp;\\hat\\phi^*_{32}&amp;\\hat\\phi^*_{33} \\end{bmatrix} = \\begin{bmatrix} 1\\\\.73&amp;1\\\\.58&amp;.39&amp;1 \\end{bmatrix} \\] Using the criteria for interpreting \\(r\\) listed above, the correlations between Motivation and Satisfaction (\\(\\hat\\phi^*_{21}\\)) and Motivation and Self-confidence (\\(\\hat\\phi^*_{31}\\) are strong correlations, whereas the correlation between Motivation and Self-confidence (\\(\\hat\\phi^*_{32}\\)) is moderate. 15.3 Standardized unique-factor variances and covariances The unique-factor (i.e., residual) variances and covariances are standardized in separate steps, corresponding to how researchers typically want to interpret them. We would like to interpret the residual covariances as residual correlations (although our example has none), so we would standardize the \\(\\hat{\\mathbfΘ}\\) matrix using the diagonal elements of \\(\\hat{\\mathbfΘ}\\) itself. \\[\\begin{equation} \\hat{\\mathbf\\Theta}^*_{ij} = \\mathbf{D}^{-1}_{\\mathbf\\Theta} \\hat{\\mathbf\\Theta} \\mathbf{D}^{-1}_\\mathbf\\Theta, \\tag{15.4} \\end{equation}\\] where \\(\\mathbf{D}_\\mathbfΘ\\) is a diagonal matrix with elements \\(\\sqrt{\\text{diag}(\\mathbf{Θ}})\\) (i.e., the square roots of the diagonal of \\(\\hat{\\mathbfΘ}\\)) and \\(i ≠ j\\), indicating we are only interested in the off-diagonal elements. The diagonal elements of \\(\\hat{\\mathbf{Θ}}_{ij}^*\\) are all 1, by definition (i.e., \\(\\hat{\\mathbf{Θ}}_{ij}^*\\) is the correlation matrix of unique factors), so \\(\\hat{\\mathbf{Θ}}_{ij}^*\\) doesn’t provide any useful information about the residual variances. Instead, we can standardize \\(\\hat{\\mathbf{Θ}}\\) using the model-implied \\(SD\\)s of the indicator variables: \\[\\begin{equation} \\hat{\\mathbf\\Theta}^*_{ii} = \\mathbf{D}^{-1}_{\\mathbf\\Sigma} \\hat{\\mathbf\\Theta} \\mathbf{D}^{-1}_\\mathbf\\Sigma, \\tag{15.5} \\end{equation}\\] where \\(i = i\\), indicating we are only interested in the diagonal elements. Each diagonal element of the resulting matrix \\(\\hat{\\mathbf\\Theta}^*_{ii}\\) contains the proportion of unexplained variance of the associated indicator variable. For example, the standardized matrix of residual variances in our illustrative example is: \\[ \\hat{\\mathbf\\Theta}^*_{ii} = \\begin{bmatrix} \\hat\\theta^*_{11}\\\\ 0 &amp; \\hat\\theta^*_{22}\\\\ 0&amp;0&amp;\\hat\\theta^*_{33}\\\\ 0&amp;0&amp;0&amp;\\hat\\theta^*_{44}\\\\ 0&amp;0&amp;0&amp;0&amp;\\hat\\theta^*_{55}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;\\hat\\theta^*_{66}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\\hat\\theta^*_{77}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\\hat\\theta^*_{88}\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\\hat\\theta^*_{99} \\end{bmatrix} = \\begin{bmatrix} .32 \\\\ 0 &amp; .38 \\\\ 0&amp;0&amp;.47 \\\\ 0&amp;0&amp;0&amp; .26 \\\\ 0&amp;0&amp;0&amp;0&amp; .84 \\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;.50\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;.41\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;.44\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp; .54 \\end{bmatrix}. \\] Here, we can see that the proportion of unexplained variance of the learning orientation (\\(\\hatθ_{11}^*\\)) is .32, indicating that 32% of the variance of this variable is unexplained by the model. Thus, the explained variance for this indicator variable is 68% (i.e., 100% − 32%). 15.4 Structure coefficients Even though not all indicator variables load on all common factors, that does not mean that the indicator variables have no relation with the common factors that they are not directly regressed on. The relationship between the indicator variables and other common factors is modelled through the covariances between the common factors. To get insight into the complete correlation structure of the indicator variables and common factors, one can calculate structure coefficients. Structure coefficients are the correlations between all observed variables and all common factors. They are calculated by multiplying the matrix of standardized factor loadings with the matrix of common factor correlations: \\[\\begin{equation} \\mathbf{P} = \\hat{\\mathbf{\\Lambda}}^* \\hat{\\mathbf{\\Phi}}^* \\tag{15.6} \\end{equation}\\] The result is a full (i.e., not symmetric) matrix \\(\\mathbf{P}\\) that contains the correlations between all observed variables (in the rows) and all common factors (in the columns). 15.5 Calculating standardized coefficients in lavaan Standardized parameter estimates can be obtained directly by analyzing the correlation matrix while scaling the common factors by fixing their variances to 1. However, it is not possible to (correctly) analyze a correlation matrix in lavaan, and in some situations (for example when doing multigroup analysis) analyzing a correlation matrix prevents meaningful comparison of coefficients across groups. Therefore, we show you how to calculate standardized coefficients in R using output from lavaan. Script 15.1 shows the code that standardizes the matrices from Script 14.1, where the output was saved in the object saqmodelOut. To be able to extract parameter estimates from the lavaan output in a pre-specified order we have created the object factornames that contains the names of the common factors: Script 15.1 ## save variable names obsnames &lt;- c(&quot;learning&quot;,&quot;concentration&quot;,&quot;homework&quot;,&quot;fun&quot;, &quot;acceptance&quot;,&quot;teacher&quot;,&quot;selfexpr&quot;,&quot;selfeff&quot;,&quot;socialskill&quot;) factornames &lt;- c(&quot;Motivation&quot;, &quot;Satisfaction&quot;, &quot;SelfConfidence&quot;) ## EITHER request model-implied and latent covariance matrices from lavaan SIGMA &lt;- lavInspect(saqmodelOut, &quot;cov.ov&quot;)[obsnames, obsnames] PHI &lt;- lavInspect(saqmodelOut, &quot;cov.lv&quot;)[factornames, factornames] ## OR extract parameter estimates and calculate it manually Estimates &lt;- lavInspect(saqmodelOut, &quot;est&quot;) LAMBDA &lt;- Estimates$lambda[obsnames, factornames] # must extract anyway PHI &lt;- Estimates$psi[factornames, factornames] THETA &lt;- Estimates$theta[obsnames, obsnames] # must extract anyway SIGMA &lt;- LAMBDA %*% PHI %*% t(LAMBDA) + THETA ## extract SDs from sigma and phi, store in a diagonal matrix SDSIGMA &lt;- diag(sqrt(diag(SIGMA))) SDPHI &lt;- diag(sqrt(diag(PHI))) ## calculate standardized parameters LAMBDAstar &lt;- solve(SDSIGMA) %*% LAMBDA %*% SDPHI PHIstar &lt;- solve(SDPHI) %*% PHI %*% solve(SDPHI) THETAstar &lt;- solve(SDSIGMA) %*% THETA %*% solve(SDSIGMA) STRUC &lt;- LAMBDAstar %*% PHIstar ## give labels to the matrices dimnames(LAMBDAstar) &lt;- list(obsnames, factornames) dimnames(PHIstar) &lt;- list(factornames, factornames) dimnames(THETAstar) &lt;- list(obsnames, obsnames) dimnames(STRUC) &lt;- list(obsnames, factornames) First, the model-implied covariance matrix, \\(\\mathbfΣ_{\\text{model}}\\), can be either requested directly from lavaan, SIGMA &lt;- lavInspect(saqmodelOut, &quot;cov.ov&quot;)[obsnames, obsnames] or it can be calculated manually from the unstandardized \\(\\mathbfΛ\\), \\(\\mathbfΦ\\), and \\(\\mathbfΘ\\) parameter estimates: \\(\\mathbf{\\Sigma}_{\\text{model}} = \\mathbf\\Lambda \\mathbf\\Phi \\mathbf\\Lambda^{\\text{T}} + \\mathbf\\Theta\\). Estimates &lt;- lavInspect(saqmodelOut, &quot;est&quot;) LAMBDA &lt;- Estimates$lambda[obsnames, factornames] PHI &lt;- Estimates$psi[factornames, factornames] THETA &lt;- Estimates$theta[obsnames, obsnames] SIGMA &lt;- LAMBDA %*% PHI %*% t(LAMBDA) + THETA As we only need the \\(SD\\)s, we use the diag() function to extract the variances, take the square-roots using the sqrt() function, then put the \\(SD\\)s on the diagonal of a matrix using the diag() function again. We do this for both the model-implied \\(SD\\)s of observed indicators and for the \\(SD\\)s of common factors. SDSIGMA &lt;- diag(sqrt(diag(SIGMA))) SDPHI &lt;- diag(sqrt(diag(PHI))) The factor loadings are standardized by pre-multiplying them with the inverted matrix of \\(SD\\)s of observed variables, and post-multiplying them with the matrix of common-factor \\(SD\\)s. LAMBDAstar &lt;- solve(SDSIGMA) %*% LAMBDA %*% SDPHI The common-factor covariances are standardized by pre- and post-multiplication with the inverted matrix of its \\(SD\\)s. PHIstar &lt;- solve(SDPHI) %*% PHI %*% solve(SDPHI) The unique-factor (i.e., residual) variances are standardized with respect to the observed variables by pre- and post-multiplying \\(\\mathbfΘ\\) with the inverted matrix of observed variable \\(SD\\)s. THETAstar &lt;- solve(SDSGIMA) %*% THETA %*% solve(SDSIGMA) The structure coefficients are calculated by multiplying the standardized \\(\\mathbf\\Lambda\\) and \\(\\mathbf\\Phi\\) matrices. STRUC &lt;- LAMBDAstar %*% PHIstar One can give labels to the standardized matrices using the dimnames() function and the obsnames and factornames objects. The labels for the structure coefficients are the same as for the \\(\\mathbfΛ\\) matrix. dimnames(LAMBDAstar) &lt;- list(obsnames, factornames) dimnames(PHIstar) &lt;- list(factornames, factornames) dimnames(THETAstar) &lt;- list(obsnames, obsnames) dimnames(STRUC) &lt;- list(obsnames, factornames) 15.6 Request standardized output with lavaan The same standardized matrices can be extracted using lavaan’s built-in function: lavInspect(saqmodelOut, &quot;std.all&quot;) You can also request standardized estimates when you use the summary() or parameterEstimates() functions with the argument “standardized = TRUE”: summary(saqmodelOut, standardized = TRUE) parameterEstimates(saqmodelOut, standardized = TRUE) This will add two columns to the output, the column std.lv gives standardized parameters when only the exogenous variables are standardized, and the column std.all gives standardized parameters when both exogenous and endogenous variables are standardized. The latter one will give equivalent output as calculated in Section 15.5. You can also request standardized estimates using the standardizedSolution() function, which also provides \\(SE\\)s for the standardized estimates themselves. However, we recommend only testing the unstandardized estimates for making inferences about population parameters (e.g., null-hypothesis significance tests), and using standardized estimates only as a standardized measure of effect size. The structure coefficients are available in the following output, which requests the correlations among all variables (latent and observed). lavInspect(saqmodelOut, &quot;cor.all&quot;) The submatrix of this output that corresponds to rows of observed variables and columns of latent variables is the structure coefficient matrix. lavInspect(saqmodelOut, &quot;cor.all&quot;)[obsnames, factornames] References Cohen, J. (1992). A power primer. Psychological Bulletin, 112(1), 155–159. doi:10.1037/0033-2909.112.1.155 "],["ch16.html", "16 The Empirical Check for Identification 16.1 Empirical check of Model A References", " 16 The Empirical Check for Identification Factor models with cross-loadings or correlated residual factors (or both) may cause convergence problems and under-identification. There are no rules of thumb of how many cross-loadings or correlated residual factors are allowed while maintaining identification of the model. Therefore, other methods are needed to check for identification. In this chapter we will explain how to use lavaan to do an empirical check for identification of a model. The empirical check has two steps. Step 1: Calculate a model-implied covariance matrix for the model you want to check. Step 2: Fit the model to the model-implied covariance matrix from Step 1. If the parameter estimates you obtain in Step 2 are identical to the parameter values you chose in Step 1, the model may be identified. If you obtain different parameter estimates in Step 2, your model is surely not identified. In this chapter we will show two examples of the empirical check. We will first check identification of the factor model depicted in Figure 16.1a, and subsequently of the factor model depicted in Figure 16.1b. Figure 16.1: Two-factor CFA models with two indicators per factor. Model A (left) has orthogonal (uncorrelated) factors, whereas Model B (right) has correlated factors. 16.1 Empirical check of Model A Script 16.1 is the script for the two steps to check identification of Model A. Script 16.1 ## STEP 1: calculate the model-implied covariance matrix LAMBDA &lt;- matrix(c(.8, 0, .7, 0, 0,.8, 0,.7), nrow = 4, ncol = 2, byrow = TRUE) PHI &lt;- matrix(c(1, 0, 0, 1), nrow = 2, ncol = 2, byrow = TRUE) THETA &lt;- diag(.5, nrow = 4, ncol = 4) SIGMA &lt;- LAMBDA %*% PHI %*% t(LAMBDA) + THETA obsnames &lt;- c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;) dimnames(SIGMA) &lt;- list(obsnames, obsnames) SIGMA ## STEP 2: fit model to the covariance matrix from Step 1 EmpiricalCheck &lt;- &#39; # regressions Ksi1 =~ L11*x1 + L21*x2 Ksi2 =~ L32*x3 + L42*x4 # residual variances x1 ~~ TH11*x1 x2 ~~ TH22*x2 x3 ~~ TH33*x3 x4 ~~ TH44*x4 # (co)variances common factors Ksi1 ~~ F11*Ksi1 Ksi2 ~~ F22*Ksi2 Ksi1 ~~ F21*Ksi2 # scaling constraints F11 == 1 F22 == 1 F21 == 0 &#39; ## fit model EmpiricalCheckOut &lt;- lavaan(EmpiricalCheck, sample.cov = SIGMA, sample.nob = 100, likelihood = &quot;wishart&quot;, fixed.x = FALSE) ## compare results to specified parameters lavInspect(EmpiricalCheckOut, &quot;est&quot;)$lambda LAMBDA lavInspect(EmpiricalCheckOut, &quot;est&quot;)$psi PHI lavInspect(EmpiricalCheckOut, &quot;est&quot;)$theta THETA When we run this model, lavaan may already give a warning21 that it is unable to compute standard errors (which is usually already a sign that there is something may be wrong with your model). Looking at the output, you will notice that the parameter estimates from Step 2 differ from the ones we specified in Step 1. We can thus conclude that this model is not identified. Recall from Chapter 14 that a factor with only two indicators requires additional constraints to be identified, beyond simply choosing a scale by setting the factor variance or a reference variable’s factor loading to 1. There are only three observed pieces of information about two indicators: two variances and a covariance. Thus, estimating more than three parameters leads to under-identification. So two possible solutions to identify Model A would be (a) to fix both factor loadings to 1 and estimate the factor variance or (b) to fix the factor variance to 1 and constrain the factor loadings to equality. These additional constraints are necessary whenever a two-indicator factor does not have a substantial correlation with another factor in the model. When the factors in Model B have a correlation that is substantially different from zero, the model actually is identified (Steiger, 2002). This seems counter-intuitive because Model B is specified the same way regardless of the data to which Model B is fit. That is, the covariances among indicators of the different factors provide a unique set of best-fitting estimated model parameters. However, Model B is empirically under-identified when the factor correlation is near zero (i.e., when the indicators from different factors are nearly uncorrelated). Script 16.2 checks the identification of Model B, assuming a moderate correlation (\\(r = .3\\)). Script 16.2 ## STEP 1: calculate the model-implied covariance matrix LAMBDA &lt;- matrix(c(.8, 0, .7, 0, 0,.8, 0,.7), nrow = 4, ncol = 2, byrow = TRUE) PHI &lt;- matrix(c( 1, .3, .3, 1), nrow = 2, ncol = 2, byrow = TRUE) THETA &lt;- diag(.5, nrow = 4, ncol = 4) SIGMA &lt;- LAMBDA %*% PHI %*% t(LAMBDA) + THETA obsnames &lt;- c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;) dimnames(SIGMA) &lt;- list(obsnames, obsnames) SIGMA ## STEP 2: fit model to the covariance matrix from Step 1 EmpiricalCheck &lt;- &#39; # regressions Ksi1 =~ L11*x1 + L21*x2 Ksi2 =~ L32*x3 + L42*x4 # residual variances x1 ~~ TH11*x1 x2 ~~ TH22*x2 x3 ~~ TH33*x3 x4 ~~ TH44*x4 # (co)variances common factors Ksi1 ~~ F11*Ksi1 Ksi2 ~~ F22*Ksi2 Ksi1 ~~ F21*Ksi2 # scaling constraints F11 == 1 F22 == 1 &#39; ## fit model EmpiricalCheckOut &lt;- lavaan(EmpiricalCheck, sample.cov = SIGMA, sample.nob = 100, likelihood = &quot;wishart&quot;, fixed.x = FALSE) ## compare results to specified parameters lavInspect(EmpiricalCheckOut, &quot;est&quot;)$lambda LAMBDA lavInspect(EmpiricalCheckOut, &quot;est&quot;)$psi PHI lavInspect(EmpiricalCheckOut, &quot;est&quot;)$theta THETA If you run this modified script, you will notice that the parameter estimates are exactly equal to our chosen values from Step 1. This is a necessary requirement for identification, but not sufficient. So we only know that the model might be identified, but we cannot be sure whether it really is identified without using algebraic methods. The curious reader can find algebraic proof that Model B is identified in Steiger (2002). References Steiger, J. H. (2002). When constraints interact: A caution about reference variables, identification constraints, and scale dependencies in structural equation modeling. Psychological Methods, 7(2), 210–227. doi:10.1037//1082-989X.7.2.210 In version 0.5-22, there is no warning, so the model appears to converge normally. This shows that it is important to conduct an empirical check, because the researcher would not know that this model is not identified.↩︎ "],["ch17.html", "17 Second Order Factor Models Getting the parameter estimates in matrix form 17.1 Standardized parameter estimates for the higher-order part of the model", " 17 Second Order Factor Models The expression for a factor model is \\(\\mathbfΣ_{\\text{model}} = \\mathbfΛ \\mathbfΦ \\mathbfΛ’+ \\mathbfΘ\\). In a hierarchical factor model, the covariances between the common factors in \\(\\mathbfΦ\\) are modeled by a second-order factor model, \\(\\mathbfΦ = \\mathbfΛ_2 \\mathbfΦ_2 \\mathbfΛ_2’+ \\mathbfΘ_2\\), where \\(\\mathbfΦ\\) denotes the covariances between first-order factors, \\(\\mathbfΛ_2\\) is a full matrix with second-order factor loadings, \\(\\mathbfΦ_2\\) is a symmetric matrix with variances and covariances of the second-order factors and \\(\\mathbfΘ_2\\) is a diagonal matrix with the variances of the second-order residual factors. Script 17.1 fits a second order factor model to the data of the School Attitudes Questionnaire (SAQ; Smits &amp; Vorst, 1982) from Chapter 14. Instead of having all three latent variables correlate with each other, we hypothesize that there is one second-order common factor (Attitudes) that explains the correlations between the first-order common factors. This model is depicted in Figure 17.1. Figure 17.1: Second-order factor model for the School Attitudes Questionnaire Script 17.1 ## Specify second-order factor model saqmodel2nd &lt;- &#39; # FIRST-ORDER PART # factor loadings Motivation =~ L11*learning + L21*concentration + L31*homework Satisfaction =~ L42*fun + L52*acceptance + L62*teacher SelfConfidence =~ L73*selfexpr + L83*selfeff + L93*socialskill # residual variances observed variables learning ~~ TH11*learning concentration ~~ TH22*concentration homework ~~ TH33*homework fun ~~ TH44*fun acceptance ~~ TH55*acceptance teacher ~~ TH66*teacher selfexpr ~~ TH77*selfexpr selfeff ~~ TH88*selfeff socialskill ~~ TH99*socialskill # scaling constraints L11 == 1 L42 == 1 L73 == 1 # SECOND-ORDER PART # factor loadings second-order Attitudes =~ L11_2*Motivation + L21_2*Satisfaction + L31_2*SelfConfidence # residual variances first-order common factors Motivation ~~ TH11_2*Motivation Satisfaction ~~ TH22_2*Satisfaction SelfConfidence ~~ TH33_2*SelfConfidence # variance second-order common factor Attitudes ~~ F11_2*Attitudes # scaling constraints L11_2 == 1 &#39; ## Run model saqmodel2ndOut &lt;- lavaan(saqmodel2nd, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;, fixed.x = FALSE) ## Output summary(saqmodel2ndOut, fit = TRUE, std = TRUE) So, in the first part of the script, we create the “First-order part” of the model. We specify the parameters of the \\(\\mathbfΛ\\) matrix (factor loadings) and Θ matrix (residual variances observed indicators), but do not specify the parameters of the Φ matrix (the variances and covariances of the first-order common factors) as this matrix is now a function of second-order factor loadings (\\(\\mathbfΛ_2\\)), second-order factor variances and covariances (\\(\\mathbfΦ_2\\)) and second-order residual variances and covariances (\\(\\mathbfΘ_2\\)). In second-order factor analysis, it is difficult to scale the first-order factors by fixing their variances to 1, because the \\(\\mathbfΦ\\) matrix is not directly defined. Therefore we scaled the first-order common factors by fixing the first factor loading of each factor to 1. Scaling of the second-order factors can be done through factor loadings or factor variances. In the current example we scaled the second-order factor through one of the factor loadings. The “Second-order part” of the model thus consists of the regression equations that define the second-order factor, the residual variances of the three first-order common factors, and the variance of the second-order common factor: # regression equations Attitudes =~ L11_2*Motivation + L21_2*Satisfaction + L31_2*SelfConfidence # residual variances first-order common factors Motivation ~~ TH11_2*Motivation Satisfaction ~~ TH22_2*Satisfaction SelfConfidence ~~ TH33_2*SelfConfidence # variance second-order common factor Attitudes ~~ F11_2*Attitudes We have used similar labels as we have used for the first-order part of the model, but added “_2” to the labels to distinguish them. Finally, we run the model using the lavaan() function and request the output using the summary() function. The output consists of two parts: “Latent variables” and “Variances”. In the presentation of the output lavaan does not distinguish between first order and second order parameter estimates. Notice that the estimated residual variance of the first order factor Motivation is negative, representing a so-called “Heywood case” or inadmissible solution. A Heywood case is a sign of either (a) model misspecification or (b) sampling error. When a true parameter is close to a boundary (e.g., small residual variances, high correlations or standardized loadings) and our sample is not asymptotically large, non-problematic Heywood cases are actually quite common. A better solution is to directly investigate the apparent problem by checking both (a) and (b) to see whether is a sufficient explanation of the Heywood case. *We check (a) using \\(χ^2\\), or by using approximate fit measures to see if the misfit is severe enough to suggest a bad model. *We check (b) by looking at the 95% CI or Wald \\(z\\) statistic for the Heywood case. If we can’t reject the null hypothesis that the true parameter is a plausible value, AND our model does not appear to be terribly misspecified, then we can’t dismiss sampling error as the cause. In this example, the estimated variance is −1.675, but the \\(SE = 1.704\\), so the CI includes positive values. RMSEA indicates mediocre fit, and \\(\\text{CFI} &gt; .95\\), so it would be reasonable to conclude that the 2nd-order factor explains most variance in Motivation, and that the estimate is negative only because of sampling error. Getting the parameter estimates in matrix form The lavaan package uses a slightly different parameterization of structural equation models than we do. All unidirectional effects between latent variables are part of matrix beta, and all (residual) variances and covariances of latent variables are part of matrix psi in lavaan. So, the second-order factor loadings, \\(\\mathbfΛ_2\\), are part of matrix beta, and the second-order factor variances and covariances, \\(\\mathbfΦ_2\\), as well as the second-order residual variances of the second order model, \\(\\mathbfΘ_2\\), are part of matrix psi. You can extract the parameter estimates in matrix form using the names of the variables and factors with the following code: Script 17.2 Estimates &lt;- lavInspect(saqmodel2ndOut, &quot;est&quot;) factor1names &lt;- c(&quot;Motivation&quot;,&quot;Satisfaction&quot;,&quot;SelfConfidence&quot;) factor2names &lt;- c(&quot;Attitudes&quot;) lambda1 &lt;- Estimates$lambda[obsnames, factor1names] theta1 &lt;- Estimates$theta[obsnames, obsnames] lambda2 &lt;- Estimates$beta[factor1names, factor2names, drop = FALSE] theta2 &lt;- Estimates$psi[factor1names, factor1names] phi2 &lt;- Estimates$psi[factor2names, factor2names, drop = FALSE] phi1 &lt;- lambda2 %*% phi2 %*% t(lambda2) + theta2 That is, by selecting the appropriate rows and columns using the names of the observed variables, first order common factors, and second order common factors, one can extract the submatrices from the larger matrices that lavaan uses. For psi2 and lambda2, we used the drop = FALSE argument in this example. This is only necessary if lambda2 has only 1 column (i.e. if there is a single second-order factor). When extracting more than 1 column (and row) from a matrix, the result will remain a matrix automatically. Notice that the phi1 matrix is now calculated using \\(\\mathbfΦ_1 = \\mathbfΛ_2 \\mathbfΦ_2 \\mathbfΛ_2’+ \\mathbfΘ_2\\), because in the second-order factor model the variances and covariances of the first-order common factors are modelled as a function of second-order parameters. 17.1 Standardized parameter estimates for the higher-order part of the model In addition to obtaining standardized estimates for (first-order) factor loadings and residual variances (as described in Chapter 13), we can also obtain standardized estimates for the second-order factor loadings, residual variances, and second-order common factor variances and covariances using matrix algebra. Standardization of the second-order coefficients involves calculating the parameter estimates that would be obtained if the standard deviations of all first- and second-order factors were equal to 1. Script 17.3 has commands that can be added to Script 17.2 to calculate the standardized parameters of the second order part of the model. Script 17.3 ## calculate standard deviations first- and second-order common factors SDphi1 &lt;- diag(sqrt(diag(phi1))) SDphi2 &lt;- diag(sqrt(diag(phi2)), nrow = 1, ncol = 1) ## calculate standardized parameters lambda2star &lt;- solve(SDphi1) %*% lambda2 %*% SDphi2 phi2star &lt;- solve(SDphi2) %*% phi2 %*% solve(SDphi2) theta2star &lt;- solve(SDphi1) %*% theta2 %*% solve(SDphi1) struc2 &lt;- lambda2star %*% phi2star ## give labels to matrices dimnames(lambda2star) &lt;- list(factor1names, factor2names) dimnames(phi2star) &lt;- list(factor2names, factor2names) dimnames(theta2star) &lt;- list(factor1names, factor1names) dimnames(struc2) &lt;- list(factor1names, factor2names) The operations that are used to calculate the standardized parameters of the second-order part of the hierarchical factor model are identical to standardization of the first-order part of a factor model. The difference is that we now extract the parameter estimates of the second-order part of the model, and we use the standard deviations of the first-order common factors (instead of the observed indicators) and the standard deviations of the second-order common factors (instead of the first-order common factors). Notice that we used the nrow and ncol arguments to the outer diag() function when creating SDphi2. Recall that the inner call to diag() is used to extract the diagonal of phi2. The outer call to diag() is used to create a matrix. There are actually two ways that diag() will accept your instructions: -If you give it a vector of numbers, it will place those numbers on the diagonal. So the dimensions of the resulting matrix will be determined by how many numbers are in the vector. For example, sqrt(diag(phi1)) contains three standard deviations, so diag(sqrt(diag(phi1))) creates a \\(3 × 3\\) diagonal matrix. -If you give it a single number, it will drop any decimal values and give you an identity matrix (ones on the diagonal) with that many rows and columns. For example, sqrt(diag(phi2)) contains only one standard deviation (\\(SD = 3.196\\)), so diag(sqrt(diag(phi2))) would create a \\(3 × 3\\) identity matrix. To correctly return a \\(1 × 1\\) matrix with 3.196 on the “diagonal,” we need to explicitly tell diag() that we want 1 row and 1 column. "],["ch18.html", "18 Structural Regression Models 18.1 Standardized parameter estimates for the structural part of the model", " 18 Structural Regression Models The name “structural regression” model or SR model refers to a path model with latent variables. Just as in a second-order factor analysis model, an SR model imposes a structure on the covariances in Φ. In the SR model, Φ has the structure of a path model: Φ = (I - Β)-1 Ψ (I - Β)-1t. Here, B is a full matrix with the direct effects between the common factors, Ψ denotes a symmetric matrix with variances and covariances of the exogenous and disturbances of endogenous factors, and I is an identity matrix. As both path analysis and factor analysis are applied with this type of model, it is also referred to as “full SEM”. Script 18.1 fits an SR model to the SAQ data from Chapter 14. Instead of having all three latent variables correlate with each other, we hypothesize that Self-confidence about ones scholastic capabilities affects Motivation for school tasks, which in turn affects Satisfaction with school life. This model is depicted in Figure 18.1. Note that the order of the common factors has been switched in the figure, so that the exogenous common factor is on the left side. All symbols in the figure refer to the parameters of the model. Figure 18.1: Structural Regression model for the School Attitudes Questionnaire. Script 18.1 ## specify SR model saqmodelSR &lt;- &#39; # MEASUREMENT PART # regression equations Motivation =~ L11*learning + L21*concentration + L31*homework Satisfaction =~ L42*fun + L52*acceptance + L62*teacher SelfConfidence =~ L73*selfexpr + L83*selfeff + L93*socialskill # residual variances observed variables learning ~~ TH11*learning concentration ~~ TH22*concentration homework ~~ TH33*homework fun ~~ TH44*fun acceptance ~~ TH55*acceptance teacher ~~ TH66*teacher selfexpr ~~ TH77*selfexpr selfeff ~~ TH88*selfeff socialskill ~~ TH99*socialskill # scaling constraints L11 == 1 L42 == 1 L73 == 1 # STRUCTURAL PART # regression equations Motivation ~ b13*SelfConfidence Satisfaction ~ b21*Motivation # (residual) variances common factors Motivation ~~ p11*Motivation Satisfaction ~~ p22*Satisfaction SelfConfidence ~~ p33*SelfConfidence &#39; ## run model saqmodelSROut &lt;- lavaan(saqmodelSR, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;) ## output summary(saqmodelSROut) The first part of the script is equal to the script of the usual factor model. Here we define the common factors. This is the measurement part of the full SEM model, where we define which observed indicators load on which common factor. The measurement part of the model consists of the regression equations that define the common factors (matrix \\(\\mathbfΛ\\)) and the residual variances of the observed indicators (matrix \\(\\mathbfΘ\\)). Because matrix \\(\\mathbfΦ\\) is not directly specified, (as with second-order CFA), we scale the common factors by fixing the first factor loading of each common factor to 1. The \\(\\mathbfΦ\\) matrix has the structure of a path model. Thus, we do not directly define parameters \\(\\mathbfΦ\\), but instead define the parameters of the path model (matrix \\(\\mathbf{B}\\) and \\(\\mathbfΨ\\)). We call this the structural part of the full SEM model. In the full SEM model the path model describes the relationships between the common factors instead of between the observed variables. We use regression equations to specify the effects between the common factors (matrix \\(\\mathbf{B}\\)). In our example, Motivation is regressed on SelfConfidence, and Satisfaction is regressed on Motivation. # STRUCTURAL PART # regression equations Motivation ~ b13*SelfConfidence Satisfaction ~ b21*Motivation In addition to the parameters of the \\(\\mathbf{B}\\) matrix, we define the parameters of the \\(\\mathbfΨ\\) matrix that contains the variances of the exogenous common factors, the residual variances of the endogenous factors and possibly the covariances between the exogenous factors and/or disturbances of the endogenous factors. In our example, there is only one exogenous factor and no disturbance covariances, so we only need to specify the (residual) variances of the common factors. # (residual) variances common factors Motivation ~~ p11*Motivation Satisfaction ~~ p22*Satisfaction SelfConfidence ~~ p33*SelfConfidence We have now defined all parameter estimates of \\(\\mathbfΛ, Θ, Β\\), and \\(\\mathbfΨ\\) that need to be estimated for our structural regression model. When we run our model and inspect the output using the summary() function we will get three blocks of parameter estimates, first the “Latent variables”, where the factor loadings are given, then the “Regressions” where the direct effects between the common factors are given, and finally the “Variances” where both residual variances of the observed indicators as the (residual) variances of the common factors are given. Part of the output is given below. Estimate Std.err Z-value P(&gt;|z|) Regressions: Motivation ~ SlfCnfd (b13) 0.444 0.033 13.572 0.000 Satisfaction ~ Motivtn (b21) 0.723 0.038 18.783 0.000 In our example, there is a significant effect of Self-confidence on Motivation, where a higher Self-confidence leads to a higher motivation. There is also a significant effect of Motivation on Satisfaction, where a higher Motivation leads to a higher Satisfaction. The code below can be used to obtain the parameter estimates in matrix form. In the standard structural regression model, the parameter matrices in lavaan match the matrices that we use. We arrange the matrices in the desired using a vector of the names of the common factors. Script 18.2 # Extract list with parameter matrices Estimates &lt;- lavInspect(saqmodelSROut, &quot;est&quot;) factornames &lt;- c(&quot;Motivation&quot;,&quot;Satisfaction&quot;,&quot;SelfConfidence&quot;) # Reorder parameter matrices and store them in separate objects lambda &lt;- Estimates$lambda[obsnames, factornames] theta &lt;- Estimates$theta[obsnames, obsnames] beta &lt;- Estimates$beta[factornames, factornames] psi &lt;- Estimates$psi[factornames, factornames] iden &lt;- diag(1, nrow(beta)) # Calculate model-implied covariance matrix of factors (phi) phi &lt;- solve(iden-beta) %*% psi %*% t(solve(iden-beta)) Notice that the common factor variances and covariances (phi) are not estimated directly, but instead are a function of parameter estimates of the path model. 18.1 Standardized parameter estimates for the structural part of the model In addition to obtaining standardized estimates for (first-order) factor loadings and residual variances (as described in Chapter 15), we can also obtain standardized estimates for the direct effects and variances and covariances from the structural model. Standardization of the structural model involves calculating the parameter estimates that would be obtained if the standard deviations of all factors were equal to 1. Script 18.3 has commands that can be added to Script 18.2 to calculate the standardized parameters of the second order part of the model. Script 18.3 # calculate standard deviations of common factors SDphi &lt;- diag(sqrt(diag(phi))) # calculate standardized parameters betastar &lt;- solve(SDphi) %*% beta %*% SDphi psistar &lt;- solve(SDphi) %*% psi %*% solve(SDphi) # provide labels dimnames(betastar) &lt;- list(factornames, factornames) dimnames(psistar) &lt;- list(factornames, factornames) The operations that are used are identical to standardization of a path model (Chapter 5). The difference is that we now have to extract the standard deviations of the fitted common factor variances and covariances (\\(mathbfΦ\\)). As this matrix is not estimated directly, but as a function of model parameters of \\(\\mathbf{B}\\) and \\(\\mathbfΨ\\), we first need to calculate the model implied matrix, using \\(\\mathbfΦ = (\\mathbf{I} - \\mathbf{Β})^{-1} \\mathbfΨ (\\mathbf{I} - \\mathbf{Β})^{-1t}\\). We therefore extract the estimates of \\(\\mathbf{B}\\) and \\(\\mathbfΨ\\) into the objects beta and psi, and then calculate \\(\\mathbfΦ\\) (object phi) and the associated standard deviations (object SDphi). Now we can calculate the standardized parameters of the structural regression model. We give labels to the matrices to facilitate interpretation. We can inspect the result by typing: betastar psistar Note that the standardized parameter estimates can also be obtained by lavaan directly using the argument ‘standardized = TRUE’ in the summary() or parameterEstimates() functions. "],["ch19.html", "19 Second-order Correlation Residuals", " 19 Second-order Correlation Residuals In a second-order factor model (Chapter 17), \\(\\mathbfΦ\\) has the structure of a factor model. In a structural regression model, \\(\\mathbfΦ\\) has the structure of a path model (Chapter 18). In both models, one might want to have information to guide re-specification of the second-order part (i.e. the model for the (first-order) common factors). Correlation residuals provide this information. Correlation residuals for the higher-order part are the differences between the model-implied factor correlations, and the correlation matrix of common factors (\\(\\mathbfΦ\\)) from the measurement model (without a higher-order model). To obtain them in lavaan, you have to run a script for the measurement model first (Chapter 14), and save the covariance matrix \\(\\mathbfΦ\\) in an object. Then, after running the higher-order model or SR model, the correlation residuals can be calculated. We will show the additional commands that could be added to Script 17.1 and to Script 18.1, to calculate the correlation residuals of the second-order part of the hierarchical factor model and the structural part of the SR model respectively. Before using this script, we ran a script with the measurement model (Script 14.1), and saved the matrix with the covariances between common factors (\\(\\mathbfΦ\\)) to the object: phi &lt;- lavInspect(saqmodelOut, &quot;est&quot;)$psi Then, we ran Script 17.1 and we calculate the model-implied \\(\\mathbfΦ\\) matrix of the second-order factor model (see also Script 17.2), with: ## calculate model-implied covariance matrix first-order factors Estimates &lt;- lavInspect(saqmodel2ndOut, &quot;est&quot;) factor1names &lt;- c(&quot;Motivation&quot;,&quot;Satisfaction&quot;,&quot;SelfConfidence&quot;) factor2names &lt;- c(&quot;Attitudes&quot;) lambda2 &lt;- Estimates$beta[factor1names, factor2names, drop = FALSE] theta2 &lt;- Estimates$psi[factor1names, factor1names] phi2 &lt;- Estimates$psi[factor2names, factor2names] phi_2nd &lt;- lambda2 %*% phi2 %*% t(lambda2) + theta2 The correlation residuals are then calculated by standardizing the two \\(\\mathbfΦ\\) matrices, and subtracting the \\(\\mathbfΦ\\) matrix of the second-order factor model (phi_2nd) from the Φ matrix of the measurement model (phi). corres2nd &lt;- cov2cor(phi) - cov2cor(phi_2nd) To calculate the correlation residuals for the structural regression model, we ran Script 18.1 and we calculate the model-implied \\(\\mathbfΦ\\) matrix (see also Script 18.2), with: # calculate model-implied covariance matrix of common factors Estimates &lt;- lavInspect(saqmodelSROut, &quot;est&quot;) factornames &lt;- c(&quot;Motivation&quot;,&quot;Satisfaction&quot;,&quot;SelfConfidence&quot;) # Reorder parameter matrices and store them in separate objects beta &lt;- Estimates$beta[factornames, factornames, drop = FALSE] psi &lt;- Estimates$psi[factornames, factornames] iden &lt;- diag(nrow(beta)) # Calculate model-implied covariance matrix of factors (phi_SR) phi_SR &lt;- solve(iden-beta) %*% psi %*% t(solve(iden-beta)) The correlation residuals are then calculated by standardizing the two \\(\\mathbfΦ\\) matrices, and subtracting the \\(\\mathbfΦ\\) matrix of the SR model from the \\(\\mathbfΦ\\) matrix of the measurement model. corresSR &lt;- cov2cor(phi) - cov2cor(phi_SR) Like with the first-order correlation residuals, we can use some R functions to find the correlation residuals higher than .10, and to find the largest correlation residual. abs(corresSR) &gt;= .10 corresSR == max(abs(corresSR)) "],["ch20.html", "20 Factors with single indicators", " 20 Factors with single indicators Like most SEM software, lavaan expresses covariance structure using LISREL matrices22 (__LI__near __S__tructural __REL__ations). LISREL matrices include two matrices of directed paths (i.e., regression slopes, or single-headed arrows in a path diagram). The Beta matrix includes paths between latent variables, and the Lambda matrix includes paths from latent variables to observed variables. There is no matrix for regression paths between observed variables, but so we use Beta in a path model, we implicitly treat each observed variable as a single indicator of a latent construct, and software automatically fixes the factor loading to 1 and residual variance to 0. If we specify a SR model that has directed effect of an observed variable on a latent variable, we need to model the observed variable as if it were a common factor. We do this by defining a common factor with just one indicator. For scaling, we will fix the factor loading to one, so a 1-unit increase in the “factor” corresponds to a 1-unit increase in the observed variable. The residual variance cannot be estimated with just one indicator and must therefore also be fixed, either to zero (assuming no measurement error) or to some nonzero value (if the reliability of the measure can be known or estimated, e.g., from previous studies). Using these restrictions transfers all the information of the indicator into the common factor so that we essentially treat this variable as we would any other common factors in the SR model. Most computer programs (like lavaan) automatically impose these modelling restrictions when direct effects between observed and latent variables are specified, just as they do in a path model that has only observed variables. But we can also impose these restrictions ourselves, which gives us the freedom to choose how to fix the residual variance of the single indicator. Script 20.1 fits the SR model from Chapter 16, with the single indicators “age” and “sex”. They are modelled as explanatory variables of self-confidence (see Figure 18.1 in Ch. 18). Script 20.1 ## observed data obsnames &lt;- c(&quot;learning&quot;,&quot;concentration&quot;,&quot;homework&quot;,&quot;fun&quot;,&quot;acceptance&quot;, &quot;teacher&quot;,&quot;selfexpr&quot;,&quot;selfeff&quot;,&quot;socialskill&quot;,&quot;sex&quot;,&quot;age&quot;) values &lt;- c(30.6301, 26.9452, 56.8918, 24.1473, 31.6878, 53.2488, 16.3770, 18.4153, 16.8599, 27.9758, 7.8174, 9.6851, 10.0114, 12.8765, 47.0970, 13.6902, 16.9232, 12.9326, 17.2880, 10.3672, 29.0119, 15.3122, 24.2849, 21.4935, 10.9621, 13.9909, 11.6333, 59.5343, 13.4457, 21.8158, 18.8545, 7.3931, 10.2333, 7.1434, 29.7953, 49.2213, 6.6074, 12.7343, 10.5768, 6.4065, 13.4258, 6.1429, 26.0849, 23.6253, 40.0922, 0.3698, 0.3706, 0.6557, 0.3491, -0.2171, 0.2958, -0.0441, -0.4148, -0.5830, 0.2502, -0.6759, -0.9188, -0.2958, -0.7017, 0.1006, -0.4551, 0.3684, 0.4908, 0.3331, -0.0178, 0.9237) saqcov &lt;- getCov(values, names = obsnames) ## define structural regression model with single indicators saqmodelSRsinind &lt;- &#39;# MEASUREMENT PART # regression equations Motivation =~ L11*learning + L21*concentration + L31*homework Satisfaction =~ L42*fun + L52*acceptance + L62*teacher SelfConfidence =~ L73*selfexpr + L83*selfeff + L93*socialskill # create single indicator common factors SEX =~ L104*sex AGE =~ L115*age # residual variances observed variables learning ~~ TH11*learning concentration ~~ TH22*concentration homework ~~ TH33*homework fun ~~ TH44*fun acceptance ~~ TH55*acceptance teacher ~~ TH66*teacher selfexpr ~~ TH77*selfexpr selfeff ~~ TH88*selfeff socialskill ~~ TH99*socialskill sex ~~ TH1010*sex age ~~ TH1111*age # scaling constraints L11 == 1 L42 == 1 L73 == 1 L104 == 1 L115 == 1 TH1010 == 0 TH1111 == 0 # STRUCTURAL PART # regressions between common factors Motivation ~ b13*SelfConfidence Satisfaction ~ b21*Motivation SelfConfidence ~ b34*SEX + b35*AGE # residual variances common factors Motivation ~~ p11*Motivation Satisfaction ~~ p22*Satisfaction SelfConfidence ~~ p33*SelfConfidence # (co)variances exogenous common factors SEX ~~ p44*SEX AGE ~~ p55*AGE SEX ~~ p54*AGE &#39; ## fit model saqmodelSRsinindOut &lt;- lavaan(saqmodelSRsinind, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;, fixed.x = FALSE) ## results summary(saqmodelSRsinindOut, fit = TRUE, std = TRUE) The first part of the script is identical to the definition of the measurement part of the model from the SR model from Chapter 18. Because the covariances between the common factors are modelled as a path model, it is required to scale the common factors through the factor loadings. Therefore, we have fixed one of the factor loadings for each of the common factors to ‘1’ as a scaling constraint. To identify the single indicators as common factors we create the common factors “SEX” and “AGE” with only one indicator. # create single indicator common factors SEX =~ L104*sex AGE =~ L115*age In addition, we specify the residual variances. # residual variances observed variables sex ~~ TH1010*sex age ~~ TH1111*age The identification constraints that we used for the single indicators are that the factor loadings are constrained to 1 and the residual variances to 0. # scaling constraints L104 == 1 L115 == 1 TH1010 == 0 TH1111 == 0 By choosing 0 for the residual variance, we assume that there is no measurement error for age and sex. This might make sense (e.g., most people can be categorized as one of two biological sexes, with some exceptions such as a second Y chromosome, so we can expect measurement error to be nearly zero), but for indicators of constructs that cannot be directly observed or are defined abstractly, this might be an unrealistic assumption. For example, if we have a single indicator variable for a measure of depression, then we might be able to estimate the measurement error for this indicator. Suppose that you know the reliability of the depression measure, for example .70, then consequently, the proportion of residual variance is .30. The (unstandardized) residual variance can then be fixed to the .30 proportion of the total variance. For example, when the variance of the indicator would be 5.8, the residual variance can be constrained to \\(0.30 × 5.8 = 1.74\\). In the second part we define the structural part of the model, where we add effects from the single indicators SEX and AGE on self-confidence. The variances of the exogenous variables and the covariance between the exogenous variables are also defined. # STRUCTURAL PART # regressions between common factors Motivation ~ b13*SelfConfidence Satisfaction ~ b21*Motivation SelfConfidence ~ b34*SEX + b35*AGE # residual variances common factors Motivation ~~ p11*Motivation Satisfaction ~~ p22*Satisfaction SelfConfidence ~~ p33*SelfConfidence # (co)variances exogenous common factors SEX ~~ p44*SEX AGE ~~ p55*AGE SEX ~~ p54*AGE When we run the model and request the output, we can see that boys score higher on self-confidence than girls (as boys are coded 0 and girls are coded 1), and that the older the pupil the higher the self-confidence. We can also request output in matrix representation using the lavInspect() function. lavInspect(saqmodelSRsinindOut, &quot;est&quot;) Script 20.2 fits the same SR model with the single indicators “age” and “sex”, but here we specify the relations between the common factors and observed indicators directly. This means that the variables “age” and “sex” will only appear in the structural part of the model, and not in the measurement part. The summary() output will simply display the effect of the observed variables “age” and “sex” on the latent factors, as though no single-indicator constructs were defined. But if we request the output in matrix form, we see that lavaan does define single-indicator constructs, using the same names as the observed variables “age” and “sex”; however, the variances are in Theta instead of Psi, so those single-indicator constructs are identified by fixing the factor (not residual) variance to 0. Script 20.2 ## define structural regression model with single indicators saqmodelSRsinind &lt;- &#39; # MEASUREMENT PART # regression equations Motivation =~ L11*learning + L21*concentration + L31*homework Satisfaction =~ L42*fun + L52*acceptance + L62*teacher SelfConfidence =~ L73*selfexpr + L83*selfeff + L93*socialskill # residual variances observed variables learning ~~ TH11*learning concentration ~~ TH22*concentration homework ~~ TH33*homework fun ~~ TH44*fun acceptance ~~ TH55*acceptance teacher ~~ TH66*teacher selfexpr ~~ TH77*selfexpr selfeff ~~ TH88*selfeff socialskill ~~ TH99*socialskill # scaling constraints L11 == 1 L42 == 1 L73 == 1 # STRUCTURAL PART # regressions between common factors Motivation ~ b13*SelfConfidence Satisfaction ~ b21*Motivation SelfConfidence ~ b34*sex + b35*age # (residual) variances common factors Motivation ~~ p11*Motivation Satisfaction ~~ p22*Satisfaction SelfConfidence ~~ p33*SelfConfidence # (co)variances exogenous variables sex ~~ p44*sex age ~~ p55*age sex ~~ p54*age &#39; ## fit model saqmodelSRsinindOut &lt;- lavaan(saqmodelSRsinind, sample.cov = saqcov, sample.nobs = 915, likelihood = &quot;wishart&quot;, fixed.x = FALSE) ## results lavInspect(saqmodelSRsinindOut, &quot;est&quot;) LISREL matrices are not the only possible way to express covariance structure, but it is the most popular because it is the oldest expression of full SEM. RAM notation (reticular action model), for example, collects all directed paths into a single matrix and all undirected paths (covariances) into a single matrix, so the distinction between observed and latent variables is only conceptual.↩︎ "],["ch21.html", "21 Mean structures 21.1 Mean structure of a factor model 21.2 Mean structure of a path model 21.3 Mean structure of a factor model in lavaan 21.4 Mean structure of a path model Appendix", " 21 Mean structures Until now we have only addressed the analysis of covariance structure. However, we can also analyze mean structure using structural equation modeling. In the case of longitudinal or multigroup models, the analyses of means becomes especially relevant if the goal of the analysis is to compare means across groups or occasions. We have shown the models for the covariances in both factor analysis and path analysis previously (see Chapters 3 and 14), but we have not yet shown the mean structure in those models. In this chapter we will first extent the models for factor analysis and path analysis to include the mean structure, and then explain how to model the mean structure in a factor model and in a path model in lavaan. 21.1 Mean structure of a factor model Let’s reconsider the factor model that we used as an example in Chapter 14. The figure below is a graphical representation of the equations (21.1) through (21.9). Figure 21.1: Factor model of the School Attitudes Questionnaire \\[\\begin{align} \\mathrm{x}_1 = \\lambda_{11}\\xi_1+\\varepsilon_1, \\tag{21.1} \\\\ \\mathrm{x}_2 = \\lambda_{21}\\xi_1+\\varepsilon_2, \\tag{21.2} \\\\ \\mathrm{x}_3 = \\lambda_{31}\\xi_1+\\varepsilon_3, \\tag{21.3} \\\\ \\mathrm{x}_4 = \\lambda_{42}\\xi_2+\\varepsilon_4, \\tag{21.4} \\\\ \\mathrm{x}_5 = \\lambda_{52}\\xi_2+\\varepsilon_5, \\tag{21.5} \\\\ \\mathrm{x}_6 = \\lambda_{62}\\xi_2+\\varepsilon_6, \\tag{21.6} \\\\ \\mathrm{x}_7 = \\lambda_{73}\\xi_3+\\varepsilon_7, \\tag{21.7} \\\\ \\mathrm{x}_8 = \\lambda_{83}\\xi_3+\\varepsilon_8, \\tag{21.8} \\\\ \\mathrm{x}_9 = \\lambda_{93}\\xi_3+\\varepsilon_9, \\tag{21.9} \\end{align}\\] If we add the mean structure to the factor model, we arrive at the following equations: \\[\\begin{align} \\mathrm{x}_1 = \\tau_{1} + \\lambda_{11}\\xi_1+\\varepsilon_1, \\tag{21.10} \\\\ \\mathrm{x}_2 = \\tau_{2} + \\lambda_{21}\\xi_1+\\varepsilon_2, \\tag{21.11} \\\\ \\mathrm{x}_3 = \\tau_{3} + \\lambda_{31}\\xi_1+\\varepsilon_3, \\tag{21.12} \\\\ \\mathrm{x}_4 = \\tau_{4} + \\lambda_{42}\\xi_2+\\varepsilon_4, \\tag{21.13} \\\\ \\mathrm{x}_5 = \\tau_{5} + \\lambda_{52}\\xi_2+\\varepsilon_5, \\tag{21.14} \\\\ \\mathrm{x}_6 = \\tau_{6} + \\lambda_{62}\\xi_2+\\varepsilon_6, \\tag{21.15} \\\\ \\mathrm{x}_7 = \\tau_{7} + \\lambda_{73}\\xi_3+\\varepsilon_7, \\tag{21.16} \\\\ \\mathrm{x}_8 = \\tau_{8} + \\lambda_{83}\\xi_3+\\varepsilon_8, \\tag{21.17} \\\\ \\mathrm{x}_9 = \\tau_{9} + \\lambda_{93}\\xi_3+\\varepsilon_9, \\tag{21.18} \\end{align}\\] Equations (21.10) through (21.18) can also be written in matrix form: \\[\\begin{equation} \\mathbf{x} = \\mathbf\\tau + \\Lambda \\mathbf\\xi+\\varepsilon, \\tag{21.19} \\end{equation}\\] where \\(\\mathbf{x}\\) is a vector of all observed variables, \\(\\mathbf\\xi\\) is a vector of all common factors, \\(\\mathbf\\varepsilon\\) is a vector of all residual factors, \\(\\mathbf\\Lambda\\) is a matrix of factor loadings, and \\(\\mathbf\\tau\\) is a vector of intercepts: \\[ \\mathbf{x}= \\begin{bmatrix} x_1\\\\x_2\\\\x_3\\\\x_4\\\\x_5\\\\x_6\\\\x_7\\\\x_8\\\\x_9 \\end{bmatrix}, \\mathbf\\xi = \\begin{bmatrix} \\xi_1\\\\\\xi_2\\\\\\xi_3 \\end{bmatrix}, \\mathbf\\varepsilon = \\begin{bmatrix} \\varepsilon_1\\\\\\varepsilon_2\\\\\\varepsilon_3\\\\\\varepsilon_4\\\\\\varepsilon_5\\\\\\varepsilon_6\\\\\\varepsilon_7\\\\\\varepsilon_8\\\\\\varepsilon_9 \\end{bmatrix}, \\mathbf\\Lambda = \\begin{bmatrix} \\lambda_{11}&amp;0&amp;0\\\\\\lambda_{21}&amp;0&amp;0\\\\\\lambda_{31}&amp;0&amp;0\\\\0&amp;\\lambda_{42}&amp;0\\\\0&amp;\\lambda_{52}&amp;0\\\\0&amp;\\lambda_{62}&amp;0\\\\0&amp;0&amp;\\lambda_{73}\\\\0&amp;0&amp;\\lambda_{83}\\\\0&amp;0&amp;\\lambda_{93} \\end{bmatrix}, \\text{ and } \\mathbf\\tau = \\begin{bmatrix} \\tau_1\\\\\\tau_2\\\\\\tau_3\\\\\\tau_4\\\\\\tau_5\\\\\\tau_6\\\\\\tau_7\\\\\\tau_8\\\\\\tau_9 \\end{bmatrix}. \\] The means of the common factors are represented by \\(\\text{MEAN}(\\xi) = \\mathbf\\kappa\\), the means of the residual factors are assumed zero, \\(\\text{MEAN}(\\varepsilon) = 0\\). With these assumptions we can derive expressions for the means of observed variables \\(\\mathbf{x}\\), called \\(\\text{MEAN}(\\mathbf{x}) = \\mathbf{\\mu}\\), \\[\\begin{equation} \\mathbf\\mu = \\mathbf\\tau + \\mathbf\\Lambda \\mathbf\\kappa \\tag{21.20} \\end{equation}\\] where \\(\\mathbfμ\\) (‘mu’) is a column vector of means of the observed variables, \\(\\mathbfτ\\) (‘tau’) is a column vector of intercepts, \\(\\mathbfΛ\\) is a matrix of factor loadings, and \\(\\mathbfκ\\) (‘kappa’) is a column vector of means for the common factors. Derivations of Equation (21.20) are given in the Appendix at the end of this Chapter. Substitution of the \\(\\mathbf\\tau\\), \\(\\mathbf\\Lambda\\), and \\(\\mathbf\\kappa\\) of our example from Figure 21.1 yields: \\[\\begin{equation} \\mathbf\\mu = \\begin{bmatrix} \\mu_1\\\\\\mu_2\\\\\\mu_3\\\\\\mu_4\\\\\\mu_5\\\\\\mu_6\\\\\\mu_7\\\\\\mu_8\\\\\\mu_9 \\end{bmatrix} = \\begin{bmatrix} \\tau_1 + \\lambda_{11}\\kappa_1\\\\ \\tau_2 + \\lambda_{21}\\kappa_2\\\\ \\tau_3 + \\lambda_{31}\\kappa_3\\\\ \\tau_4 + \\lambda_{41}\\kappa_4\\\\ \\tau_5 + \\lambda_{51}\\kappa_5\\\\ \\tau_6 + \\lambda_{61}\\kappa_6\\\\ \\tau_7 + \\lambda_{71}\\kappa_7\\\\ \\tau_8 + \\lambda_{81}\\kappa_8\\\\ \\tau_9 + \\lambda_{91}\\kappa_9 \\end{bmatrix}, \\tag{21.21} \\end{equation}\\] or \\(\\mathbf\\mu_{\\text{population}} = \\mathbf\\mu_{\\text{model}}\\). 21.2 Mean structure of a path model If we go back to the path model from Chapter 3 (see Figure 21.2), and include the mean structure, we arrive at the following equations: \\[\\begin{align} \\mathrm{y}_1 &amp; = \\alpha_1 + \\zeta_1, \\tag{21.22} \\\\ \\mathrm{y}_2 &amp; = \\alpha_2 + \\zeta_2 , \\tag{21.23} \\\\ \\mathrm{y}_3 &amp; = \\alpha_3 + \\beta_{31}\\mathrm{y}_1 + \\beta_{32}\\mathrm{y}_2 + \\zeta_3 \\tag{21.24} \\\\ \\mathrm{y}_4 &amp; = \\alpha_4 + \\beta_{43}\\mathrm{y}_3 + \\zeta_44 , \\tag{21.25} \\\\ \\end{align}\\] where \\(\\mathrm{y}_1\\), \\(\\mathrm{y}_2\\), \\(\\mathrm{y}_3\\), and \\(\\mathrm{y}_4\\) are observed variables, \\(\\zeta_1\\), \\(\\zeta_2\\), \\(\\zeta_3\\) and \\(\\zeta_4\\) are residual factors, \\(\\alpha_1\\) \\(\\alpha_2\\), \\(\\alpha_3\\), and \\(\\alpha_4\\) are intercepts, and \\(\\beta_{31}\\), \\(\\beta_{32}\\), and \\(\\beta_{43}\\) are regression coefficients. Figure 21.2: Path model of child anxiety. Equations (21.22) through (21.25) can also be written in matrix form: \\[\\begin{equation} \\mathbf{y} = \\mathbf\\alpha+\\mathbf{B}\\mathbf{y}+\\mathbf\\zeta \\tag{21.26} \\end{equation}\\] where \\(\\mathbf{y}\\) is a vector of all observed variables, \\(\\mathbf\\zeta\\) is a vector of all residual factors, \\(\\mathbf\\alpha\\) is a vector of intercepts, and \\(\\mathbf{B}\\) is a matrix of regression coefficients, \\[ \\mathbf{y} = \\begin{bmatrix}\\mathrm{y}_1\\\\ \\mathrm{y}_2\\\\ \\mathrm{y}_3 \\\\ \\mathrm{y}_4 \\end{bmatrix}, \\mathbf\\zeta = \\begin{bmatrix} \\zeta_1 \\\\ \\zeta_2 \\\\ \\zeta_3 \\\\ \\zeta_4 \\end{bmatrix}, \\mathbf\\alpha = \\begin{bmatrix} \\alpha_1 \\\\ \\alpha_2 \\\\ \\alpha_3 \\\\ \\alpha_4 \\end{bmatrix}, \\text{ and }\\mathbf{B} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\\ \\beta_{31} &amp; \\beta_{32} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\beta_{43} &amp; 0 \\end{bmatrix}. \\] We assume the residual factors have zero means: \\(\\text{MEAN}(\\mathbf\\zeta) = 0\\). In order to find the model for the means of the observed variables, we first have to rewrite \\(\\mathbf{y}\\) in Equation (21.26) as a function of model parameters. \\[\\begin{align} \\mathbf{y} &amp;= \\mathbf\\alpha + \\mathbf{B} \\mathbf{y} + \\mathbf\\zeta \\Leftrightarrow \\\\ \\mathbf{y} &amp;= (\\mathbf{I} - \\mathbf{B})^{-1} \\mathbf\\alpha + (\\mathbf{I} - \\mathbf{B})^{-1} \\mathbf\\zeta, \\tag{21.27} \\end{align}\\] Now, using covariance algebra we can find expressions for the means of \\(\\mathrm{y}\\)y, called \\(\\mathbf{\\mu} = \\text{MEAN}(\\mathrm{y})\\), \\[\\begin{equation} \\mathbf{\\mu} = (\\mathbf{\\text{I}} - \\mathbf{\\text{B}})^{-1}\\hspace{1mm}\\mathbf\\alpha. \\tag{21.28} \\end{equation}\\] Derivations of Equations (21.27) and (21.28) are given in Appendix 1, at the end of this Chapter. Substituting the \\(\\mathbf\\alpha\\) and \\(\\mathbf{\\text{B}}\\) of our example from Figure 21.2 we obtain: \\[\\begin{equation} \\mathbf{\\mu} = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\mu_3 \\\\ \\mu_4 \\end{bmatrix} = \\begin{bmatrix} \\alpha_1\\\\ \\alpha_2\\\\ \\alpha_3 + \\beta_{31} \\alpha_1 + \\beta_{32}\\alpha_2\\\\ \\alpha_4 + \\beta_{43}(\\alpha_3 + \\beta_{31}\\alpha_1 + \\beta_{32}\\alpha_2) \\end{bmatrix}, \\tag{21.29} \\end{equation}\\] or \\(\\mathbf\\mu_{\\text{population}} = \\mathbf{\\mu}_{\\text{model}}\\) 21.3 Mean structure of a factor model in lavaan The model for the means in a factor model is \\(\\mathbf\\mu = \\mathbf\\tau + \\mathbf\\Lambda \\mathbf\\kappa.\\) In this equation, \\(\\mathbfμ\\) (‘mu’) is a column vector of means of the observed variables, \\(\\mathbfτ\\) (‘tau’) is a column vector of intercepts, \\(\\mathbfΛ\\) is the usual full matrix of factor loadings, and \\(\\mathbfκ\\) (‘kappa’) is a column vector of means for the common factors. For our example of the SAQ measurement model from Chapter 14, the model looks like this: \\[ \\mathbf\\mu = \\begin{bmatrix} \\mu_1\\\\\\mu_2\\\\\\mu_3\\\\\\mu_4\\\\\\mu_5\\\\\\mu_6\\\\\\mu_7\\\\\\mu_8\\\\\\mu_9\\\\ \\end{bmatrix}=\\begin{bmatrix} \\tau_1\\\\\\tau_2\\\\\\tau_3\\\\\\tau_4\\\\\\tau_5\\\\\\tau_6\\\\\\tau_7\\\\\\tau_8\\\\\\tau_9\\\\ \\end{bmatrix}+\\begin{bmatrix} \\lambda_{11}&amp;0&amp;0\\\\ \\lambda_{21}&amp;0&amp;0\\\\ \\lambda_{31}&amp;0&amp;0\\\\ 0&amp;\\lambda_{42}&amp;0\\\\ 0&amp;\\lambda_{52}&amp;0\\\\ 0&amp;\\lambda_{62}&amp;0\\\\ 0&amp;0&amp;\\lambda_{73}\\\\ 0&amp;0&amp;\\lambda_{83}\\\\ 0&amp;0&amp;\\lambda_{93}\\\\ \\end{bmatrix}\\begin{bmatrix} \\kappa_1\\\\\\kappa_2\\\\\\kappa_3\\\\ \\end{bmatrix} \\] In the model for the covariances, we had to give scale to the common factor, either by fixing the factor variances at a nonzero value (typically 1) or by constraining factor loadings (e.g., fix one loading per factor to 1, or constrain a factor’s loadings to have a mean of 1). In the model for the means, we need to give the common factors an ‘origin’23. We do this in a way that is analogous to identifying the scale of a factor: We can fix the factor mean to 0, which is analogous to fixing the factor variance to 1. This “fixed-factor” method reflects a choice to interpret common factors as having a standard normal distribution, like z scores. We can fix one intercept per factor to 0. This gives the latent mean the same mean as that reference variable, and other indicator intercepts are interpreted relative to that mean. We can constrain a factor’s intercepts to have an average (or sum) of zero. This has the effect of giving the factor a mean that is the grand mean across indicators. All indicator intercepts are interpreted relative to that grand mean. Script 21.1 is analogous to Script 14.1, but it fits the measurement model of the SAQ with a mean structure. Scale and origin are given through common factor variances and means (by fixing elements in \\(\\mathbfΦ\\) and \\(\\mathbfκ\\)). Script 21.1 ## observed data ## observed covariance matrix obsnames &lt;- c(&quot;learning&quot;,&quot;concentration&quot;,&quot;homework&quot;,&quot;fun&quot;, &quot;acceptance&quot;,&quot;teacher&quot;,&quot;selfexpr&quot;,&quot;selfeff&quot;,&quot;socialskill&quot;) values &lt;- c(30.6301, 26.9452, 56.8918, 24.1473, 31.6878, 53.2488, 16.3770, 18.4153, 16.8599, 27.9758, 7.8174, 9.6851, 12.0114, 12.8765, 47.0970, 13.6902, 16.9232, 12.9326, 17.2880, 12.3672, 29.0119, 15.3122, 24.2849, 21.4935, 12.9621, 13.9909, 11.6333, 59.5343, 13.4457, 21.8158, 18.8545, 7.3931, 12.2333, 7.1434, 29.7953, 49.2213, 6.6074, 12.7343, 12.5768, 6.4065, 13.4258, 6.1429, 26.0849, 23.6253, 40.0922) saqcov &lt;- getCov(values, names = obsnames) ## means saqmeans &lt;- c(39.7346, 36.1846, 37.4528, 42.9006, 41.3240, 41.4077, 35.7519, 35.6172, 38.9092) names(saqmeans) &lt;- obsnames ## define model including mean structure ## scale and locate by fixing common factor variances and means saqmodel &lt;- &#39;## MODEL COVARIANCE STRUCTURE # define latent common factors Motivation =~ L11*learning + L21*concentration + L31*homework Satisfaction =~ L42*fun + L52*acceptance + L62*teacher SelfConfidence =~ L73*selfexpr + L83*selfeff + L93*socialskill # indicator residual variances (or use &quot;auto.var = TRUE&quot;) learning ~~ TH11*learning concentration ~~ TH22*concentration homework ~~ TH33*homework fun ~~ TH44*fun acceptance ~~ TH55*acceptance teacher ~~ TH66*teacher selfexpr ~~ TH77*selfexpr selfeff ~~ TH88*selfeff socialskill ~~ TH99*socialskill # common factor variances (or use &quot;auto.var = TRUE&quot;) Motivation ~~ F11*Motivation Satisfaction ~~ F22*Satisfaction SelfConfidence ~~ F33*SelfConfidence # factor covariances (or use &quot;auto.cov.lv.x = TRUE&quot;) Motivation ~~ F21*Satisfaction Motivation ~~ F31*SelfConfidence Satisfaction ~~ F32*SelfConfidence # OPTIONAL: fix factor variances (or use &quot;std.lv = TRUE&quot;) F11 == 1 F22 == 1 F33 == 1 ## MODEL MEAN STRUCTURE # intercepts observed variables learning ~ T1*1 concentration ~ T2*1 homework ~ T3*1 fun ~ T4*1 acceptance ~ T5*1 teacher ~ T6*1 selfexpr ~ T7*1 selfeff ~ T8*1 socialskill ~ T9*1 # means common factors Motivation ~ K1*1 Satisfaction ~ K2*1 SelfConfidence ~ K3*1 # OPTIONAL: manually specify location constraints # fixed-factor method (default in lavaan, not needed in syntax) K1 == 0 K2 == 0 K3 == 0 # marker- / reference-variable method (MUST specify in syntax) # T1 == 0 # T4 == 0 # T7 == 0 # effects-coding method (MUST specify in syntax) # NOTE: 3 different ways yield the same solution # (T1 + T2 + T3) / 3 == 0 # mean(τ) = 0 # T4 + T5 + T6 == 0 # sum(τ) = 0 # T7 == 0 – T8 – T9 # 1 τ = negative sum of remaining τ &#39; ## fit model saqmodelOut &lt;- lavaan(saqmodel, sample.cov = saqcov, sample.mean = saqmeans, sample.nobs = 915, likelihood = &quot;normal&quot;, fixed.x = FALSE) ## results summary(saqmodelOut) ## parameter matrices lavInspect(saqmodelOut, &quot;est&quot;) We first define our observed data. In this case, we have to define the means of our observed data in addition to the covariance. The object saqmeans now contains the means of the nine observed variables, and we provide variable labels using the function names(). saqmeans &lt;- c(39.7346, 36.1846, 37.4528, 42.9006, 41.3240, 41.4077, 35.7519, 35.6172, 38.9092) names(saqmeans) &lt;- obsnames In the model specification we have to define the parameters for the model of the means, in addition to the parameters that are defined for the model of the variances and covariances. We have split the specification of the saqmodel into a section “MODEL COVARIANCE STRUCTURE” and “MODEL MEAN STRUCTURE” to emphasize this distinction. The model for the covariances is equal to the model that we used for the measurement model of the SAQ in Chapter 12. We give scales to the common factors by fixing the common factor variances at 1. The model for the means includes the intercept parameters of the observed indicators (\\(τ\\)) and the common factor means (\\(κ\\)). To define these parameters we use the tilde sign (~) in combination with a ‘1’. This combination (~ 1) specifies that we want to define the mean structure of our model, where the mean structure is represented as regressing a variable onto a constant ‘1’. Recall that this is also how to specify an intercept-only model using ordinary least-squares regression: lm(learning ~ 1). ## MODEL MEAN STRUCTURE # intercepts observed variables learning ~ T1*1 concentration ~ T2*1 homework ~ T3*1 fun ~ T4*1 acceptance ~ T5*1 teacher ~ T6*1 selfexpr ~ T7*1 selfeff ~ T8*1 socialskill ~ T9*1 # means common factors (exclude if relying on lavaan&#39;s default) Motivation ~ K1*1 Satisfaction ~ K2*1 SelfConfidence ~ K3*1 The labels that we use here refer to the position of the parameter estimate in the vector of intercepts (“T1” to “T9” in tau) and the vector of common factor means (“K1” to “K3’ in kappa). We then use these labels to impose the necessary identification constraints. Here, we freely estimate all intercepts, but we constrain all common factor means to zero. Note that lavaan constrains common-factor means by default, so the factor means and their constraints could be omitted from the model syntax. # fixed-factor method (default in lavaan, not needed in syntax) K1 == 0 K2 == 0 K3 == 0 When we run the model using the lavaan() function, we have to provide the observed means in addition to the other elements. saqmodelOut &lt;- lavaan(saqmodel, sample.cov = saqcov, sample.mean = saqmeans, sample.nobs = 915, likelihood = &quot;normal&quot;, fixed.x = FALSE) Note that we are now using “normal” likelihood instead of “Wishart” likelihood because we are including the mean structure. This still means that we rely on the assumption that our observed data are normally distributed in the population, but the underlying statistical theory is based on the sampling variability of actual data vectors (\\(\\mathrm{y}\\)) instead of the sampling variability of covariance matrices (\\(\\mathbf\\Sigma\\)). One practical consequence of this distinction is that we calculate our standard errors and \\(χ^2\\) test statistic using \\(N\\) instead of \\(N – 1\\) in our formulas. Results will be indistinguishable in asymptotically large samples, but you will notice minor differences in smaller samples. The point is simply that a Wishart distribution only describes the sampling variability of covariance matrices, not of mean vectors, so it is not appropriate to use Wishart likelihood when modeling mean and covariance structure (although it is valid to use normal likelihood even if you only model the covariance structure). Note that lavaan uses normal likelihood by default, so when fitting a model to a mean vector or to raw data, you can leave out the likelihood argument. The output will now give us an additional part named “Intercepts” that displays both the parameter estimates of the intercepts of the observed indicators and of the common factors. Note that intercepts of exogenous variables are means because the model of an exogenous variable is an intercept-only model. Like residual variances, the intercepts of endogenous variables are denoted with a “.” prefix. Estimate Std.err Z-value P(&gt;|z|) Intercepts: .learning (T1) 39.735 0.183 217.292 0.000 .concntrtn (T2) 36.185 0.249 145.193 0.000 .homework (T3) 37.453 0.241 155.338 0.000 .fun (T4) 42.901 0.175 245.482 0.000 .acceptanc (T5) 41.324 0.227 182.244 0.000 .teacher (T6) 41.408 0.178 232.670 0.000 .selfexpr (T7) 35.752 0.255 140.237 0.000 .selfeff (T8) 35.617 0.232 153.650 0.000 .socilskll (T9) 38.909 0.209 185.982 0.000 Motivatin (K1) 0.000 Satisfctn (K2) 0.000 SlfCnfdnc (K3) 0.000 In this case, the mean structure of our model is just-identified. Thus, the parameter estimates of the intercepts of the observed indicators equal the observed means. Thus, the model fit, χ2(24) = 184.04, p &lt; .001, is identical to the results from Script 12.1, which modeled covariance structure only. Script 21.1 also shows how to provide an origin for the common factors via intercepts (by fixing or constraining elements in τ). There is no lavaan argument to do these by default, so these options must be specified in the model syntax. # marker- / reference-variable method (MUST specify in syntax) # T1 == 0 # T4 == 0 # T7 == 0 # effects-coding method (MUST specify in syntax) # NOTE: 3 different ways yield the same solution # (T1 + T2 + T3) / 3 == 0 # mean(τ) = 0 # T4 + T5 + T6 == 0 # sum(τ) = 0 # T7 == 0 – T8 – T9 # 1 τ = negative sum of remaining τ Note that identification of mean structure is independent of identification of covariance structure (unless data are categorical; see Chapter 25). So you can use the fixed-factor method to identify factor means even if you use a reference variable or effects coding to identify factor variances. 21.4 Mean structure of a path model The model for the means in a path model are given by \\(\\mathbf\\mu = (\\mathbf{\\text{I}} − \\textbf{B})^{−1} \\mathbf\\alpha,\\) where \\(\\mathbfμ\\) (‘mu’) is a column vector of means of the observed variables, matrix \\(\\textbf{B}\\) is the usual full matrix of direct effects between the observed variables, and \\(\\mathbf\\alpha\\) (‘alpha’) is a column vector of intercepts. For our example of the child anxiety model from Chapter 3, the model looks like this: \\[ \\mathbf\\mu = \\begin{bmatrix} \\mu_1\\\\\\mu_2\\\\\\mu_3\\\\\\mu_4\\\\ \\end{bmatrix} = \\begin{pmatrix} \\begin{bmatrix} 1&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0\\\\0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;0\\\\ \\end{bmatrix} - \\begin{bmatrix} 0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0\\\\\\beta_{31}&amp;\\beta_{32}&amp;0&amp;0\\\\0&amp;0&amp;\\beta_{43}&amp;0\\\\ \\end{bmatrix} \\end{pmatrix} ^{-1} \\begin{bmatrix} \\alpha_1\\\\\\alpha_2 \\\\ \\alpha_3 \\\\ \\alpha_4\\\\ \\end{bmatrix} , \\] If we would like to add the mean structure to our path model from Chapter 3, we have to define the intercepts in our model (using the ‘~1’ operator, just as we did in the factor model), and we would have to provide the vector of observed means in the lavaan() function (using sample.mean = AWmeans). Again, in this situation the model for the means is just-identified. The mean structure of a path model can also be applied in structural regression models. When the means are modeled in a structural regression model, not only the covariances but also the means of the common factors are modeled using a path model. In this case, both the covariance matrix of the common factors (\\(\\mathbfΦ\\)) and the means of the common factors (\\(\\mathbfκ\\)) are estimated as a function of parameters from a path model, using \\(\\mathbfΦ = (\\textbf{I} − \\textbf{Β})^{−1} \\mathbfΨ (\\textbf{I} − \\textbf{Β})^{−1\\text{T}}\\) and \\(\\mathbfκ = (\\textbf{I} − \\textbf{Β})^{−1} \\mathbf\\alpha\\). Thus, just as the covariance structure of a full SEM is \\(\\mathbf\\Sigma_{\\text{model}} = \\mathbf\\Lambda (\\textbf{I} − \\textbf{Β})^{−1} \\mathbf{Ψ} (\\textbf{I} − \\textbf{Β})^{−1\\text{T}} \\mathbf\\Lambda^{\\text{T}} + \\mathbf\\Theta\\), the mean structure of a full SEM is \\(\\mathbf\\Sigma_{\\text{model}} = \\mathbf\\tau + \\mathbf\\Lambda (\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\alpha\\). Appendix Derivations of equation (21.20), (21.27), and (21.28). Derivation of Equation 21.20 \\[\\begin{align} \\mathbf\\mu &amp;= \\text{MEAN}(\\mathrm{x}) \\Leftrightarrow \\\\ &amp; (\\text{substitute Equation 21.19}) \\\\ \\mathbf\\mu &amp;= \\text{MEAN}(\\mathbf\\tau + \\mathbf\\Lambda \\mathbf\\xi + \\mathbf\\varepsilon) \\Leftrightarrow\\\\ &amp; (\\text{mean of sum equals the sum of means}) \\\\ \\mathbf\\mu &amp;= \\text{MEAN}(\\mathbf\\tau) + \\text{MEAN}(\\mathbf\\Lambda \\mathbf\\xi) + \\text{MEAN}(\\mathbf\\varepsilon)) \\Leftrightarrow \\\\ &amp; (\\text{mean of a constant equals the constant}) \\\\ \\mathbf\\mu &amp;= \\mathbf\\tau + \\mathbf\\Lambda \\text{MEAN}(\\mathbf\\xi) + \\text{MEAN}(\\mathbf\\varepsilon) \\Leftrightarrow \\\\ &amp; (\\text{means of } \\mathbf\\xi \\text{ are given by } \\mathbf\\kappa \\text{, and means of } \\mathbf\\varepsilon \\text{ are assumed zero)} \\\\ \\mathbf\\mu &amp;= \\mathbf\\tau + \\mathbf\\Lambda \\mathbf\\kappa \\\\ \\end{align}\\] Derivation of Equation 21.27 \\[\\begin{align} \\mathrm{y} &amp;= \\mathbf\\alpha + \\textbf{B}\\mathrm{y} + \\mathbf\\zeta \\Leftrightarrow \\\\ \\mathrm{y} − \\textbf{B}\\mathrm{y} &amp;= \\mathbf\\alpha + \\mathbf\\zeta \\Leftrightarrow \\\\ \\textbf{I}\\mathrm{y} − \\textbf{B}\\mathrm{y} &amp;= \\mathbf\\alpha + \\mathbf\\zeta \\Leftrightarrow \\\\ (\\textbf{I} − \\textbf{B})\\mathrm{y} &amp;= \\mathbf\\alpha + \\mathbf\\zeta \\Leftrightarrow \\\\ \\end{align}\\] (premultiply both sides by \\((\\textbf{I} − \\textbf{B})^{−1}\\)) \\[\\begin{align} (\\textbf{I} − \\textbf{B})^{−1} (\\textbf{I} − \\textbf{B})\\mathrm{y} &amp;= (\\textbf{I} − \\textbf{B})^{−1} (\\mathbf\\alpha + \\mathbf\\zeta )\\Leftrightarrow \\\\ \\mathrm{y} &amp;= (\\textbf{I} − \\textbf{B})^{−1} (\\mathbf\\alpha + \\mathbf\\zeta) \\Leftrightarrow \\\\ \\mathrm{y} &amp;= (\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\alpha + (\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\zeta \\\\ \\end{align}\\] Derivation of Equation 21.28 \\[\\begin{align} \\mathbf\\mu &amp;= \\text{MEAN}(\\mathrm{y}) \\Leftrightarrow \\\\ &amp;(\\text{substitute Equation 21.27})\\\\ \\mathbf\\mu &amp;= \\text{MEAN}((\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\alpha + (\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\zeta) \\Leftrightarrow \\\\ &amp;(\\text{mean of sum equals the sum of means})\\\\ \\mathbf\\mu &amp;= \\text{MEAN}((\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\alpha) + \\text{MEAN}((\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\zeta) \\Leftrightarrow \\\\ &amp;(\\text{mean of a constant equals the constant)}\\\\ \\mathbf\\mu &amp;=(\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\alpha + (\\textbf{I} − \\textbf{B})^{−1} \\text{MEAN} (\\mathbf\\zeta) \\Leftrightarrow \\\\ &amp;(\\text{means of } \\mathbf\\zeta \\text{ are assumed zero})\\\\ \\mathbf\\mu &amp;= (\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\alpha + (\\textbf{I} − \\textbf{B})^{−1} 0 \\Leftrightarrow\\\\ \\mathbf\\mu &amp;=(\\textbf{I} − \\textbf{B})^{−1} \\mathbf\\alpha \\\\ \\end{align}\\] Think of this as a ‘location’ on the number line where we put the center of our latent variable’s distribution, and we scale it by deciding how spread out around that location the distribution is.↩︎ "],["ch22.html", "22 Multigroup Models 22.1 Measurement invariance 22.2 Across group equality constraints 22.3 Standardized estimates for a multigroup model 22.4 lavaan shortcuts", " 22 Multigroup Models 22.1 Measurement invariance With multigroup models, we can simultaneously fit models to different groups (samples from different populations). This gives the possibility to test the equality of parameters across groups. It may for example be interesting to compare factor means and variances across groups. However, in order to make reliable comparisons on factor variances and means over groups, one has to make sure that the factors have the same meaning in the two groups. In other words, in order to make comparisons on factors, the measurement of those factors should be invariant across groups (Mellenbergh, 1989; Meredith, 1993). Measurement invariance can be tested by equating measurement parameters across groups. Before equating parameters, one should evaluate whether the same factor structure holds in all groups. To test measurement invariance, we can use the following steps: Configural invariance. Fit the same factor model structure to all groups. Weak factorial invariance. Fit a model with equality constraints on the factor loadings across groups, and free factor variances at all but the first group (the reference group). Weak factorial invariance is also called metric invariance. Strong factorial invariance. Fit a model with additional equality constraints on the intercepts across groups, and free factor means all but the first group. Strong factorial invariance is also called scalar invariance. Strict factorial invariance. Fit a model with additional equality constraints on the residual factor variances across groups. The last step (strict factorial invariance) is not required for a valid comparison of common factor means, variances, or covariances across groups, but it is required (along with equality of common-factor variances over groups) if one wants to test whether the observed indicators are equally reliable across groups. Table 1 shows the different types of invariance with the associated constraints, together with the appropriate methods of scaling and giving origin to the common factors. Subscripts 1 and 2 refer to the parameters associated with group 1 or 2. So Λ1 indicates the factor loadings in group 1 and Λ2 indicated the factor loadings in group 2. Degree of invariance Constraints Scaling Origin Configural invariance pattern \\(\\mathbfΛ_1=\\) pattern \\(\\mathbfΛ_2\\) \\(\\text{diag}(\\mathbfΦ_1)=\\text{diag}(\\textbf{I})\\) \\(\\mathbf{κ}_1=0\\) \\(\\text{diag}(\\mathbfΦ_2)=\\text{diag}(\\textbf{I})\\) \\(\\mathbfκ_2 = 0\\) Weak factorial invariance / Metric invariance \\(\\mathbfΛ_1 = \\mathbf\\Lambda_2\\) \\(\\text{diag}(\\mathbfΦ_1) = \\text{diag}(\\textbf{I})\\) \\(\\mathbfκ_1 = 0\\) \\(\\text{diag}(\\mathbf{Φ}_2) = \\text{free}\\) \\(\\mathbfκ_2 = 0\\) Strong factorial invariance / Scalar Invariance \\(\\mathbfΛ_1=\\mathbfΛ_2,\\mathbfτ_1=\\mathbfτ_2\\) \\(\\text{diag}(\\mathbfΦ_1)=\\text{diag}(\\textbf{I})\\) \\(\\mathbfκ_1 = 0\\) \\(\\text{diag}(\\mathbfΦ_2) = \\text{free}\\) \\(\\mathbfκ_2 = \\text{free}\\) Strict factorial invariance \\(\\mathbfΛ_1=\\mathbfΛ_2,\\mathbfτ_1=\\mathbfτ_2,\\mathbfΘ_1=\\mathbfΘ_2\\) \\(\\text{diag}(\\mathbfΦ_1)=\\text{diag}(\\textbf{I})\\) \\(\\mathbfκ_1 = 0\\) \\(\\text{diag}(\\mathbfΦ_2) = \\text{free}\\) \\(\\mathbfκ_2 = \\text{free}\\) In this chapter, we will discuss two-group models, but the same principles apply to multigroup models with more groups. Script 22.1 fits the measurement model of the SAQ with mean structure, where the sample is split into two groups: a sample of boys (\\(N = 467\\)) and girls (\\(N = 448\\)). We give scale and origin to the common factors by fixing the common factor variances at 1 and common factor means at 0. There are no equality constraints across groups, so this represents the model with configural invariance. Script 22.1 ## SAQ observed data names obsnames &lt;- c(&quot;learning&quot;,&quot;concentration&quot;,&quot;homework&quot;,&quot;fun&quot;, &quot;acceptance&quot;,&quot;teacher&quot;,&quot;selfexpr&quot;,&quot;selfeff&quot;, &quot;socialskill&quot;) ## SAQ observed data boys bvalues &lt;- c( 33.1673, 29.3029, 58.9056, 28.1938, 34.8028, 58.3240, 17.5110, 19.6911, 18.9098, 30.9436, 8.2167, 10.7283, 9.6210, 13.2711, 40.2987, 13.2590, 18.2347, 13.9296, 19.0842, 10.4321, 30.2353, 15.7417, 23.8981, 23.6277, 12.0223, 12.9815, 11.3998, 59.1952, 12.8761, 21.3100, 20.0288, 7.3135, 10.3282, 7.1202, 28.5092, 44.5547, 7.7550, 13.1092, 10.3934, 7.7236, 11.9903, 7.5445, 23.8209, 21.0226, 32.6244) saqcovboy &lt;- getCov(bvalues, names = obsnames) saqmeansboy &lt;- c(39.01, 35.46, 36.17, 42.22, 41.75, 40.83, 35.84, 36.43, 40.05) names(saqmeansboy) &lt;- obsnames ## SAQ observed data girls gvalues &lt;- c( 27.0021, 23.4847, 53.9206, 18.0520, 26.5917, 44.6775, 14.2107, 16.1073, 12.9246, 24.0094, 8.0902, 9.2953, 11.6241, 13.1408, 54.0089, 13.3044, 14.7323, 10.3630, 14.6472, 10.8696, 27.1497, 15.0637, 24.9267, 19.5973, 10.0306, 15.0257, 12.0336, 60.1345, 15.3504, 23.6937, 19.9337, 8.6904, 9.4411, 8.1999, 31.1155, 52.8966, 7.2009, 14.1647, 13.9375, 6.7247, 13.9469, 6.1179, 28.3494, 24.4655, 45.2774) saqcovgirl &lt;- getCov(gvalues, names = obsnames) saqmeansgirl &lt;- c(40.49, 36.94, 38.79, 43.61, 40.88, 42.01, 35.66, 34.77, 37.72) names(saqmeansgirl) &lt;- obsnames ## specify the multigroup model, using fixed-factor constraints saqmod.config &lt;- &#39; ## MODEL COVARIANCE STRUCTURE # regression equations Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill # residual variances observed variables learning ~~ learning concentration ~~ concentration homework ~~ homework fun ~~ fun acceptance ~~ acceptance teacher ~~ teacher selfexpr ~~ selfexpr selfeff ~~ selfeff socialskill ~~ socialskill # variances and covariances common factors Motivation ~~ 1*Motivation Satisfaction ~~ 1*Satisfaction SelfConfidence ~~ 1*SelfConfidence Motivation ~~ Satisfaction Motivation ~~ SelfConfidence Satisfaction ~~ SelfConfidence ## MODEL MEAN STRUCTURE # intercepts observed variables learning ~ 1 concentration ~ 1 homework ~ 1 fun ~ 1 acceptance ~ 1 teacher ~ 1 selfexpr ~ 1 selfeff ~ 1 socialskill ~ 1 # means common factors Motivation ~ 0*1 Satisfaction ~ 0*1 SelfConfidence ~ 0*1 &#39; ## fit the model saqout.config &lt;- lavaan(saqmod.config, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl)) ## results summary(saqout.config, fit = TRUE, std = TRUE) We first define our observed data. In this case, we have a covariance matrix for boys (saqcovboy) and a covariance matrix for girls (saqcovgirl), and also a mean vector for boys (saqmeansboys) and a mean vector for girls (saqmeansgirl). The specifications of the model are not different from specifying a single-group model, but we need to tell lavaan that the model should be fitted to the two samples separately by providing both group’s covariance matrices in a list (likewise for mean vectors and sample sizes) to the lavaan() function: saqout.config &lt;- lavaan(saqmod.config, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl)) Here, we use list() to tell lavaan there are two inputs for each group. This can be extended to multiple groups by adding additional elements to the lists. When we run this model, the factor model that we specified (SAQ measurement model) will be modelled for both groups without any across-group equality constraints. So the all parameters will be able to differ, unless they are fixed to zero or one for identification. The output will show the results for both groups separately. By default lavaan will name the output “Group 1”, “Group 2”, etc. You can also provide names for the groups by specifying group.label in the lavaan() function. For example, to name the groups “boys” and “girls”, we used: group.label = c(&quot;boys&quot;,&quot;girls&quot;) The multigroup model without any across group constraints is called the “configural” model, meaning that the only constraint placed across groups is that their models have the same configuration (same form, same pattern of fixed and free values). Traditionally, the assumption of configural invariance is evaluated using the \\(χ^2\\) test of overall model fit, which is simply the sum of each group’s \\(χ^2\\) value (discrepancy between the observed and model-implied covariance matrix and mean vector in that group). The \\(df\\) of the overall model is calculated the same way as for single-group models: by subtracting the total number of estimated parameters from the total number of observed sample statistics (variances, covariances, and means). By default, lavaan displays the \\(χ^2\\) value of each individual group, as well as the total \\(χ^2\\) value. Note that a group with a higher \\(χ^2\\) does not necessarily mean that the model fits worse in that group, because a group’s \\(χ^2\\) value is calculated using that group’s \\(N\\). Because we fit the same model to both groups’ data, failing to reject the \\(\\text{H}_0\\) of exact fit of the model to the entire sample would imply failing to reject the same \\(\\text{H}_0\\) for any particular group. And if the same model fits well in all groups, that implies that the groups must have the same model configurations. However, when we reject the H0 of exact fit for the overall model, it is unclear whether the test was significant because (a) the model configuration is correct for one group but incorrect for another group, in which case configural invariance does not hold, or because (b) the groups’ true population models do have the same configuration, but the analysis model only approximately corresponds to the true model. Testing configural invariance is still an active area of research. In current practice, most researchers accept configural invariance as tenable if the configural model’s RMSEA and/or CFI show good approximate fit, even if the \\(χ^2\\) test is significant. 22.2 Across group equality constraints To test additional measurement invariance models, we must apply equality constraints to the model parameters. In the next section, we will fit two additional models, with the following constraints on model parameters across groups: Metric equivalence (or weak factorial invariance): A multigroup model with equality constraints on factor loadings, and free factor variances in all but the first group. Scalar equivalence (or strong factorial invariance): A multigroup model with additional equality constraints on intercepts, and free factor means in all but the first group. Strict measurement equivalence/invariance can also be tested by additionally constraining indicators’ residual variances to equality across groups; however, this assumption is not required to compare means, variances, or correlations of latent common factors across groups. In Script 22.2 we fit the metric equivalence model to the data from the SAQ for boys and girls. Script 22.2 ## specify the multigroup model with metric equivalence constraints saqmod.metric &lt;- &#39; ## MODEL COVARIANCE STRUCTURE # regression equations Motivation =~ c(L1, L1)*learning + c(L2, L2)*concentration + c(L3, L3)*homework Satisfaction =~ c(L4, L4)*fun + c(L5, L5)*acceptance + c(L6, L6)*teacher SelfConfidence =~ c(L7, L7)*selfexpr + c(L8, L8)*selfeff + c(L9, L9)*socialskill # residual variances observed variables learning ~~ learning concentration ~~ concentration homework ~~ homework fun ~~ fun acceptance ~~ acceptance teacher ~~ teacher selfexpr ~~ selfexpr selfeff ~~ selfeff socialskill ~~ socialskill # variances and covariances common factors Motivation ~~ c(1, NA)*Motivation Satisfaction ~~ c(1, NA)*Satisfaction SelfConfidence ~~ c(1, NA)*SelfConfidence Motivation ~~ Satisfaction Motivation ~~ SelfConfidence Satisfaction ~~ SelfConfidence ## MODEL MEAN STRUCTURE # intercepts observed variables learning ~ 1 concentration ~ 1 homework ~ 1 fun ~ 1 acceptance ~ 1 teacher ~ 1 selfexpr ~ 1 selfeff ~ 1 socialskill ~ 1 # means common factors Motivation ~ 0*1 Satisfaction ~ 0*1 SelfConfidence ~ 0*1 &#39; ## fit model saqout.metric &lt;- lavaan(saqmod.metric, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl)) ## results summary(saqout.metric, fit = TRUE, std = TRUE) ## test difference in fit anova(saqout.config, saqout.metric) Equality constraints across groups are specified by giving the associated parameter(s) the same label(s) in the two groups. We do this by multiplying the indicator with the specified label, and repeating the label for both groups using the c() function. For example, to constrain the factor loadings of the common factor Motivation to be equal across groups we use: Motivation =~ c(L1, L1)*learning + c(L2, L2)*concentration + c(L3, L3)*homework The first L1 applies to the first group (boys) and the second L1 applies to the second group (girls). In order to test only the assumption of equal factor loadings, we must allow the factor variances to differ across groups. If we forget to free the constraints on the factor variances, then we are simultaneously testing the equality of factor loadings and factor variances. The assumption of equal factor loadings implies that the only reason indicators have different variances is because their common and unique factor variances differ, not because the relationships between the common factor and the indicator(s) differ(s). Because we constrain the factor loadings to be equal across groups, a factor’s variance only needs to be identified in one group. Therefore, we can freely estimate all other groups’ factor variances, and those estimates are identified. In our example, we use the common practice of fixing the variances of the first group to 1. To let lavaan know that this constraint only applies to the first group, we use the c() function and specify “NA” for the second group. This works because when lavaan sees values instead of labels, it assumes you want to fix the parameters to those values; and if a fixed value is missing (NA), that indicates the parameter should be estimated. Motivation ~~ c(1, NA)*Motivation Satisfaction ~~ c(1, NA)*Satisfaction SelfConfidence ~~ c(1, NA)*SelfConfidence When we run the model and look at the parameter estimates, we can now see that the estimates for the factor loadings are the same for both boys and girls. In addition, the common factor variances for girls are now freely estimated. To test whether the equality constraints on the factor loadings are tenable, we can test the difference in model fit using the anova() function: anova(saqout.metric, saqout.config) This will display the results of the \\(Δχ^2\\) test (also AIC). In our example, the \\(\\text{H}_0\\) of weak factorial invariance (or metric equivalence) cannot be rejected, so there is no evidence that the relationships between common factors and indicators differ across groups. Thus, we assume the common factors are on the same metric in both groups. Script 22.3 fits the model with additional equality constraints on the intercepts across groups (the \\(\\text{H}_0\\) of strong factorial invariance, also called scalar equivalence because it refers to the scalar/constant in the indicator’s regression model: the intercept). Script 22.3 ## specify the multigroup model with scalar equivalence constraints saqmod.scalar &lt;- &#39; ## MODEL COVARIANCE STRUCTURE # regression equations Motivation =~ c(L1, L1)*learning + c(L2, L2)*concentration + c(L3, L3)*homework Satisfaction =~ c(L4, L4)*fun + c(L5, L5)*acceptance + c(L6, L6)*teacher SelfConfidence =~ c(L7, L7)*selfexpr + c(L8, L8)*selfeff + c(L9, L9)*socialskill # residual variances observed variables learning ~~ learning concentration ~~ concentration homework ~~ homework fun ~~ fun acceptance ~~ acceptance teacher ~~ teacher selfexpr ~~ selfexpr selfeff ~~ selfeff socialskill ~~ socialskill # variances and covariances common factors Motivation ~~ c(1, NA)*Motivation Satisfaction ~~ c(1, NA)*Satisfaction SelfConfidence ~~ c(1, NA)*SelfConfidence Motivation ~~ Satisfaction Motivation ~~ SelfConfidence Satisfaction ~~ SelfConfidence ## MODEL MEAN STRUCTURE # intercepts observed variables learning ~ c(T1, T1)*1 concentration ~ c(T2, T2)*1 homework ~ c(T3, T3)*1 fun ~ c(T4, T4)*1 acceptance ~ c(T5, T5)*1 teacher ~ c(T6, T6)*1 selfexpr ~ c(T7, T7)*1 selfeff ~ c(T8, T8)*1 socialskill ~ c(T9, T9)*1 # means common factors Motivation ~ c(0, NA)*1 Satisfaction ~ c(0, NA)*1 SelfConfidence ~ c(0, NA)*1 &#39; ## fit model saqout.scalar &lt;- lavaan(saqmod.scalar, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl)) ## results summary(saqout.scalar, fit = TRUE, std = TRUE) ## test difference in fit anova(saqout.scalar, saqout.metric) Here we use the labels “T1” to “T9” to constrain the intercepts to be equal for both boys and girls. In order to test only the assumption of equal intercepts, we must allow the factor means to differ across groups. If we forget to free the constraints on the factor means, then we are simultaneously testing the equality of intercepts and factor means. Testing the assumption of equal intercepts implies that we think the only reason indicators have different means is because their common factors have different means. In other words, there if we had observed the common factor and used it (and the grouping variable) to predict the indicator in a regular regression model, there would be no interaction effect between the common factor and the grouping variable. Because we constrain the intercepts to be equal across groups, a factor’s mean only needs to be identified in one group. Therefore, we can freely estimate all other groups’ factor means, and those estimates are identified. In our example, we use the common practice of fixing the means of the first group to 0. The factor mean estimates in the second group then represent the difference in factor means across groups. We tell lavaan to fix this parameter only in the first group by using the c() function and specifying “NA” for the second group. We can use the summary() function to inspect model parameters and fit, and anova() to test whether to reject the \\(\\text{H}_0\\) of strong factorial invariance (scalar equivalence). anova(saqout.scalar, saqout.metric) We can see from the output that we reject the \\(\\text{H}_0\\), so we must test which equality constraints do not hold. In the following two chapters, we will show how to obtain mean residuals, and how to obtain modification indices and SEPCs involving equality constraints rather than parameters fixed to specific values. 22.3 Standardized estimates for a multigroup model Standardized estimates of the multigroup model can be calculated for each group separately, using the same operations as in Chapter 15. The function lavInspect() returns parameter estimates in matrix form, but with multiple groups, there is now a higher-level list: one list of matrices per group. Estimates &lt;- lavInspect(saqout.scalar, &quot;est&quot;) Each group’s matrices can be extracted using the group names you gave them, after which you can extract the individual matrices in a similar way as with a single-group factor model. Thus, to extract the parameter matrices of the first group you can use: boyEstimates &lt;- Estimates$boys girlEstimates &lt;- Estimates$girls ## calculate LAMBDA &lt;- boyEstimates$lambda PHI &lt;- boyEstimates$psi # note: lavaan doesn&#39;t use &quot;phi&quot; THETA &lt;- boyEstimates$theta TAU &lt;- boyEstimates$nu # note: lavaan doesn&#39;t use &quot;tau&quot; KAPPA &lt;- boyEstimates$nu # note: lavaan doesn&#39;t use &quot;kappa&quot; You can now calculate standardized covariance-structure parameters for the factor model of the first group using the guidelines in Chapter 13, as well as standardized mean-structure parameters of the first group using the guidelines in Chapter 21. 22.4 lavaan shortcuts You can also obtain the standardized solution easily from the summary() and parameterEstimates() functions by specifying “standardized = TRUE”. Because factor models are so much larger than path models, specifying every single nonzero parameter (or labeling each parameter) increases the likelihood of user error. Therefore, it may be preferable to use lavaan’s built-in arguments and wrapper functions. Namely, factor models can be fit using the cfa() function, which runs lavaan() with several sensible defaults (e.g., auto.fix.first, auto.fix.single, auto.var, and auto.cov.lv.x are all set to TRUE). This enables you to specify the same model in a much shorter script. Script 22.4 reproduces the exact same results as Scripts 22.1–22.3, but using much less space. Note that specifying meanstructure = TRUE makes it necessary to specify means only in the strong invariance (scalar equivalence) model, and the auto.* and std.lv arguments remove the need to specify residual or latent (co)variances, unless we need to override std.lv = TRUE in the second group. Script 22.4 ## specify the multigroup model, using fixed-factor constraints saqmod.config &lt;- &#39; ## factor loadings Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill &#39; ## fit the model saqout.config &lt;- cfa(saqmod.config, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl), meanstructure = TRUE, std.lv = TRUE) ## specify the multigroup model with metric equivalence constraints saqmod.metric &lt;- &#39; ## factor loadings Motivation =~ c(L1, L1)*learning + c(L2, L2)*concentration + c(L3, L3)*homework Satisfaction =~ c(L4, L4)*fun + c(L5, L5)*acceptance + c(L6, L6)*teacher SelfConfidence =~ c(L7, L7)*selfexpr + c(L8, L8)*selfeff + c(L9, L9)*socialskill # variances and covariances common factors Motivation ~~ c(1, NA)*Motivation Satisfaction ~~ c(1, NA)*Satisfaction SelfConfidence ~~ c(1, NA)*SelfConfidence &#39; ## fit the model saqout.metric &lt;- cfa(saqmod.metric, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl), meanstructure = TRUE, std.lv = TRUE) ## test difference in fit anova(saqout.config, saqout.metric) ## specify the multigroup model with scalar equivalence constraints saqmod.scalar &lt;- &#39; ## factor loadings Motivation =~ c(L1, L1)*learning + c(L2, L2)*concentration + c(L3, L3)*homework Satisfaction =~ c(L4, L4)*fun + c(L5, L5)*acceptance + c(L6, L6)*teacher SelfConfidence =~ c(L7, L7)*selfexpr + c(L8, L8)*selfeff + c(L9, L9)*socialskill # variances and covariances common factors Motivation ~~ c(1, NA)*Motivation Satisfaction ~~ c(1, NA)*Satisfaction SelfConfidence ~~ c(1, NA)*SelfConfidence ## MODEL MEAN STRUCTURE # intercepts observed variables learning ~ c(T1, T1)*1 concentration ~ c(T2, T2)*1 homework ~ c(T3, T3)*1 fun ~ c(T4, T4)*1 acceptance ~ c(T5, T5)*1 teacher ~ c(T6, T6)*1 selfexpr ~ c(T7, T7)*1 selfeff ~ c(T8, T8)*1 socialskill ~ c(T9, T9)*1 # means common factors Motivation ~ c(0, NA)*1 Satisfaction ~ c(0, NA)*1 SelfConfidence ~ c(0, NA)*1 &#39; ## fit the model saqout.scalar &lt;- cfa(saqmod.scalar, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl), meanstructure = TRUE, std.lv = TRUE) ## test difference in fit anova(saqout.scalar, saqout.metric) Using the group.equal argument allows you to tell lavaan what kinds of parameters you want to constrain across groups, rather than specifying the constraints manually with labels in the model syntax. Script 22.5 is thus even short than Script 22.4, because lavaan will automatically free latent means in all but the first group when the intercepts are constrained to equality across groups. Thus, the group.equal argument allows you to use the same metric-equivalence model syntax to fit the metric and scalar models. Script 22.5 ## specify the multigroup model, using fixed-factor constraints saqmod.config &lt;- &#39; ## factor loadings Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill &#39; ## fit the model saqout.config &lt;- cfa(saqmod.config, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl), meanstructure = TRUE, std.lv = TRUE) ## specify the multigroup model with metric equivalence constraints saqmod.metric &lt;- &#39; ## factor loadings Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill # variances and covariances common factors Motivation ~~ c(1, NA)*Motivation Satisfaction ~~ c(1, NA)*Satisfaction SelfConfidence ~~ c(1, NA)*SelfConfidence &#39; ## fit the model saqout.metric &lt;- cfa(saqmod.metric, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl), meanstructure = TRUE, std.lv = TRUE, group.equal = &quot;loadings&quot;) ## test difference in fit anova(saqout.config, saqout.metric) ## fit the scalar-invariance model saqout.scalar &lt;- cfa(saqmod.metric, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl), meanstructure = TRUE, std.lv = TRUE, group.equal = c(&quot;loadings&quot;,&quot;intercepts&quot;)) ## test difference in fit anova(saqout.scalar, saqout.metric) Note that group.equal can only simplify testing equality constraints in multigroup (not longitudinal) models. Additionally, the semTools package provides a function that accepts a single model syntax (for the configural model) and automatically adapts it to fit all levels of measurement invariance. Script 22.6 shows how to use it. Script 22.6 ## specify the multigroup configural model saqmod.config &lt;- &#39; ## factor loadings Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill &#39; ## fit all measurement invariance models in one step library(semTools) mi.out &lt;- measurementInvariance(saqmod.config, std.lv = TRUE, meanstructure = TRUE, group.label = c(&quot;boys&quot;,&quot;girls&quot;), sample.nobs = list(467, 448), sample.cov = list(saqcovboy, saqcovgirl), sample.mean = list(saqmeansboy, saqmeansgirl)) Notice that the output prints tables of nested model comparisons, and these show the same results as above, as well as a test of an additional model (equal factor means). There is an additional argument for strict invariance, if that is of interest. There is also a table of differences in fit indices (by default, RMSEA and CFI), but the rules of thumb proposed to evaluate measurement equivalence with fit indices do not perform well. This function returns a list of the fitted models, so you can extract and print the parameter estimates or any other information. saqout.config &lt;- mi.out[[&quot;fit.configural&quot;]] saqout.metric &lt;- mi.out[[&quot;fit.loadings&quot;]] saqout.scalar &lt;- mi.out[[&quot;fit.intercepts&quot;]] If measurement invariance is rejected at an earlier step (e.g., loadings, or even a poorly fitting configural model), then the measurementInvariance function may not save you much time because you would have to make model modifications before proceeding to more constrained models. The next two chapters demonstrate some tools for detecting invalid equality constraints using mean residuals, modification indices, and expected parameter changes. "],["ch23.html", "23 Calculating Mean Residuals Script 23.1 Script 22.2 Script 23.3 References", " 23 Calculating Mean Residuals When testing equality constraints on the intercepts across groups or across time points, one may find that not all intercepts are equal. Valid comparison can still be made between groups’ latent means as long as at least two intercepts can be constrained to equality. If some, but not all, of a factor’s measurement parameters (loadings, intercepts, or residual variances) can be constrained to equality across groups or occasions, this is called ‘partial measurement invariance’. Invalid equality constraints on factor loadings are not clearly revealed by correlation residuals, but standardized mean residuals can be useful to identify which intercepts vary most across groups or occasions. They are calculated by standardizing the observed means and the model implied means, and looking at the difference between them. You may have noticed when requesting correlation residuals from lavaan that it also outputs a vector of standardized means. Previously, these mean vectors were zero because we did not include a mean structure in our models. Now that we are including mean structure that is not saturated, the standardized residuals can be informative. Script 23.1 reiterates how to request these from lavaan. Script 23.1 resid(saqout.scalar, type = &quot;cor&quot;) ## the default standardization method is Bollen&#39;s (1989) formula resid(saqout.scalar, type = &quot;cor.bollen&quot;) For pedagogical purposes, Script 23.2 shows how to manually calculate the mean residuals—using Bollen’s (1989) formula—for the boys and girls using the multigroup output from Script 22.3. This may be necessary, for example, if you want to test invariance of a second-order factor, and you need to calculate second-order mean residuals. Script 22.2 ## extract model-implied covariance matrices and mean vectors (Sigma &lt;- lavInspect(saqout.scalar, &quot;cov.ov&quot;)) (Mu &lt;- lavInspect(saqout.scalar, &quot;mean.ov&quot;)) ## extract observed sample statistics (Obs &lt;- lavInspect(saqout.scalar, &quot;sampstat&quot;)) ## pay attention to the nested structure of the lists ## for boys: ## divide model-implied means by model-implied SDs std.mod.means.boys &lt;- Mu$boys / sqrt(diag(Sigma$boys)) ## likewise, divide observed means by observed SDs std.obs.means.boys &lt;- Obs$boys$mean / sqrt(diag(Obs$boys$cov)) ## standardized mean residuals are the differences (meanresid.boys &lt;- std.obs.means.boys - std.mod.means.boys) ## for girls std.mod.means.girls &lt;- Mu$girls / sqrt(diag(Sigma$girls)) std.obs.means.girls &lt;- Obs$girls$mean / sqrt(diag(Obs$girls$cov)) (meanresid.girls &lt;- std.obs.means.girls - std.mod.means.girls) ## search boys and girls residuals at the same time round(cbind(meanresid.boys, meanresid.girls), 3) To calculate the mean residuals, we first save the model-implied means and covariance matrices in two objects, embedding the assignment within parentheses to simultaneously print the newly created objects. Notices that these objects are lists, with one matrix/vector for Group 1 (boys) and another for Group 2 (girls). (Sigma &lt;- lavInspect(saqout.scalar, &quot;cov.ov&quot;)) (Mu &lt;- lavInspect(saqout.scalar, &quot;mean.ov&quot;)) We also save the observed sample statistics (which would be EM estimates if any data are missing and we use FIML estimation). This is also a list, but it is a list of lists: the first element is called “boys”, which is a list with two elements (a covariance matrix and a mean vector), and the second element is the same type of list but for girls. (Obs &lt;- lavInspect(saqout.scalar, &quot;sampstat&quot;)) Because R will perform regular scalar mathematical operations (e.g., +, −, ×, or ÷) in a “vectorized” manner (i.e., element-by-element), we can standardize each mean vector by dividing them by the square-root of the diagonal of the covariance matrix (i.e., \\(SD\\)s). std.mod.means.boys &lt;- Mu$boys / sqrt(diag(Sigma$boys)) std.obs.means.boys &lt;- Obs$boys$mean / sqrt(diag(Obs$boys$cov)) The standardized mean residuals are calculated by subtracting the standardized mean vectors from each other. The procedure for calculating girls’ residuals is identical. (meanresid.boys &lt;- std.obs.means.boys - std.mod.means.boys) When looking for fixed parameters that should be freely estimated, the largest residual probably causes the largest misfit in the model. An equality constrained parameter is still estimated, but freeing that constraint would “free” multiple estimates simultaneously. Thus, rather than freeing the largest residual, you should look for variables with large residuals in both groups. round(cbind(meanresid.boys, meanresid.girls), 3) Notice that the indicator ‘acceptance’ has large residuals for both groups (0.179 and −0.199), as do (to a lesser degree) the indicators ‘homework’ (−0.097 and 0.232) and ‘self-expression’ (−0.146 and 0.094). Perhaps freeing the equality constraint for ‘acceptance’ would allow for partial measurement invariance. Script 23.3 shows how to request standardized mean residuals using Bentler’s (1995) formula, which you may recall differs in that the differences in unstandardized observed and model-implied means are calculated first, then standardized with respect to the observed \\(SD\\)s only. Script 23.3 ## request Bentler&#39;s (1995) formula resid(saqout.scalar, type = &quot;cor.bentler&quot;) ## extract model-implied mean vectors (covariances not required) (Mu &lt;- lavInspect(saqout.scalar, &quot;mean.ov&quot;)) ## extract observed sample statistics (Obs &lt;- lavInspect(saqout.scalar, &quot;sampstat&quot;)) ## for boys: (meanresid.boys &lt;- Obs$boys$mean - Mu$boys) / sqrt(diag(Obs$boys$cov)) ## for girls (meanresid.girls &lt;- Obs$girls$mean - Mu$girls) / sqrt(diag(Obs$girls$cov)) ## search boys and girls residuals at the same time round(cbind(meanresid.boys, meanresid.girls), 3) Notice that this produces slightly different results (the residuals seem smaller), but they are just as valid as Bollen’s (1989) formula. Using Bentler’s (1995) formula, only the ‘acceptance’ indicator has large residuals in both groups, so it is the clear choice to free that equality constraint. In the next chapter, we will see how to also inspect modification indices for equality constraints, along with their associated expected parameter changes. References Bentler, P. M. (1995). EQS structural equations program manual. Encino, CA: Multivariate Software. Bollen, K. A. (1989). Structural equations with latent variables. Hoboken, NJ: Wiley. "],["ch24.html", "24 Modification Indices and EPC’s for Equality Constraints 24.1 Modification index for simultaneously freeing a set of parameters 24.2 Modification indices for releasing equality constraints 24.3 EPC-interest References", " 24 Modification Indices and EPC’s for Equality Constraints To test whether a fixed parameter should be freely estimated, you can fit a constrained model in which the parameter is fixed, and an unconstrained model in which the parameter is freely estimated. Because these models are nested, the \\(Δχ^2\\) provides a valid test statistic, assuming distributional assumptions of the test are met. Model modification would be quite cumbersome if it required fitting every possible alternative model in which a single parameter is freed to improve fit. Luckily, the original results from the constrained model provide enough information to estimate how much \\(Δχ^2\\) would be if a parameter (or set of parameters) were to be freed. These estimates are called Lagrange multipliers, often referred to as modification indices. The same information also provides a way to estimate how much a parameter would change if that (or another) parameter were to be freed. These are called expected parameter changes (EPCs), for which standardized versions (SEPCs) are available. Chapter 9 introduced these statistics for model modification, but there they were only discussed in their most limited sense: a \\(1-df\\) \\(Δχ^2\\) test for freeing a single, fixed parameter (modification index) and how much that same parameter might change (EPC). In this chapter, we will extend the same concept in three ways (see Bentler &amp; Chou, 1993, for details). First, modification indices can be calculated for releasing a constraint on a parameter that is already estimated rather than fixed. These constraints can refer to inequalities (e.g., psi22 \\(&gt; 0\\) or beta32 \\(&lt; 1\\)) or to equalities (e.g., constraining measurement parameters to equality across groups or occasions). Second, modification indices can be calculated for releasing multiple constraints (e.g., a \\(3-df\\) \\(Δχ^2\\) test for releasing three constraints). Third, EPCs can be calculated on the condition that other parameters are freed, rather than the same parameter. For example, if we were to release an equality constrain for one indicator’s intercepts across groups, how much might the estimated mean of its common factor change? This type of EPC has been called EPC-interest (Oberski, 2014). Although most SEM software make modification indices available for the first extension (for equality constraints as well as fixed parameters), only lavaan currently offers the second and third extensions. These are available via the function lavTestScore(). We will demonstrate how to implement each of these three extensions in the following three sections. 24.1 Modification index for simultaneously freeing a set of parameters Script 24.1 demonstrates how to request the simplest case from lavaan. Using the path model we fit in Script 3.1, recall that the largest modification index (that made sense in the context of the model) was for the regression of child anxiety on parent anxiety. We can reproduce the same value using the lavTestScore() function with the add argument, which is used to provide model syntax for currently fixed parameter(s) to be added to the model syntax. The resulting modification indices are identical. Script 24.1 ## using the modificationIndices() function modificationIndices(AWmodelOut, sort. = TRUE) ## using the lavTestScore() function lavTestScore(AWmodelOut, add = &#39;child_anx ~ parent_anx&#39;) Script 24.2 demonstrates how to get multiple modification indices, by specifying multiple additional parameters to free. In the path model from chapter 3, the only parameters that it makes sense to free are the regressions of child anxiety onto both exogenous variables (parent anxiety and parent perfectionism). Script 24.2 lavTestScore(AWmodelOut, add = c(&#39;child_anx ~ parent_anx&#39;, &#39;child_anx ~ perfect&#39;)) Again, the individual (univariate) modification indices are identical to the output from the modificationIndices() function. But unlike the modificationIndices() function, lavTestScore() also provides a total test statistic, corresponding the estimated \\(2-df\\) \\(Δχ^2\\) test if both parameters were freed at the same time and compared to the constrained model. total score test: test X2 df p.value 1 score 7.082 2 0.029 univariate score tests: lhs op rhs X2 df p.value 1 child_anx~parent_anx == 0 6.716 1 0.010 2 child_anx~perfect == 0 0.109 1 0.742 24.2 Modification indices for releasing equality constraints Script 22.3 fits a strong invariance (scalar equivalence) model, which fit significantly worse than the weak invariance (metric equivalence) model. Thus, we rejected the \\(\\text{H}_0\\) that all indicators’ intercepts were equal across groups. To establish partial invariance, we first inspected standardized mean residuals in chapter 23. Script 24.3 demonstrates how to request modification indices for the intercept constraints using the release argument. This involves multiple steps, but it is good motivation for researchers to think carefully about which (and therefore how many) modification indices to inspect, and adjust \\(α\\) accordingly. Script 24.3 ## save parameter table (PT &lt;- parTable(saqout.scalar)) ## extract the part of the table regarding constraints CT &lt;- PT[PT$op == &quot;==&quot;, ] rownames(CT) &lt;- NULL ## to know the actual &quot;constraint number&quot; CT ## find out which constraints involve the intercepts PT[PT$op == &quot;~1&quot;, ] ## Parameters 25-33 are constrained to equal parameters 61-69. ## In the constraints table, these are rows 10-18 CT[10:18, ] ## We need to adjust our alpha level for the number of tests length(10:18) ## 9 tests .05 / 9 ## Bonferroni-adjusted alpha level 1 - .95^(1/9) ## Sidak-adjusted alpha level ## To calculate modification indices for these constraints, specify those ## rows. Compare the values in the &quot;X2&quot; column to the critical value. lavTestScore(saqout.scalar, release = 10:18) ## The following constraints are significant ## .p27. == .p63. ## .p29. == .p65 ## .p31. == .p67 ## .p33. == .p69. ## They correspond to these indicators: PT$lhs[PT$plabel %in% c(&quot;.p27.&quot;,&quot;.p29.&quot;,&quot;.p31.&quot;,&quot;.p33.&quot;)] First, we extract the parameter table from our fitted lavaan object. This contains all the free parameters we specified in our model syntax, as well as any parameters that may have been freed by default in the cfa() function or using (for example) the auto.* arguments in lavaan(). At the bottom are rows corresponding to equality constraints. (PT &lt;- parTable(saqout.scalar)) Notice that there are columns for the left-hand side (lhs) and right-hand side (rhs) of every parameter specification, separated by the operator (op) that defines the relationship between the two variables in lhs and rhs. For mean-structure parameters, the rhs is empty because the operator is a regression onto a constant rather than a variable (~1). The operator for equality constraints is the double-equals sign (==). To request modification indices for specific constraints, we need to refer to the order in which they appear in the parameter table. So we next need to extract the rows corresponding only to constraints, and “erase” the row numbers from the full parameter table by setting them to NULL. CT &lt;- PT[PT$op == &quot;==&quot;, ] rownames(CT) &lt;- NULL ## to know the actual &quot;constraint number&quot; CT Because lavaan uses its own internal labels, it is not obvious to which parameters these constraints refer. To find out, we refer back to the full parameter table, and pay attention to the plabel column, which contains lavaan’s default parameter labels (distinct from your user-defined labels in the label column). Rather than print the full table, we can request the rows we are interested in. For example, if weak invariance (metric equivalence) did not pass, then we would be interested in equality constraints involving factor loadings, so we would request rows of PT corresponding to op == \"=~\". Because we are testing equality constraints on intercepts in this example, we request rows only corresponding to mean-structure parameters (where op == \"~1\"). This also prints out the latent means, but there are only a few of those, so they are easy to ignore. PT[PT$op == &quot;~1&quot;, ] Now that we can see that the intercepts were labeled by lavaan with the numbers 25–33 in the first group (boys) and 61–69 in the second group (girls; notice the group column, as well as the estimate and se columns). Looking back at the constraints table (CT), we can now see that rows 10–18 correspond to constraints on the intercepts. Therefore, we request modification indices for those specific constraints. lavTestScore(saqout.scalar, release = 10:18) Because there are 9 tests (one for each intercept), we need to test the \\(Δχ^2\\) value in the X2 column using a Bonferroni-adjusted \\(α = .05 / 9 = .0056\\), or a Sidak-adjusted \\(α = 1 –.95^{1⁄9} = .0057\\), to which we can compare the \\(p\\)-values in the output. Notice that there are four significant constraints. We can see which indicators those constraints correspond to by printing the lhs variable only for rows of PT where plabel is in that list of strings (only one plabel per constraint is necessary). PT$lhs[PT$plabel %in% c(&quot;.p27.&quot;,&quot;.p29.&quot;,&quot;.p31.&quot;,&quot;.p33.&quot;)] Notice that “acceptance” has the third largest modification index. This indicator also had the largest pair of mean residuals. The indicators “homework” and “selfexpr” also had large pairs of residuals (using Bollen’s formula), and their modification indices are significant, too. The social skills modification index is significant, but its residual is only large for boys. 24.3 EPC-interest If we were to release the equality constraint on the ‘acceptance’ intercepts, how much would we expect each of the intercept estimates to change? And how much would that affect the estimated latent mean of its factor (Satisfaction) in Group 2 (girls)? We can request these EPCs to be added to the output of lavTestScore() using the epc argument. They will reflect how much we expect each free (not fixed, unless the parameter(s) are specified using the add argument) model parameter to change if all constraints specified in the release argument were freed. Thus, when we request EPCs, we should only specify one constraint at a time. If there are more than two groups, specify only one indicator’s set of constraints. ## request all EPCs lavTestScore(saqout.scalar, release = 14, epc = TRUE) ## save them to print only the mean-structure EPCs EPCs.accept &lt;- lavTestScore(saqout.scalar, release = 14, epc = TRUE)$epc EPCs.accept[EPCs.accept$op == &quot;~1&quot;, ] The columns est, epc, and epv correspond to the current estimate, the expected change (EPC), and the expected resulting value (\\(\\text{epc} = \\text{est} + \\text{epc}\\)), respectively. Notice that there are no standardized versions (SEPCs) currently available (as of lavaan 0.5-22), but they could easily be calculated to use the 0.1 rule-of-thumb. According to the EPC output, the estimated means and intercepts of other factors and their indicators are not expected to change if we free the ‘acceptance’ intercepts across groups. However, the ‘acceptance’ intercepts themselves are expected to increase by 0.659 for boys and to decrease by 1.076 for girls. Using the methods described in chapter 22, we can find out that the model-implied variances of acceptance are 41.165 for boys and 52.617 for girls, so we could calculate our own SEPCs: \\[ \\text{SEPC}_\\text{Boys} =0.659/√41.165=0.103 \\hspace{10mm} \\text{SEPC}_\\text{Girls} =1.076/√52.617=0.148 \\] These are both substantial changes. The other Satisfaction-indicator intercepts are expected to change only a little bit (0.05–0.07), and the latent mean of Satisfaction itself is expected to increase by 0.028 for girls (the latent mean for boys is fixed to zero, so it is not expected to change). With a latent Satisfaction variance of 0.78 for girls, the SEPC would be: \\[ \\text{SEPC} =0.028/√0.78=0.03 \\] That is a small EPC-interest, so Oberski (2014) might argue that there is little practical consequence to leaving the intercepts fixed. But EPC-interest is a newly implemented method, so it needs more study before we can comfortably draw this conclusion. In this example, the latent mean difference is already significant, so freeing the intercept constraint would not change our decision. However, allowing an invalid constraint might bias our results enough to bias any meta-analysis results that included this study. Only time will tell! References Bentler, P. M., &amp; Chou, C. P. (1993). Some new covariance structure model improvement statistics. Sage Focus Editions, 154, 235–255. Oberski, D. L. (2014). Evaluating sensitivity of parameters of interest to measurement invariance in latent variable models. Political Analysis, 22(1), 45–60. doi:10.1093/pan/mpt014 "],["ch25.html", "25 MIMIC (and RFA) models 25.1 Illustration testing uniform bias in a MIMIC model 25.2 Evaluating non-uniform measurement bias 25.3 Connection with measurement invariance testing in multigroup models 25.4 RFA-models References", " 25 MIMIC (and RFA) models Multiple indicator multiple cause (MIMIC) models are a type of full SEM model where a common factor with multiple indicators is an endogeneous variable, cause by one or more observed variables. Technically, MIMIC models are just full SEM models with single indicator factors as exogeneous variables. What makes MIMIC models especially interesting is that they can also be used to evaluate measurement invariance across groups or across continuous variables (Muthén, 1989). Measurement invariance was defined by Mellenbergh (1998) as: \\[\\begin{equation*} f(X|T=t, V=v) = f(X|T=t), \\end{equation*}\\] which in plain words indicates that the distribution of \\(X\\) given values of \\(T\\) (representing what you want to measure) and given values of \\(V\\) (a variable that possibly violates invariance), should be equal to the distribution of \\(X\\) conditioned on \\(T\\) but with varying \\(V\\). Suppose that \\(X\\) represents item scores, \\(T\\) represents mathematical ability, and \\(V\\) represents gender. In that case, measurement invariance holds if the distribution of the item scores for individuals with the same mathematical ability does not depend on gender. Mellenbergh distinguished between uniform and non-uniform bias, depending on whether the distribution of X given T is uniformly or non-uniformly affected by \\(V\\). Figure 25.1 shows a graphical display of the relationships between X, T and V in case of unbiased measurement, uniform measurement bias, and non-uniform measurement bias. Figure 25.1: Graphical representation of unbiased measurement, uniform measurement bias, and non-uniform measurement bias. In a MIMIC model, \\(T\\) is operationalized as a common factor, \\(X\\) is operationalized as a set of indicators reflective of that common factor, and \\(V\\) is an observed variable. A MIMIC model that represents indicators of \\(T\\) that are unbiased (in other words, measurement invariant) with respect to \\(V\\) is depicted in Figure 25.2. In this model, variable V has solely indirect effects on the indicators. So, if V represents gender, any gender effects on X are the result of gender differences in the common factor. Figure 25.2: A MIMIC model. 25.1 Illustration testing uniform bias in a MIMIC model The illustration uses data from the open-source psychometrics project Open Psychometrics. Specifically, we used three items from the Humor Styles Questionnaire (HSQ), designed to reflect ‘affiliative humor’. These three items were scored on a 7-point scale ranging from 1 to 7. Q5. I don’t have to work very hard at making other people laugh—I seem to be a naturally humorous person. Q13. I laugh and joke a lot with my closest friends. Q21. I enjoy making people laugh. library(lavaan) data &lt;- read.csv(&quot;demoData/dataHSQ.csv&quot;) subdat &lt;- data[,c(&quot;Q5&quot;,&quot;Q13&quot;,&quot;Q21&quot;,&quot;age&quot;,&quot;gender&quot;)] subdat &lt;- subdat[subdat$gender%in%c(1,2),] subdat &lt;- subdat[subdat$age&lt;100,] subdat &lt;- subdat[rowSums(subdat[,1:3]&gt;0)==3,] humordat &lt;- subdat # descriptives of age and gender min(humordat$age) ## [1] 14 max(humordat$age) ## [1] 70 median(humordat$age) ## [1] 22 table(humordat$gender) ## ## 1 2 ## 574 471 round(cor(humordat),3) ## Q5 Q13 Q21 age gender ## Q5 1.000 0.373 0.458 0.054 -0.072 ## Q13 0.373 1.000 0.465 -0.089 -0.017 ## Q21 0.458 0.465 1.000 0.028 -0.011 ## age 0.054 -0.089 0.028 1.000 -0.039 ## gender -0.072 -0.017 -0.011 -0.039 1.000 The first step when testing evaluating measurement bias with respect to some covariates with a MIMIC model would be to evaluate the factor structure without the covariates. In our example data, there are only three indicators for the construct, so the one-factor model is saturated and its fit cannot be tested. library(lavaan) # factor model without covariates model1 &lt;- &#39; # define common factor humor =~ 1*Q5 + l21*Q13 + l31*Q21 # indicator residual variances Q5 ~~ th11*Q5 Q13 ~~ th22*Q13 Q21 ~~ th33*Q21 # common factor variance (fixed) humor ~~ humor&#39; factormodelOut &lt;- lavaan(model1, data = humordat) summary(factormodelOut, standardized = TRUE) ## lavaan 0.6-19 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1045 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## humor =~ ## Q5 1.000 0.629 0.607 ## Q13 (l21) 0.833 0.063 13.319 0.000 0.524 0.615 ## Q21 (l31) 1.028 0.081 12.651 0.000 0.646 0.755 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Q5 (th11) 0.680 0.041 16.556 0.000 0.680 0.632 ## .Q13 (th22) 0.451 0.028 16.195 0.000 0.451 0.622 ## .Q21 (th33) 0.314 0.033 9.556 0.000 0.314 0.429 ## humor 0.395 0.046 8.571 0.000 1.000 1.000 Next, we add the variables Age and Gender to the model. The latent variable is regressed on both variables, and Age and Gender are correlated. # MIMIC model with dummy Gender and continuous Age as covariate MIMIC_genderage &lt;- &#39; # define latent common factor humor =~ 1*Q5 + l21*Q13 + l31*Q21 # indicator residual variances Q5 ~~ th11*Q5 Q13 ~~ th22*Q13 Q21 ~~ th33*Q21 # common factor variance humor ~~ humor gender ~~ gender age ~~ age # correlate gender age gender ~~ age # regress humor on age and gender humor ~ b_age*age + b_gender*gender&#39; ## fit model MIMICgenderageOut &lt;- lavaan(MIMIC_genderage, data = humordat) ## results summary(MIMICgenderageOut) ## lavaan 0.6-19 ended normally after 30 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 11 ## ## Number of observations 1045 ## ## Model Test User Model: ## ## Test statistic 24.704 ## Degrees of freedom 4 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## humor =~ ## Q5 1.000 ## Q13 (l21) 0.831 0.062 13.327 0.000 ## Q21 (l31) 1.021 0.080 12.692 0.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## humor ~ ## age (b_ag) 0.000 0.002 0.092 0.927 ## gender (b_gn) -0.053 0.046 -1.137 0.256 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## age ~~ ## gender -0.215 0.170 -1.270 0.204 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Q5 (th11) 0.677 0.041 16.487 0.000 ## .Q13 (th22) 0.451 0.028 16.212 0.000 ## .Q21 (th33) 0.317 0.033 9.683 0.000 ## .humor 0.398 0.046 8.603 0.000 ## gender 0.248 0.011 22.858 0.000 ## age 121.282 5.306 22.858 0.000 In order to evaluate whether there are relatively large unmodeled dependencies across Gender or Age and the indicators of humor, you can evaluate correlation residuals. # look at correlation residuals resid(MIMICgenderageOut, type = &quot;cor&quot;) ## $type ## [1] &quot;cor.bollen&quot; ## ## $cov ## Q5 Q13 Q21 age gender ## Q5 0.000 ## Q13 -0.001 0.000 ## Q21 0.000 0.001 0.000 ## age 0.051 -0.092 0.024 0.000 ## gender -0.047 0.009 0.021 0.000 0.000 # look at modification indices modificationIndices(MIMICgenderageOut, sort. = TRUE) ## lhs op rhs mi epc sepc.lv sepc.all sepc.nox ## 18 Q13 ~~ age 18.749 -1.138 -1.138 -0.154 -0.154 ## 17 Q13 ~~ Q21 5.516 0.872 0.872 2.308 2.308 ## 15 Q5 ~~ age 5.247 0.733 0.733 0.081 0.081 ## 16 Q5 ~~ gender 4.327 -0.030 -0.030 -0.074 -0.074 ## 20 Q21 ~~ age 3.146 0.492 0.492 0.079 0.079 ## 21 Q21 ~~ gender 2.390 0.019 0.019 0.069 0.069 ## 13 Q5 ~~ Q13 1.770 -0.411 -0.411 -0.744 -0.744 ## 14 Q5 ~~ Q21 0.596 -0.341 -0.341 -0.737 -0.737 ## 19 Q13 ~~ gender 0.066 0.003 0.003 0.009 0.009 The largest correlation residual is found between Age and Q13. The modification indices show that adding a direct effect of Age on Q13 is expected to lead to a drop in the model’s chi-square statistic of around 18.75, and that the standardized expected parameter change is -.15, which could be interpreted as substantial. Therefore, we added the direct effect of Age on Q13 to the model, representing uniform measurement bias with respect to age in the item Q13. # add direct effect of age on Q13 MIMIC_genderage2 &lt;- c(MIMIC_genderage, &#39; Q13 ~ age &#39;) # fit the new model by &quot;updating&quot; the original model MIMICgenderage2Out &lt;- update(MIMICgenderageOut, model = MIMIC_genderage2) summary(MIMICgenderage2Out, standardized = TRUE) ## lavaan 0.6-19 ended normally after 35 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## ## Number of observations 1045 ## ## Model Test User Model: ## ## Test statistic 5.609 ## Degrees of freedom 3 ## P-value (Chi-square) 0.132 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## humor =~ ## Q5 1.000 0.636 0.613 ## Q13 (l21) 0.836 0.062 13.470 0.000 0.531 0.624 ## Q21 (l31) 1.007 0.078 12.956 0.000 0.640 0.748 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## humor ~ ## age (b_ag) 0.003 0.002 1.354 0.176 0.005 0.052 ## gender (b_gn) -0.054 0.047 -1.152 0.249 -0.085 -0.042 ## Q13 ~ ## age -0.009 0.002 -4.382 0.000 -0.009 -0.123 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## age ~~ ## gender -0.215 0.170 -1.270 0.204 -0.215 -0.039 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Q5 (th11) 0.671 0.041 16.490 0.000 0.671 0.624 ## .Q13 (th22) 0.438 0.028 15.931 0.000 0.438 0.604 ## .Q21 (th33) 0.323 0.032 10.141 0.000 0.323 0.441 ## .humor 0.402 0.046 8.720 0.000 0.995 0.995 ## gender 0.248 0.011 22.858 0.000 0.248 1.000 ## age 121.282 5.306 22.858 0.000 121.282 1.000 # look at correlation residuals again resid(MIMICgenderage2Out, type = &quot;cor&quot;) ## $type ## [1] &quot;cor.bollen&quot; ## ## $cov ## Q5 Q13 Q21 age gender ## Q5 0.000 ## Q13 -0.005 0.000 ## Q21 0.000 0.003 0.000 ## age 0.021 0.000 -0.012 0.000 ## gender -0.045 0.006 0.022 0.000 0.000 # look at modification indices modificationIndices(MIMICgenderage2Out, sort. = TRUE) ## lhs op rhs mi epc sepc.lv sepc.all sepc.nox ## 18 Q13 ~~ Q21 4.588 0.506 0.506 1.344 1.344 ## 17 Q5 ~~ gender 4.295 -0.030 -0.030 -0.074 -0.074 ## 14 Q5 ~~ Q13 3.297 -0.397 -0.397 -0.732 -0.732 ## 22 Q21 ~~ gender 2.288 0.019 0.019 0.067 0.067 ## 21 Q21 ~~ age 0.958 -0.335 -0.335 -0.053 -0.053 ## 16 Q5 ~~ age 0.934 0.328 0.328 0.036 0.036 ## 19 Q13 ~~ age 0.087 1.964 1.964 0.269 0.269 ## 23 humor ~ Q13 0.087 0.240 0.378 0.322 0.322 ## 15 Q5 ~~ Q21 0.087 -0.127 -0.127 -0.272 -0.272 ## 20 Q13 ~~ gender 0.087 0.003 0.003 0.011 0.011 ## 29 gender ~ Q13 0.087 0.008 0.008 0.014 0.014 ## 24 Q13 ~ gender 0.087 0.014 0.014 0.008 0.008 Exact fit is not rejected for the modified MIMIC model (\\(\\chi^2(3) = 5.40, p = .132\\)), and there are no correlation residuals larger than .10. We therefore do not modify the model further. The results show no significant gender or age differences in the common factor humor. The statistically significant direct effect of Age on Q13 of \\(\\hat{\\beta} = -.123\\) indicated that for equal levels of ‘humor’, older respondents provided less positive responses to this item. To interpret this uniform bias, we would have to reflect on attributes that are specific to this item (as opposed to the other 2 items) that could cause less positive responses by older people. In this example, the item refers to laughing and joking a lot ‘with my closest friends’, while the other two items do not refer to specific types of social company. Since younger people may be spending more time with their closest friends (in school for example), than older people (who spend relatively more time with colleagues and family), the age bias in item Q13 may be explained by these differences in social environment. 25.2 Evaluating non-uniform measurement bias The direct effects of covariates on items in a MIMIC model represent uniform measurement bias. In a multi-group model, uniform measurement bias would be reflected by unequal measurement intercepts across groups. Non-uniform bias is reflected by unequal factor loadings across groups in a multigroup model. In a MIMIC model, moderation of factor loadings by a covariate would be represented by an interaction effect of the common factor and the covariate on an indicator (Woods &amp; Grimm, 2011). Since we cannot directly observe the common factor scores, simply calculating each person’s score on the Factor*covariate product variable is not possible. Alternative options to evaluate non-uniform measurement bias in MIMIC models are using latent moderated structures (Klein &amp; Moosbrugger, 2000), which however leads to inflated type 1 error rates or the product indicator approach, which has better performance (Kolbe &amp; Jorgensen, 2017). 25.3 Connection with measurement invariance testing in multigroup models In situations where the covariate is a grouping variable, meaurement invariance can also be tested in a multigroup model. For example, if variable \\(V\\) in Figure 2 represents gender (0 = boy 1 = girl), one could evaluate measurement invariance using either a MIMIC/RFA model, or a multigroup model. A large difference between the two approaches is that in the multigroup model without equality constraints, all parameters are uniquely estimated in the two groups. So, not only the factor loadings and intercepts, but also the residual variances and the factor (co)variances are unconstrained in the configural invariance model. There is no such equivalent in the MIIMIC model, because the MIMIC model is fitted to the total sample of boys and girls together. There will be only one set of estimates for residual variances or factor variances, implying that those parameters do not differ between boys and girls. Moreover, in A MIMIC model it is not possible to regress all indicators on \\(V\\) simultaneously because such a model would not be identified. The MIMIC model needs so-called ‘anchor items’ that are assumed to be invariant and are therefore not tested. Selecting these anchor items is not an easy task (Kolbe &amp; Jorgensen, 2019). In the example analysis provides above, we started with a MIMIC model that represents no measurement bias (none of the indicators was regressed on \\(V\\)), and then used correlation residuals to identify whether any effects of V on indicators should be included. The starting point was thus the most constrained model, and we freed parameters when deemed necessary. A similar approach could be taken in a multigroup model by starting with a model that represents strong factorial invariance, and releasing equality constraints when necessary. By taking this approach one is effectively using all remaining indicators as anchor items. 25.4 RFA-models Restricted Factor Analysis (RFA) models (Oort, 1992) are statistically equivalent to MIMIC-models. The only difference is that in RFA-models the common factor is correlated with the covariates, instead of regressed on the covariates. References Klein, A., &amp; Moosbrugger, H. (2000). Maximum likelihood estimation of latent interaction effects with theLMS method.Psychometrika, 65, 457-474. Kolbe, L., &amp; Jorgensen, T. D. (2017, July). Using product indicators in restricted factor analysis models to detect nonuniform measurement bias. In The Annual Meeting of the Psychometric Society (pp. 235-245). Springer, Cham. Kolbe, L., &amp; Jorgensen, T. D. (2019). Using restricted factor analysis to select anchor items and detect differential item functioning. Behavior Research Methods, 51(1), 138-151. Muthén, B. O. (1989). Latent variable modeling in heterogeneous populations. Psychometrika, 54(4), 557-585. Oort, F. J. (1992). Using restricted factor analysis to detect item bias. Methodika, 6(2), 150-166. Woods, C. M., &amp; Grimm, K. J. (2011). Testing for nonuniform differential item functioning with multiple indicator multiple cause models. Applied Psychological Measurement, 35, 339-361. "],["ch26.html", "26 Longitudinal Factor Analysis 26.1 Step 1: A longitudinal factor model with configural invariance 26.2 Step 2: A longitudinal model with weak factorial invariance. 26.3 Step 3: Longitudinal model with strong factorial invariance 26.4 Step 4: A model with strict factorial invariance 26.5 Standardized estimates for a (longitudinal) factor model with means References", " 26 Longitudinal Factor Analysis With longitudinal factor analysis, a factor model is fitted to a set of indicators of which responses are collected at different time points. It may be interesting to compare factor means and variance across time. Fitting a longitudinal factor model is not very different from fitting a factor model with means, except that in a longitudinal factor model there are covariances between the residual factors of the same indicator at different time points. Figure 1 depicts a one-factor model of “Self-efficacy” with six indicators, measured at two different time points. Because each indicator is measured twice in the same individuals, the item specific components of each indicator covary across timepoints. Figure 26.1: Self-efficacy measured at two time points. In order to compare latent variances or latent means over across timepoints, the measurement of the latent variables should be equal over time. To test longitudinal invariance, we can use similar steps as when testing measurement invariance across groups: Configural invariance. Fit the same factor model to all time points (with residual covariances). Weak factorial invariance. Fit a model with equality constraints on the factor loadings across time, and free factor variances at the later time points. Strong factorial invariance. Fit a model with additional equality constraints on the intercepts across time, and free factor means at later time points. Strict factorial invariance. Fit a model with additional equality constraints on the residual factor variances across time points. The last step (strict factorial invariance) is not required for a valid comparison of common factor means, variances, or covariances across occasions, but it is required (along with equality of common-factor variances over time) to test the assumption that the observed indicators are measured with the same reliability across time points. 26.1 Step 1: A longitudinal factor model with configural invariance Script 26.1 fits the model from Figure 1 to data from Hornstra, van der Veen, Peetsma and Volman (2013), without equality constraints across time. Script 26.1 ## observed data obsnames &lt;- c(&quot;t1v1&quot;,&quot;t1v2&quot;,&quot;t1v3&quot;,&quot;t1v4&quot;,&quot;t1v5&quot;,&quot;t1v6&quot;, &quot;t2v1&quot;,&quot;t2v2&quot;,&quot;t2v3&quot;,&quot;t2v4&quot;,&quot;t2v5&quot;,&quot;t2v6&quot;) values &lt;- c( 0.5237, 0.2387, 0.6653, 0.0606, 0.0576, 0.6169, 0.1260, 0.1640, 0.1800, 0.6467, 0.1489, 0.2452, 0.0621, 0.1665, 0.6151, 0.2383, 0.3781, 0.1109, 0.2248, 0.3143, 0.7241, 0.2691, 0.1920, 0.0778, 0.1296, 0.1445, 0.2599, 0.6678, 0.1686, 0.2949, 0.0952, 0.1548, 0.2139, 0.3171, 0.3080, 0.7102, 0.0881, 0.0667, 0.1673, 0.0872, 0.0719, 0.0852, 0.1681, 0.1604, 0.6583, 0.1473, 0.1594, 0.0795, 0.2021, 0.1393, 0.1769, 0.2639, 0.2910, 0.1445, 0.6218, 0.1744, 0.2025, 0.0899, 0.1621, 0.2381, 0.2736, 0.2792, 0.3640, 0.1411, 0.3163, 0.7072, 0.2192, 0.2630, 0.1325, 0.1730, 0.2348, 0.3630, 0.3613, 0.4471, 0.1884, 0.2894, 0.4354, 0.7768) hornstracov &lt;- getCov(x=values, names = obsnames) hornstrameans &lt;- c(3.3640, 3.4138, 3.9444, 3.8544, 3.8391, 3.1992, 3.4674, 3.4693, 4.0057, 3.9119, 3.8218, 3.2778) names(hornstrameans) &lt;- obsnames ## STEP 1: define longitudinal model without equality constraints hornstramodel1 &lt;- &#39; # COVARIANCES # regression equations selfeff1 =~ t1v1 + t1v2 + t1v3 + t1v4 + t1v5 + t1v6 selfeff2 =~ t2v1 + t2v2 + t2v3 + t2v4 + t2v5 + t2v6 # residual variances t1v1 ~~ t1v1 t1v2 ~~ t1v2 t1v3 ~~ t1v3 t1v4 ~~ t1v4 t1v5 ~~ t1v5 t1v6 ~~ t1v6 t2v1 ~~ t2v1 t2v2 ~~ t2v2 t2v3 ~~ t2v3 t2v4 ~~ t2v4 t2v5 ~~ t2v5 t2v6 ~~ t2v6 # residual covariances t1v1 ~~ t2v1 t1v2 ~~ t2v2 t1v3 ~~ t2v3 t1v4 ~~ t2v4 t1v5 ~~ t2v5 t1v6 ~~ t2v6 # common factor (co)variances selfeff1 ~~ 1*selfeff1 selfeff2 ~~ 1*selfeff2 selfeff1 ~~ selfeff2 # MEANS # intercepts observed indicators t1v1 ~ 1 t1v2 ~ 1 t1v3 ~ 1 t1v4 ~ 1 t1v5 ~ 1 t1v6 ~ 1 t2v1 ~ 1 t2v2 ~ 1 t2v3 ~ 1 t2v4 ~ 1 t2v5 ~ 1 t2v6 ~ 1 # means common factors selfeff1 ~ 0*1 selfeff2 ~ 0*1 &#39; ## run the model hornstramodel1Out &lt;- lavaan(hornstramodel1, sample.cov = hornstracov, sample.mean = hornstrameans, sample.nobs = 522, likelihood = &quot;normal&quot;, fixed.x = FALSE) ## output summary(hornstramodel1Out) Actually, the longitudinal factor model is an ordinary factor model (with mean structure). Differences are present in the \\(\\mathbfΘ\\) matrix, where we have now specified residual factor covariances between the residual factors of the same indicators across time. 26.2 Step 2: A longitudinal model with weak factorial invariance. Script 26.2 shows how to fit the model from Figure 1 to the data of Hornstra et al. with equality constraints on the factor loadings across time, and free to be estimated factor variances at the later time points. Script 26.2 ## STEP 2 ## constrain factor loadings to be equal across occasions hornstramodel2 &lt;- &#39; # COVARIANCES # regression equations selfeff1 =~ L1*t1v1 + L2*t1v2 + L3*t1v3 + L4*t1v4 + L5*t1v5 + L6*t1v6 selfeff2 =~ L1*t2v1 + L2*t2v2 + L3*t2v3 + L4*t2v4 + L5*t2v5 + L6*t2v6 # residual variances t1v1 ~~ t1v1 t1v2 ~~ t1v2 t1v3 ~~ t1v3 t1v4 ~~ t1v4 t1v5 ~~ t1v5 t1v6 ~~ t1v6 t2v1 ~~ t2v1 t2v2 ~~ t2v2 t2v3 ~~ t2v3 t2v4 ~~ t2v4 t2v5 ~~ t2v5 t2v6 ~~ t2v6 # residual covariances t1v1 ~~ t2v1 t1v2 ~~ t2v2 t1v3 ~~ t2v3 t1v4 ~~ t2v4 t1v5 ~~ t2v5 t1v6 ~~ t2v6 # common factor (co)variances selfeff1 ~~ 1*selfeff1 selfeff2 ~~ selfeff2 selfeff1 ~~ selfeff2 # MEANS # intercepts observed indicators t1v1 ~ 1 t1v2 ~ 1 t1v3 ~ 1 t1v4 ~ 1 t1v5 ~ 1 t1v6 ~ 1 t2v1 ~ 1 t2v2 ~ 1 t2v3 ~ 1 t2v4 ~ 1 t2v5 ~ 1 t2v6 ~ 1 # means common factors selfeff1 ~ 0*1 selfeff2 ~ 0*1 &#39; ## run model hornstramodel2Out &lt;- lavaan(hornstramodel2, sample.cov = hornstracov, sample.mean = hornstrameans, sample.nobs = 522, likelihood = &quot;normal&quot;, fixed.x = FALSE) ## output summary(hornstramodel2Out) ## compare fit with configural model anova(hornstramodel1Out,hornstramodel2Out) We constrain the factor loadings of the same indicator to be equal across time points, by using identical labels for the factor loadings. Because with this equality constraint the variance of the common factor of the second measurement is already identified, we can freely estimate this parameter (do not forget to release the constraint!). The fit of this model can be compared to the model fit of the model without any across occasion constraints to test whether the equality constraints on the factor loadings lead to a (significant) deterioration in model fit. When the deterioration in fit is not significant, we may conclude that the assumption of weak factorial invariance holds. 26.3 Step 3: Longitudinal model with strong factorial invariance Script 26.3 shows how to fit the model with additional equality constraints on the intercepts across time, and free to be estimated factor means at later time points. Script 26.3 ## STEP 3 ## Constrain intercepts to be equal across occasions hornstramodel3 &lt;- &#39; # COVARIANCES # regression equations selfeff1 =~ L1*t1v1 + L2*t1v2 + L3*t1v3 + L4*t1v4 + L5*t1v5 + L6*t1v6 selfeff2 =~ L1*t2v1 + L2*t2v2 + L3*t2v3 + L4*t2v4 + L5*t2v5 + L6*t2v6 # residual variances t1v1 ~~ t1v1 t1v2 ~~ t1v2 t1v3 ~~ t1v3 t1v4 ~~ t1v4 t1v5 ~~ t1v5 t1v6 ~~ t1v6 t2v1 ~~ t2v1 t2v2 ~~ t2v2 t2v3 ~~ t2v3 t2v4 ~~ t2v4 t2v5 ~~ t2v5 t2v6 ~~ t2v6 # residual covariances t1v1 ~~ t2v1 t1v2 ~~ t2v2 t1v3 ~~ t2v3 t1v4 ~~ t2v4 t1v5 ~~ t2v5 t1v6 ~~ t2v6 # common factor (co)variances selfeff1 ~~ 1*selfeff1 selfeff2 ~~ selfeff2 selfeff1 ~~ selfeff2 # MEANS # intercepts observed indicators t1v1 ~ T1*1 t1v2 ~ T2*1 t1v3 ~ T3*1 t1v4 ~ T4*1 t1v5 ~ T5*1 t1v6 ~ T6*1 t2v1 ~ T1*1 t2v2 ~ T2*1 t2v3 ~ T3*1 t2v4 ~ T4*1 t2v5 ~ T5*1 t2v6 ~ T6*1 # means common factors selfeff1 ~ 0*1 selfeff2 ~ 1 &#39; ## run model hornstramodel3Out &lt;- lavaan(hornstramodel3, sample.cov = hornstracov, sample.mean = hornstrameans, sample.nobs = 522, likelihood = &quot;normal&quot;, fixed.x = FALSE) ## output summary(hornstramodel3Out) ## compare fit with weak factorial invariance model anova(hornstramodel2Out,hornstramodel3Out) Again, we use labels to constrain the intercepts to be equal across occasions. This allows us to freely estimate the common factor mean of self-efficacy at the second time point. To test whether the assumption of strong factorial invariance holds, we can compare the model fit of this model to the model fit of the model without equality constraints imposed on the intercepts. 26.4 Step 4: A model with strict factorial invariance Sometimes, additional equality constraints are imposed on the residual factor variances across time. This is also referred to as ‘strict factorial invariance’. We can use labels to impose the equality constraints, similar like we did with the intercepts. Script 26.4 shows how to fit this model. Script 26.4 ## STEP 4: Additional constraints on THETA hornstramodel4 &lt;- &#39; # COVARIANCES # regression equations selfeff1 =~ L1*t1v1 + L2*t1v2 + L3*t1v3 + L4*t1v4 + L5*t1v5 + L6*t1v6 selfeff2 =~ L1*t2v1 + L2*t2v2 + L3*t2v3 + L4*t2v4 + L5*t2v5 + L6*t2v6 # residual variances t1v1 ~~ TH1*t1v1 t1v2 ~~ TH2*t1v2 t1v3 ~~ TH3*t1v3 t1v4 ~~ TH4*t1v4 t1v5 ~~ TH5*t1v5 t1v6 ~~ TH6*t1v6 t2v1 ~~ TH1*t2v1 t2v2 ~~ TH2*t2v2 t2v3 ~~ TH3*t2v3 t2v4 ~~ TH4*t2v4 t2v5 ~~ TH5*t2v5 t2v6 ~~ TH6*t2v6 # residual covariances t1v1 ~~ t2v1 t1v2 ~~ t2v2 t1v3 ~~ t2v3 t1v4 ~~ t2v4 t1v5 ~~ t2v5 t1v6 ~~ t2v6 # common factor (co)variances selfeff1 ~~ 1*selfeff1 selfeff2 ~~ selfeff2 selfeff1 ~~ selfeff2 # MEANS # intercepts observed indicators t1v1 ~ T1*1 t1v2 ~ T2*1 t1v3 ~ T3*1 t1v4 ~ T4*1 t1v5 ~ T5*1 t1v6 ~ T6*1 t2v1 ~ T1*1 t2v2 ~ T2*1 t2v3 ~ T3*1 t2v4 ~ T4*1 t2v5 ~ T5*1 t2v6 ~ T6*1 # means common factors selfeff1 ~ 0*1 selfeff2 ~ 1 &#39; ## run model hornstramodel4Out &lt;- lavaan(hornstramodel4, sample.cov = hornstracov, sample.mean = hornstrameans, sample.nobs = 522, sample.cov.rescale = FALSE, fixed.x = FALSE) ## output summary(hornstramodel4Out) ## compare fit with strong factorial invariance model anova(hornstramodel3Out,hornstramodel4Out) 26.5 Standardized estimates for a (longitudinal) factor model with means Standardizing a longitudinal factor model works the same as standardizing a normal factor model, only now we also have a mean structure which can be standardized. To extract the estimates in matrix form from the lavaan output, including the estimates for the intercepts of the observed indicators and the common factor means, we use the lavInspect() function. Script 26.5 has the code that uses matrix algebra to obtain the standardized parameter estimates. Script 26.5 factornames &lt;- c(&quot;selfeff1&quot;,&quot;selfeff2&quot;) Estimates &lt;- lavInspect(hornstramodel3Out, &quot;est&quot;) LAMBDA &lt;- Estimates$lambda[obsnames, factornames] PHI &lt;- Estimates$psi[factornames, factornames] THETA &lt;- Estimates$theta[obsnames, obsnames] TAU &lt;- Estimates$nu[obsnames,1,drop=FALSE] KAPPA &lt;- Estimates$alpha[factornames,1,drop=FALSE] # Model implied covariance matrix (SIGMA) and mean vector (MU) SIGMA &lt;- LAMBDA %*% PHI %*% t(LAMBDA) + THETA MU &lt;- TAU + LAMBDA %*% KAPPA ## calculate standard deviations sigma and phi SDSIGMA &lt;- sqrt(diag(diag(SIGMA))) SDPHI &lt;- sqrt(diag(diag(PHI))) ## calculate standardized parameters LAMBDAstar &lt;- solve(SDSIGMA) %*% LAMBDA %*% SDPHI PHIstar &lt;- solve(SDPHI) %*% PHI %*% solve(SDPHI) THETAstar &lt;- solve(SDSIGMA) %*% THETA %*% solve(SDSIGMA) STRUC &lt;- LAMBDAstar %*% PHIstar KAPPAstar &lt;- KAPPA * diag(solve(SDPHI)) TAUstar &lt;- TAU * diag(solve(SDSIGMA)) ## provide labels dimnames(LAMBDAstar) &lt;- list(obsnames,factornames) dimnames(PHIstar) &lt;- list(factornames,factornames) dimnames(THETAstar) &lt;- list(obsnames,obsnames) dimnames(STRUC) &lt;- list(obsnames,factornames) dimnames(KAPPAstar) &lt;- list(factornames,&quot;Common factor means&quot;) dimnames(TAUstar) &lt;- list(obsnames,&quot;Intercepts&quot;) The intercepts (TAU) and factor means (KAPPA) are part of respectively the ‘mu’ (\\(\\mathbf\\mu\\)) and ‘alpha’(\\(\\mathbf\\alpha\\)) matrices in lavaan. We extract them by selecting the rows that correspond to the observed variable names for TAU and with the factor names for KAPPA. The ‘1’ specifies that we want to select the first column, and drop = FALSE is needed to ensure that the result is stored in a column vector. TAU &lt;- Estimates$nu[obsnames,1,drop=FALSE] KAPPA &lt;- Estimates$alpha[factornames,1,drop=FALSE] The common factor means are standardized by multiplying the column vector with the factor means with a vector with the inverse of the factor standard deviations. As the standard deviations are on the diagonal of SDPHI, we use the diag() function to extract the diagonal elements. By using simple multiplication * (as opposed to matrix multiplication) the first elements of the two object are multiplied with each other, the second elements with each other, and so on. Intercepts are standardized in the same way as factor means, but with respect to the standard deviations of the observed variables: KAPPAstar &lt;- KAPPA * diag(solve(SDPHI)) TAUstar &lt;- TAU * diag(solve(SDSIGMA)) Alternatively, you can specify “standardized = TRUE” in the summary() function. References Hornstra, L., van der Veen, I., Peetsma T. &amp; Volman M. (2013). Developments in motivation and achievement during primary school: A longitudinal study on group-specific differences. Learning and Individual Differences, 23, 195-204. "],["ch27.html", "27 Latent Growth Curve Models 27.1 Prepare Data and Workspace 27.2 Random Intercept Model 27.3 Linear Growth Model 27.4 Unrestricted Growth Models 27.5 Explaining Growth Factors 27.6 Latent Indicators of Growth Factors 27.7 Multigroup Growth Models References", " 27 Latent Growth Curve Models In structural equation modeling (SEM), multiple indicators of a construct can be modeled using exploratory/confirmatory factor analysis (E/CFA). A latent common factor (or common cause) is posited as being the source of shared variance among the observed indicators, and the measurement models for multiple common factors can be embedded within a larger SEM. This chapter introduces another type of common factor, often called a growth factor. Rather than repeatedly measuring a construct with different indicators of that construct (e.g., “I feel …”: happy, glad, cheerful, joyous), growth factors are measured by the same indicator on multiple occasions. Growth factors are interpreted as patterns of change in the indicators’ expected values, where the type of pattern is defined by the factor loadings. In this chapter we first import and summarize example data, then we use a single-factor model to illustrate differences between growth factors and other common factors (e.g., specification and interpretation). Readers familiar with multilevel modeling (MLM) will benefit from a brief comparison between MLM and SEM for the same data. Next, we 2-factor model for linear growth (again comparing it to a MLM for change) and saturated growth model (comparing it to repeated-measures ANOVA). We conclude by discussing important caveats with some common extensions to the latent growth curve model (LGCM): predictors of growth latent indicators of growth comparing growth across groups 27.1 Prepare Data and Workspace library(lavaan) For illustration, we will use summary statistics reported by Duncan and Duncan (1996, pp. 329–330). alcohol, cigarette, and cannabis use (thc) were each measured annually for 4 years using a 5-point scale: never used previous but not current use current use of \\(&lt; 4\\) times per month) current use of \\(4 - 29\\) times per month current use of \\(\\ge 30\\) times per month We also imported 2 variables measured at the beginning of the study: age (recruited between 11 and 15 years old) peer encouragement, measured by summing 3 items (alc, cig, thc) using a 5-point Likert scale indicating how much their best friend encouraged use of that substance The following summary statistics were observed for the \\(N=321\\) adolescents who provided complete data in all 4 years. ## variable names vn &lt;- c(paste0(&quot;alc&quot;, 1:4), paste0(&quot;cig&quot;, 1:4), paste0(&quot;thc&quot;, 1:4),&quot;age&quot;,&quot;peer&quot;) ## mean vector duncanM &lt;- setNames(c(2.271, 2.560, 2.694, 2.965, 1.847, 2.043, 2.227, 2.510, 1.510, 1.672, 1.828, 1.947, 13.108, 6.193), nm = vn) ## they reported variances (squared SDs) sqSDs &lt;- c(1.004, .922, .832, .846, 1.305, 1.536, 1.645, 1.888, .807, .896, 1.074, 1.125, 2.216, 8.844) ## correlation matrix (lower triangle) tri &lt;- c(1.000, .640, 1.000, .586, .670, 1.000, .454, .566, .621, 1.000, .568, .451, .390, .357, 1.000, .531, .449, .360, .360, .850, 1.000, .494, .449, .380, .425, .783, .815, 1.000, .387, .393, .344, .473, .617, .702, .779, 1.000, .602, .431, .408, .346, .706, .648, .576, .543, 1.000, .522, .460, .394, .403, .644, .689, .687, .535, .759, 1.000, .499, .461, .440, .472, .542, .592, .676, .566, .671, .790, 1.000, .398, .385, .358, .472, .452, .522, .594, .644, .533, .642, .793, 1.000, .497, .370, .429, .326, .418, .409, .337, .205, .456, .413, .345, .248, 1.000, .336, .398, .300, .276, .397, .433, .386, .318, .388, .522, .421, .342, .273, 1) ## scale tri to make covariance matrix duncanCOV &lt;- getCov(x = tri, sds = sqrt(sqSDs), names = vn) ## sample size N &lt;- 321 27.2 Random Intercept Model Let’s focus on a single measure—alcohol use—measured on 4 occasions for each of \\(N=321\\) adolescents. A random-intercept model for Subject \\(i\\)’s alcohol use in Year \\(t\\) is frequently depicted in MLM as: \\[\\begin{align} \\mathrm{y}_{i,t} &amp;= \\beta_{i,0} + \\varepsilon_{i,t} \\tag{27.1} \\\\ &amp;= (\\gamma_{0} + u_i) + \\varepsilon_{i,t} \\tag{27.2} \\end{align}\\] indicating that each Subject \\(i\\) has their own intercept, so the random intercept \\(\\beta_{i,0}\\) is itself a variable. As Eq. (27.2) shows, the average intercept can be depicted as the sum of 2 components: the average intercept (\\(\\gamma_{0}\\)) This is the grand mean because there are no other predictors. individual deviations around \\(\\gamma_{0}\\) (i.e., \\(u_i\\)) This is how much each subject’s mean differs from the grand mean. This can also be interpreted as a Level-2 residual The Level-1 residual (\\(\\varepsilon_{i,t}\\)) is how much each subject’s time-specific alcohol use differs from their average alcohol use. Both residuals have distributional assumptions, often depicted as normally distributed with some variance: \\[ u_i \\sim \\mathcal{N}(0, \\tau_0) \\ \\ \\ , \\ \\ \\ \\varepsilon_{i,t} \\sim \\mathcal{N}(0, \\sigma) \\] This MLM can also be represented as a SEM. In fact, random effects are latent variables (Mehta &amp; Neale, 2005; Skrondal &amp; Rabe-Hesketh, 2004). The SEM representation of Equations (27.1) and (27.2) looks superficially different: there are different symbols, and Subject \\(i\\)’s \\(t=1, \\dots, T\\) measurements are stored in a single vector \\(\\mathbf{y}_i\\): \\[\\begin{align*} \\mathbf{y}_i &amp;= \\Lambda \\mathbf{\\eta}_i + \\varepsilon_i \\\\ \\mathbf{\\eta}_i &amp;= \\alpha + \\zeta_i \\end{align*}\\] Note that many parameters from the full SEM are missing (e.g., indicator intercepts \\(\\tau\\) and latent regressions \\(\\mathbf{B}\\)) because they are merely 0 in this model. But the nonzero components of this SEM can all be mapped onto the MLM above (Bauer, 2003; Curran, 2003; Singer &amp; Willett, 2003, ch. 8): \\[\\mathbf{\\eta}_i=\\beta_{0,i} \\ \\ , \\ \\ \\alpha=\\gamma_0 \\ \\ , \\ \\ \\zeta_i=u_i \\ \\ , \\ \\ \\varepsilon_i=\\varepsilon_i \\ \\ , \\ \\ \\Lambda=\\mathbf{1}\\] Note that the factor-loading matrix is merely a vector of ones, filling the role of the constant in a regression model. That is, a vector of ones is treated as a predictor, and its “slope” is the regression model’s intercept. The role of factor loadings in a LGCM is counter-intuitive because in most SEMs, we think of them as slopes. Instead, the loadings of a growth factor instead map onto observed variables in a multilevel regression, and random coefficients (\\(\\beta_{0,i}\\)) are represented by the latent variables (growth factors: \\(\\mathbf{\\eta}_i\\)). Figure 27.1: Random intercept model for alcohol-use data from Duncan and Duncan (1996). The path diagram above illuminates the differences between a growth factor (here, a random intercept) and a common factor. First, factor loadings in a CFA are freely estimated, and they indicate how strongly an indicator is related to the common factor. In a LGCM, factor loadings are fixed to specify how the growth factor is interpreted. A random intercept’s loadings are all 1 because every occasion’s \\(\\mathrm{y}_i\\) is weighted equally to calculate the Subject \\(i\\)’s overall mean. Second, indicator intercepts in a CFA are freely estimated, and are the indicators’ expected values when the common factor = 0. Because the common-factor mean is typically constrained to zero for identification, indicator intercepts are often simply the indicator means. In a LGCM, indicator intercepts are fixed to zero, but the growth-factor mean is freely estimated. Thus, the only reason that an indicator’s model-implied mean differs from zero is if the latent intercept’s mean differs from zero. This is a primary feature of an LGCM: the mean structure of the indicators is captured entirely by the mean structure of the growth factors. Thus, this random-intercept model reflects the hypothesis that the mean (\\(\\alpha_1\\): here, average alcohol use) is equal across occasions, although the means can still vary across subjects (\\(\\psi_{1,1}\\)). The mean structure of the latent curve model is a special case of the mean structure of a “normal” factor model, where the mean structure is given by: \\(\\mu=\\tau+\\mathbf{\\Lambda}\\kappa\\), where \\(\\mathbf\\mu\\) (“mu”) is a column vector of model-implied means of the observed variables, \\(\\mathbf\\tau\\) (“tau”) is a column vector of indicator intercepts, \\(\\mathbf{\\Lambda}\\) (“lambda”) is a matrix of factor loadings, and \\(\\kappa\\) (“kappa”) is a column vector of latent growth-factor means. Because all growth indicators have intercepts fixed to 0, the equation for the mean structure simplifies to \\(\\mu=\\mathbf{\\Lambda}\\kappa\\). And because this chapter includes examples for growth factors being predicted by other variables (a “full SEM”), we will refer to both means and intercepts of growth factors as \\(\\mathbf\\alpha\\) (the path-model notation). 27.2.1 Specification and Estimation The following lavaan model syntax specifies the model from Figure 27.1. mod.ri &lt;- &#39; ## loadings for random intercept INTERCEPT =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 ## residual variances alc1 ~~ alc1 alc2 ~~ alc2 alc3 ~~ alc3 alc4 ~~ alc4 ## latent mean and variance INTERCEPT ~ 1 INTERCEPT ~~ INTERCEPT &#39; fit.ri &lt;- lavaan(mod.ri, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N) The lavaan package has a dedicated growth() package, with default lavOptions() that make sense for a LGCM: int.ov.free = FALSE leaves indicator intercepts fixed to zero int.lv.free = TRUE freely estimates latent intercepts/means auto.var = TRUE freely estimates all variances auto.cov.lv.x = TRUE freely estimates covariances among exogenous latent variables So a shorter syntax could simply specify the factor loadings for the growth factor(s): mod.ri &lt;- &#39; INTERCEPT =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 &#39; fit.ri &lt;- growth(mod.ri, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N) However, as LGCMs become more complex (e.g., latent indicators of growth), this set of lavOptions() becomes problematic. Thus, we advise and demonstrate using the basic lavaan() function, either with fully specified model syntax or by explicitly setting lavOptions() that make sense. For example: mod.ri &lt;- &#39; INTERCEPT =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 &#39; fit.ri &lt;- lavaan(mod.ri, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE) 27.2.2 Interpret Results The results in the summary() output indicate that the grand mean alcohol use in this sample is 2.638, which is between “previous but not current use” and “&lt; 4 times per month” on the 1–5 scale. parameterEstimates(fit.ri, output = &quot;pretty&quot;) ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## INTERCEPT =~ ## alc1 1.000 1.000 1.000 ## alc2 1.000 1.000 1.000 ## alc3 1.000 1.000 1.000 ## alc4 1.000 1.000 1.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## INTERCEPT 2.638 0.045 59.223 0.000 2.551 2.725 ## .alc1 0.000 0.000 0.000 ## .alc2 0.000 0.000 0.000 ## .alc3 0.000 0.000 0.000 ## .alc4 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## .alc1 0.646 0.059 11.026 0.000 0.531 0.761 ## .alc2 0.321 0.035 9.293 0.000 0.253 0.389 ## .alc3 0.257 0.030 8.467 0.000 0.198 0.317 ## .alc4 0.549 0.051 10.729 0.000 0.449 0.650 ## INTERCEPT 0.541 0.051 10.697 0.000 0.442 0.640 The INTERCEPT variance indicates that individual subjects’ means vary \\(SD = \\sqrt{0.541} = 0.736\\) around the grand mean, frequently referred to as the Level-2 variance in a MLM. Whereas a MLM only estimates a single Level-1 residual variance, the SEM approach is more flexible in allowing Level-1 residuals to be heteroskedastic across time (i.e., the degree to which time-specific observations deviate from subject means). The \\(\\text{H}_0\\) of homoskedasticity could be tested by comparing this fitted model to one in which the residual variances are constrained to equality. 27.3 Linear Growth Model A linear LGCM has two growth factors: a random intercept (the subject’s initial status) a random slope (the subject’s rate of change) In order to prevent confusion of the terms intercept and slope with other model parameters, we will refer to the growth factors as initial status and rate of change (Singer &amp; Willett, 2003). Each growth factor has a mean (the average initial status and rate of change across subjects) and a variance (individual differences in initial status and rate of change). Just as in MLM, the random intercept and random slope can covary. Recall that the factor loadings in a LGCM are specified to according to how the growth factors should be interpreted—specifically, the loadings in \\(\\mathbf{\\Lambda}\\) correspond to the matrix of predictors (\\(\\mathbf{X}\\)) in a regression model. Thus, it is more appropriate to think of \\(\\mathbf{\\Lambda}\\) as observed data and of the growth factors as slopes (which vary across subjects). In addition to a column of ones (to estimate the latent intercept), the matrix of factor loadings for linear growth includes a column of values indicating how time should be coded. Figure 2 depicts a common choice for coding time: the number of years (or other units) elapsed since the beginning of the study. \\[\\mathbf{X}_i \\Longleftrightarrow \\mathbf{\\Lambda} = \\begin{bmatrix} 1 &amp; 0 \\\\ 1 &amp; 1 \\\\ 1 &amp; 2 \\\\ 1 &amp; 3\\end{bmatrix}\\] The first row of loadings implies that the expected value of the first indicator is only a function of the first growth factor’s mean, because the second column contains a zero. For each subsequent row, that indicator’s expected value is a sum of the mean initial-status plus increasing amounts of the mean rate of change. Specifically, the mean rate of change is multiplied by the second column’s loading, similar to a regular regression, in which the slope (rate of change: \\(\\beta_1\\)) is multiplied by the value of time. Note that these specified loadings are arbitrary. We could code time using a different occasion as the reference, such as the last occasion: \\[\\mathbf{X}_i \\Longleftrightarrow \\mathbf{\\Lambda} = \\begin{bmatrix} 1 &amp; -3 \\\\ 1 &amp; -2 \\\\ 1 &amp; -1 \\\\ 1 &amp; 0\\end{bmatrix}\\] Using this alternative coding scheme, the mean rate-of-change would remain the same, but the mean of the latent intercept would instead be interpreted as the average status at the end of the study (final status, rather than initial status). However, we will proceed by coding 0 for the first occasion so that the latent intercept represents initial status. Figure 27.2: Linear growth model for alcohol-use data from Duncan and Duncan (1996). mod.lin &lt;- &#39; ## loadings Init.Status =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 Rate.Change =~ 1*alc2 + 2*alc3 + 3*alc4 ## factor covariance Init.Status ~~ Rate.Change &#39; fit.lin &lt;- lavaan(mod.lin, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE) summary(fit.lin, std = TRUE) ## lavaan 0.6-19 ended normally after 27 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 321 ## ## Model Test User Model: ## ## Test statistic 8.174 ## Degrees of freedom 5 ## P-value (Chi-square) 0.147 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status =~ ## alc1 1.000 0.836 0.820 ## alc2 1.000 0.836 0.889 ## alc3 1.000 0.836 0.931 ## alc4 1.000 0.836 0.895 ## Rate.Change =~ ## alc2 1.000 0.195 0.208 ## alc3 2.000 0.391 0.435 ## alc4 3.000 0.586 0.628 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status ~~ ## Rate.Change -0.080 0.023 -3.504 0.000 -0.489 -0.489 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status 2.291 0.054 42.558 0.000 2.739 2.739 ## Rate.Change 0.220 0.018 12.342 0.000 1.128 1.128 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .alc1 0.341 0.051 6.660 0.000 0.341 0.328 ## .alc2 0.306 0.033 9.337 0.000 0.306 0.346 ## .alc3 0.274 0.030 9.224 0.000 0.274 0.339 ## .alc4 0.309 0.046 6.726 0.000 0.309 0.354 ## Init.Status 0.700 0.077 9.064 0.000 1.000 1.000 ## Rate.Change 0.038 0.010 3.665 0.000 1.000 1.000 The initial-status mean indicates average alcohol use began as 2.291, and the rate-of-change mean indicates average alcohol use increased by 0.220 per year. The standardized solution is not particularly meaningful for some LGCM parameters (e.g., loadings, latent means), but it is helpful for interpreting the size of the (significant) covariance between initial status and rate of change. The substantial factor correlation (\\(-0.489\\)) indicates that adolescents who drank less at the beginning of the study tended to increase the drinking at a higher annual rate. 27.3.1 Model Fit and Comparison The model-fit test statistic in the summary() output does not provide any evidence against the \\(\\text{H}_0\\) that linear change is sufficiently complex to describe the data, \\(\\chi^2(5)=8.174, p=.147\\). Linear change is the simplest functional form of change, and significant latent mean, \\(z=12.342, p&lt;.001\\), indicates that the model cannot be made simpler by omitting linear change. We can verify this by testing whether the random-intercept model statistically differs from the linear growth model in which it is nested. Because the linear-growth loadings are all fixed values, the random-intercept model can be seen as a linear-growth model in which the latent rate of change has a mean and variance of zero (in which case it cannot covary with another factor). lavTestLRT(fit.ri, fit.lin) # or anova(fit.ri, fit.lin) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit.lin 5 2963.8 2997.7 8.174 ## fit.ri 8 3128.8 3151.4 179.175 171 0.41768 3 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The linear growth model captures the observed data patterns significantly better than the random-intercept model, \\(\\chi^2(3)=171.001, p&lt;.001\\). The standard baseline model for calculating incremental-fit indices (e.g., CFI, TLI) is merely the statistical-independence model: all covariances fixed to zero means and variances are freely estimated But this model is not nested within all competing LGCMs Even the linear-growth model places more constraints on the mean structure than the standard independence model, and it also constrains the model-implied variances. Thus, Widamin and Thompson (2003) recommended a more constrained null/baseline model in which all means (and all variances) of repeatedly measured variables are constrained to equality (representing no change in those values). mod.null &lt;- c(paste(paste0(&quot;alc&quot;, 1:4, collapse = &quot; + &quot;), &quot;~ m*1&quot;), paste0(&quot;alc&quot;, 1:4, &quot; ~~ v*alc&quot;, 1:4)) cat(mod.null, sep = &quot;\\n&quot;) # print model syntax to see what the code above does ## alc1 + alc2 + alc3 + alc4 ~ m*1 ## alc1 ~~ v*alc1 ## alc2 ~~ v*alc2 ## alc3 ~~ v*alc3 ## alc4 ~~ v*alc4 fit.null &lt;- lavaan(mod.null, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N) This model is nested within the LGCMs. semTools::net(fit.null, fit.ri, fit.lin) ## ## If cell [R, C] is TRUE, the model in row R is nested within column C. ## ## If the models also have the same degrees of freedom, they are equivalent. ## ## NA indicates the model in column C did not converge when fit to the ## implied means and covariance matrix from the model in row R. ## ## The hidden diagonal is TRUE because any model is equivalent to itself. ## The upper triangle is hidden because for models with the same degrees ## of freedom, cell [C, R] == cell [R, C]. For all models with different ## degrees of freedom, the upper diagonal is all FALSE because models with ## fewer degrees of freedom (i.e., more parameters) cannot be nested ## within models with more degrees of freedom (i.e., fewer parameters). ## ## fit.lin fit.ri fit.null ## fit.lin (df = 5) ## fit.ri (df = 8) TRUE ## fit.null (df = 12) TRUE TRUE Thus, it can be used to calculate incremental fit indices, which requires using the fitMeasures() function rather than merely summary(..., fit = TRUE). fitMeasures(fit.lin, c(&quot;cfi&quot;,&quot;tli&quot;), baseline.model = fit.null) ## cfi tli ## 0.995 0.988 27.4 Unrestricted Growth Models Although linear growth appears sufficient to explain these data, this will not always be the case. When a linear-growth model does not fit well, standardized residuals from lavResiduals() can reveal which summary statistics the model fails to reproduce closely. Large residuals for indicator means imply the mean structure is too restrictive, in which case an exploratory growth model can help to reveal how much more complex the latent trajectory is. Note that this would be a switch from confirmatory to exploratory methods, so you would no longer be testing or (dis)confirming a hypothesis; instead, you would be generating a hypothesis or revising your theory. Transparency is vitally important to the scientific process, so clearly communicate in your report when you are conducting confirmatory vs. exploratory research, preferably in separate sections. That is, first test your theory using a priori hypotheses; if your data disconfirm your expectations, then begin looking for evidence in the data of how your theory should be revised. Note also that specific hypotheses of nonlinear growth might be expected based on a study design. For example, trajectories might be expected to differ before and after a particular occasion (a change-point, e.g., an intervention or an important life event). In such cases, a piecewise-growth model can be specified, in which there is are separate latent rate-of-change factors whose loadings are specified to capture changes in means among indicators before and after the change-point. There are a couple of options for exploratory LGCMs, described below. 27.4.1 Latent Basis Curve The most popular is the latent basis curve, which resembles the linear model but only fixes 2 loadings for the rate-of-change factor, freeing the others to capture non-specific change patterns. For example, fixing the first 2 loadings to 0 and 1, respectively, sets the (average) amount of change between the first 2 occasions as a baseline. This is depicted in the path diagram below (left panel). Figure 27.3: Latent basis models for alcohol-use data from Duncan and Duncan (1996). The script below specifies the model depicted in the left panel of Figure 27.3. mod.basis12 &lt;- &#39; ## loadings Init.Status =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 Rate.Change =~ 1*alc2 + NA*alc3 + NA*alc4 ## factor covariance Init.Status ~~ Rate.Change &#39; fit.basis12 &lt;- lavaan(mod.basis12, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE) coef(fit.basis12)[paste0(&quot;Rate.Change=~alc&quot;, 3:4)] ## Rate.Change=~alc3 Rate.Change=~alc4 ## 1.502240 2.466024 The two fixed loadings determine the interpretation of the latent mean \\(\\alpha_2\\), which is no longer a constant rate of change but rather the amount of change that occurred between the reference occasions. Each estimated loading tells us how much (average) change occurred at that occasion since the first (or whichever occasion’s loading is fixed to 0), relative to the amount of change between the first 2 occasions. That is, there is a 1-unit increase in time, represented between the loadings of alc1 and alc2. If change were perfectly linear, we would expect the estimated loadings to continue increasing by 1 unit at a time (assuming the occasions are evenly spread out, as they are in these annual measurements). However, we observe something different: There is only a 0.5-unit increase in the loadings from alc2 to alc3, indicating that only half as much (average) change occurred between those 2 occasions than between the first 2 occasions. There is a (nearly) 1-unit increase in the loadings from alc3 to alc4, indicating that about as much change occurred between those occasions as between the first 2 occasions. This model estimates the average rate of change to be (\\(0.281\\)), the unrestricted change pattern during this 4-year span appears to be an increase of \\(0.281\\) units, then \\(0.1405\\) units, then \\(0.281\\) units again. To test whether this deviation from linearity can be accounted for by mere sampling error, we can conduct a nested model comparison: lavTestLRT(fit.lin, fit.basis12) # or anova(fit.lin, fit.basis12) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit.basis12 3 2962.7 3004.2 3.114 ## fit.lin 5 2963.8 2997.7 8.174 5.0601 0.06904 2 0.07966 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We cannot reject the null hypothesis that linearity is sufficiently complex. Another example of a latent basis curve fixes the first and last loadings to 0 and 1, respectively, with similar implications for interpretation. The script below specifies the model depicted in the right panel of Figure 27.3. mod.basis14 &lt;- &#39; ## loadings Init.Status =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 Rate.Change =~ NA*alc2 + NA*alc3 + 1*alc4 ## factor covariance Init.Status ~~ Rate.Change &#39; fit.basis14 &lt;- lavaan(mod.basis14, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE) coef(fit.basis14)[paste0(&quot;Rate.Change=~alc&quot;, 2:3)] ## Rate.Change=~alc2 Rate.Change=~alc3 ## 0.4055110 0.6091749 Here, the baseline amount of change is set by comparing the first and last occasions. Again, if change were perfectly linear, we would expect the estimated loadings to increase by a constant amount, but we see a similar pattern as the first basis model above. There is a 0.4-unit increase in the loadings from alc1 to alc2 The increase in loadings from alc2 to alc3 is about half that (0.2 units) Then the loadings increase from alc3 to alc4 by about as much as the increase between the first 2 occasions This basis model is statistically equivalent to the first basis model, so they yield identical model fit with proportionally equivalent estimated loadings. Likewise, the estimated latent mean is proportionally higher because it reflects the average amount of change between Years 1 and 4. A latent basis model is flexible in terms of the factor loadings, which are somewhat easy to interpret. However, there is a “hidden” proportionality assumption represented by estimating only a single latent variance for rate of change (\\(\\psi_{2,2}\\); Wu &amp; Lang, 2016). Although some software (e.g., Mplus and OpenMx) can be tricked into relaxing this assumption (McNeish, 2020), an alternative model (described next) can be even more useful for exploratory purposes. 27.4.2 Saturated Growth Model A saturated model fits perfectly by definition, although the perfect fit is arbitrary because all information from summary statistics was used to estimate parameters to reproduce those summary statistics (i.e., \\(df=0\\)). However, because we are in hypothesis-generating exploratory mode, testing a hypothesis of fit is not necessarily a priority. In this section, we show how to fit a saturated LGCM by using polynomial contrast codes to specify the loadings (Voelkle &amp; McKnight, 2012). This can be advantageous in situations where the standard coding of time leads to converges problems (read about a real-world problem here). In the GLM or MLM, polynomial contrast codes can be used to represent a predictor that is an ordinal grouping variable, which is often a continuous variable that is merely measured in discrete units. In our example, time is measured only in whole years, discounting differences in days or months. Note: In fact, a limitation of wide-format approaches for longitudinal data (LGCM and repeated-measures ANOVA) is that time must be treated discretely. In long-format approaches (e.g., MLM), predictors like time can be represented continuously, capturing more detail about individual differences in measurement schedules, thus providing more information about true developmental trajectories. A polynomial is the power to which a variable is raised. For example, a linear effect is merely the first power (\\(x^1=x\\)), but a quadratic effect is the second power (\\(x^2\\)) and a cubic effect is the third power (\\(x^3\\)), etc. Any number raised to the zero power is 1 (\\(x^0=1\\)), which is the constant used to estimate the intercept. Thus, even linear models are a polynomial model, but only up to the first power. When we measure a variable on \\(t=1, \\dots, T\\) occasions, we can estimate up to the \\(T-1\\) power, for the same reason that differences between \\(g=1, \\dots, G\\) groups can be represented by \\(G-1\\) dummy codes. Our example has \\(T=4\\) occasions, so we can estimate up to power 3; another way to think of it is that we do estimate \\(T=4\\) polynomial effects, but we begin with a power of 0 (\\(\\text{Time}^0\\), so multiply the latent intercept by \\(\\text{Time}^0 = 1\\)) followed by a power of 1 (i.e., multiply the linear slope by \\(\\text{Time}^1 = \\text{Time}\\)), then power of 2, and so on. Note that a saturated LGCM could simply use the same loadings for the latent intercept and linear slope, then a quadratic (and cubic) factor can have loadings that are the squared (and cubed) values of the linear-slope’s loadings; however, we can avoid possible (multi)collinearity of growth factors by specifying orthogonal contrast codes instead (Voelkle &amp; McKnight, 2012). Polynomial contrast codes can be obtained in R using the contr.poly() function, whose first argument is the number of occasions (\\(T=4\\)): contr.poly(4) # .L = linear, .Q = quadratic, .C = cubic ## .L .Q .C ## [1,] -0.6708204 0.5 -0.2236068 ## [2,] -0.2236068 -0.5 0.6708204 ## [3,] 0.2236068 -0.5 -0.6708204 ## [4,] 0.6708204 0.5 0.2236068 If we have unequally spaced measurements (e.g., measured at ages 7, 9, 12, and 13), we can indicate this using the scores= argument: contr.poly(4, scores = c(7, 9, 12, 13)). Rather than fixing loadings of the latent intercept to 1, we can specify a “centercept” (Wainer, 2000) as \\(\\frac{1}{\\sqrt{T}}\\) (\\(\\frac{1}{2}\\)). The advantage of specifying the latent “level” (rather than initial status) in this way is that its variance (\\(\\psi_{1,1}\\)) captures individual differences in grand means, not merely individual differences at a particular occasion or in the middle of all occasions (Voelkle &amp; McKnight, 2012, p. 26). Finally, because there are as many growth factors as occasions, the entire covariance structure can be reproduced in the latent space (factor (co)variances). Thus, we must fix indicators’ residual variances to zero, as depicted in Figure 27.4. Figure 27.4: Saturated growth model for alcohol-use data from Duncan and Duncan (1996). The script below specifies the model in Figure 27.4, fits the model, and prints the estimated latent means for interpretation. mod.sat &lt;- &#39; ## loadings Level =~ .5*alc1 + .5*alc2 + .5*alc3 + .5*alc4 Linear =~ -.671*alc1 + -.224*alc2 + .224*alc3 + .671*alc4 Quad =~ .5*alc1 + -.5*alc2 + -.5*alc3 + .5*alc4 Cubic =~ -.224*alc1 + .671*alc2 + -.671*alc3 + .224*alc4 ## residual variances alc1 ~~ 0*alc1 alc2 ~~ 0*alc2 alc3 ~~ 0*alc3 alc4 ~~ 0*alc4 &#39; fit.sat &lt;- lavaan(mod.sat, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE, auto.cov.lv.x = TRUE) PE.sat &lt;- parameterEstimates(fit.sat, output = &quot;pretty&quot;) PE.sat[PE.sat$op == &quot;~1&quot;, ] ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## alc1 0.000 0.000 0.000 ## alc2 0.000 0.000 0.000 ## alc3 0.000 0.000 0.000 ## alc4 0.000 0.000 0.000 ## Level 5.245 0.088 59.649 0.000 5.073 5.417 ## Linear 0.495 0.040 12.386 0.000 0.417 0.574 ## Quad -0.009 0.031 -0.287 0.774 -0.071 0.053 ## Cubic 0.065 0.030 2.216 0.027 0.008 0.123 The latent quadratic trend is not significant, but the cubic one is. A quadratic curve (i.e., a parabola) can only change directions once (i.e., from increasing to decreasing, or from decreasing to increasing). A cubic curve can change directions twice (and a 4th-order curve can change direction 3 times, etc.). This result is consistent with what we observed with the latent basis model, when the increase was steeper, then less steep, then steeper again. Unfortunately, we have no way to test whether this developmental trajectory truly follows a cubic (3rd-order) trend using only \\(3+1=4\\) occasions—recall that \\(df=0\\). If we were to generate a hypothesis about nonlinear change, it would need to be confirmed with new data gather from a design with more measurement occasions. But in this case, also recall that we could not reject the \\(H_0\\) of linear change because the linear model does not fit significantly worse than a saturated model (such as the one above). fitMeasures(fit.lin, c(&quot;chisq&quot;,&quot;df&quot;,&quot;pvalue&quot;), output = &quot;pretty&quot;) ## ## Model Test User Model: ## ## Test statistic 8.174 ## Degrees of freedom 5 ## P-value 0.147 Fixing both the quadratic and cubic factor means to zero would not lead to rejecting the \\(\\text{H}_0\\) (\\(p=.08\\)), so this is a lesson in guarding against using multiple tests to conduct exploratory analyses. If you employ a saturated or latent-basis model, bear in mind that they are exploratory, and it is safer to interpret the informative parameters descriptively in order to generate (not test) new hypotheses derived from the data. Alternative Contrast Codes When estimating growth factors from intervention studies, linear growth might not be reasonable because we hypothesize means will change immediately after the intervention but not after. For example, in a pretest, posttest, follow-up design, our hypotheses might be: \\(\\text{H}_1\\): Parenting intervention will reduce parent–child conflicts \\(\\text{H}_2\\): The effect will be stable after intervention The piecewise growth model we mentioned at the beginning of Section 4 would be appropriate in principle, but it would not be practical because there are only 3 occasions with a changepoint between the first 2 occasions (pretest and posttest). Instead, we can simply apply a different set of contrast codes than the polynomials discussed above. Helmert contrast codes would be appropriate to test whether pretest scores differ from both posttest and follow-up scores (\\(\\text{H}_1\\)) and whether follow-up scores differ from initial posttest scores (\\(\\text{H}_2\\)). The factor loadings below would allow these hypotheses to be tested: Intercept Pre.v.After Post.v.Follow Pretest \\(\\frac{1}{\\sqrt{3}}\\) -2 0 Posttest \\(\\frac{1}{\\sqrt{3}}\\) 1 -1 Follow-up \\(\\frac{1}{\\sqrt{3}}\\) 1 1 This “growth” trajectory would be saturated, but 3 occasions already does not allow for sufficient df to test strong hypotheses about fit (e.g., a quadratic factor would already make it saturated). But relevant and sensible hypotheses that follow from such a 3-occasion intervention study can be answered using these contrast codes. 27.5 Explaining Growth Factors Growth-factor variances represent individual differences in developmental trajectories. The literature often distinguishes two related concepts: Individual differences occur between subjects Individual change occurs within a subject Thus, growth-curve models (in MLM or SEM) simultaneously model inter-individual differences in intra-individual change. It is possible to estimate latent trajectories while statistically controlling for Level-1 covariates that only vary within subjects. These are often called time-varying predictors. It is also possible to explain inter-individual differences in latent trajectories, using Level-2 predictors that only vary between subjects. These are often called time-invariate predictors. Either type of predictor introduces moderation of (or by) time, which is not as familiar as moderation represented by interactions in regression models. Here, too, a comparison with MLM will facilitate interpretation of moderated effects in LGCMs using SEM. The fundamental principle to bear in mind is the basic meaning of moderation: the relationship between two variables is a function of a third variable. To this end, we briefly review statistical interaction in a regression model, wherein moderation is represented by a product between predictors. \\[\\begin{align} Y_i &amp;= \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\beta_3 X_{i1} X_{i2} + \\varepsilon_i \\\\ &amp;= (\\beta_0 + \\beta_1 X_{i1}) + (\\beta_2 + \\beta_3 X_{i1}) \\times X_{i2} + \\varepsilon_i \\\\ &amp;= \\vartheta_0 + \\vartheta_1 X_{i2} + \\varepsilon_i \\tag{27.3} \\end{align}\\] By grouping the terms in the second row of Eq. (27.3), we can reinterpret it as a simple regression of \\(Y\\) on \\(X_2\\) (the third row of Eq. (27.3)). But the intercept and slope are themselves variables because they depend on (are functions of) \\(X_1\\). Simple intercepts: \\(\\vartheta_0 = \\beta_0 + \\beta_1 X_{i1}\\) Simple slopes: \\(\\vartheta_1 = \\beta_2 + \\beta_3 X_{i1}\\) Recall the moderation is symmetric, so the terms in Eq. (27.3) could also be grouped such that the effect of \\(X_1\\) depends on \\(X_2\\). Moderation can also be interpreted in both directions in a LGCM, but it is not as obvious how because time is not an explicit variable in the model, as other predictors are. Before proceeding, consider that growth factors are variables in a SEM. They can therefore be predictors as well as outcomes, even in the same model. Growth factors have already been treated as predictors of occasion-specific indicators in the sections above, but they could also predict subject-level outcome variables (e.g., to investigate whether the rate of increased alcohol consumption predictors a student’s academic performance). The following sections only elaborate on predictors of growth factors and correlations among latent trajectories, but bear in mind that more complex models are possible. 27.5.1 Time-Invariant (Level-2) Predictors Level-2 predictors vary between subjects, so they can explain between-subject differences in trajectories, which are represented by growth factors. Although Duncan and Duncan (1996) had several such covariates, our example data include the following two subject-level predictors: age at the beginning of the study and peer encouragement to consume illicit substances. Consider the MLM for growth, which extends Eq. (27.1) by adding time as a predictor. Below, we intersperse some equivalent SEM symbols as reminders of how the MLM and SEM frameworks map onto each other (Bauer, 2003; Curran, 2003; Singer &amp; Willett, 2003, ch. 8). \\[\\begin{align} \\text{Level 1: } y_{i,t} &amp;= \\beta_{i,0} + \\beta_{i,1} \\text{Time}_{i,t} + \\varepsilon_{i,t} = \\color{blue}{\\Lambda \\mathbf{\\eta}_i + \\varepsilon_i} \\tag{27.4} \\\\ \\text{Level 2: } \\beta_{i,0} &amp;= \\color{blue}{(\\eta_0=)} \\gamma_{0,0} + \\gamma_{0,1} \\text{Age}_i + \\gamma_{0,2} \\text{Peer-Influence}_i + u_{0,i} \\tag{27.5} \\\\ \\beta_{i,1} &amp;= \\color{blue}{(\\eta_1=)} \\gamma_{1,0} + \\gamma_{1,1} \\text{Age}_i + \\gamma_{1,2} \\text{Peer-Influence}_i + u_{1,i} \\tag{27.6} \\\\ \\text{Combined: } y_{i,t} &amp;= \\gamma_{0,0} + \\gamma_{0,1} \\text{Age}_i + \\gamma_{0,2} \\text{Peer-Influence}_i + \\gamma_{1,0} \\text{Time}_{i,t} \\tag{27.7} \\\\ &amp;+ \\gamma_{1,1} (\\text{Age}_i \\times \\text{Time}_{i,t}) + \\gamma_{1,2} (\\text{Peer-Influence}_i \\times \\text{Time}_{i,t}) \\tag{27.8} \\\\ &amp;+ u_{0,i} + u_{1,i} \\text{Time}_{i,t} + \\varepsilon_{i,t} \\ \\ \\color{gray}{\\text{(joint residual)}} \\tag{27.9} \\end{align}\\] The path diagram below depicts age and peer influence as observed variables that predict growth factors, conforming to how ?lavaan::model.syntax works. In the background, lavaan internally represents observed predictors as single-indicator factors. Thus, age and peer influence are assigned \\(\\eta_3\\) and \\(\\eta_4\\), respectively, in the path diagram below. Figure 27.5: Linear growth model for alcohol-use data from Duncan and Duncan (1996) with subject-level predictors of growth factors. The LGCM script below specifies a measurement model for the growth factors (Eq. (27.4)) and a structural model that includes both predictors of initial status (Eq. (27.5)) and rate of change (Eq. (27.6)). We will consider the combined model in Eqs. (27.7)–(27.9) further when we interpret the structural model. mod.pred2 &lt;- &#39; ##### MEASUREMENT MODEL Init.Status =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 Rate.Change =~ 1*alc2 + 2*alc3 + 3*alc4 ##### STRUCTURAL MODEL ## Level-2 predictors of growth trajectories Init.Status + Rate.Change ~ age + peer ## factor (residual) covariance Init.Status ~~ Rate.Change &#39; fit.pred2 &lt;- lavaan(mod.pred2, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE) summary(fit.pred2, std = TRUE, rsq = TRUE) ## lavaan 0.6-19 ended normally after 43 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Number of observations 321 ## ## Model Test User Model: ## ## Test statistic 23.607 ## Degrees of freedom 9 ## P-value (Chi-square) 0.005 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status =~ ## alc1 1.000 0.841 0.832 ## alc2 1.000 0.841 0.887 ## alc3 1.000 0.841 0.936 ## alc4 1.000 0.841 0.902 ## Rate.Change =~ ## alc2 1.000 0.203 0.214 ## alc3 2.000 0.406 0.452 ## alc4 3.000 0.609 0.653 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status ~ ## age 0.269 0.031 8.579 0.000 0.320 0.476 ## peer 0.086 0.016 5.455 0.000 0.102 0.303 ## Rate.Change ~ ## age -0.033 0.012 -2.700 0.007 -0.163 -0.243 ## peer -0.008 0.006 -1.227 0.220 -0.037 -0.110 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Init.Status ~~ ## .Rate.Change -0.054 0.020 -2.741 0.006 -0.424 -0.424 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .Init.Status -1.774 0.399 -4.447 0.000 -2.108 -2.108 ## .Rate.Change 0.703 0.156 4.505 0.000 3.462 3.462 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .alc1 0.315 0.047 6.645 0.000 0.315 0.308 ## .alc2 0.320 0.033 9.834 0.000 0.320 0.356 ## .alc3 0.275 0.029 9.373 0.000 0.275 0.341 ## .alc4 0.301 0.045 6.634 0.000 0.301 0.346 ## .Init.Status 0.427 0.056 7.587 0.000 0.603 0.603 ## .Rate.Change 0.038 0.010 3.740 0.000 0.914 0.914 ## ## R-Square: ## Estimate ## alc1 0.692 ## alc2 0.644 ## alc3 0.659 ## alc4 0.654 ## Init.Status 0.397 ## Rate.Change 0.086 Although we can reject the omnibus \\(\\text{H}_0\\) of perfect data–model correspondence, \\(\\chi^2(9)=23.607, p=.005\\), inspection of standardized residuals (lavResiduals(fit.pred2) output not shown) suggests the misfit is merely the accumulation of several minor discrepancies between observed and expected summary statistics. So we will proceed to interpret the model parameters. Note: If one were interested in interpreting an incremental fit index (e.g., CFI) for this model, the custom null model in Section 3.1 must be appended by including the Level-2 predictors, whose means and variances are also estimated. But because they are exogenous covariates, the null model should also estimate the age~~peer covariance. The estimated intercept for the initial-status factor is \\(\\alpha_0=-1.774\\), which is the expected alcohol use when all predictors (age, peer, and Time) are 0. In this case, it is an extrapolation beyond the data because no subjects began the study at birth, and peer-influence was measured on a 1–5 scale. Simple Effects There are 3 predictors with simple effects in Eq. (27.7): age, peer, and Time. But their effects are not represented in the same way in a LGCM. First, we focus on the effects of time-invariant predictors. Both effects of Level-2 predictors on initial status were significant (\\(p&lt;.001, R^2=39.7\\%\\)), indicating that when the study began, adolescents who were older and whose best friends more strongly encouraged illicit-substance use exhibited more frequent alcohol consumption. Standardized slopes indicator both effects were medium, but unstandardized slopes are interpretable in the given units. Specifically, each year older increases their expected initial alcohol consumption by \\(\\gamma_{0,1}=0.269\\) units, for a given level of peer influence. And at a given age, one (Likert-scale) unit higher peer influence increases their expected initial alcohol consumption by \\(\\gamma_{0,2}=0.086\\) units. The simple effects of age and peer are conditional on Time = 0 (the beginning of the study), but we might be interested in probing their effects at other occasions. To obtain simple effects of time-invariant predictors conditional on other occasions, simply change the reference occasion in \\(\\mathbf{\\Lambda}\\) and fit the (statistically equivalent) model. For example, we could set the rate-of-change factor loadings to \\(\\lambda_{2,.}=-1, 0, 1, 2\\), which would make the latent intercept interpreted as the level at the second occasion. Thus, the simple effects of age and peer would be conditional on Time = 1 year after the study began. The simple effect of Time, on the other hand, is not an explicit regression slope in a LGCM. Instead, it is a latent variable: the rate-of-change factor. The simple effect of Time, therefore, is the estimated intercept (\\(\\alpha_1=0.703\\)) of the rate-of-change factor (i.e., the average rate of change, conditional on age = 0 and peer = 0). As with the estimated initial-status intercept, this is an extrapolation beyond the data. If one were interested in interpreting simple slopes of Time for particular (observed) values of age and peer, one could center age and peer at those values and fit the statistically equivalent model. Moderation Effects The interactions in Eq. (27.8) are represented by the predictors’ effects on the rate-of-change factor, which explained \\(R^2=8.6\\%\\) of between-subjects variance in growth trajectories. That is, the effect of Time depends on both age and peer. The form of the model facilitates describing the nature of this interaction when Time is the focal predictor. At a given level of peer influence, one year older decreases the effect of Time on alcohol consumption by \\(\\gamma_{1,1}=-0.033\\) units/year. The effect of peer influence (given age) was not significant, implying no evidence moderation of Time’s effect by peer influence. We did not estimate an age \\(\\times\\) peer interaction, so the LGCM also did not estimate a 3-way interaction. This is not possible in our example because doing so would require raw data to calculate the product term and include it as an additional predictor of growth factors. The 3-way interaction would be represented by the age \\(\\times\\) peer product term’s effect on the rate-of-change factor, while the product’s (simple) 2-way interaction would be represented by its effect on the initial-status factor. 27.5.2 Time-Varying (Level-1) Predictors Level-1 predictors vary within subjects, as does Time. Thus, we can estimate the effect of Time while statistically controlling for time-varying predictors. Our example data includes annual cigarette use, which would be included in the Level-1 component of a MLM for growth. \\[\\begin{equation} \\text{AlcUse}_{i,t} = \\beta_{i,0} + \\beta_{i,1} \\text{Time}_{i,t} + \\beta_2 \\text{CigUse}_{i,t} + \\beta_3 (\\text{Time}_{i,t} \\times \\text{CigUse}_{i,t}) + \\varepsilon_{i,t} \\tag{27.10} \\end{equation}\\] Notice that Eq. (27.10) only includes a fixed (not random) effect of cigarette use. The possibility of including a random effect for both Time and cigarette use is one of the ways in which MLM is more flexible than SEM. Notice also that Eq. (27.10) includes a Time \\(\\times\\) cigarette-use interaction effect (\\(\\beta_3\\)). This is how moderation is represented in a regression model, but moderation of Time by a Level-1 variable in LGCM is quite different, involving more than one parameter. The path diagram below depicts both alcohol and cigarette use as observed variables, with the latter predicting the former. However, lavaan’s internal LISREL representation does not have a parameter matrix for regressions among observed variables (Mplus does, and the RAM representation used by the OpenMx package only has a single matrix with all slopes among observed and latent variables). So internally, lavaan “promotes” alcohol and cigarette use variables to latent variables corresponding to their single indicators. However, to keep the path diagram readable, this is overlooked and the slopes are labeled simply as \\(\\beta\\)s. Figure 27.6: Linear growth model for alcohol-use data from Duncan and Duncan (1996), controlling for cigarette-use data. The LGCM script below specifies a measurement model for the growth factors, but also regresses each indicator on the level-1 covariate at the same occasion. The latter parameters are labeled so that we can apply equality constraints= in the lavaan() call, to exclude moderation between Time and cigarette use. mod.pred1 &lt;- &#39; ## loadings Init.Status =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 Rate.Change =~ 1*alc2 + 2*alc3 + 3*alc4 ## factor covariance Init.Status ~~ Rate.Change ## Level-1 covariates alc1 ~ b1*cig1 alc2 ~ b2*cig2 alc3 ~ b3*cig3 alc4 ~ b4*cig4 &#39; fit.pred1 &lt;- lavaan(mod.pred1, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE, ## constrain cigarette-use&#39;s effect to equality over time constraints = c(&quot;b1 == b2&quot;, &quot;b1 == b3&quot;, &quot;b1 == b4&quot;)) summary(fit.pred1, std = TRUE) ## lavaan 0.6-19 ended normally after 28 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## Number of equality constraints 3 ## ## Number of observations 321 ## ## Model Test User Model: ## ## Test statistic 86.677 ## Degrees of freedom 20 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status =~ ## alc1 1.000 0.679 0.725 ## alc2 1.000 0.679 0.753 ## alc3 1.000 0.679 0.764 ## alc4 1.000 0.679 0.752 ## Rate.Change =~ ## alc2 1.000 0.185 0.205 ## alc3 2.000 0.370 0.416 ## alc4 3.000 0.555 0.615 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## alc1 ~ ## cig1 (b1) 0.260 0.023 11.490 0.000 0.260 0.316 ## alc2 ~ ## cig2 (b2) 0.260 0.023 11.490 0.000 0.260 0.356 ## alc3 ~ ## cig3 (b3) 0.260 0.023 11.490 0.000 0.260 0.374 ## alc4 ~ ## cig4 (b4) 0.260 0.023 11.490 0.000 0.260 0.394 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status ~~ ## Rate.Change -0.058 0.020 -2.927 0.003 -0.460 -0.460 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status 1.814 0.062 29.228 0.000 2.671 2.671 ## Rate.Change 0.165 0.018 9.286 0.000 0.893 0.893 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .alc1 0.328 0.049 6.687 0.000 0.328 0.374 ## .alc2 0.330 0.034 9.789 0.000 0.330 0.406 ## .alc3 0.312 0.032 9.800 0.000 0.312 0.396 ## .alc4 0.266 0.044 6.107 0.000 0.266 0.326 ## Init.Status 0.462 0.059 7.769 0.000 1.000 1.000 ## Rate.Change 0.034 0.010 3.462 0.001 1.000 1.000 ## ## Constraints: ## |Slack| ## b1 - (b2) 0.000 ## b1 - (b3) 0.000 ## b1 - (b4) 0.000 We reject the \\(H_0\\) of perfect model fit, \\(\\chi^2(20)=86.677, p&lt;.001\\), and there are many large standardized residuals (lavResiduals(fit.pred1) output not shown). This is not surprising given how constrained this model is. Cigarette-use is not only constrained to have a constant effect across time, but the effects only occur within an occasion. There are many theoretically motivated reasons to improve the model—for example, one might expect that smoking leads to later alcohol consumption. We could add lagged effects (e.g., alc2 ~ cig1) to improve model fit, which combines features of cross-lagged panel models and LGCMs. In fact, there have also been attempts to merge autoregressive and latent-growth models (e.g., the autoregressive latent-trajectory (ALT) model; Bollen &amp; Curran, 2004). We will not explore these complexities here, but we will briefly discuss the importance of the equality-constrained slopes on the interpretation of Time’s average effect (i.e., the rate-of-change mean). The script below releases the constraints, which significantly improves model fit. fit.tc &lt;- lavaan(mod.pred1, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE) lavTestLRT(fit.pred1, fit.tc) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit.tc 17 2844.7 2893.7 67.036 ## fit.pred1 20 2858.3 2896.1 86.677 19.64 0.13145 3 0.0002015 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The effect of cigarette use now decreases as time goes on, and the decrease is not linear as it is in Eq. (27.10) because the LGCM can add 3 parameters to account for moderation more flexibly than only \\(\\beta_3\\). Because the effect of cigarette use now depends on Time, the estimated rate-of-change mean is only a simple slope for Time conditional on \\(\\text{CigUse} = 0\\) (again, an extrapolation beyond the bounds of this 1–5 scale). Probing the effect of time at different levels of cigarette use is simple enough: simply center the moderator (all 4 cig variables) at the same theoretically interesting value (e.g., 1, 3, and 5), which changes the interpretation of each \\(\\text{AlcUse}\\) intercept to the expected value at that level of \\(\\text{CigUse}\\). ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## alc1 ~ ## cig1 (b1) 0.364 0.035 10.281 0.000 0.364 0.434 ## alc2 ~ ## cig2 (b2) 0.308 0.027 11.415 0.000 0.308 0.415 ## alc3 ~ ## cig3 (b3) 0.221 0.025 8.738 0.000 0.221 0.326 ## alc4 ~ ## cig4 (b4) 0.213 0.028 7.687 0.000 0.213 0.327 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status 1.626 0.078 20.852 0.000 2.500 2.500 ## Rate.Change 0.276 0.034 8.171 0.000 1.573 1.573 How does one recenter variables without raw data? Well, the first step of calculating a (co)variance is to subtract the mean, so the covariance matrix does not change. And we know exactly how recentering the variables would affect the mean vector: simply subtract the same value from each mean that would have been subtracted from the variable itself. For example, let’s probe the simple effect of Time when \\(\\text{CigUse}\\) is in the middle of the scale (3). duncM3 &lt;- duncanM # copy, then center cig1-cig4 duncM3[paste0(&quot;cig&quot;, 1:4)] &lt;- duncM3[paste0(&quot;cig&quot;, 1:4)] - 3 fit.tc3 &lt;- update(fit.tc, sample.mean = duncM3) # refit model with centered means ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## alc1 ~ ## cig1 (b1) 0.382 0.035 10.911 0.000 0.382 0.453 ## alc2 ~ ## cig2 (b2) 0.266 0.030 8.766 0.000 0.266 0.367 ## alc3 ~ ## cig3 (b3) 0.220 0.029 7.660 0.000 0.220 0.324 ## alc4 ~ ## cig4 (b4) 0.242 0.030 8.133 0.000 0.242 0.368 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Status 2.693 0.058 46.438 0.000 4.096 4.096 ## Rate.Change 0.118 0.021 5.551 0.000 0.650 0.650 Note that this model is not statistically equivalent to the model fitted to uncentered data. The rate-of-change factor loadings constrain the trajectory to be linear, and fit.tc imposes that linearity constraint on different intercepts than fit.tc3 does. The average rate of change when \\(\\text{CigUse} = 3\\) is \\(\\alpha_1=0.118\\). 27.5.3 Parallel Growth Curves In LGCM, time-varying covariates must be measured in parallel with the outcome itself (i.e., at all the same occasions). An alternative to controlling for them is to simultaneously model their own developmental trajectory. In such models, we can explore how the development of different variables relate to each other. The script below specifies linear growth factors for both alcohol and cigarette use. mod.par &lt;- &#39; ## loadings for alcohol use Init.Alc =~ 1*alc1 + 1*alc2 + 1*alc3 + 1*alc4 Lin.Alc =~ 1*alc2 + 2*alc3 + 3*alc4 ## loadings for cigarette use Init.Cig =~ 1*cig1 + 1*cig2 + 1*cig3 + 1*cig4 Lin.Cig =~ 1*cig2 + 2*cig3 + 3*cig4 &#39; fit.par &lt;- lavaan(mod.par, sample.cov = duncanCOV, sample.mean = duncanM, sample.nobs = N, int.lv.free = TRUE, auto.var = TRUE, auto.cov.lv.x = TRUE) ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Alc ~~ ## Lin.Alc -0.095 0.023 -4.191 0.000 -0.511 -0.511 ## Init.Cig 0.627 0.071 8.850 0.000 0.662 0.662 ## Lin.Cig -0.026 0.019 -1.375 0.169 -0.106 -0.106 ## Lin.Alc ~~ ## Init.Cig -0.096 0.021 -4.508 0.000 -0.394 -0.394 ## Lin.Cig 0.029 0.006 4.477 0.000 0.463 0.463 ## Init.Cig ~~ ## Lin.Cig -0.068 0.026 -2.584 0.010 -0.213 -0.213 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Init.Alc 2.288 0.054 42.560 0.000 2.690 2.690 ## Lin.Alc 0.223 0.018 12.419 0.000 1.021 1.021 ## Init.Cig 1.842 0.064 28.773 0.000 1.651 1.651 ## Lin.Cig 0.210 0.019 10.793 0.000 0.733 0.733 Results indicate increases in average use of both substances during adolescence (i.e., both linear-growth factors have positive intercepts/means). Both latent intercepts (Int.Alc and Int.Cig) are negatively correlated with both latent slopes (Lin.Alc and Lin.Cig), indicating that those who used either illicit substance at the beginning of the study tended to increase the use of either substance at a higher rate (although initial alcohol consumption was not significantly correlated with change in cigarette use). Latent intercepts were positively correlated (Int.Alc~~Int.Cig), indicating that adolescents who used one substance more frequently at the beginning of the study tended to use the other more frequently as well. Latent slopes were also positively correlated (Lin.Alc~~Lin.Cig), indicating that adolescents who increasingly used one substance tended to increasingly use the other. 27.6 Latent Indicators of Growth Factors All the examples so far have used observed indicators of growth factors. When we want to estimate an LGCM for a latent variable, additional identification constraints are required, depending on the type of latent variable. Recall that latent variables have no intrinsic location (mean) or scale (variance) because they have not been directly measured. We give them arbitrary locations/scales simply to identify the model. Growth-factor means are identified because we fix all the indicator intercepts to zero; thus, indicator means are reproduced as functions of growth-factor means. Growth-factor variances are identified because we fix all the factor loadings; thus, (co)variances among indicators are reproduced as functions of growth-factor (co)variances and loadings. We will discuss 2 commonly used types of latent growth indicator: a common factor (itself measured with multiple indicators) and a latent response variable (LRV) underlying a discrete (binary, ordinal) observation. 27.6.1 Common Factors Recall that a common factor can be identified by making it \\(z\\) scores—that is, we fix its \\(\\alpha_i=0\\) and \\(\\psi_{i,i}=1\\). Other identification methods place constraints on measurement parameters (loadings and intercepts), but we will ignore those methods because they hide the identification issues that we discuss below. After discussing LGCM with common-factor indicators (where LGCM is the structural model imposed on a CFA), we also briefly discuss another type of model in which the nested components are switched (a CFA to capture common varience in several parallel growth models). Curve of Factors At first glance, common factors may seem like poor indicators of growth because all the means are fixed to zero; thus, the identification method makes it appear that no change can occur. However, recall that when a common factor is measured repeatedly with the same indicators, we can use a longitudinal CFA to evaluate equivalence/invariance of the measurement parameters across time. If scalar invariance constraints (equal loadings and intercepts) can be validly applied to at least a subset of repeatedly measured indicators, then the identification constraints (\\(\\alpha_i=0\\), \\(\\psi_{i,i}=1\\)) would only be required on the first occasion. On subsequent occasions, latent means (and variances) would be estimable. Thus, growth factors could be specified to reproduce the mean (and covariance) structure among the common factors. However, because the common-factor mean remains fixed to zero at the first occasion, it follows that the Initial-Status growth factor must have a mean of zero. In a LGCM, all growth-factor indicators have their intercepts fixed to zero, but with common-factor indicators, the first indicator’s latent intercept is already fixed to zero for identification, so there is no exchange of df to estimate the latent mean of Initial Status. Therefore, in a LGCM with common-factor indicators, the mean of Initial Status must be fixed to zero for identification. The path diagram in Figure 27.7 illustrates a “curve of factors” model, in which growth factors explain growth among repeated measures of a common factor “substance use”. This common factor represents adolescents’ propensity for engaging in risk substance-use behaviors, indicated by their use of alcohol, cigarettes, and cannabis (thc). The left panel of Figure 7 illustrates only one occasion’s measurement model, with longitudinal scalar-invariance constraints in place (i.e., the same \\(\\lambda\\)s and \\(\\nu\\)s are constant across occasions). The left panel also shows that each common-factor intercept is fixed to \\(\\alpha=0\\) because those means are structured by the (higher-order) LGCM. The gray arrow directed from the left to right panels indicates that this measurement model applies to each latent indicator of growth. The right panel depicts the (higher-order) LGCM itself. Because only one measurement model for substance use is depicted, Figure 7 is missing the residual covariances that should be estimated for each substance-use indicator across time (i.e., alc1’s residuals are correlated with alc2’s, alc3’s, and alc4’s residuals; same for cigarettes and cannabis). In practice, measurement invariance should be tested first, as shown in Chapter 26. Although some authors have advocated testing longitudinal invariance with the LGCM in place (), we recommend using a CFA to test invariance because it places no restrictions on the latent mean or covariance structures. Any misfit due to invalid structural constraints (e.g., linear growth when true growth is nonlinear) would inflate Type I error rates for tests of invariance. Note also that if one identifies common factors by fixing a reference (or average) indicator’s loading to 1 and intercept to 0, common-factor means and variances would be freely estimated even without invariance constraints in place. However, the LGCM would not truly model change in a common factor, but rather change in the reference indicator. Measurement invariance is a prerequisite to drawing valid inferences about structural differences/changes in a construct. Figure 27.7: Curve-of-factors model for substance-use data from Duncan and Duncan (1996). The script below specifies the curve-of-factors model depicted in Figure 27.7. mod.cof &lt;- &#39; ##### MEASUREMENT MODEL (3 indicators) ## equal loadings across 4 occasions SubUse1 =~ L1*alc1 + L2*cig1 + L3*thc1 SubUse2 =~ L1*alc2 + L2*cig2 + L3*thc2 SubUse3 =~ L1*alc3 + L2*cig3 + L3*thc3 SubUse4 =~ L1*alc4 + L2*cig4 + L3*thc4 ## equal intercepts across 4 occasions alc1 + alc2 + alc3 + alc4 ~ nu1*1 cig1 + cig2 + cig3 + cig4 ~ nu2*1 thc1 + thc2 + thc3 + thc4 ~ nu3*1 ## residual (co)variances across 4 occasions alc1 ~~ alc1 + alc2 + alc3 + alc4 alc2 ~~ alc2 + alc3 + alc4 alc3 ~~ alc3 + alc4 alc4 ~~ alc4 cig1 ~~ cig1 + cig2 + cig3 + cig4 cig2 ~~ cig2 + cig3 + cig4 cig3 ~~ cig3 + cig4 cig4 ~~ cig4 thc1 ~~ thc1 + thc2 + thc3 + thc4 thc2 ~~ thc2 + thc3 + thc4 thc3 ~~ thc3 + thc4 thc4 ~~ thc4 ## STRUCTURAL MODEL (higher-order LGCM) ## loadings for growth factors Init.Status =~ 1*SubUse1 + 1*SubUse2 + 1*SubUse3 + 1*SubUse4 Rate.Change =~ 1*SubUse2 + 2*SubUse3 + 3*SubUse4 ## growth-factor means and (co)variances Init.Status ~ 0*1 # fixed to 0 for identification Rate.Change ~ 1 ## growth-factor means and (co)variances Init.Status ~~ Init.Status + Rate.Change Rate.Change ~~ Rate.Change ## residual variances of growth indicators SubUse1 ~~ psi1*SubUse1 SubUse2 ~~ NA*SubUse2 SubUse3 ~~ NA*SubUse3 SubUse4 ~~ NA*SubUse4 &#39; fit.cof &lt;- lavaan(mod.cof, sample.cov = duncanCOV, sample.mean = duncanM, ## identify the model by constraining the first loading sample.nobs = N, constraints = &quot;L1 == 1&quot;) ## Alternatively, use effects-coding: constraints = &quot;L1 == 3 - L2 - L3&quot; ## or fix first factor&#39;s variance using: std.lv = TRUE or constraints = &quot;psi1 == 1&quot; We do not present output because the conclusions are quite similar to the linear model for alcohol consumption in Section 3. The added benefit of this model is that we can see cigarette and cannabis use are stronger indicators (std. factor loadings approximately 0.8) of propensity for substance use than alcohol consumption (std. loadings 0.6–0.7). The benefit of modeling change in an error-free construct is only as valid as the CFA itself. The disadvantage of latent indicators is that each method of identification in the script above provides a different (arbitrary) scale on which to interpret the average rate of change. The standardized solution provides a scale-free estimate, but the units of \\(SD\\) with which to interpret it are between-subject differences in rates of change, which is not necessarily a meaningful quantity to judge the size of the average rate of change. Factor of Curves Although (individual differences in) growth trajectories might differ across substances, an individual’s trajectories might be correlated (e.g., an adolescent whose alcohol-consumption trajectory is higher than average might also increase their cigarette and cannabis use more than average). One might posit a common factor that explains why each substance’s initial statuses are correlated, and another common factor explaining when each substance’s rates of change are correlated. Duncan and Duncan (1996, pp. 335–338) discussing fitting a factor-of-curves model to their substance-use data, which involves several parameter constraints that are less than intuitive and open to criticism. The factor-of-curves model is rarely used in practice, and its plausibility is often tenuous, with limited benefits over interpreting the higher-order growth factors in a curve-of-factors model. Thus, we do not discuss or demonstrate the factor-of-curves model here. 27.6.2 Discrete Indicators Latent growth can be modeled for LRVs underlying discrete data, which means that the interpretations of growth factors will apply to the LRV locations and scales. As with common factors, the locations and scales are arbitrary, so regarding interpretation of the size of rate-of-change (for example), LGCMs for discrete data share the same drawbacks as curve-of-factors models. However, hypotheses about the functional form of growth (if any) can still be tested using latent indicators. Binary Indicators As discussed in Chapter 12, binary outcomes have a single threshold (\\(\\tau\\)) to discretize a continuous/normal LRV (\\(\\mathrm{y}^*\\)) into 2 categories: \\[\\mathrm{y} = \\textbf{I}(\\mathrm{y}^* &gt; \\tau),\\] where the indicator function \\(\\textbf{I}()\\) assigns 1 when its argument is TRUE and 0 when it is FALSE. The default behavior in lavaan is to identify the model by fixing each LRV’s intercept and variance to 0 and 1, respectively, enabling all thresholds to be estimated. However, it is statistically equivalent to fix a binary item’s threshold to zero and estimate its intercept. In fact, they will have the same absolute value but opposite sign. Because indicator means are fixed to zero anyway (so they can be reproduced by growth factors via factor loadings), one could hypothetically fix thresholds for binary indicators to zero in lavaan syntax in order to fit a a LGCM to it (Newsom, 2015, p. 185). For example, if we had raw example data whose substance-use indicators were binary, we could update any of the scripts above by adding something like this to the model syntax: &#39; alc1 + alc2 + alc3 + alc4 | 0*t1&#39; However, there is no way to link the LRV scales across time because there is only one threshold, whose \\(df\\) is “traded” for the intercept (all of which are in turn traded for growth-factor means). Recall also from Chapter 12 that there are 2 common methods of identifying the LRV scale: parameterization = \"delta\" (default) fixes the marginal/total variance of an LRV to 1 parameterization = \"theta\" fixes an LRV’s residual variance to 1 Either parameterization implies equality of variance across occasions, neither of which is likely to hold in practice. So even if the mean LRV remains the same over time, a change in variance will make it appear as though the mean does change because its distance from zero in units of \\(SD\\) changes. Thus, any true change in the mean is confounded with changes in variance, making it highly problematic to fit a LGCM to binary growth indicators. Ordinal Indicators With more than 2 categories, we can trade 2 df (e.g., by fixing the first threshold to 0 and second threshold to 1) to estimate both the LRV intercept and variance. Recall from Chapter 12 that any ordinal variable with categories \\(c=0, \\ldots, C\\) can be interpreted as a crude discretization of an underlying LRV, whose \\(C\\) thresholds divide the latent distribution into \\(C+1\\) categories. \\[\\mathrm{y}=c \\ \\ \\ \\text{ if } \\ \\ \\ \\tau_c &lt; \\mathrm{y}^* \\le \\tau_{c+1}\\] Because the normal distribution is unbounded, the first category “starts” at \\(\\tau_0 = -\\infty\\), and the last category “ends” at \\(\\tau_{C+1} = +\\infty\\). With only 3 categories, there is only enough information to trade the \\(C=2\\) thresholds for the LRV intercept and variance, which is sufficient to link the response scales across occasions. So we can still only assume (not test) the assumption that thresholds do not change over time, but threshold invariance can be tested when items have \\(\\ge3\\) thresholds (Mehta et al., 2004). In our example data, substance use was measured with 5 categories, so each indicator would have \\(C=4\\) thresholds, enabling us to test the assumption of threshold invariance (if we had access to the raw data). Chapter 29 will discuss threshold invariance in greater detail in the context of CFA with categorical indicators, but here it is sufficient to say that we can constrain thresholds across occasions in LGCM model syntax by using the same labels (below, a, b, c, and d) for equality-constrained parameters. &#39; alc1 | a*t1 + b*t2 + c*t3 + d*t4 alc2 | a*t1 + b*t2 + c*t3 + d*t4 alc3 | a*t1 + b*t2 + c*t3 + d*t4 alc4 | a*t1 + b*t2 + c*t3 + d*t4 &#39; Intercepts remain constrained to zero (the default setting) so that the LRV means can be modeled by the growth-factor means and loadings. However, we must free the variances in the model syntax as well. Similar to invariance with common factors, the first occasion’s variance remains fixed to 1. Using the default parameterization = \"delta\", we must free the marginal variances on subsequent occasions, which is controlled by the “latent scale” parameters, whose operator resembles how we specify a (co)variance that includes an asterisk to indicate it refers to the LRV \\(\\mathrm{y}^*\\). &#39; alc2 ~*~ NA*alc2 alc3 ~*~ NA*alc3 alc4 ~*~ NA*alc4 &#39; Using parameterization = \"theta\", we must instead free the residual variances on subsequent occasions. &#39; alc2 ~~ NA*alc2 alc3 ~~ NA*alc3 alc4 ~~ NA*alc4 &#39; The estimated growth trajectories will still differ across parameterizations because the latent scales will differ. However, the latent scales are now linked across occasions, so changes in the LRV intercepts are no longer confounded with changes in the LRV scale. So the estimated growth trajectories will be proportionally equivalent across parameterizations (i.e., the standardized solutions will be equivalent). 27.7 Multigroup Growth Models Any of the models already discussed can be fitted simultaneously to multiple groups. Differences in parameters across groups represent moderation by the grouping variable. For example, if the latent mean of the Initial-Status factor differs across groups, that is the simple effect of Group at Time 0. Other simple effects of Time can be probed by choosing a different reference occasion, just as discussed with explicit predictors of growth factors in Section 5.1. Likewise, if the latent mean of the Rate-of-Change factor differs across groups, that is the moderation of Time’s effect by Group. And if there is a predictor of growth factors, then the same principles from Section 5.1 can be extended to the grouping variable. Extending the example from Section 5.1, if the effect of Age on Initial Status (i.e., the simple effect of Age) differs across groups, that is an Age \\(\\times\\) Group interaction. And if the effect of Age on Rate of Change (i.e., the Age \\(\\times\\) Time interaction) differs across groups, that is an Age \\(\\times\\) Time \\(\\times\\) Group interaction. When the growth-factor indicators are latent variables (see Section 6), comparisons across groups are only valid in the presence of invariance constraints. For common factors, scalar invariance must therefore be tested across both groups and occasions. For discrete indicators, thresholds must be invariant across both groups and occasions. For both types of latent indicator, identification constraints for the latent scale only need to be set on one Group–Time combination (typically the “first” group on the first occasion), while latent scales in all other groups/occasions can be freely estimated. References Bauer, D. J. (2003). Estimating multilevel linear models as structural equation models. Journal of Educational and Behavioral Statistics, 28(2), 135–167. https://doi.org/10.3102/10769986028002135 Bollen, K. A., &amp; Curran, P. J. (2004). Autoregressive latent trajectory (ALT) models: A synthesis of two traditions. Sociological Methods &amp; Research, 32(3), 336–383. https://doi.org/10.1177/0049124103260222 Curran, P. J. (2003). Have multilevel models been structural equation models all along? Multivariate Behavioral Research, 38(4), 529–569. https://doi.org/10.1207/s15327906mbr3804_5 Duncan, S. C., &amp; Duncan, T. E. (1996). A multivariate latent growth curve analysis of adolescent substance use. Structural Equation Modeling, 3(4), 323–347. https://doi.org/10.1080/10705519609540050 McNeish, D. (2020). Relaxing the proportionality assumption in latent basis models for nonlinear growth. (Structural Equation Modeling, 27)(5), 817–824. https://doi.org/10.1080/10705511.2019.1696201 Mehta, P. D., &amp; Neale, M. C. (2005). People are variables too: Multilevel structural equations modeling. Psychological Methods, 10(3), 259–284. https://doi.org/10.1037/1082-989X.10.3.259 Mehta, P. D., Neale, M. C., &amp; Flay, B. R. (2004). Squeezing interval change from ordinal panel data: Latent growth curves with ordinal outcomes. Psychological Methods, 9(3), 301–333. https://doi.org/10.1037/1082-989X.9.3.301 Newsom, J. T. (2015). Longitudinal structural equation modeling: A comprehensive introduction. Routledge. Singer, J. D., &amp; Willett, J. B. (2003). Applied longitudinal data analysis: Modeling change and event occurrence. Oxford University Press. https://doi.org/10.1093/acprof:oso/9780195152968.001.0001 Skrondal, A., &amp; Rabe-Hesketh, S. (2004). Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models. Chapman and Hall/CRC. https://doi.org/10.1201/9780203489437 Voelkle, M. C., &amp; McKnight, P. E. (2012). One size fits all? A Monte-Carlo simulation on the relationship between repeated measures (M)ANOVA and latent curve modeling. Methodology, 8(1), 23–38. https://doi.org/10.1027/1614-2241/a000044 Wainer, H. (2000). The centercept: An estimable and meaningful regression parameter. Psychological Science, 11(5), 434–436. https://doi.org/10.1111/1467-9280.00284 Widaman, K. F., &amp; Thompson, J. S. (2003). On specifying the null model for incremental fit indices in structural equation modeling. Psychological Methods, 8(1), 16–37. https://doi.org/10.1037/1082-989X.8.1.16 Wu, W., &amp; Lang, K. M. (2016). Proportionality assumption in latent basis curve models: A cautionary note. Structural Equation Modeling, 23(1), 140–154. https://doi.org/10.1080/10705511.2014.938578 "],["ch28.html", "28 Analysis of categorical outcomes 28.1 Factor analysis using categorical indicators References and further reading", " 28 Analysis of categorical outcomes Until now we have focused on the analysis of continuous outcomes (endogenous variables in path models, indicators in factor models), and we have used the maximum likelihood (ML) estimator that assumes that the distribution of the scores on the observed variables are multivariate normal. Various robust estimators can be used when the assumption of multivariate normality cannot be met, which adjust the \\(χ^2\\) test statistic and \\(SE\\)s for nonnormality, but those robust estimators still assume the data are continuous. When we want to analyse categorical data, adjusting for nonnormality is not sufficient because the parameters are not interpretable if the model does not take into account the categorical nature of the observed variables it is trying to explain. The chapters on multiple groups and single-indicator constructs introduced how to incorporate categorical predictors into a SEM. In this chapter we will focus on how we can analyse categorical outcomes. When we have categorical data instead of continuous data, the responses are limited to a small number of values (e.g., 2, 3, or 4 response categories). To be able to analyse these responses, we assume that the categorical responses are representations of a continuous underlying variable, often called a “latent response” variable (distinct from a latent common factor). A latent response is a variable we would like to have measured (e.g., how happy you are) using a more sensitive instrument, but in practice we were only capable of measuring whether someone is in a particular range (e.g., whether they feel happy never, rarely, often, or always). The idea is that people with lower scores on the latent response are likely to indicate lower categories of the observed categorical response, whereas people with higher scores on the latent response are likely to indicate higher categories of the observed categorical response. We can think of each latent response as being a single-indicator construct, where the single indicator is the observed categorical response. Figure 28.1 shows the relation between the underlying continuous variable (\\(\\mathrm{y}^{*}\\)) and the observed categorical response (\\(\\mathrm{y}\\)) for a dichotomous variable. Let’s consider this to be a test question, which is a common situation with binary indicators. In this example, the latent response variable \\(\\mathrm{y}^{*}\\) could be labelled “how well [they] understand this test question” or their “propensity for solving this problem”, and the observed binary response would simply be correct (1) or incorrect (0). Here, the difference between the answer “0” and “1” is determined by the threshold (\\(δ_1\\)), which represents “how well [they] need to understand this test question in order to get it correct”. When an individual’s unobserved \\(\\mathrm{y}^{*}\\) is below the threshold, we assume that the observed categorical response would be “0” (i.e., they do not understand well enough to get the question correct), whereas a latent response above the threshold would result in an observed response of “1” (i.e., they do understand well enough to get the question correct). When we assume this underlying variable follows a standard normal distribution (i.e., with \\(μ = 0\\) and \\(σ = 1\\)), then the position of the threshold is the value of the standard normal distribution (\\(z\\) score) that makes the area under the curve lower than (to the left of) the threshold equal to the proportion of observed responses of ‘0’ (i.e., what percentage got the question incorrect). Figure 28.1: A dichotomous response (\\(y\\)) and associated theshold (\\(δ_1\\)) for an underlying continuous variable \\(y^{*}\\) The information above applies to the situation when we have two response categories (dichotomous/binary data), but can easily be extended to multiple ordered response categories (polytomous/ordinal data). Additional thresholds define the classification of the observed categorical responses, where the number of thresholds (\\(c\\)) is equal the number of categories (\\(C\\)) minus one (\\(c = C − 1\\)). An example of a variable with three response categories is given in Figure 28.2. Figure 28.2: The estimation of thresholds (\\(δ_1\\) and \\(δ_2\\)): Observed categorical responses y are representations of underlying continuous scores \\(y^*\\). There are 20%, 45%, and 35% observed responses in categories 0, 1, and 2 respectively. Cumulatively this is 20%, 65% (20 + 45), and 100% (20 + 45 + 35) of the entire distribution. The first threshold is located where the area under the curve to the left of the threshold is 20% (\\(δ_1 = Z_{20} = −0.842\\)). The second threshold is located where the area under the curve to the left of the threshold is 65% (\\(δ_2 = Z_{65} = 0.385\\)). With multiple ordinal variables, we can estimate the correlations between their associated latent responses (called “polychoric” correlations) by relying on the assumption that the latent response variables are normally distributed. A polychoric correlation approximates what the Pearson correlation would be if the variables had been measured using a continuous scale that represented their true distributional form. In the special case that both observed categorical responses are binary, this estimate is called a “tetrachoric” correlation, but we can use the more general term polychoric correlation matrix to refer to these summary statistics. When we fit a SEM to categorical outcomes, we therefore need to estimate thresholds, followed by the polychoric correlation matrix. Because the latent responses have not been observed, we fix \\(μ = 0\\) and \\(σ = 1\\) for identification, just like we do for latent common factors. Alternative estimators and adjustments to the \\(χ^2\\) test statistic and \\(SE\\)s should be used to arrive at correct parameter estimates and model fit. In the current chapter we will explain how to fit CFA models to categorical outcomes in lavaan using the diagonally weighted least squares (DWLS) estimator of parameters, which does not rely on assuming that data are normally distributed, or even continuous (although they certainly can be). Because the standard \\(χ^2\\) test statistic and \\(SE\\)s have inflated Type I error rates, lavaan also provides a robust \\(χ^2\\) and \\(SE\\)s. Models must be fitted to complete raw data rather than summary statistics. We will give two examples: one for binary item responses and one for three-category ordinal item responses. Because CFA models for categorical indicators are fit to individual items (e.g., test questions) rather than to sums of test/questionnaire items, this is sometimes called “item factor analysis” (IFA). The implied distinction is that CFA models are not appropriate for item-level data, which cannot be normally (or continuously) distributed in practice because they are measured using binary (e.g., yes/no) or ordinal (e.g., Likert-type) scales. Factor models were indeed developed for explaining covariation among separate tests of a common construct (e.g., sum scores on separate tests of mathematical skills) rather than for explaining covariation among individual test/questionnaire items. 28.1 Factor analysis using categorical indicators The Script 28.1 fits the three-factor model of Smits and Vorst’s (1982) School Attitudes Questionnaire (SAQ) to raw observed data from \\(N = 915\\) school pupils, where the responses have been dichotomized to “1” and “2’. See a depiction of the factor model from Chapter 12 in Figure 28.3, which now includes nonlinear effects of latent responses on observed responses. Figure 28.3: Item Factor Analysis (IFA) model of the School Aptitude Questionnaire (SAQ). Script 28.1 ## import raw data library(foreign) # the package foreign contains the read.spss function ## create a data frame that contains the data from the spss file saq2cat saq2cat &lt;- read.spss(&quot;saq2cat.sav&quot;, to.data.frame = TRUE) ## extract the variable names from the columns of the saq2cat object obsnames &lt;- colnames(saq2cat) ## specify the CFA model modSAQ &lt;- &#39;# factor loadings Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill &#39; ## fit model to data out.2cat &lt;- cfa(modSAQ, std.lv = TRUE, data = saq2cat, # raw data file ordered = obsnames, # names of ordinal variables parameterization = &quot;delta&quot;) # default identification ## results with fit measures and standardized solution summary(out.2cat, fit = TRUE, std = TRUE) For the analysis of categorical data it is required that we have the complete raw data file, so that lavaan can calculate the polychoric (here, tetrachoric) correlations. Therefore, we read in the data from an SPSS file “saq2cat.sav” that contains all observed dichotomous responses of all 915 individuals on the SAQ. To do this, we use the read.spss() function that is part of the foreign package. This will result in a data frame saq2cat that has 9 columns (referring to the observed dichotomous variables) and 915 rows (where each row contains the responses of one individual). The names of the variables that are in the SPSS file are used to provide column names for the object saq2cat, and we extract these column names from the saq2cat object to create the obsnames object. library(foreign) # the package foreign contains the read.spss function ## create a data frame that contains the data from the spss file saq2cat saq2cat &lt;- read.spss(&quot;saq2cat.sav&quot;, to.data.frame = TRUE) ## extract the variable names from the columns of the saq2cat object (obsnames &lt;- colnames(saq2cat)) We specify factor loadings for the common factors Motivation, Satisfaction, and Self-Confidence in the lavaan model syntax the same way we did for continuous data. Although the common factors are hypothesized to affect the latent responses \\(\\mathrm{y}^*\\) rather than \\(\\mathrm{y}\\), we do not need to specify the latent responses in the model syntax. Just like for single-indicator constructs, lavaan will automatically define a latent response for each categorical outcome, giving the latent response the same name as its corresponding observed indicator. We fixed latent variances to 1 with the argument std.lv = TRUE, but as with continuous indicators, we could instead identify common factors by constraining loadings. Likewise, we could constrain intercepts/thresholds instead of common-factor means. When we fit the model, we use the data= argument to provide the data frame that contains all the observed responses. We do not have to provide separate information on the number of observations or summary statistics of the indicators. In order for lavaan to know which variables are categorical, provide those variable names using the ordered argument. out.2cat &lt;- cfa(modSAQ, std.lv = TRUE, data = saq2cat, # raw data file ordered = obsnames, # names of ordinal variables parameterization = &quot;delta&quot;) # default identification When lavaan sees that there are ordered outcomes in the model, it will use “DWLS” as the default estimator of model parameters, and it will calculate robust \\(SE\\)s and a mean- and variance-adjusted (scaled and shifted) \\(χ^2\\) test statistic in the “Robust” column of the summary() output below (ignore the “DWLS” column, which is the naïve \\(χ^2\\) test statistic). Number of observations 915 Estimator DWLS Robust Minimum Function Test Statistic 61.330 86.077 Degrees of freedom 24 24 P-value (Chi-square) 0.000 0.000 Scaling correction factor 0.731 Shift parameter 2.151 for simple second-order correction (Mplus variant) Notice that the “robust” CFI, TLI, and RMSEA values are missing because those have not been worked out yet; the ones in the “Robust” column are merely calculated the naïve way, plugging the \\(χ^2\\) test statistics in the “Robust” column into the standard formulas. The summary() output contains the usual sections (e.g., factor loadings under “Latent variables”), as well as estimates of the “Thresholds”. Thresholds: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all learning|t1 -0.796 0.047 -17.076 0.000 -0.796 -0.796 concentratn|t1 -0.119 0.042 -2.874 0.004 -0.119 -0.119 homework|t1 -0.322 0.042 -7.619 0.000 -0.322 -0.322 fun|t1 -1.219 0.055 -22.225 0.000 -1.219 -1.219 acceptance|t1 -0.881 0.048 -18.410 0.000 -0.881 -0.881 teacher|t1 -1.091 0.052 -21.060 0.000 -1.091 -1.091 selfexpr|t1 0.010 0.041 0.231 0.817 0.010 0.010 selfeff|t1 0.018 0.041 0.430 0.668 0.018 0.018 socialskill|t1 -0.551 0.044 -12.579 0.000 -0.551 -0.551 Negative threshold values (e.g., “learning | t1”) indicate that the tipping point of scoring “2” instead of “1” is associated with a score of the underlying continuous variable that is below the mean. In other words, it is relatively easy to score “2” on this indicator. A positive value of the threshold indicates that the tipping point of scoring “2” instead of “1” is associated with a score of the underlying continuous variable that is above the mean. Thus, it is relatively difficult to score “2” compared to “1”. Notice that the standardized solution provides the same values as the unstandardized solution. This is because we used the default method of identifying the latent-response scales (parameterization = \"delta\"), which is to set their means (actually, their intercepts, because they are endogenous) to zero and their total variances to one. This is indicated in the section “Scales y*:”, which contains the SDs of the latent responses. Notice that they are fixed values, not estimated, so they do not have \\(SE\\)s or Wald \\(z\\) tests. Residual variances of latent responses are also not estimated, but are fixed to \\(θ = 1 − λ^2ψ\\), so that the total variance = 1. Recall that we identified the common-factor scale by fixing \\(ψ = 1\\) in this example. Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .learning 0.366 0.366 0.366 .concentration 0.350 0.350 0.350 .homework 0.429 0.429 0.429 .fun 0.300 0.300 0.300 .acceptance 0.773 0.773 0.773 .teacher 0.402 0.402 0.402 .selfexpr 0.245 0.245 0.245 .selfeff 0.386 0.386 0.386 .socialskill 0.607 0.607 0.607 Scales y*: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all learning 1.000 1.000 1.000 concentration 1.000 1.000 1.000 homework 1.000 1.000 1.000 fun 1.000 1.000 1.000 acceptance 1.000 1.000 1.000 teacher 1.000 1.000 1.000 selfexpr 1.000 1.000 1.000 selfeff 1.000 1.000 1.000 socialskill 1.000 1.000 1.000 Thresholds are therefore interpreted as \\(z\\) scores. Likewise, factor loadings are already correlations between the latent common factor and the latent item-response. Because the scaling method is arbitrary, we could have chosen instead to fix the residual variances of the latent responses to be \\(θ = 1\\), so that the total variances would be \\(1 + λ^2ψ\\). This is called the “theta” parameterization, which produces a statistically equivalent model. The theta parameterization becomes useful when testing hypotheses about equivalence of residual variances, such as strict measurement invariance. In single-group single-occasion models, the choice between delta and theta parameterizations is of little consequence. As Script 28.2 shows, the standardized solution is identical to the unstandardized delta solution. Script 28.2 ## fit the same model to data, using theta parameterization out.theta &lt;- cfa(modSAQ, std.lv = TRUE, data = saq2cat, ordered = obsnames, parameterization = &quot;theta&quot;) ## results with standardized solution summary(out.theta, std = TRUE) In this summary() output, the residual variances are now all fixed to 1, and the thresholds are no longer \\(z\\) scores. However, the standardized solution is equivalent to the output above. The \\(χ^2\\) test statistics and fit measures are also unchanged because the delta and theta parameterizations are statistically equivalent (analogous to ULI vs. UVI constraints). Thresholds: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all learning|t1 -1.315 0.121 -10.904 0.000 -1.315 -0.796 concentratn|t1 -0.202 0.072 -2.818 0.005 -0.202 -0.119 homework|t1 -0.491 0.070 -7.024 0.000 -0.491 -0.322 fun|t1 -2.226 0.327 -6.810 0.000 -2.226 -1.219 acceptance|t1 -1.002 0.064 -15.695 0.000 -1.002 -0.881 teacher|t1 -1.720 0.179 -9.613 0.000 -1.720 -1.091 selfexpr|t1 0.019 0.084 0.231 0.817 0.019 0.010 selfeff|t1 0.029 0.067 0.429 0.668 0.029 0.018 socialskill|t1 -0.707 0.062 -11.344 0.000 -0.707 -0.551 Variances: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .learning 1.000 1.000 0.366 .concentration 1.000 1.000 0.350 .homework 1.000 1.000 0.429 .fun 1.000 1.000 0.300 .acceptance 1.000 1.000 0.773 .teacher 1.000 1.000 0.402 .selfexpr 1.000 1.000 0.245 .selfeff 1.000 1.000 0.386 .socialskill 1.000 1.000 0.607 Fixing the latent-response intercepts is also an arbitrary choice. It merely allows us to interpret a threshold between two categories as being a certain distance from the mean, assuming the latent-response mean is zero (controlling for the common factor). But we could just as easily identify the model by fixing the thresholds to zero (an equally arbitrary choice) and estimating the latent-response intercepts. We actually get the same answers but with opposite signs (i.e., \\(τ = −δ\\)), which provides the same interpretation. We still interpret a threshold as being a certain distance from the mean of the latent-response distribution, but now we arbitrarily assume the threshold \\(δ = 0\\) instead of assuming the intercept \\(τ = 0\\). Script 28.3 shows how to specify threshold parameters by using the “|” operator (called a “vertical bar” or “pipe”, found by holding the Shift key and typing the backslash above the Enter/Return key). lavaan always labels thresholds in an orderly fashion, so the first (and only) threshold for a dichotomous response is defined with “| t1”. Script 28.3 ## specify free intercepts and fixed thresholds mod.fixThresh &lt;- &#39;# factor loadings Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill # thresholds for observed variables learning | 0*t1 concentration | 0*t1 homework | 0*t1 fun | 0*t1 acceptance | 0*t1 teacher | 0*t1 selfexpr | 0*t1 selfeff | 0*t1 socialskill | 0*t1 # intercepts of latent item-responses learning ~ NA*1 concentration ~ NA*1 homework ~ NA*1 fun ~ NA*1 acceptance ~ NA*1 teacher ~ NA*1 selfexpr ~ NA*1 selfeff ~ NA*1 socialskill ~ NA*1 &#39; ## fit the model to data, using default delta parameterization out.fixThresh &lt;- cfa(mod.fixThresh, data = saq2cat, std.lv = TRUE, ordered = obsnames) ## results with standardized solution summary(out.fixThresh, std = TRUE) In this summary() output, the thresholds are now all fixed to 0, and estimated intercepts have the same values as the previously estimated thresholds, but with opposite signs. Thus, the threshold for “learning” is still 0.796 below the mean of the latent-response distribution, as indicated by the previous estimate of −0.796 (i.e., 0.796 below the fixed intercept of 0). The \\(SE\\)s are also of identical magnitude, so Wald \\(z\\) tests yield the same conclusions. Intercepts: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all .learning 0.796 0.047 17.076 0.000 0.796 0.796 .concentration 0.119 0.042 2.874 0.004 0.119 0.119 .homework 0.322 0.042 7.619 0.000 0.322 0.322 .fun 1.219 0.055 22.225 0.000 1.219 1.219 .acceptance 0.881 0.048 18.410 0.000 0.881 0.881 .teacher 1.091 0.052 21.060 0.000 1.091 1.091 .selfexpr -0.010 0.041 -0.231 0.817 -0.010 -0.010 .selfeff -0.018 0.041 -0.430 0.668 -0.018 -0.018 .socialskill 0.551 0.044 12.579 0.000 0.551 0.551 Motivation 0.000 0.000 0.000 Satisfaction 0.000 0.000 0.000 SelfConfidence 0.000 0.000 0.000 Thresholds: Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all learning|t1 0.000 0.000 0.000 concentratn|t1 0.000 0.000 0.000 homework|t1 0.000 0.000 0.000 fun|t1 0.000 0.000 0.000 acceptance|t1 0.000 0.000 0.000 teacher|t1 0.000 0.000 0.000 selfexpr|t1 0.000 0.000 0.000 selfeff|t1 0.000 0.000 0.000 socialskill|t1 0.000 0.000 0.000 To access the polychoric correlation matrix to which the model was fit, use the lavInspect() function. These “observed” polychoric correlations and the model-implied polychorics will both be correlation matrices with diagonals of 1. &gt; lavInspect(out.2cat, &quot;sampstat&quot;) # &quot;observed&quot; tetrachoric correlations $cov lernng cncntr homwrk fun accptn teachr slfxpr selfff sclskl learning 1.000 concentration 0.642 1.000 homework 0.628 0.585 1.000 fun 0.581 0.399 0.476 1.000 acceptance 0.184 0.238 0.190 0.396 1.000 teacher 0.465 0.417 0.380 0.668 0.306 1.000 selfexpr 0.335 0.450 0.407 0.241 0.292 0.370 1.000 selfeff 0.311 0.435 0.373 0.076 0.276 0.151 0.651 1.000 socialskill 0.141 0.312 0.218 0.071 0.272 0.171 0.548 0.549 1.000 &gt; lavInspect(out.2cat, &quot;cov.ov&quot;) # model-implied tetrachoric correlations lernng cncntr homwrk fun accptn teachr slfxpr selfff sclskl learning 1.000 concentration 0.642 1.000 homework 0.602 0.609 1.000 fun 0.467 0.472 0.443 1.000 acceptance 0.265 0.269 0.252 0.398 1.000 teacher 0.431 0.437 0.409 0.647 0.368 1.000 selfexpr 0.402 0.406 0.381 0.289 0.165 0.267 1.000 selfeff 0.362 0.367 0.343 0.261 0.148 0.241 0.681 1.000 socialskill 0.290 0.293 0.275 0.209 0.119 0.193 0.544 0.491 1.000 The Script 28.4 fits the same three-factor model of the SAQ, but now to the raw data of categorical responses with three categories (“1”, “2”, and “3”). With three categories, items now have 2 thresholds (“| t1” and “| t2”). Although specifying factor loadings is sufficient when using thecfa() function because all factor (co)variances and residual variances will be estimated by default, we specify labels for the thresholds in order to illustrate how thresholds can be specified in lavaan model syntax. Script 28.4 ## import 3-category data from the SPSS file saq3cat saq3cat &lt;- read.spss(&quot;saq3cat.sav&quot;, to.data.frame = TRUE) obsnames &lt;- colnames(saq3cat) ## specify the model mod.3cat &lt;- &#39;## factor loadings Motivation =~ learning + concentration + homework Satisfaction =~ fun + acceptance + teacher SelfConfidence =~ selfexpr + selfeff + socialskill ## thresholds for observed variables learning | th1.1*t1 + th1.2*t2 concentration | th2.1*t1 + th2.2*t2 homework | th3.1*t1+ th3.2*t2 fun | th4.1*t1 + th4.2*t2 acceptance | th5.1*t1 + th5.2*t2 teacher | th6.1*t1 + th6.2*t2 selfexpr | th7.1*t1 + th7.2*t2 selfeff | th8.1*t1 + th8.2*t2 socialskill | th9.1*t1 + th9.2*t2 &#39; ## fit the model to data out.3cat &lt;- cfa(mod.3cat, data = saq3cat, std.lv = TRUE, ordered = obsnames) ## results summary(out.3cat) The two thresholds for each observed indicator have now been labelled with a suffix (e.g., “th1.1” and “th1.2” for the first and second thresholds of the first item). The output below displays estimated thresholds for the indicators “learning” and “fun”. Thresholds: Estimate Std.Err Z-value P(&gt;|z|) lrnn|1 (t1.1) -1.224 0.055 -22.269 0.000 lrnn|2 (t1.2) 0.169 0.042 4.062 0.000 fun|t1 (t4.1) -1.563 0.066 -23.580 0.000 fun|t2 (t4.2) -0.513 0.044 -11.802 0.000 Interpretation of the thresholds is similar to the situation of dichotomous variables, but now we have information of the threshold for the tipping point of the score “1” to “2”, and of “2” to “3”. So, for the indicator learning it seems that the tipping point of “1” to “2” is associated with a score of the underlying continuous variable below the mean, and that the tipping point of “2” to “3” is associated with a score of the underlying continuous variable above the mean. On the other hand, for the indicator fun both thresholds estimates are negative (and significantly different from zero), which indicates that both tipping points occur for values of the underlying continuous variable that are below the mean. Therefore, it is relatively easy to score high on the indicator fun compared to the indicator learning. References and further reading Kamata, A., &amp; Bauer, D. J. (2008). A note on the relation between factor analytic and item response theory models. Structural Equation Modeling, 15(1), 136–153. doi:10.1080/10705510701758406 Mehta, P. D., Neale, M. C., &amp; Flay, B. R. (2004). Squeezing interval change from ordinal panel data: Latent growth curves with ordinal outcomes. Psychological Methods, 9(3), 301–333. doi:10.1037/1082-989X.9.3.301 Muthén, B., &amp; Asparouhov, T. (2002). Latent variable analysis with categorical outcomes: Multiple-group and growth modeling in Mplus: Mplus Web Note 4. Retrieved from http://www.statmodel.com/download/webnotes/CatMGLong.pdf "],["ch29.html", "29 Fitting CFA models with multilevel data 29.1 Intraclass correlations of observed variables 29.2 Multilevel structure as a nuisance: Correcting for the dependency 29.3 Two-level factor models 29.4 Intraclass correlations of common factors 29.5 Climate and contextual between-level latent variables 29.6 Full SEM with multilevel data References", " 29 Fitting CFA models with multilevel data In this chapter we introduce multilevel (two-level) factor models. These models will be relevant if one has obtained data with a nested structure, such as students nested in school classes, and the theoretical model involves latent variables. In Chapter 13, we introduced path models on observed variables with multilevel data. If constructs are operationalised with multiple indicators, these can be modeled using CFA. In a CFA with multilevel data, there are special considerations relating to measurement invariance and the interpretation of the common factor(s) at the different levels. We will illustrate the analysis of multilevel CFA using 6 indicators of teacher-student conflict. The items inquired after the amount of conflict students experiences with their teacher. An example item is: “I can be very angry at my teacher”. The items were scored on a 5-point Likert scale ranging from ‘definitely does not apply’ to ‘definitely does apply’. These items were answered by 800 students, on 44 independent teachers. So, the same teacher was the referent for about 20 students. For these data, it seems likely that the item responses from students that share a teacher will differ (some students experience more conflict than others with the same teacher), and that the average scores between teachers will vary (some teachers experience (on average) more conflict with their students than others). Just as with multilevel path modeling, the item responses can be decomposed in a within-cluster and between-cluster part. The item scores from subject i in cluster j are decomposed into means (\\(\\mu_j\\)), and individual deviations from the cluster means (\\(\\eta_{ij}\\)): \\[\\begin{align} \\mathrm{y}_{ij} &amp;= \\mu_j + (\\mathrm{y}_{ij} - \\mu_j) \\\\ &amp;= \\mu_j + \\eta_{ij} \\end{align}\\] where \\(\\mu_j\\) and \\(\\eta_{ij}\\) are independent. In the example of teacher-student conflict, a person’s within-component of an item, \\(\\eta_{ij}\\), reflects the person’s score on that conflict item deviates from the average scores of that item across all students who shared the specific teacher (\\(\\mu_j\\)). The \\(\\mu_j\\) component thus reflects how the teacher’s item score (obtained by averaging the item scores of the students) deviates from the overall mean item score. Just as with multilevel path analysis, the overall covariances of \\(y_{ij}\\) (\\(\\Sigma_{total}\\)) can be written as the sum of the covariances of these two components: \\[\\begin{align} \\mathbf\\Sigma_\\text{total} &amp;= \\text{COV}(\\mu_j, \\mu_j) + \\text{COV}(\\eta_{ij}, \\eta_{ij}) \\\\ &amp;= \\mathbf\\Sigma_\\text{between} + \\mathbf\\Sigma_\\text{within} \\\\ &amp;= \\mathbf\\Sigma_\\text{B} + \\mathbf\\Sigma_\\text{W} \\end{align}\\] 29.1 Intraclass correlations of observed variables Intraclass correlations (ICCs) indicate what proportion of a variable’s total variance exists at Level 2. Script 29.1 shows how to obtain the ICCs of the conflict items using lavaan.the file \"conflict.dat\" contains the item scores of the students (multilevel models require the analysis of raw data). Script 29.1 library(lavaan) data &lt;- read.table(&quot;demoData/conflict.dat&quot;) names(data) &lt;- c(&quot;teacher&quot;,paste0(&quot;v&quot;,1:6)) head(data) ## teacher v1 v2 v3 v4 v5 v6 ## 1 41 1 1 1 1 1 1 ## 2 41 1 4 1 1 1 5 ## 3 41 1 1 1 1 1 1 ## 4 41 1 1 1 1 1 4 ## 5 41 1 1 2 1 1 1 ## 6 41 1 1 1 1 1 1 modelsat &lt;- &#39; level: 1 v1 ~~ v2 + v3 + v4 + v5 + v6 v2 ~~ v3 + v4 + v5 + v6 v3 ~~ v4 + v5 + v6 v4 ~~ v5 + v6 v5 ~~ v6 level: 2 v1 ~~ v2 + v3 + v4 + v5 + v6 v2 ~~ v3 + v4 + v5 + v6 v3 ~~ v4 + v5 + v6 v4 ~~ v5 + v6 v5 ~~ v6 v1 ~ 1 v2 ~ 1 v3 ~ 1 v4 ~ 1 v5 ~ 1 v6 ~ 1 &#39; fitsat &lt;- lavaan(modelsat, data = data, cluster = &quot;teacher&quot;, auto.var = TRUE) # extract covariance matrices to calculate ICCs manually Sigma_w &lt;- lavInspect(fitsat, &quot;sampstat&quot;)$within$cov Sigma_b &lt;- lavInspect(fitsat, &quot;sampstat&quot;)$teacher$cov ICC &lt;- diag(Sigma_b/(Sigma_b + Sigma_w)) round(ICC,3) ## v1 v2 v3 v4 v5 v6 ## 0.072 0.072 0.042 0.044 0.046 0.232 # or extract ICCs directly lavInspect(fitsat,&quot;icc&quot;) ## v1 v2 v3 v4 v5 v6 ## 0.072 0.072 0.042 0.044 0.046 0.232 29.2 Multilevel structure as a nuisance: Correcting for the dependency If you add the argument cluster = “clustervariable”, then lavaan will report cluster-robust \\(SE\\)s (Williams, 2000) and a corrected test statistic. This would be an acceptable approach when your hypotheses are only about Level 1 processes, and you just want to correct for the nested data. In this approach, the factor model is effectively fit to \\(\\mathbf\\Sigma_\\text{total}\\). If a research question involves hypotheses at Level 1 and Level 2, or it involves latent variables at Level 2, the one should take the two-level approach. 29.3 Two-level factor models In the within/between formulation (Muthén, 1990, 1994; Schmidt, 1969), one can postulate separate models for \\(\\mathbf\\Sigma_\\text{B}\\) and \\(\\mathbf\\Sigma_\\text{W}\\). Technically, these models can be completely different (one could even fit a path model to one level and a factor model to the other level). However, to obtain an appropriate interpretation of common factors at different levels, one often needs some constraints across levels. In our conflict example, we could name the common factor “teacher-student conflict”. Similar to the decomposition of the observed variables into a within-cluster and a between-cluster component, one could imagine decomposing the (unobserved) common factor scores: \\[\\begin{align} \\xi_{ij} &amp;= \\kappa_j + (\\xi_{ij} - \\kappa_j) \\\\ &amp;= \\kappa_j + \\gamma_{ij} \\end{align}\\] In this decomposition \\(\\kappa_j\\) represents the cluster averages on the common factor, and \\(\\gamma_{ij}\\) represents the individual deviations from the cluster average on the common factor. For such an interpretation, the factor loadings relating the common factor to the indicators should be invariant across levels. If the common factor is the only variable that differs at both levels, there will not be residual factors (and residual variance) at the between level. This kind of model is called the variance components factor model by Rabe, Hesketh &amp; Skrondal (2004). Note that this variance components factor model represents the situation in which all observed differences in the cluster means of the indicators results from cluster mean differences in the common factor. In other words, observed differences between clusters are not the result of differences in measurement parameters (factor loadings, intercepts, or residual variances), which corresponds to the definition of measurement invariance. Indeed, the variance components factor model represents a model with strong factorial invariance (or equivalently, scalar invariance) across clusters. If strong factorial invariance across clusters holds, then the models for \\(\\mathbf\\Sigma_\\text{within}\\) an \\(\\mathbf\\Sigma_\\text{between}\\) are: \\[\\begin{align} \\mathbf\\Sigma_\\text{W} &amp;= \\mathbf\\Lambda \\mathbf\\Phi_\\text{W} \\mathbf\\Lambda^\\intercal + \\mathbf\\Theta_\\text{W} \\\\ \\mathbf\\Sigma_\\text{B} &amp;= \\mathbf\\Lambda \\mathbf\\Phi_\\text{B} \\mathbf\\Lambda^\\intercal \\\\ \\end{align}\\] If indicator intercepts are not equal across clusters, but factor loadings are (so weak factorial invariance/metric invariance holds), then the intercept differences across clusters will will appear as residual variance at the between-level: \\[\\begin{align} \\mathbf\\Sigma_\\text{W} &amp;= \\mathbf\\Lambda \\mathbf\\Phi_\\text{W} \\mathbf\\Lambda^\\intercal + \\mathbf\\Theta_\\text{W} \\\\ \\mathbf\\Sigma_\\text{B} &amp;= \\mathbf\\Lambda \\mathbf\\Phi_\\text{B} \\mathbf\\Lambda^\\intercal + \\mathbf\\Theta_\\text{B}\\\\ \\end{align}\\] In such a case, the common factor at the two levels still represents the within- and between components of the same common factor. If in addition the factor loadings are not equal, so that weak factorial invariance (metric) invariance across clusters does not hold, then this will also lead to increased residual variance at the between level, and in addition the factor loadings may become unequal across levels (Jak, Oort &amp; Dolan, 2013; Muthén &amp; Asparouhov, 2018). If factor loadings are unequal across levels, the interpretation of the common factor at the two levels becomes very complicated, as they do not longer represent the within- and between components of the same latent variable (Mehta &amp; Neale, 2005). Moreover, it would mean that the common factor has a different interpretation in each cluster. The between-level part of the model then reflects a model for cluster differences in different latent variables (Jak &amp; Jorgensen, 2017). Script 29.2 fits the multilevel factor model to the six conflict indicators, in which there is one factor underlying the indicator scores. Below you can find a graphical display of the model. Figure 29.1: A two-level factor model on six conflict items. The factor loadings are constrained to be equal across levels by providing the same labels to the parameters across levels. Because these equality constraints already provide a scale to the between-level common factor, the factor variance at the between level is freely estimated, while the factor variance at the within level is fixed at one (this could also be specified the other way around). In this model the residual variances at the between level are freely estimated. Script 29.2 # Fit two-level factor model with equal factor loadings across levels model1 &lt;- &#39; level: 1 # factor loadings conflict =~ L11*v1 + L21*v2 + L31*v3 + L41*v4 + L51*v5 + L61*v6 # factor variance fixed at 1 conflict ~~ 1*conflict # residual variances v1 ~~ v1 v2 ~~ v2 v3 ~~ v3 v4 ~~ v4 v5 ~~ v5 v6 ~~ v6 level: 2 # factor loadings conflict =~ L11*v1 + L21*v2 + L31*v3 + L41*v4 + L51*v5 + L61*v6 # factor variance free conflict ~~ phi_b*conflict # residual variances v1 ~~ th1*v1 v2 ~~ th2*v2 v3 ~~ th3*v3 v4 ~~ th4*v4 v5 ~~ th5*v5 v6 ~~ th6*v6 # intercepts v1 ~ 1 v2 ~ 1 v3 ~ 1 v4 ~ 1 v5 ~ 1 v6 ~ 1 &#39; fit1 &lt;- lavaan(model1, data = data, cluster = &quot;teacher&quot;) summary(fit1, fit = TRUE) ## lavaan 0.6-19 ended normally after 59 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 31 ## Number of equality constraints 6 ## ## Number of observations 800 ## Number of clusters [teacher] 44 ## ## Model Test User Model: ## ## Test statistic 49.694 ## Degrees of freedom 23 ## P-value (Chi-square) 0.001 ## ## Model Test Baseline Model: ## ## Test statistic 1209.905 ## Degrees of freedom 30 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.977 ## Tucker-Lewis Index (TLI) 0.970 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -5096.885 ## Loglikelihood unrestricted model (H1) -5072.039 ## ## Akaike (AIC) 10243.771 ## Bayesian (BIC) 10360.886 ## Sample-size adjusted Bayesian (SABIC) 10281.497 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.038 ## 90 Percent confidence interval - lower 0.023 ## 90 Percent confidence interval - upper 0.053 ## P-value H_0: RMSEA &lt;= 0.050 0.907 ## P-value H_0: RMSEA &gt;= 0.080 0.000 ## ## Standardized Root Mean Square Residual (corr metric): ## ## SRMR (within covariance matrix) 0.024 ## SRMR (between covariance matrix) 0.188 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## ## Level 1 [within]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## conflict =~ ## v1 (L11) 0.398 0.019 21.149 0.000 ## v2 (L21) 0.402 0.022 18.073 0.000 ## v3 (L31) 0.485 0.027 17.728 0.000 ## v4 (L41) 0.544 0.037 14.739 0.000 ## v5 (L51) 0.458 0.028 16.487 0.000 ## v6 (L61) 0.572 0.033 17.233 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## conflict 1.000 ## .v1 0.148 0.011 14.027 0.000 ## .v2 0.258 0.016 16.467 0.000 ## .v3 0.379 0.023 16.278 0.000 ## .v4 0.731 0.042 17.357 0.000 ## .v5 0.432 0.025 17.027 0.000 ## .v6 0.516 0.032 16.355 0.000 ## ## ## Level 2 [teacher]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## conflict =~ ## v1 (L11) 0.398 0.019 21.149 0.000 ## v2 (L21) 0.402 0.022 18.073 0.000 ## v3 (L31) 0.485 0.027 17.728 0.000 ## v4 (L41) 0.544 0.037 14.739 0.000 ## v5 (L51) 0.458 0.028 16.487 0.000 ## v6 (L61) 0.572 0.033 17.233 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .v1 1.196 0.032 37.273 0.000 ## .v2 1.238 0.033 37.195 0.000 ## .v3 1.418 0.042 34.037 0.000 ## .v4 1.713 0.058 29.645 0.000 ## .v5 1.349 0.040 33.781 0.000 ## .v6 1.605 0.070 22.948 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## conflct (ph_b) 0.152 0.051 2.984 0.003 ## .v1 (th1) 0.002 0.003 0.829 0.407 ## .v2 (th2) -0.001 0.004 -0.250 0.803 ## .v3 (th3) 0.004 0.006 0.654 0.513 ## .v4 (th4) 0.039 0.018 2.205 0.027 ## .v5 (th5) 0.001 0.006 0.108 0.914 ## .v6 (th6) 0.110 0.032 3.460 0.001 The overall fit of this model is acceptable. Next, we evaluate whether the residual variances at the between level can be constrained to zero, which would represent strong factorial invariance across clusters. fixtheta &lt;- &#39;th1 == 0 th2 == 0 th3 == 0 th4 == 0 th5 == 0 th6 == 0&#39; fit2 &lt;- lavaan(c(model1,fixtheta), data = data, cluster = &quot;teacher&quot;) anova(fit1,fit2) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## fit1 23 10244 10361 49.694 ## fit2 29 10316 10405 133.573 83.879 0.12738 6 5.634e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The fit results show that constraining the residual variances to zero leads to significantly worse model fit according to the chi-square difference test. Moreover, the AIC is lower for model 1. Therefore, we would continue with model 1. 29.4 Intraclass correlations of common factors In a model in which factor loadings are equal across levels, one can calculate the intraclass correlation of the common factor(s) (Mehta &amp; Neale, 2005) using: \\[\\begin{align} \\text{ICC} &amp;= \\frac{\\mathbf\\Phi_\\text{B}}{\\mathbf\\Phi_\\text{B} + \\mathbf\\Phi_\\text{W}}\\\\ \\end{align}\\] These ICCs represent the proportion of a common factor’s total variance that exists at Level 2. For the conflict factor, the common factor variance at the within level is fixed at 1 for identification, and the common factor variance at the between level is estimated as 0.152, so the intraclass correlation of the common factor equals 0.152 / ( 0.152 + 1) = 0.132. 29.5 Climate and contextual between-level latent variables Researchers frequently use the responses of individuals in clusters to measure constructs at the cluster level. For example, in educational research, student evaluations may be used to measure the teaching quality of instructors. in other fields, patient reports may be used to evaluate social skills of therapists, and residents’ ratings may be used to evaluate neighborhood safety. In these three examples the target construct is something that (in theory) only varies at the cluster level; the individuals within one cluster all share the same instructor, therapist, or neighborhood. A contrasting type of cluster-level constructs can be defined as constructs that theoretically differ across individuals within the same cluster. Examples are reading skills of students in a classroom, depressive symptoms of individual patients of a therapist, and number of years that individuals live in a particular neighborhood. Although the target construct here is defined at the individual level, it is quite likely that the averages across clusters will also vary due to cluster-level factors. For instance, the average reading skills of students in different classrooms may differ due to differences of teaching styles or years of teaching experience across classrooms, the average amount of depressive symptoms of patients may differ across therapists due to differences in therapists’ approaches, and some neighborhoods may have a higher turnaround of residence than other neighborhoods due to differences in local council policies and amenities. In the terminology of Marsh et al. (2012), if the referent of the item is the individual (e.g., “I like going to school”), then the cluster-level variable represents a contextual construct. If the referent of the item is the cluster (e.g., “My school is fun to go to”), then the cluster-aggregate represents a climate construct. The distinction between these types of constructs is more a theoretical one than a statistical one, because the same factor model (with equal factor loadings across levels) applies for both types of constructs. Marsh et al. (2012) call this factor model the doubly latent model. ‘Doubly latent’ in this context refers to using multiple indicators to measure a common factor, and decomposing the observed indicators into latent within- and between parts. 29.6 Full SEM with multilevel data In this chapter we only discussed CFA, and in Chapter 13 we only discussed path models on observed variables with multilevel data. One can also fit path models n latent variables (full SEM) with multilevel data. Similar to single level analysis, this would involve two steps. First one would establish a good measurement model using CFA, and in a second step one could specify a path model on the common factors. In practice, the number of clusters is often relatively small. In our example, we have measurements about only 44 teachers. The sample size at the between-level is thus 44, which is very small. With such small samples it is not possible to evaluate very complex models with many parameters, even in single level analysis. Therefore, the general advice is to keep the between-level model as simple as possible, and to collect data from many clusters if the research question involves between-level variables. One alternative option to test path models on latent variables would be using simple regression analysis on factor scores (see Devlieger &amp; Rosseel, 2020). References Devlieger, I., &amp; Rosseel, Y. (2020). Multilevel factor score regression. Multivariate behavioral research, 55(4), 600-624. Jak, S. &amp; Jorgensen, T.D. (2017). Relating measurement invariance, cross-level invariance, and multilevel reliability. Frontiers in Psychology, 8, 1640. Jak, S., Oort, F.J. &amp; Dolan, C.V. (2013). A test for cluster bias: Detecting violations of measurement invariance across clusters in multilevel data. Structural Equation Modeling, 20, 265-282. Marsh, H. W., Lüdtke, O., Robitzsch, A., Trautwein, U., Asparouhov, T., Muthén, B., &amp; Nagengast, B. (2009). Doubly-latent models of school contextual effects: Integrating multilevel and structural equation approaches to control measurement and sampling error. Multivariate Behavioral Research, 44(6), 764-802. Mehta, P. D., &amp; Neale, M. C. (2005). People are variables too: multilevel structural equations modeling. Psychological methods, 10(3), 259. Muthén, B.O. (1990). Mean and covariance structure analysis of hierarchical data. Los Angeles, CA: UCLA. Muthén, B.O. (1994). Multilevel covariance structure analysis. Sociological Methods &amp; Research, 22(3), 376–398. https://doi.org/10.1177%2F0049124194022003006 Muthén, B.O., &amp; Asparouhov, T. (2018). Recent methods for the study of measurement invariance with many groups: Alignment and random effects. Sociological Methods &amp; Research, 47(4), 637-664. Rabe-Hesketh, S., Skrondal, A., &amp; Pickles, A. (2004). Generalized multilevel structural equation modeling. Psychometrika, 69(2), 167-190. Williams, R. L. (2000). A note on robust variance estimation for cluster‐correlated data. Biometrics, 56(2), 645–646. https://doi.org/10.1111/j.0006-341X.2000.00645.x Schmidt, W. H. (1969). Covariance structure analysis of the multivariate random effects model [Doctoral dissertation]. University of Chicago, Department of Education. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
