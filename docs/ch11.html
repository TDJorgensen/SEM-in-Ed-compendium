<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11 Measures of Model Fit | A lavaan Compendium for Structural Equation Modeling in Educational Research</title>
  <meta name="description" content="11 Measures of Model Fit | A lavaan Compendium for Structural Equation Modeling in Educational Research" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="11 Measures of Model Fit | A lavaan Compendium for Structural Equation Modeling in Educational Research" />
  <meta property="og:type" content="book" />
  
  
  <meta name="github-repo" content="TDJorgensen/SEM-in-Ed-compendium" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11 Measures of Model Fit | A lavaan Compendium for Structural Equation Modeling in Educational Research" />
  
  
  

<meta name="author" content="Suzanne Jak and Terrence D. Jorgensen" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch10.html"/>
<link rel="next" href="ch12.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#copyright"><i class="fa fa-check"></i>Copyright</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ch1.html"><a href="ch1.html"><i class="fa fa-check"></i><b>1</b> Regression as Mean- and Covariance-Structure Analysis</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ch1.html"><a href="ch1.html#what-are-mean-and-covariance-structures"><i class="fa fa-check"></i><b>1.1</b> What Are Mean and Covariance <em>Structures</em>?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="ch1.html"><a href="ch1.html#ch1-1-1"><i class="fa fa-check"></i><b>1.1.1</b> Types of Data Used in SEM</a></li>
<li class="chapter" data-level="1.1.2" data-path="ch1.html"><a href="ch1.html#interpreting-covariance"><i class="fa fa-check"></i><b>1.1.2</b> Interpreting Covariance</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="ch1.html"><a href="ch1.html#importing-data-for-sem"><i class="fa fa-check"></i><b>1.2</b> Importing Data for SEM</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ch1.html"><a href="ch1.html#installing-lavaan"><i class="fa fa-check"></i><b>1.2.1</b> Installing <code>lavaan</code></a></li>
<li class="chapter" data-level="1.2.2" data-path="ch1.html"><a href="ch1.html#importing-raw-data"><i class="fa fa-check"></i><b>1.2.2</b> Importing Raw Data</a></li>
<li class="chapter" data-level="1.2.3" data-path="ch1.html"><a href="ch1.html#calculate-summary-statistics-from-raw-data"><i class="fa fa-check"></i><b>1.2.3</b> Calculate Summary Statistics from Raw Data</a></li>
<li class="chapter" data-level="1.2.4" data-path="ch1.html"><a href="ch1.html#importing-summary-data"><i class="fa fa-check"></i><b>1.2.4</b> Importing Summary Data</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ch1.html"><a href="ch1.html#regression-using-matrix-algebra"><i class="fa fa-check"></i><b>1.3</b> Regression Using Matrix Algebra</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="ch1.html"><a href="ch1.html#ch1-3-1"><i class="fa fa-check"></i><b>1.3.1</b> Linear Regression Models</a></li>
<li class="chapter" data-level="1.3.2" data-path="ch1.html"><a href="ch1.html#intercepts-and-means"><i class="fa fa-check"></i><b>1.3.2</b> Intercepts and Means</a></li>
<li class="chapter" data-level="1.3.3" data-path="ch1.html"><a href="ch1.html#categorical-predictors"><i class="fa fa-check"></i><b>1.3.3</b> Categorical Predictors</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ch1.html"><a href="ch1.html#summary"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="" data-path="ch1.html"><a href="ch1.html#references"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch2.html"><a href="ch2.html"><i class="fa fa-check"></i><b>2</b> Using <code>lavaan</code> to Run Regression and ANOVA as a SEM</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch2.html"><a href="ch2.html#prepare-data-and-workspace"><i class="fa fa-check"></i><b>2.1</b> Prepare Data and Workspace</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ch2.html"><a href="ch2.html#import-example-data"><i class="fa fa-check"></i><b>2.1.1</b> Import Example Data</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch2.html"><a href="ch2.html#ch2-1-2"><i class="fa fa-check"></i><b>2.1.2</b> <code>lavaan</code> Syntax</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch2.html"><a href="ch2.html#comparing-2-group-means-in-glm-and-sem"><i class="fa fa-check"></i><b>2.2</b> Comparing 2 Group Means in GLM and SEM</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch2.html"><a href="ch2.html#the-glm-approach"><i class="fa fa-check"></i><b>2.2.1</b> The GLM Approach</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch2.html"><a href="ch2.html#the-sem-approach-single-group-sem"><i class="fa fa-check"></i><b>2.2.2</b> The SEM Approach (single-group SEM)</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch2.html"><a href="ch2.html#multigroup-sem-approach"><i class="fa fa-check"></i><b>2.2.3</b> Multigroup SEM Approach</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch2.html"><a href="ch2.html#fit-an-sem-to-summary-statistics"><i class="fa fa-check"></i><b>2.3</b> Fit an SEM to Summary Statistics</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="ch2.html"><a href="ch2.html#advantages-of-analyzing-summary-statistics"><i class="fa fa-check"></i><b>2.3.1</b> Advantages of Analyzing Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch2.html"><a href="ch2.html#moderation-in-sem"><i class="fa fa-check"></i><b>2.4</b> Moderation in SEM</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ch2.html"><a href="ch2.html#moderation-by-groups-using-mg-sem"><i class="fa fa-check"></i><b>2.4.1</b> Moderation by Groups Using MG-SEM</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch2.html"><a href="ch2.html#the-emmeans-package"><i class="fa fa-check"></i><b>2.4.2</b> The <code>emmeans</code> Package</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch2.html"><a href="ch2.html#summary-1"><i class="fa fa-check"></i><b>2.5</b> Summary</a></li>
<li class="chapter" data-level="" data-path="ch2.html"><a href="ch2.html#references-1"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch3.html"><a href="ch3.html"><i class="fa fa-check"></i><b>3</b> Path Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch3.html"><a href="ch3.html#illustrative-example"><i class="fa fa-check"></i><b>3.1</b> Illustrative example</a></li>
<li class="chapter" data-level="3.2" data-path="ch3.html"><a href="ch3.html#conceptual-explanation"><i class="fa fa-check"></i><b>3.2</b> Conceptual explanation</a></li>
<li class="chapter" data-level="3.3" data-path="ch3.html"><a href="ch3.html#matrix-explanation"><i class="fa fa-check"></i><b>3.3</b> Matrix explanation</a></li>
<li class="chapter" data-level="3.4" data-path="ch3.html"><a href="ch3.html#path-analysis-using-lavaan"><i class="fa fa-check"></i><b>3.4</b> Path analysis using lavaan</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ch3.html"><a href="ch3.html#installing-lavaan-1"><i class="fa fa-check"></i><b>3.4.1</b> Installing lavaan</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch3.html"><a href="ch3.html#fitting-a-path-model"><i class="fa fa-check"></i><b>3.4.2</b> Fitting a path model</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch3.html"><a href="ch3.html#syntax-shortcuts"><i class="fa fa-check"></i><b>3.4.3</b> Syntax shortcuts</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch3.html"><a href="ch3.html#extracting-results-from-lavaan-output-in-matrix-form"><i class="fa fa-check"></i><b>3.4.4</b> Extracting results from lavaan output in matrix form</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#references-2"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#appendix"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#derivations-of-equation-refeq3-08"><i class="fa fa-check"></i>Derivations of Equation @ref(eq:3-08)</a></li>
<li class="chapter" data-level="" data-path="ch3.html"><a href="ch3.html#derivations-of-equation-refeq3-09"><i class="fa fa-check"></i>Derivations of Equation @ref(eq:3-09)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch4.html"><a href="ch4.html"><i class="fa fa-check"></i><b>4</b> Standard Errors and Confidence Intervals</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch4.html"><a href="ch4.html#standard-errors"><i class="fa fa-check"></i><b>4.1</b> Standard Errors</a></li>
<li class="chapter" data-level="4.2" data-path="ch4.html"><a href="ch4.html#confidence-intervals"><i class="fa fa-check"></i><b>4.2</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ch4.html"><a href="ch4.html#likelihood-based-confidence-intervals"><i class="fa fa-check"></i><b>4.2.1</b> Likelihood-based confidence intervals</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch4.html"><a href="ch4.html#bootstrapped-confidence-intervals"><i class="fa fa-check"></i><b>4.2.2</b> Bootstrapped confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch4.html"><a href="ch4.html#obtaining-standard-errors-and-confidence-intervals-in-lavaan"><i class="fa fa-check"></i><b>4.3</b> Obtaining standard errors and confidence intervals in <code>lavaan</code></a></li>
<li class="chapter" data-level="" data-path="ch4.html"><a href="ch4.html#references-3"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch5.html"><a href="ch5.html"><i class="fa fa-check"></i><b>5</b> Direct, Indirect, and Total Effects</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch5.html"><a href="ch5.html#testing-significance-of-indirect-effects"><i class="fa fa-check"></i><b>5.1</b> Testing significance of indirect effects</a></li>
<li class="chapter" data-level="5.2" data-path="ch5.html"><a href="ch5.html#higher-order-indirect-effects"><i class="fa fa-check"></i><b>5.2</b> Higher order indirect effects</a></li>
<li class="chapter" data-level="5.3" data-path="ch5.html"><a href="ch5.html#using-matrix-algebra-to-calculate-total-total-indirect-and-specific-indirect-effects"><i class="fa fa-check"></i><b>5.3</b> Using matrix algebra to calculate total, total indirect and specific indirect effects</a></li>
<li class="chapter" data-level="5.4" data-path="ch5.html"><a href="ch5.html#calculating-total-total-indirect-and-specific-indirect-effects-using-lavaan-output"><i class="fa fa-check"></i><b>5.4</b> Calculating total, total indirect and specific indirect effects using lavaan output</a></li>
<li class="chapter" data-level="5.5" data-path="ch5.html"><a href="ch5.html#calculating-specific-indirect-effects-in-lavaan"><i class="fa fa-check"></i><b>5.5</b> Calculating specific indirect effects in lavaan</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch6.html"><a href="ch6.html"><i class="fa fa-check"></i><b>6</b> Calculating Standardized Parameter Estimates</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ch6.html"><a href="ch6.html#standardized-regression-coefficients"><i class="fa fa-check"></i><b>6.1</b> Standardized regression coefficients</a></li>
<li class="chapter" data-level="6.2" data-path="ch6.html"><a href="ch6.html#standardized-residual-factor-variances-and-covariances"><i class="fa fa-check"></i><b>6.2</b> Standardized residual factor variances and covariances</a></li>
<li class="chapter" data-level="6.3" data-path="ch6.html"><a href="ch6.html#calculating-standardized-coefficients-in-r-using-lavaan-results"><i class="fa fa-check"></i><b>6.3</b> Calculating standardized coefficients in R using lavaan results</a>
<ul>
<li class="chapter" data-level="" data-path="ch6.html"><a href="ch6.html#script-6.1"><i class="fa fa-check"></i>Script 6.1</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ch6.html"><a href="ch6.html#request-standardized-output-with-lavaan"><i class="fa fa-check"></i><b>6.4</b> Request standardized output with lavaan</a></li>
<li class="chapter" data-level="6.5" data-path="ch6.html"><a href="ch6.html#standardizing-indirect-and-total-effects"><i class="fa fa-check"></i><b>6.5</b> Standardizing indirect and total effects</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch7.html"><a href="ch7.html"><i class="fa fa-check"></i><b>7</b> Identification</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ch7.html"><a href="ch7.html#assessment-of-identification-using-the-elements-of-mathbfsigma_textpopulation-and-mathbfsigma_textmodel"><i class="fa fa-check"></i><b>7.1</b> Assessment of identification using the elements of <span class="math inline">\(\mathbf\Sigma_{\text{population}}\)</span> and <span class="math inline">\(\mathbf\Sigma_{\text{model}}\)</span></a></li>
<li class="chapter" data-level="7.2" data-path="ch7.html"><a href="ch7.html#assessing-identification-through-heuristics"><i class="fa fa-check"></i><b>7.2</b> Assessing identification through heuristics</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ch7.html"><a href="ch7.html#the-recursive-rule"><i class="fa fa-check"></i><b>7.2.1</b> The recursive rule</a></li>
<li class="chapter" data-level="7.2.2" data-path="ch7.html"><a href="ch7.html#the-order-condition"><i class="fa fa-check"></i><b>7.2.2</b> The order condition</a></li>
<li class="chapter" data-level="7.2.3" data-path="ch7.html"><a href="ch7.html#the-rank-condition"><i class="fa fa-check"></i><b>7.2.3</b> The rank condition</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ch7.html"><a href="ch7.html#assessment-of-empirical-model-identification-using-lavaan"><i class="fa fa-check"></i><b>7.3</b> Assessment of empirical model identification using <code>lavaan</code></a>
<ul>
<li class="chapter" data-level="" data-path="ch7.html"><a href="ch7.html#script-7.1"><i class="fa fa-check"></i>Script 7.1</a></li>
<li class="chapter" data-level="" data-path="ch7.html"><a href="ch7.html#script-7.2"><i class="fa fa-check"></i>Script 7.2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch7.html"><a href="ch7.html#appendix-1"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="ch7.html"><a href="ch7.html#algebraic-assessment-of-identification-using-elements-of-mathbfsigma_textpopulation-and-mathbfsigma_textmodel"><i class="fa fa-check"></i>Algebraic assessment of identification using elements of <span class="math inline">\(\mathbf\Sigma_{\text{population}}\)</span> and <span class="math inline">\(\mathbf\Sigma_{\text{model}}\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch8.html"><a href="ch8.html"><i class="fa fa-check"></i><b>8</b> Autoregression</a>
<ul>
<li class="chapter" data-level="" data-path="ch8.html"><a href="ch8.html#script-8.1"><i class="fa fa-check"></i>Script 8.1</a></li>
<li class="chapter" data-level="8.1" data-path="ch8.html"><a href="ch8.html#autoregression-models-with-predictors"><i class="fa fa-check"></i><b>8.1</b> Autoregression models with predictors</a>
<ul>
<li class="chapter" data-level="" data-path="ch8.html"><a href="ch8.html#script-8.2"><i class="fa fa-check"></i>Script 8.2</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ch8.html"><a href="ch8.html#cross-lagged-panel-models"><i class="fa fa-check"></i><b>8.2</b> Cross-lagged panel models</a></li>
<li class="chapter" data-level="" data-path="ch8.html"><a href="ch8.html#references-4"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch9.html"><a href="ch9.html"><i class="fa fa-check"></i><b>9</b> Model Specification and Model Identification</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ch9.html"><a href="ch9.html#from-theory-to-model"><i class="fa fa-check"></i><b>9.1</b> From theory to model</a></li>
<li class="chapter" data-level="9.2" data-path="ch9.html"><a href="ch9.html#model-parsimony"><i class="fa fa-check"></i><b>9.2</b> Model parsimony</a></li>
<li class="chapter" data-level="9.3" data-path="ch9.html"><a href="ch9.html#a-priori-model-specification"><i class="fa fa-check"></i><b>9.3</b> A priori model specification</a></li>
<li class="chapter" data-level="9.4" data-path="ch9.html"><a href="ch9.html#post-hoc-model-modification"><i class="fa fa-check"></i><b>9.4</b> Post hoc model modification</a></li>
<li class="chapter" data-level="9.5" data-path="ch9.html"><a href="ch9.html#backward-and-forward-specification-searches"><i class="fa fa-check"></i><b>9.5</b> Backward and forward specification searches</a></li>
<li class="chapter" data-level="9.6" data-path="ch9.html"><a href="ch9.html#correlation-residuals"><i class="fa fa-check"></i><b>9.6</b> Correlation residuals</a></li>
<li class="chapter" data-level="9.7" data-path="ch9.html"><a href="ch9.html#modification-indices"><i class="fa fa-check"></i><b>9.7</b> Modification indices</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="ch9.html"><a href="ch9.html#script-9.0"><i class="fa fa-check"></i><b>9.7.1</b> Script 9.0</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="ch9.html"><a href="ch9.html#cross-validation"><i class="fa fa-check"></i><b>9.8</b> Cross-validation</a></li>
<li class="chapter" data-level="9.9" data-path="ch9.html"><a href="ch9.html#calculating-correlation-residuals-in-lavaan"><i class="fa fa-check"></i><b>9.9</b> Calculating correlation residuals in <code>lavaan</code></a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="ch9.html"><a href="ch9.html#requesting-mis-and-sepcs-in-lavaan"><i class="fa fa-check"></i><b>9.9.1</b> Requesting MIs and (S)EPCs in <code>lavaan</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch9.html"><a href="ch9.html#references-5"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch10.html"><a href="ch10.html"><i class="fa fa-check"></i><b>10</b> Estimation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ch10.html"><a href="ch10.html#improper-solutions"><i class="fa fa-check"></i><b>10.1</b> Improper Solutions</a></li>
<li class="chapter" data-level="10.2" data-path="ch10.html"><a href="ch10.html#specifying-starting-values-in-lavaan"><i class="fa fa-check"></i><b>10.2</b> Specifying starting values in <code>lavaan</code></a></li>
<li class="chapter" data-level="10.3" data-path="ch10.html"><a href="ch10.html#alternative-estimators"><i class="fa fa-check"></i><b>10.3</b> Alternative estimators</a></li>
<li class="chapter" data-level="10.4" data-path="ch10.html"><a href="ch10.html#robust-estimators"><i class="fa fa-check"></i><b>10.4</b> Robust estimators</a></li>
<li class="chapter" data-level="10.5" data-path="ch10.html"><a href="ch10.html#requesting-alternative-and-robust-estimators-in-lavaan"><i class="fa fa-check"></i><b>10.5</b> Requesting alternative and robust estimators in lavaan</a></li>
<li class="chapter" data-level="10.6" data-path="ch10.html"><a href="ch10.html#ch10-6"><i class="fa fa-check"></i><b>10.6</b> Alternative calculation of the ML discrepancy function when analysing raw data</a></li>
<li class="chapter" data-level="10.7" data-path="ch10.html"><a href="ch10.html#ch10-7"><i class="fa fa-check"></i><b>10.7</b> Using FIML to analyse raw data with missing values in lavaan</a></li>
<li class="chapter" data-level="" data-path="ch10.html"><a href="ch10.html#references-6"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch11.html"><a href="ch11.html"><i class="fa fa-check"></i><b>11</b> Measures of Model Fit</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ch11.html"><a href="ch11.html#the-chi-squared-test-of-exact-fit"><i class="fa fa-check"></i><b>11.1</b> The chi-squared test of exact fit</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ch11.html"><a href="ch11.html#alternative-basis-for-calculating-the-test-statistic-when-analysing-raw-data"><i class="fa fa-check"></i><b>11.1.1</b> Alternative basis for calculating the test statistic when analysing raw data</a></li>
<li class="chapter" data-level="11.1.2" data-path="ch11.html"><a href="ch11.html#testing-exact-fit-vs.-describing-the-degree-of-approximate-fit"><i class="fa fa-check"></i><b>11.1.2</b> Testing exact fit vs. describing the degree of approximate fit</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ch11.html"><a href="ch11.html#root-mean-square-error-of-approximation-rmsea"><i class="fa fa-check"></i><b>11.2</b> Root Mean Square Error of Approximation (RMSEA)</a></li>
<li class="chapter" data-level="11.3" data-path="ch11.html"><a href="ch11.html#other-descriptive-fit-indices"><i class="fa fa-check"></i><b>11.3</b> Other descriptive fit indices</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="ch11.html"><a href="ch11.html#the-tuckerlewis-index-tli-and-the-comparative-fit-index-cfi"><i class="fa fa-check"></i><b>11.3.1</b> The Tucker–Lewis Index (TLI) and the Comparative Fit Index (CFI)</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch11.html"><a href="ch11.html#the-root-mean-square-residual-rmr-and-standardized-rmr-srmr"><i class="fa fa-check"></i><b>11.3.2</b> The Root Mean Square Residual (RMR) and Standardized RMR (SRMR)</a></li>
<li class="chapter" data-level="11.3.3" data-path="ch11.html"><a href="ch11.html#information-criteria"><i class="fa fa-check"></i><b>11.3.3</b> Information Criteria</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch11.html"><a href="ch11.html#a-note-on-using-available-fit-indices"><i class="fa fa-check"></i><b>11.4</b> A note on using available fit indices</a></li>
<li class="chapter" data-level="11.5" data-path="ch11.html"><a href="ch11.html#difference-in-model-fit"><i class="fa fa-check"></i><b>11.5</b> Difference in model fit</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="ch11.html"><a href="ch11.html#deltachi2-as-a-likelihood-ratio-test"><i class="fa fa-check"></i><b>11.5.1</b> <span class="math inline">\(\Delta\chi^2\)</span> as a likelihood ratio test</a></li>
<li class="chapter" data-level="11.5.2" data-path="ch11.html"><a href="ch11.html#describing-differences-in-fit"><i class="fa fa-check"></i><b>11.5.2</b> Describing differences in fit</a></li>
<li class="chapter" data-level="11.5.3" data-path="ch11.html"><a href="ch11.html#testing-differences-in-fit-between-non-nested-models"><i class="fa fa-check"></i><b>11.5.3</b> Testing differences in fit between non-nested models</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="ch11.html"><a href="ch11.html#request-fit-measures-in-lavaan"><i class="fa fa-check"></i><b>11.6</b> Request fit measures in <code>lavaan</code></a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="ch11.html"><a href="ch11.html#compare-fit-of-lavaan-models"><i class="fa fa-check"></i><b>11.6.1</b> Compare fit of lavaan models</a></li>
<li class="chapter" data-level="11.6.2" data-path="ch11.html"><a href="ch11.html#fit-measures-in-lavaan-when-adjusting-for-non-normal-data"><i class="fa fa-check"></i><b>11.6.2</b> Fit measures in <code>lavaan</code> when adjusting for non-normal data</a></li>
<li class="chapter" data-level="11.6.3" data-path="ch11.html"><a href="ch11.html#test-statistic-adjusted-for-small-sample-size"><i class="fa fa-check"></i><b>11.6.3</b> Test statistic adjusted for small sample size</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch11.html"><a href="ch11.html#references-7"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ch12.html"><a href="ch12.html"><i class="fa fa-check"></i><b>12</b> Path Analysis with Categorical Outcomes</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ch12.html"><a href="ch12.html#prepare-data-and-workspace-1"><i class="fa fa-check"></i><b>12.1</b> Prepare Data and Workspace</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="ch12.html"><a href="ch12.html#import-example-data-1"><i class="fa fa-check"></i><b>12.1.1</b> Import Example Data</a></li>
<li class="chapter" data-level="12.1.2" data-path="ch12.html"><a href="ch12.html#summarize-data"><i class="fa fa-check"></i><b>12.1.2</b> Summarize Data</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="ch12.html"><a href="ch12.html#regression-models-for-binary-variables"><i class="fa fa-check"></i><b>12.2</b> Regression Models for Binary Variables</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ch12.html"><a href="ch12.html#fit-a-logistic-regression-model"><i class="fa fa-check"></i><b>12.2.1</b> Fit a Logistic Regression Model</a></li>
<li class="chapter" data-level="12.2.2" data-path="ch12.html"><a href="ch12.html#fit-a-probit-regression-model"><i class="fa fa-check"></i><b>12.2.2</b> Fit a Probit Regression Model</a></li>
<li class="chapter" data-level="12.2.3" data-path="ch12.html"><a href="ch12.html#compare-models"><i class="fa fa-check"></i><b>12.2.3</b> Compare Models</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ch12.html"><a href="ch12.html#latent-response-variable"><i class="fa fa-check"></i><b>12.3</b> Latent Response Variable</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ch12.html"><a href="ch12.html#ordinal-outcomes"><i class="fa fa-check"></i><b>12.3.1</b> Ordinal Outcomes</a></li>
<li class="chapter" data-level="12.3.2" data-path="ch12.html"><a href="ch12.html#estimating-thresholds"><i class="fa fa-check"></i><b>12.3.2</b> Estimating Thresholds</a></li>
<li class="chapter" data-level="12.3.3" data-path="ch12.html"><a href="ch12.html#estimating-polychoric-correlations"><i class="fa fa-check"></i><b>12.3.3</b> Estimating Polychoric Correlations</a></li>
<li class="chapter" data-level="12.3.4" data-path="ch12.html"><a href="ch12.html#estimating-an-sem-with-estimated-input"><i class="fa fa-check"></i><b>12.3.4</b> Estimating an SEM with Estimated Input</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ch12.html"><a href="ch12.html#mediation-model-with-categorical-outcomes"><i class="fa fa-check"></i><b>12.4</b> Mediation Model with Categorical Outcomes</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="ch12.html"><a href="ch12.html#estimate-mediation-models"><i class="fa fa-check"></i><b>12.4.1</b> Estimate Mediation Models</a></li>
<li class="chapter" data-level="12.4.2" data-path="ch12.html"><a href="ch12.html#interpreting-coefficients"><i class="fa fa-check"></i><b>12.4.2</b> Interpreting Coefficients</a></li>
<li class="chapter" data-level="12.4.3" data-path="ch12.html"><a href="ch12.html#delta-vs.-theta-parameterizations"><i class="fa fa-check"></i><b>12.4.3</b> Delta vs. Theta Parameterizations</a></li>
<li class="chapter" data-level="12.4.4" data-path="ch12.html"><a href="ch12.html#decomposing-total-effects"><i class="fa fa-check"></i><b>12.4.4</b> Decomposing Total Effects</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch12.html"><a href="ch12.html#references-8"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ch13.html"><a href="ch13.html"><i class="fa fa-check"></i><b>13</b> Fitting Path Models with Multilevel Data</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ch13.html"><a href="ch13.html#intraclass-correlation"><i class="fa fa-check"></i><b>13.1</b> Intraclass correlation</a></li>
<li class="chapter" data-level="13.2" data-path="ch13.html"><a href="ch13.html#multilevel-structure-as-a-nuisance-correcting-for-the-dependency"><i class="fa fa-check"></i><b>13.2</b> Multilevel structure as a nuisance: Correcting for the dependency</a></li>
<li class="chapter" data-level="13.3" data-path="ch13.html"><a href="ch13.html#two-level-path-models"><i class="fa fa-check"></i><b>13.3</b> Two-level path models</a></li>
<li class="chapter" data-level="13.4" data-path="ch13.html"><a href="ch13.html#obtaining-iccs-and-estimates-of-sigma_textw-and-sigma_textb"><i class="fa fa-check"></i><b>13.4</b> Obtaining ICCs, and estimates of <span class="math inline">\(\Sigma_\text{W}\)</span> and <span class="math inline">\(\Sigma_\text{B}\)</span></a>
<ul>
<li class="chapter" data-level="" data-path="ch13.html"><a href="ch13.html#script-13.1"><i class="fa fa-check"></i>Script 13.1</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="ch13.html"><a href="ch13.html#fitting-a-two-level-path-model"><i class="fa fa-check"></i><b>13.5</b> Fitting a two-level path model</a>
<ul>
<li class="chapter" data-level="" data-path="ch13.html"><a href="ch13.html#script-13.2"><i class="fa fa-check"></i>Script 13.2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch13.html"><a href="ch13.html#references-9"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ch14.html"><a href="ch14.html"><i class="fa fa-check"></i><b>14</b> Factor Models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ch14.html"><a href="ch14.html#empirical-example-of-a-factor-model"><i class="fa fa-check"></i><b>14.1</b> Empirical example of a factor model</a></li>
<li class="chapter" data-level="14.2" data-path="ch14.html"><a href="ch14.html#conceptual-explanation-of-a-factor-model"><i class="fa fa-check"></i><b>14.2</b> Conceptual explanation of a factor model</a></li>
<li class="chapter" data-level="14.3" data-path="ch14.html"><a href="ch14.html#symbolic-explanation-of-a-factor-model"><i class="fa fa-check"></i><b>14.3</b> Symbolic explanation of a factor model</a></li>
<li class="chapter" data-level="14.4" data-path="ch14.html"><a href="ch14.html#identification-of-model-parameters-in-a-factor-model"><i class="fa fa-check"></i><b>14.4</b> Identification of model parameters in a factor model</a></li>
<li class="chapter" data-level="14.5" data-path="ch14.html"><a href="ch14.html#fitting-a-factor-model-using-lavaan"><i class="fa fa-check"></i><b>14.5</b> Fitting a factor model using lavaan</a>
<ul>
<li class="chapter" data-level="" data-path="ch14.html"><a href="ch14.html#script-14.1"><i class="fa fa-check"></i>Script 14.1</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch14.html"><a href="ch14.html#references-10"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="" data-path="ch14.html"><a href="ch14.html#appendix-2"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="ch14.html"><a href="ch14.html#derivations-of-equation-14.13"><i class="fa fa-check"></i>Derivations of Equation 14.13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ch15.html"><a href="ch15.html"><i class="fa fa-check"></i><b>15</b> Standardized Parameter Estimates for the Factor Model</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ch15.html"><a href="ch15.html#standardized-factor-loadings"><i class="fa fa-check"></i><b>15.1</b> Standardized factor loadings</a></li>
<li class="chapter" data-level="15.2" data-path="ch15.html"><a href="ch15.html#standardized-common-factor-variances-and-covariances"><i class="fa fa-check"></i><b>15.2</b> Standardized common-factor variances and covariances</a></li>
<li class="chapter" data-level="15.3" data-path="ch15.html"><a href="ch15.html#standardized-unique-factor-variances-and-covariances"><i class="fa fa-check"></i><b>15.3</b> Standardized unique-factor variances and covariances</a></li>
<li class="chapter" data-level="15.4" data-path="ch15.html"><a href="ch15.html#structure-coefficients"><i class="fa fa-check"></i><b>15.4</b> Structure coefficients</a></li>
<li class="chapter" data-level="15.5" data-path="ch15.html"><a href="ch15.html#ch15-5"><i class="fa fa-check"></i><b>15.5</b> Calculating standardized coefficients in lavaan</a>
<ul>
<li class="chapter" data-level="" data-path="ch15.html"><a href="ch15.html#script-15.1"><i class="fa fa-check"></i>Script 15.1</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="ch15.html"><a href="ch15.html#request-standardized-output-with-lavaan-1"><i class="fa fa-check"></i><b>15.6</b> Request standardized output with lavaan</a></li>
<li class="chapter" data-level="" data-path="ch15.html"><a href="ch15.html#references-11"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ch16.html"><a href="ch16.html"><i class="fa fa-check"></i><b>16</b> The Empirical Check for Identification</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ch16.html"><a href="ch16.html#empirical-check-of-model-a"><i class="fa fa-check"></i><b>16.1</b> Empirical check of Model A</a>
<ul>
<li class="chapter" data-level="" data-path="ch16.html"><a href="ch16.html#script-16.1"><i class="fa fa-check"></i>Script 16.1</a></li>
<li class="chapter" data-level="" data-path="ch16.html"><a href="ch16.html#script-16.2"><i class="fa fa-check"></i>Script 16.2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch16.html"><a href="ch16.html#references-12"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ch17.html"><a href="ch17.html"><i class="fa fa-check"></i><b>17</b> Second Order Factor Models</a>
<ul>
<li class="chapter" data-level="" data-path="ch17.html"><a href="ch17.html#script-17.1"><i class="fa fa-check"></i>Script 17.1</a></li>
<li class="chapter" data-level="" data-path="ch17.html"><a href="ch17.html#getting-the-parameter-estimates-in-matrix-form"><i class="fa fa-check"></i>Getting the parameter estimates in matrix form</a>
<ul>
<li class="chapter" data-level="" data-path="ch17.html"><a href="ch17.html#script-17.2"><i class="fa fa-check"></i>Script 17.2</a></li>
</ul></li>
<li class="chapter" data-level="17.1" data-path="ch17.html"><a href="ch17.html#standardized-parameter-estimates-for-the-higher-order-part-of-the-model"><i class="fa fa-check"></i><b>17.1</b> Standardized parameter estimates for the higher-order part of the model</a>
<ul>
<li class="chapter" data-level="" data-path="ch17.html"><a href="ch17.html#script-17.3"><i class="fa fa-check"></i>Script 17.3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ch18.html"><a href="ch18.html"><i class="fa fa-check"></i><b>18</b> Structural Regression Models</a>
<ul>
<li class="chapter" data-level="" data-path="ch18.html"><a href="ch18.html#script-18.1"><i class="fa fa-check"></i>Script 18.1</a></li>
<li class="chapter" data-level="" data-path="ch18.html"><a href="ch18.html#script-18.2"><i class="fa fa-check"></i>Script 18.2</a></li>
<li class="chapter" data-level="18.1" data-path="ch18.html"><a href="ch18.html#standardized-parameter-estimates-for-the-structural-part-of-the-model"><i class="fa fa-check"></i><b>18.1</b> Standardized parameter estimates for the structural part of the model</a>
<ul>
<li class="chapter" data-level="" data-path="ch18.html"><a href="ch18.html#script-18.3"><i class="fa fa-check"></i>Script 18.3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ch19.html"><a href="ch19.html"><i class="fa fa-check"></i><b>19</b> Second-order Correlation Residuals</a></li>
<li class="chapter" data-level="20" data-path="ch20.html"><a href="ch20.html"><i class="fa fa-check"></i><b>20</b> Factors with single indicators</a>
<ul>
<li class="chapter" data-level="" data-path="ch20.html"><a href="ch20.html#script-20.1"><i class="fa fa-check"></i>Script 20.1</a></li>
<li class="chapter" data-level="" data-path="ch20.html"><a href="ch20.html#script-20.2"><i class="fa fa-check"></i>Script 20.2</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ch21.html"><a href="ch21.html"><i class="fa fa-check"></i><b>21</b> Mean structures</a>
<ul>
<li class="chapter" data-level="21.1" data-path="ch21.html"><a href="ch21.html#mean-structure-of-a-factor-model"><i class="fa fa-check"></i><b>21.1</b> Mean structure of a factor model</a></li>
<li class="chapter" data-level="21.2" data-path="ch21.html"><a href="ch21.html#mean-structure-of-a-path-model"><i class="fa fa-check"></i><b>21.2</b> Mean structure of a path model</a></li>
<li class="chapter" data-level="21.3" data-path="ch21.html"><a href="ch21.html#mean-structure-of-a-factor-model-in-lavaan"><i class="fa fa-check"></i><b>21.3</b> Mean structure of a factor model in <code>lavaan</code></a>
<ul>
<li class="chapter" data-level="" data-path="ch21.html"><a href="ch21.html#script-21.1"><i class="fa fa-check"></i>Script 21.1</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="ch21.html"><a href="ch21.html#mean-structure-of-a-path-model-1"><i class="fa fa-check"></i><b>21.4</b> Mean structure of a path model</a></li>
<li class="chapter" data-level="" data-path="ch21.html"><a href="ch21.html#appendix-3"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="" data-path="ch21.html"><a href="ch21.html#derivation-of-equation-21.20"><i class="fa fa-check"></i>Derivation of Equation 21.20</a></li>
<li class="chapter" data-level="" data-path="ch21.html"><a href="ch21.html#derivation-of-equation-21.27"><i class="fa fa-check"></i>Derivation of Equation 21.27</a></li>
<li class="chapter" data-level="" data-path="ch21.html"><a href="ch21.html#derivation-of-equation-21.28"><i class="fa fa-check"></i>Derivation of Equation 21.28</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="ch22.html"><a href="ch22.html"><i class="fa fa-check"></i><b>22</b> Multigroup Models</a>
<ul>
<li class="chapter" data-level="22.1" data-path="ch22.html"><a href="ch22.html#measurement-invariance"><i class="fa fa-check"></i><b>22.1</b> Measurement invariance</a>
<ul>
<li class="chapter" data-level="" data-path="ch22.html"><a href="ch22.html#script-22.1"><i class="fa fa-check"></i>Script 22.1</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="ch22.html"><a href="ch22.html#across-group-equality-constraints"><i class="fa fa-check"></i><b>22.2</b> Across group equality constraints</a>
<ul>
<li class="chapter" data-level="" data-path="ch22.html"><a href="ch22.html#script-22.2"><i class="fa fa-check"></i>Script 22.2</a></li>
<li class="chapter" data-level="" data-path="ch22.html"><a href="ch22.html#script-22.3"><i class="fa fa-check"></i>Script 22.3</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="ch22.html"><a href="ch22.html#standardized-estimates-for-a-multigroup-model"><i class="fa fa-check"></i><b>22.3</b> Standardized estimates for a multigroup model</a></li>
<li class="chapter" data-level="22.4" data-path="ch22.html"><a href="ch22.html#lavaan-shortcuts"><i class="fa fa-check"></i><b>22.4</b> <code>lavaan</code> shortcuts</a>
<ul>
<li class="chapter" data-level="" data-path="ch22.html"><a href="ch22.html#script-22.4"><i class="fa fa-check"></i>Script 22.4</a></li>
<li class="chapter" data-level="" data-path="ch22.html"><a href="ch22.html#script-22.5"><i class="fa fa-check"></i>Script 22.5</a></li>
<li class="chapter" data-level="" data-path="ch22.html"><a href="ch22.html#script-22.6"><i class="fa fa-check"></i>Script 22.6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="ch23.html"><a href="ch23.html"><i class="fa fa-check"></i><b>23</b> Calculating Mean Residuals</a>
<ul>
<li class="chapter" data-level="" data-path="ch23.html"><a href="ch23.html#script-23.1"><i class="fa fa-check"></i>Script 23.1</a></li>
<li class="chapter" data-level="" data-path="ch23.html"><a href="ch23.html#script-22.2-1"><i class="fa fa-check"></i>Script 22.2</a></li>
<li class="chapter" data-level="" data-path="ch23.html"><a href="ch23.html#script-23.3"><i class="fa fa-check"></i>Script 23.3</a></li>
<li class="chapter" data-level="" data-path="ch23.html"><a href="ch23.html#references-13"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="ch24.html"><a href="ch24.html"><i class="fa fa-check"></i><b>24</b> Modification Indices and EPC’s for Equality Constraints</a>
<ul>
<li class="chapter" data-level="24.1" data-path="ch24.html"><a href="ch24.html#modification-index-for-simultaneously-freeing-a-set-of-parameters"><i class="fa fa-check"></i><b>24.1</b> Modification index for simultaneously freeing a set of parameters</a>
<ul>
<li class="chapter" data-level="" data-path="ch24.html"><a href="ch24.html#script-24.1"><i class="fa fa-check"></i>Script 24.1</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="ch24.html"><a href="ch24.html#modification-indices-for-releasing-equality-constraints"><i class="fa fa-check"></i><b>24.2</b> Modification indices for releasing equality constraints</a>
<ul>
<li class="chapter" data-level="" data-path="ch24.html"><a href="ch24.html#script-24.3"><i class="fa fa-check"></i>Script 24.3</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="ch24.html"><a href="ch24.html#epc-interest"><i class="fa fa-check"></i><b>24.3</b> EPC-interest</a></li>
<li class="chapter" data-level="" data-path="ch24.html"><a href="ch24.html#references-14"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="ch25.html"><a href="ch25.html"><i class="fa fa-check"></i><b>25</b> MIMIC (and RFA) models</a>
<ul>
<li class="chapter" data-level="25.1" data-path="ch25.html"><a href="ch25.html#illustration-testing-uniform-bias-in-a-mimic-model"><i class="fa fa-check"></i><b>25.1</b> Illustration testing uniform bias in a MIMIC model</a></li>
<li class="chapter" data-level="25.2" data-path="ch25.html"><a href="ch25.html#evaluating-non-uniform-measurement-bias"><i class="fa fa-check"></i><b>25.2</b> Evaluating non-uniform measurement bias</a></li>
<li class="chapter" data-level="25.3" data-path="ch25.html"><a href="ch25.html#connection-with-measurement-invariance-testing-in-multigroup-models"><i class="fa fa-check"></i><b>25.3</b> Connection with measurement invariance testing in multigroup models</a></li>
<li class="chapter" data-level="25.4" data-path="ch25.html"><a href="ch25.html#rfa-models"><i class="fa fa-check"></i><b>25.4</b> RFA-models</a></li>
<li class="chapter" data-level="" data-path="ch25.html"><a href="ch25.html#references-15"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="ch26.html"><a href="ch26.html"><i class="fa fa-check"></i><b>26</b> Longitudinal Factor Analysis</a>
<ul>
<li class="chapter" data-level="26.1" data-path="ch26.html"><a href="ch26.html#step-1-a-longitudinal-factor-model-with-configural-invariance"><i class="fa fa-check"></i><b>26.1</b> Step 1: A longitudinal factor model with configural invariance</a>
<ul>
<li class="chapter" data-level="" data-path="ch26.html"><a href="ch26.html#script-26.1"><i class="fa fa-check"></i>Script 26.1</a></li>
</ul></li>
<li class="chapter" data-level="26.2" data-path="ch26.html"><a href="ch26.html#step-2-a-longitudinal-model-with-weak-factorial-invariance."><i class="fa fa-check"></i><b>26.2</b> Step 2: A longitudinal model with weak factorial invariance.</a>
<ul>
<li class="chapter" data-level="" data-path="ch26.html"><a href="ch26.html#script-26.2"><i class="fa fa-check"></i>Script 26.2</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="ch26.html"><a href="ch26.html#step-3-longitudinal-model-with-strong-factorial-invariance"><i class="fa fa-check"></i><b>26.3</b> Step 3: Longitudinal model with strong factorial invariance</a>
<ul>
<li class="chapter" data-level="" data-path="ch26.html"><a href="ch26.html#script-26.3"><i class="fa fa-check"></i>Script 26.3</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="ch26.html"><a href="ch26.html#step-4-a-model-with-strict-factorial-invariance"><i class="fa fa-check"></i><b>26.4</b> Step 4: A model with strict factorial invariance</a>
<ul>
<li class="chapter" data-level="" data-path="ch26.html"><a href="ch26.html#script-26.4"><i class="fa fa-check"></i>Script 26.4</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="ch26.html"><a href="ch26.html#standardized-estimates-for-a-longitudinal-factor-model-with-means"><i class="fa fa-check"></i><b>26.5</b> Standardized estimates for a (longitudinal) factor model with means</a>
<ul>
<li class="chapter" data-level="" data-path="ch26.html"><a href="ch26.html#script-26.5"><i class="fa fa-check"></i>Script 26.5</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch26.html"><a href="ch26.html#references-16"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="ch27.html"><a href="ch27.html"><i class="fa fa-check"></i><b>27</b> Latent Growth Curve Models</a>
<ul>
<li class="chapter" data-level="27.1" data-path="ch27.html"><a href="ch27.html#prepare-data-and-workspace-2"><i class="fa fa-check"></i><b>27.1</b> Prepare Data and Workspace</a></li>
<li class="chapter" data-level="27.2" data-path="ch27.html"><a href="ch27.html#random-intercept-model"><i class="fa fa-check"></i><b>27.2</b> Random Intercept Model</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="ch27.html"><a href="ch27.html#specification-and-estimation"><i class="fa fa-check"></i><b>27.2.1</b> Specification and Estimation</a></li>
<li class="chapter" data-level="27.2.2" data-path="ch27.html"><a href="ch27.html#interpret-results"><i class="fa fa-check"></i><b>27.2.2</b> Interpret Results</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="ch27.html"><a href="ch27.html#linear-growth-model"><i class="fa fa-check"></i><b>27.3</b> Linear Growth Model</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="ch27.html"><a href="ch27.html#model-fit-and-comparison"><i class="fa fa-check"></i><b>27.3.1</b> Model Fit and Comparison</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="ch27.html"><a href="ch27.html#unrestricted-growth-models"><i class="fa fa-check"></i><b>27.4</b> Unrestricted Growth Models</a>
<ul>
<li class="chapter" data-level="27.4.1" data-path="ch27.html"><a href="ch27.html#latent-basis-curve"><i class="fa fa-check"></i><b>27.4.1</b> Latent Basis Curve</a></li>
<li class="chapter" data-level="27.4.2" data-path="ch27.html"><a href="ch27.html#saturated-growth-model"><i class="fa fa-check"></i><b>27.4.2</b> Saturated Growth Model</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="ch27.html"><a href="ch27.html#explaining-growth-factors"><i class="fa fa-check"></i><b>27.5</b> Explaining Growth Factors</a>
<ul>
<li class="chapter" data-level="27.5.1" data-path="ch27.html"><a href="ch27.html#time-invariant-level-2-predictors"><i class="fa fa-check"></i><b>27.5.1</b> Time-Invariant (Level-2) Predictors</a></li>
<li class="chapter" data-level="27.5.2" data-path="ch27.html"><a href="ch27.html#time-varying-level-1-predictors"><i class="fa fa-check"></i><b>27.5.2</b> Time-Varying (Level-1) Predictors</a></li>
<li class="chapter" data-level="27.5.3" data-path="ch27.html"><a href="ch27.html#parallel-growth-curves"><i class="fa fa-check"></i><b>27.5.3</b> Parallel Growth Curves</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="ch27.html"><a href="ch27.html#latent-indicators-of-growth-factors"><i class="fa fa-check"></i><b>27.6</b> Latent Indicators of Growth Factors</a>
<ul>
<li class="chapter" data-level="27.6.1" data-path="ch27.html"><a href="ch27.html#common-factors"><i class="fa fa-check"></i><b>27.6.1</b> Common Factors</a></li>
<li class="chapter" data-level="27.6.2" data-path="ch27.html"><a href="ch27.html#discrete-indicators"><i class="fa fa-check"></i><b>27.6.2</b> Discrete Indicators</a></li>
</ul></li>
<li class="chapter" data-level="27.7" data-path="ch27.html"><a href="ch27.html#multigroup-growth-models"><i class="fa fa-check"></i><b>27.7</b> Multigroup Growth Models</a></li>
<li class="chapter" data-level="" data-path="ch27.html"><a href="ch27.html#references-17"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="ch28.html"><a href="ch28.html"><i class="fa fa-check"></i><b>28</b> Analysis of categorical outcomes</a>
<ul>
<li class="chapter" data-level="28.1" data-path="ch28.html"><a href="ch28.html#factor-analysis-using-categorical-indicators"><i class="fa fa-check"></i><b>28.1</b> Factor analysis using categorical indicators</a>
<ul>
<li class="chapter" data-level="" data-path="ch28.html"><a href="ch28.html#script-28.1"><i class="fa fa-check"></i>Script 28.1</a></li>
<li class="chapter" data-level="" data-path="ch28.html"><a href="ch28.html#script-28.2"><i class="fa fa-check"></i>Script 28.2</a></li>
<li class="chapter" data-level="" data-path="ch28.html"><a href="ch28.html#script-28.3"><i class="fa fa-check"></i>Script 28.3</a></li>
<li class="chapter" data-level="" data-path="ch28.html"><a href="ch28.html#script-28.4"><i class="fa fa-check"></i>Script 28.4</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ch28.html"><a href="ch28.html#references-and-further-reading"><i class="fa fa-check"></i>References and further reading</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="ch29.html"><a href="ch29.html"><i class="fa fa-check"></i><b>29</b> Fitting CFA models with multilevel data</a>
<ul>
<li class="chapter" data-level="29.1" data-path="ch29.html"><a href="ch29.html#intraclass-correlations-of-observed-variables"><i class="fa fa-check"></i><b>29.1</b> Intraclass correlations of observed variables</a>
<ul>
<li class="chapter" data-level="" data-path="ch29.html"><a href="ch29.html#script-29.1"><i class="fa fa-check"></i>Script 29.1</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="ch29.html"><a href="ch29.html#multilevel-structure-as-a-nuisance-correcting-for-the-dependency-1"><i class="fa fa-check"></i><b>29.2</b> Multilevel structure as a nuisance: Correcting for the dependency</a></li>
<li class="chapter" data-level="29.3" data-path="ch29.html"><a href="ch29.html#two-level-factor-models"><i class="fa fa-check"></i><b>29.3</b> Two-level factor models</a>
<ul>
<li class="chapter" data-level="" data-path="ch29.html"><a href="ch29.html#script-29.2"><i class="fa fa-check"></i>Script 29.2</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="ch29.html"><a href="ch29.html#intraclass-correlations-of-common-factors"><i class="fa fa-check"></i><b>29.4</b> Intraclass correlations of common factors</a></li>
<li class="chapter" data-level="29.5" data-path="ch29.html"><a href="ch29.html#climate-and-contextual-between-level-latent-variables"><i class="fa fa-check"></i><b>29.5</b> Climate and contextual between-level latent variables</a></li>
<li class="chapter" data-level="29.6" data-path="ch29.html"><a href="ch29.html#full-sem-with-multilevel-data"><i class="fa fa-check"></i><b>29.6</b> Full SEM with multilevel data</a></li>
<li class="chapter" data-level="" data-path="ch29.html"><a href="ch29.html#references-18"><i class="fa fa-check"></i>References</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A <code>lavaan</code> Compendium for Structural Equation Modeling in Educational Research</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch11" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">11</span> Measures of Model Fit<a href="ch11.html#ch11" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>When the model is identified, then <span class="math inline">\(\mathbf{\Sigma}_\text{sample}\)</span> can be used to derive parameter estimates that yield a covariance matrix (<span class="math inline">\(\hat{\mathbf{\Sigma}}_{\text{model}}\)</span>) that is as close as possible to the observed sample covariance matrix. In general, when the discrepancies between <span class="math inline">\(\mathbf{\Sigma}_\text{sample}\)</span> and <span class="math inline">\(\hat{\mathbf{\Sigma}}_{\text{model}}\)</span> are large, this indicates that the specified model cannot give a good description of the data and therefore one might question whether the model is true in the population, i.e., whether the model is misspecified. For just-identified models, the model parameters can usually be estimated so that <span class="math inline">\(\hat{\mathbf{\Sigma}}_{\text{model}}\)</span> equals <span class="math inline">\(\mathbf{\Sigma}_\text{sample}\)</span>. Evaluation of model fit is therefore uninformative. The model that is specified might not necessarily be the ‘true’ model, but there is not enough information to evaluate possible misspecification of the model as a whole. For models that are over identified (i.e., that have positive degrees of freedom) the evaluation of model fit may be informative as it can give an indication as to what extent the discrepancies between <span class="math inline">\(\mathbf{\Sigma}_\text{sample}\)</span> and <span class="math inline">\(\hat{\mathbf{\Sigma}}_{\text{model}}\)</span> can be attributed to misspecification of the model. Below we first discuss the <span class="math inline">\(\chi^2\)</span> test of ‘exact fit’, then we explain the evaluation of ‘approximate fit’, and give a short overview of other descriptive measures of model fit. We also discuss the evaluation of differences in model fit, and finally show how to obtain all these measures of model fit in <code>lavaan</code>.</p>
<div id="the-chi-squared-test-of-exact-fit" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> The chi-squared test of exact fit<a href="ch11.html#the-chi-squared-test-of-exact-fit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <span class="math inline">\(\chi^2\)</span> test of exact fit is the basic statistical evaluation of overall model fit for over-identified SEMs. It is used to evaluate the following hypothesis:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{\text{population}} = \mathbf{\Sigma}_{\text{model}}, \hspace{50mm} (\text{11.01})
\]</span></p>
<p>where <span class="math inline">\(\mathbf\Sigma_{\text{population}}\)</span> refers to the matrix of population variances and covariances of the observed variables, and <span class="math inline">\(\mathbf\Sigma_{\text{model}}\)</span> refers to the population matrix of variances and covariances as implied by the path model. <span class="math inline">\(\mathbf\Sigma_{\text{model}}\)</span> is a function of model parameters (following Equations <a href="ch3.html#eq:3-09">(3.9)</a> and <a href="ch3.html#eq:3-10">(3.10)</a>. If the model gives a true description of reality then <span class="math inline">\(\mathbf\Sigma_{\text{model}}\)</span> is equal to the population variances and covariances <span class="math inline">\(\mathbf\Sigma_{\text{population}}\)</span>. However, these population matrices cannot be directly observed and therefore their values are unknown. Instead, the matrix of observed covariances <span class="math inline">\(\mathbf\Sigma_{\text{sample}}\)</span> is taken as an estimate of the population covariance matrix, and <span class="math inline">\(\hat{\mathbf\Sigma}_{\text{model}}\)</span> is the covariance matrix as implied by model parameters derived from the sample estimates. Because the sample covariance matrix and estimated model-implied covariance matrix are only estimates of their corresponding population covariance matrices, it is possible that <span class="math inline">\(\hat{\mathbf\Sigma}_{\text{population}} ≠ \hat{\mathbf\Sigma}_{\text{model}}\)</span>, even if <span class="math inline">\(\mathbf\Sigma_{\text{population}} = \mathbf\Sigma_{\text{model}}\)</span>. Figure <a href="ch11.html#fig:fig11-1">11.1</a> gives a graphical representation of the population covariance matrices (<span class="math inline">\(\mathbf\Sigma_{\text{population}}\)</span> and <span class="math inline">\(\mathbf\Sigma_{\text{model}}\)</span>) and the sample covariance matrices (<span class="math inline">\(\mathbf\Sigma_{\text{sample}}\)</span> and <span class="math inline">\(\hat{\mathbf\Sigma}_{\text{model}}\)</span>), and the different types of discrepancies that play a role in model fit evaluation. The term ‘sample discrepancy’ refers to the observed differences between the sample covariance matrix and the model-implied covariance matrix as derived from model parameter estimates. The term ‘population discrepancy’ refers to the differences between the population covariance matrix and the population model-implied covariance matrix.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig11-1"></span>
<img src="images/Ch11_discrepancy.png" alt="Population and sample covariance matrices that play a role in model fit evaluation." width="80%" />
<p class="caption">
Figure 11.1: Population and sample covariance matrices that play a role in model fit evaluation.
</p>
</div>
<p>The <span class="math inline">\(\chi^2\)</span> test of exact fit is based on the assumption that exact fit holds in the population, i.e., the population discrepancy is zero (<span class="math inline">\(\mathbf{\Sigma}_{\text{population}} = \mathbf{\Sigma}_{\text{model}}\)</span>). Under this null hypothesis, the <span class="math inline">\(p\)</span> value associated with the observed <span class="math inline">\(\chi^2\)</span> fit statistic gives the probability of observing a sample discrepancy (i.e., the difference between <span class="math inline">\(\hat{\mathbf\Sigma}_{\text{population}}\)</span> and <span class="math inline">\(\hat{\mathbf\Sigma}_{\text{model}}\)</span>) at least as large as the observed one, when any discrepancy is due solely to random sampling error. When this probability is very low (e.g., lower than <span class="math inline">\(\alpha = .05\)</span>), then we reject the null hypothesis of exact fit and conclude that the model does not hold in the population. In other words, we conclude that the model is misspecified (i.e., the population discrepancy is not zero but contains discrepancy due to misspecification).</p>
<p>The <span class="math inline">\(\chi^2\)</span> test of exact fit is based on the maximum likelihood (ML) discrepancy function. When all assumptions are satisfied, <span class="math inline">\((N − 1) \times \text{F}_{\text{ML}}\)</span> has a central <span class="math inline">\(\chi^2\)</span> distribution:</p>
<span class="math display" id="eq:11-01">\[\begin{equation}
\chi^2 = (N-1) \times \text{F}_\text{ML}
\tag{11.1}
\end{equation}\]</span>
<p>with degrees of freedom equal to</p>
<span class="math display" id="eq:11-02">\[\begin{equation}
df = ½ \hspace{1mm}(p \hspace{1mm} (p + 1)) - q
\tag{11.2}
\end{equation}\]</span>
<p>where <span class="math inline">\(p\)</span> is the number of observed variables and <span class="math inline">\(q\)</span> is the number of free model parameters to be estimated. If the <span class="math inline">\(p\)</span> value associated with the <span class="math inline">\(\chi^2\)</span> value is smaller than the significance level <span class="math inline">\(\alpha\)</span>, the null hypothesis of exact fit (i.e., <span class="math inline">\(\mathbf{\Sigma}_{\text{population}} = \mathbf{\Sigma}_{\text{model}}\)</span>) is rejected. Otherwise, the model is regarded as compatible with the population covariance matrix <span class="math inline">\(\mathbf{\Sigma}_{\text{population}}\)</span>. Note that when only the covariance structure is analysed, we use Wishart likelihood, so we multiply <span class="math inline">\(\text{F}_{\text{ML}}\)</span> by <span class="math inline">\(N - 1\)</span>, but when both mean and covariance structure are analysed (e.g., when analysing raw data, or when using any robust correction), we use normal likelihood, so we multiply <span class="math inline">\(\text{F}_{\text{ML}}\)</span> by <span class="math inline">\(N\)</span>.</p>
<p>The full mediation model of child anxiety from our illustrative example yields the following <span class="math inline">\(\chi^2\)</span> test result:</p>
<p><span class="math inline">\(\chi^2 = 7.429\)</span>, with <span class="math inline">\(df = 2\)</span>, and associated <span class="math inline">\(p\)</span> value <span class="math inline">\(= .024\)</span>.</p>
<p>Thus, the <span class="math inline">\(\chi^2\)</span> value is significant (at <span class="math inline">\(\alpha = .05\)</span>), so we reject the null hypothesis of exact fit.</p>
<div id="alternative-basis-for-calculating-the-test-statistic-when-analysing-raw-data" class="section level3 hasAnchor" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> Alternative basis for calculating the test statistic when analysing raw data<a href="ch11.html#alternative-basis-for-calculating-the-test-statistic-when-analysing-raw-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Equation <a href="ch11.html#eq:11-01">(11.1)</a> shows how to calculate <span class="math inline">\(\chi^2\)</span> from summary statistics (i.e., observed and model-implied covariance matrices, and optionally mean vectors). This equation only applies when analysing complete data. In practice, data are often partially observed. When some data are missing, you can use full-information maximum likelihood (FIML) estimation (review the last section of <a href="ch10.html#ch10-7">Chapter 10</a> for details).</p>
<p>We use a the log-likelihood (<span class="math inline">\(\ell\)</span>)<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> of the partially observed sample data, given the model parameters, to calculate the <span class="math inline">\(\chi^2\)</span> test statistic for the model. We can also use <span class="math inline">\(\ell\)</span> with complete data, in which case the <span class="math inline">\(\chi^2\)</span> value is the same as it would be using equation <a href="ch11.html#eq:11-01">(11.1)</a>. Although we discuss model comparison more thoroughly later in the chapter, calculating <span class="math inline">\(\chi^2\)</span> using <span class="math inline">\(\ell\)</span> implicitly involves a model comparison via a likelihood-ratio test (LRT; review the last section of <a href="ch10.html#ch10-6">Chapter 10</a> for details):</p>
<span class="math display" id="eq:11-03">\[\begin{equation}
\chi^2 = -2 \times (\ell_{\text{A}} - \ell_{\text{B}}) = -2 \ell_{\text{A}}(-2\ell_{\text{B}})
\tag{11.3}
\end{equation}\]</span>
<p>Notice that the <span class="math inline">\(\chi^2\)</span> statistic in equation <a href="ch11.html#eq:11-03">(11.3)</a> is the same quantity as the LRT in equation <a href="ch10.html#eq:10-06">(10.6)</a> in the <a href="ch10.html#ch10">previous chapter</a>. An individual model’s <span class="math inline">\(\chi^2\)</span> statistic is calculated by considering the target model as Model A, and the perfectly fitting saturated model as Model B. If the hypothesized model is the true data-generating model, then there should be little or no difference between <span class="math inline">\(\ell_{\text{Target}}\)</span> and <span class="math inline">\(\ell_{\text{Saturated}}\)</span>, so the <span class="math inline">\(\chi^2\)</span> statistic should be small (relative to its <span class="math inline">\(df\)</span>).</p>
</div>
<div id="testing-exact-fit-vs.-describing-the-degree-of-approximate-fit" class="section level3 hasAnchor" number="11.1.2">
<h3><span class="header-section-number">11.1.2</span> Testing exact fit vs. describing the degree of approximate fit<a href="ch11.html#testing-exact-fit-vs.-describing-the-degree-of-approximate-fit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In general, a researcher usually specifies a model that he or she thinks is the ‘true’ model, and therefore is interested in obtaining a non-significant <span class="math inline">\(\chi^2\)</span> value. However, is it realistic to assume that there is an exactly ‘true’ model that satisfies the assumption of exact fit, i.e., <span class="math inline">\(\mathbf{\Sigma}_{\text{population}} = \mathbf{\Sigma}_{\text{model}}\)</span>? It has been argued that it is implausible that any model that we specify is anything more than an approximation to reality (Brown &amp; Cudeck, 1992). When we assume that the models that we specify are only an approximation of a real data-generating process, then the null hypothesis that a model fits exactly in the population is known to be false <em>a priori</em>. Even if the discrepancy is small enough to be ignored in practice (i.e., because the model is approximately correct enough to be useful), small differences between <span class="math inline">\(\mathbf\Sigma_{\text{sample}}\)</span> and <span class="math inline">\(\hat{\mathbf\Sigma}_{\text{model}}\)</span> may become statistically significant in large samples (e.g., see Equation <a href="ch11.html#eq:11-01">(11.1)</a>). It has been argued that models that approximate the population covariance matrix will almost certainly be rejected under the null hypothesis of exact fit if sample size is sufficiently large (see for example Marsh, Balla, &amp; McDonald, 1988).</p>
<p>Therefore, rather than testing whether the model fits exactly in the population (when we already know the answer is no), it might be more sensible to assess the degree to which the model fits in the population. Numerous descriptive fit indices have been developed as an alternative to the <span class="math inline">\(\chi^2\)</span> test of exact fit. These descriptive fit indices do not provide a statistical significance test to assess model fit, but rather provide a descriptive evaluation of fit. Such indices are based on the idea that models are simplifications of reality and will never exactly hold in the population. Some of these fit indices take into account sample size, model parsimony, or compare the fit of the model to a baseline model. Fit indices typically have unknown sampling distributions, so they cannot be used as actual test statistics because there is no analytical way to derive a critical value<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> . However, this has not stopped some researchers from proposing ‘rules of thumb’ to delineate poor and good fit—these are typically treated as critical values by applied researchers, which is not how we recommend they be used. Rather, we recommend viewing descriptive fit indices as complementing the exact fit test in a way that is analogous to any statistical test being accompanied by a measure of effect size. In the case of statistically significant model misfit, fit indices can be used to assess whether the degree of misfit is of practical importance. Below we explain how a number of descriptive fit indices can be derived and interpreted.</p>
</div>
</div>
<div id="root-mean-square-error-of-approximation-rmsea" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Root Mean Square Error of Approximation (RMSEA)<a href="ch11.html#root-mean-square-error-of-approximation-rmsea" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One of the earliest and most popular descriptive fit indices is the Root Mean Square Error of Approximation (RMSEA; Steiger &amp; Lind, 1980). The rationale behind the RMSEA is that the null hypothesis of exact fit (i.e., <span class="math inline">\(\mathbf{\Sigma}_{\text{population}} = \mathbf{\Sigma}_{\text{model}}\)</span>) is invariably false in practical situations. Therefore, the hypothesis of exact fit is replaced by the hypothesis of approximate fit:</p>
<span class="math display" id="eq:11-04">\[\begin{equation}
\mathbf{\Sigma}_{\text{population}} \approx \mathbf{\Sigma}_{\text{model}},
\tag{11.4}
\end{equation}\]</span>
<p>where it assumed that the specified model will only be an approximation to reality and thus some specification error should be allowed such that <span class="math inline">\(\mathbf\Sigma_{\text{model}}\)</span> will never be exactly equal to <span class="math inline">\(\mathbf\Sigma_{\text{population}}\)</span>. However, a question that then comes up is: when do we decide that the model is a close enough approximation to reality? When we look at Figure <a href="ch11.html#fig:fig11-1">11.1</a>, the population discrepancy is not assumed to be zero under the hypothesis of approximate fit. But how large can the specification error be before a model should be rejected? To accommodate approximate fit within the context of model fit evaluation, an additional error term is introduced: the ‘error of approximation’. The error of approximation concerns the questions of how well the model with unknown but optimally chosen parameters can be expected to fit the population covariance matrix. Assuming that the model is not expected to hold exactly in the population there will always be a certain amount of approximation error. Given that the model holds approximately, the <span class="math inline">\((N − 1) \times \text{F}_{\text{ML}}\)</span> from Equation <a href="ch11.html#eq:11-01">(11.1)</a> follows a noncentral <span class="math inline">\(\chi^2\)</span> distribution, with noncentrality parameter <span class="math inline">\(\lambda\)</span>. Therefore, if you think that the model is an approximation of reality, you should evaluate <span class="math inline">\((N − 1) \times \text{F}_{\text{ML}}\)</span> against a noncentral <span class="math inline">\(\chi^2\)</span> distribution instead of a central <span class="math inline">\(\chi^2\)</span> distribution. The noncentrality parameter (<span class="math inline">\(\lambda\)</span>) can be estimated using<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>:</p>
<span class="math display" id="eq:11-05">\[\begin{equation}
\lambda = (N-1)\varphi_{\text{A}},
\tag{11.5}
\end{equation}\]</span>
<p>where <span class="math inline">\(\varphi_{\text{A}}\)</span> refers to the discrepancy due to approximation. Cudeck and Henly (1991) proposed that the approximation discrepancy, in turn, can be estimated with:</p>
<span class="math display" id="eq:11-06">\[\begin{equation}
\hat{\varphi}_{\text{A}} = \text{F}_{\text{ML}} - df / (N-1)
\tag{11.6}
\end{equation}\]</span>
<p>Substituting Equation 11.06 into Equation 11.05 gives an estimate of <span class="math inline">\(λ\)</span>:</p>
<span class="math display" id="eq:11-07">\[\begin{equation}
\hat{\lambda} = (N-1) \times \text{F}_{\text{ML}} - df, \hspace{3mm} \text{or, equivalently,} \hspace{3mm} \hat{\lambda} = \chi^2 - df.
\tag{11.7}
\end{equation}\]</span>
<p>The RMSEA is a measure of approximate fit, and is computed based on the sample size, the noncentrality parameter, and <span class="math inline">\(df\)</span> of the model. The noncentrality parameter is divided by <span class="math inline">\(df \times (N − 1)\)</span>, which makes it less sensitive to changes in sample size, and produces a measure of misspecification per <span class="math inline">\(df\)</span>. It therefore also takes model parsimony into account. The point estimate of the RMSEA is calculated as follows:</p>
<span class="math display" id="eq:11-08">\[\begin{equation}
\text{RMSEA} = \sqrt{\frac{\text{max}((\chi^2 - df), 0)}{df(N-1)}} = \sqrt{\frac{\text{max}\hat{\lambda},0)}{df(N-1)}}
\tag{11.8}
\end{equation}\]</span>
<p>Notice that if <span class="math inline">\(\chi^2 &lt; df\)</span>, then the RMSEA is set to zero. An RMSEA of zero indicates the model fits at least as well as would be expected if the null hypothesis of exact fit were true. In evaluating the value of the RMSEA, we accept some error of approximation. Browne and Cudeck (1992) suggested that an <span class="math inline">\(\text{RMSEA} &lt; .05\)</span> indicates “close fit”, an RMSEA between 0.05–0.08 is thought to indicate a “reasonable error of approximation”, and that models with an RMSEA <span class="math inline">\(&gt; 0.10\)</span> have poor fit. MacCallum, Browne, and Sugawara (1996) suggested that RMSEA between 0.08–0.10 indicates “mediocre” fit.</p>
<p>A confidence interval (CI) can be computed for RMSEA. Ideally the lower value of the 90% CI includes or is very near zero and the upper value is not very large, i.e., less than 0.08. However, this is only typically achieved in practice when both of two conditions hold: large sample size and large <span class="math inline">\(df\)</span>. Kenny, Kaniskan, and McCoach (2015) show that when either of the terms in the denominator of RMSEA (<span class="math inline">\(N\)</span> or <span class="math inline">\(df\)</span>; see equation <a href="ch11.html#eq:11-08">(11.8)</a> above) are small, the sampling variability of RMSEA is very erratic, so it is nearly impossible to trust the estimated RMSEA in any single sample when either <span class="math inline">\(N\)</span> or <span class="math inline">\(df\)</span> are small. Unfortunately, this will almost always be the case with a path model, which typically have very small <span class="math inline">\(df\)</span> even when there are many variables, regardless of how large the sample is. So in practice, RMSEA may only be informative in latent variable models, in which many observed variables are modeled as being associated (often indirectly) via many fewer common factors.</p>
<p>In our illustrative example, the RMSEA value of the full mediation model is 0.189, with a 90% CI of 0.058–0.343. Thus, the point estimate of the RMSEA indicates poor model fit, and the CI is very wide. The CI therefore gives an indication of the imprecision of the estimated point estimate of the RMSEA. As a comparison, the RMSEA value of the partial mediation model is 0, with a 90% CI of 0.000–0.259. The RMSEA indicates exact fit (because this model is saturated, it fits perfectly by definition, so <span class="math inline">\(\chi^2 = 0\)</span>; however, <span class="math inline">\(\text{RMSEA} = 0\)</span> in over-identified models whenever <span class="math inline">\(\chi^2 &lt; df\)</span>), but the CI shows (again) that the point estimate of RMSEA is not very precise.</p>
<p>Browne and Cudeck (1992) proposed the ‘test of close fit’ where it is tested whether RMSEA is significantly greater than .05 (i.e., the null hypothesis is that if we fit our model to the population covariance matrix, RMSEA ). We conduct the test by constructing a CI, using a confidence level that is <span class="math inline">\(2 \times \alpha\)</span> (so that we can conduct a one-sided test of our directional hypothesis using the CI). For example, using <span class="math inline">\(α = .05\)</span> as criterion, we use a 90% CI for RMSEA. When the lower confidence limit &gt; 0.05, we can reject the null hypothesis of close fit (because the entire CI is above the 0.05 threshold). MacCallum et al. (1996) extended this idea by ‘flipping’ the null hypothesis (i.e., that the population <span class="math inline">\(\text{RMSEA} \ge 0.05\)</span>), which they called a “test of not-close fit”. When the upper confidence limit of the <span class="math inline">\(\text{RMSEA} &lt; 0.05\)</span>, we can reject the null hypothesis of not-close fit (because the entire CI is below the 0.05 threshold). Different thresholds could also be used—for example, 0.08 can be used to provide a ‘test of approximate fit’ or ‘not-approximate fit’.</p>
<p>The only distinction between tests of close vs. not-close fit is which one you use as the null hypothesis. Recall that one very useful interpretation of a CI is that it is a range of null hypothesized values that could not be rejected using the sample data. In our example from <a href="ch7.html#ch7">chapter 7</a>, the partial mediation model has exact fit (<span class="math inline">\(\chi^2\)</span> and <span class="math inline">\(\text{RMSEA} = 0\)</span>), but the 90% CI ranges from 0.000–0.259, so we could not reject a null hypothesis of exact fit (<span class="math inline">\(\text{RMSEA} = 0\)</span>), of close fit (<span class="math inline">\(\text{RMSEA} \le 0.05\)</span>), a null hypothesis of approximate fit (<span class="math inline">\(\text{RMSEA} \le 0.08\)</span>), a null hypothesis of mediocre fit (<span class="math inline">\(\text{RMSEA} \le 0.10\)</span>), or a null hypothesis of poor fit (<span class="math inline">\(\text{RMSEA} &gt; 0.10\)</span>). Because no possible null hypothesis could be rejected (i.e., no theory could be falsified), the RMSEA in this example is effectively useless (i.e., it is uninformative in any practical sense). As Kenny et al. (2015) indicated, this is to be expected whenever <span class="math inline">\(N\)</span> or <span class="math inline">\(df\)</span> are small.</p>
</div>
<div id="other-descriptive-fit-indices" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Other descriptive fit indices<a href="ch11.html#other-descriptive-fit-indices" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Below, we give a short description of other popular descriptive fit indices. We limit our discussion to the fit indices that are provided by <code>lavaan</code>’s <code>summary()</code> output (which are also the indices provided by M<em>plus</em>), although many additional indices are available from <code>lavaan</code>’s <code>fitMeasures()</code> function, as well as the <code>moreFitIndices()</code> function in the <code>semTools</code> package. The information on the different fit indices is kept as concise as possible, but more detailed overviews of these (and other) fit indices can be found in other sources (e.g., Bollen, 1989; Schermelleh-Engel, Moosbrugger, &amp; Müller, 2003; West, Taylor, &amp; Wu, 2012).</p>
<div id="the-tuckerlewis-index-tli-and-the-comparative-fit-index-cfi" class="section level3 hasAnchor" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> The Tucker–Lewis Index (TLI) and the Comparative Fit Index (CFI)<a href="ch11.html#the-tuckerlewis-index-tli-and-the-comparative-fit-index-cfi" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Tucker–Lewis Index (TLI; Tucker &amp; Lewis, 1973) and the Comparative Fit Index (CFI; Bentler, 1990) are so-called incremental fit indices (also called relative or comparative fit indices). Incremental fit indices compare the fit of the model of interest with a baseline or null model. Tucker and Lewis (1973) original developed TLI as a sort of reliability coefficient for extracting the correct number of factors in exploratory factor analysis. However, Bentler and Bonett (1980) developed a framework for different types of incremental fit indices and illuminated their particular advantage in comparing models, which we will discuss later in this chapter.</p>
<p>Conceptually, incremental fit indices place a target model somewhere on a continuum between the best fitting (i.e., perfectly fitting saturated) model and the worst fitting (but still theoretically plausible) model. Figure <a href="ch11.html#fig:fig11-2">11.2</a> depicts this conceptual continuum, which is anchored on the left by zero because a model cannot fit better than perfectly (i.e., zero discrepancy). On the right, the null model is as poorly fitting as we can conceive being plausible (e.g., without constraining variances to equal one million for 7-point Likert scales), although greater discrepancies are possible. If our target model is a good approximation of the true data-generating model (i.e., the “population”), then our target model should be much closer to the left-hand side of the continuum than to the right-hand side. In general, incremental fit indices range from 0 to 1, so they could be interpreted as a proportion of the continuum in Figure <a href="ch11.html#fig:fig11-2">11.2</a>, with higher values indicating better fit.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig11-2"></span>
<img src="images/Ch11_TLI.png" alt="Continuum between poor and perfect fit." width="80%" />
<p class="caption">
Figure 11.2: Continuum between poor and perfect fit.
</p>
</div>
<p>The most common choice for the baseline model is the so-called independence model, where all covariances in <span class="math inline">\(\mathbf\Sigma_{\text{population}}\)</span> are assumed zero. Although other baseline models could be used, this is not often seen in practice<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>. There are several incremental fit indices, but here we limit the discussion to the TLI and CFI because they have shown the most favourable properties in simulation research (e.g., insensitivity to sample size, sensitivity to model misspecification). The TLI, also referred to as the non-normed fit index (NNFI) by Bentler and Bonett (1980), is calculated using the <span class="math inline">\(\chi^2\)</span> and <span class="math inline">\(df\)</span> of the independence (null) and target (model) models:</p>
<span class="math display" id="eq:11-09">\[\begin{equation}
\text{TLI} = \frac{\frac{\chi^2_{\text{null}}}{df_{\text{null}}}-\frac{\chi^2_{\text{model}}}{df_{\text{model}}}}{\frac{\chi^2_{\text{null}}}{df_{\text{null}}}-1}
\tag{11.9}
\end{equation}\]</span>
<p>Because TLI is not normed (i.e., not forced to be within the bounds of 0 and 1), the values of the TLI will be larger than 1 whenever the target model’s <span class="math inline">\(\chi^2 &lt; df\)</span>, or may even be slightly below 0 if the target model’s <span class="math inline">\(\chi^2\)</span>-to-<span class="math inline">\(df\)</span> ratio is greater than the null model’s ratio.</p>
<p>The CFI is calculated in a very similar way as the TLI, but uses the differences between <span class="math inline">\(\chi^2\)</span> and <span class="math inline">\(df\)</span> of the null and target models (recall from equation <a href="ch11.html#eq:11-07">(11.7)</a> that this difference is an estimate of the noncentrality parameter <span class="math inline">\(\hat{\lambda}\)</span>):</p>
<span class="math display" id="eq:11-10">\[\begin{equation}
\text{CFI} = \frac{\text{max}[0,(\chi^2_{\text{null}}-df_{\text{null}})]-\text{max}[0,(\chi^2_{\text{model}}-df_{\text{model}})]}{\text{max}[0,(\chi^2_{\text{null}}-df_{\text{null}})]} = 1-\frac{\text{max}[0,(\chi^2_{\text{model}}-df_{\text{model}})]}{\text{max}[0,(\chi^2_{\text{null}}-df_{\text{null}}),(\chi^2_{\text{model}}-df_{\text{model}})]}
\tag{11.10}
\end{equation}\]</span>
<p>In this formula, the numerator is 0 if the target model’s <span class="math inline">\(\chi^2 &lt; df\)</span>, and the denominator is equal to the numerator if the target model’s <span class="math inline">\(\chi^2 &lt; df\)</span> or if the null model fits at least as well as the target model. This ensures that the CFI will range between 0 and 1.</p>
<p>As a rule of thumb, TLI or <span class="math inline">\(\text{CFI} &gt; .90\)</span> (Bentler &amp; Bonett, 1980) or <span class="math inline">\(&gt; .95\)</span> (Hu &amp; Bentler, 1999) may be interpreted as indicative of good fit relative to the null model. TLI and CFI take model complexity into account and are relatively unaffected by samples size (Bollen, 1990; Hu &amp; Bentler, 1998; Marsh, Balla, &amp; McDonald, 1988; West et al., 2012). However, they are sensitive to the size of the observed covariances. The closer the observed covariances are to zero (especially a majority), the more <span class="math inline">\(\mathbf\Sigma_{\text{sample}}\)</span> resembles the independence model, which makes it more difficult for a target model to cross the divide between the null and saturated models.</p>
</div>
<div id="the-root-mean-square-residual-rmr-and-standardized-rmr-srmr" class="section level3 hasAnchor" number="11.3.2">
<h3><span class="header-section-number">11.3.2</span> The Root Mean Square Residual (RMR) and Standardized RMR (SRMR)<a href="ch11.html#the-root-mean-square-residual-rmr-and-standardized-rmr-srmr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>RMR (Jöreskog &amp; Sörbom, 1981) and SRMR (Bentler, 1995) are overall badness-of-fit measures that are based on the fitted residuals (i.e., difference between model-implied and sample covariance matrices).</p>
<span class="math display" id="eq:11-11">\[\begin{equation}
\text{RMR} = \sqrt{\frac{\sum_{i=1}^p \sum_{j=1}^i (s_{ij}-\hat\sigma_{ij})^2}{p(p+1)/2}}
\tag{11.11}
\end{equation}\]</span>
<p>RMR is defined as the square-root of the mean of the squared fitted residuals. In principle, RMR values close to zero suggest a good fit. But as the elements of <span class="math inline">\(\mathbf{S}\)</span> and <span class="math inline">\(\mathbf\Sigma\)</span> are scale dependent, the fitted residuals are scale dependent, too, which implies that RMR depends on the sizes of the variances and covariances of the observed variables. In other words, without taking the scales of the variables into account, it is virtually impossible to say whether a given RMR value indicates good or bad fit. To overcome this problem, the standardized RMR was been introduced, where the residuals <span class="math inline">\(s_{ij}\)</span> and <span class="math inline">\(\hat\sigma_{ij}\)</span> are standardized using the variances of the observed variables (i.e., <span class="math inline">\(s_{ii}\)</span> and <span class="math inline">\(s_{jj}\)</span> from the sample covariance matrix<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>).</p>
<span class="math display" id="eq:-">\[\begin{equation}
\text{SRMR} = \sqrt{\frac{\sum_{i=1}^{p} \sum_{j=1}^{i} \Big( \frac{s_{ij} - \hat\sigma_{ij}}{\sqrt{s_{ii}s_{jj}}} \Big)^2}{\frac{p(p+1)}{2}}}  =  \sqrt{\frac{\sum_{i=1}^{p} \sum_{j=1}^{i} \frac{(s_{ij} - \hat\sigma_{ij})^2}{s_{ii}s_{jj}} }{\frac{p(p+1)}{2}}}
\tag{11.12}
\end{equation}\]</span>
<p>SRMR continues to be popular despite its limitations. Interpreting SRMR is complicated by the fact that its expected value varies with sample size, but as a rule of thumb SRMR values lower than .05 are taken as indicative of good fit, and SRMR lower than .10 may be interpreted as acceptable fit. However, we do not recommend paying attention to SRMR as a global measure of overall model fit; rather, we recommend paying attention to individual correlation residuals, as described in chapter 8 on model modification. In that example, the average correlation residual was SRMR = .087, which would indicate acceptable (but not good) global fit. However, most of the correlation residuals were zero, so the average (SRMR) masked the fact that the largest correlation residual (.272) was unacceptably large, indicating a severe local source of model misspecification.</p>
</div>
<div id="information-criteria" class="section level3 hasAnchor" number="11.3.3">
<h3><span class="header-section-number">11.3.3</span> Information Criteria<a href="ch11.html#information-criteria" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Akaike Information Criterion (AIC; Akaike, 1987) and so-called “Bayesian”<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> Information Criterion (BIC; Raftery, 1986, 1995) are fit indices that were developed specifically to compare models fit to the same data. In general, lower values indicate a better fit, so the model with the lowest value is the best fitting model after adjusting for model complexity (as measured by the number of free parameters in the model). However, the absolute value is irrelevant; only the AIC (or BIC) of one model relative to the AIC (or BIC) of another model can be meaningfully interpreted. An advantage of these fit indices is that the competing models do not need to be nested. A disadvantage is that they are based on likelihoods, so they are only available when using ML estimation (e.g., not using WLS for modelling categorical outcomes).</p>
<p>The values of information criteria can differ across software even when the model parameters and fit statistics are the same. The differences are not really meaningful as they all lead to the same ordering of competing models, but they differ because there are different formulas for AIC. One formula is based on the log-likelihood of the model (<span class="math inline">\(\ell\)</span>):</p>
<span class="math display" id="eq:11-13">\[\begin{equation}
\text{AIC} = \ell − q
\tag{11.13}
\end{equation}\]</span>
<p>where <span class="math inline">\(q\)</span> is the number of free parameters in the model. Another formula is based on <span class="math inline">\(−2\ell\)</span> (which is the one reported in <code>lavaan</code>):</p>
<span class="math display" id="eq:11-14">\[\begin{equation}
\text{AIC} = -2\ell + 2q
\tag{11.14}
\end{equation}\]</span>
<p>which is simple <span class="math inline">\(−2\)</span> times the formula in <a href="ch11.html#eq:11-13">(11.13)</a>. Finally, AIC can also be calculated using the <span class="math inline">\(\chi^2\)</span> statistic instead of <span class="math inline">\(−2\ell\)</span> in <a href="ch11.html#eq:11-14">(11.14)</a>, which yields the same rank-order of candidate models because each competing model’s <span class="math inline">\(\chi^2\)</span> is calculated relative to the same saturated model (see equation <a href="ch11.html#eq:11-03">(11.3)</a>). Regardless of which formula is used, AIC penalizes models that have more free parameters (i.e., are more complex). The rationale behind information criteria is that a model with more estimated parameters (some of which may be near zero in the population) should not be favoured over a model that may be slightly simplified but provides similar predictions as the more complex model. AIC was developed specifically to identify which among a set of models would be expected to have the least prediction error when fitted to new samples (i.e., to identify which model generalizes best).</p>
<p>The BIC was derived based on Bayesian theory (an alternative to classical “frequentist” hypothesis testing) as a rough approximation of the log of a Bayes factor (the Bayesian analogue of a LRT) comparing the target model to the saturated model. The resulting index is similar to the AIC, but the penalty against complex models increases as sample size increases:</p>
<span class="math display" id="eq:11-15">\[\begin{equation}
\text{BIC} = -2\ell + \log(N) \times q
\tag{11.15}
\end{equation}\]</span>
<p>where <span class="math inline">\(\log(N)\)</span> is the natural logarithm of the number of cases in the sample. Similar to AIC, an alternative calculation of BIC would be to use <span class="math inline">\(\chi^2\)</span> instead of <span class="math inline">\(−2\ell\)</span> in equation <a href="ch11.html#eq:11-15">(11.15)</a>, which provides identical rank-ordering of competing models.</p>
<p>Simulations have shown that BIC tends to select the true model if it is in the set of competing models (which may never be true in practice), whereas the AIC tends to select the model that makes the most accurate predictions about new samples, regardless of whether the true model is in the candidate set. They both perform better with larger samples, so small-sample adjustments have been proposed. The Sample-Size Adjusted BIC (SABIC; Sclove, 1987) uses <span class="math inline">\(\log(\frac{N+2}{24})\)</span>) instead of <span class="math inline">\(\log(N)\)</span> in equation<a href="ch11.html#eq:11-14">(11.14)</a>, which places a smaller emphasis on parsimony. In contrast, the corrected AIC (AICc; Burnham &amp; Anderson, 2003) adds <span class="math inline">\(\frac{2q(q+1)}{(N-q-1)}\)</span> to AIC (as defined in equation <a href="ch11.html#eq:11-14">(11.14)</a>), placing even greater emphasis on parsimony. This is necessary because in small samples, AIC is more likely to select a model that overfits to sample nuances, reducing its generalizability.</p>
</div>
</div>
<div id="a-note-on-using-available-fit-indices" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> A note on using available fit indices<a href="ch11.html#a-note-on-using-available-fit-indices" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There exists considerable controversy concerning the use of fit indices. Some researchers do not believe that descriptive fit indices are of much added value, and that the <span class="math inline">\(\chi^2\)</span> test of exact fit should be the only substantive test of model fit applied (e.g., Barrett, 2007). Another problem is that with so many different alternative fit indices to choose from, one might be tempted to choose to report only those indices that support your model, based on arbitrary rules-of-thumb. This might result in too many misspecified models being reported as ‘acceptable’ models. Also, some argue that cutoffs for a descriptive fit index can be misleading as these descriptive fit indices are then wrongfully treated as actual test statistics (e.g., Hayduk, Cummings, Boadu, Pazderka-Robinson, &amp; Boulianne, 2007). Some researchers have argued that a specific combination of descriptive fit indices should be preferred for model evaluation (e.g., Hu &amp; Bentler, 1999). In general, it could be recommended to inspect and report several descriptive fit indices, in addition to the <span class="math inline">\(\chi^2\)</span> test, but that the researcher should be aware that choice of the specific fit index might depend on the specifics of the data (e.g., sample size) or model (e.g., complexity) and the specific goal of model evaluation (e.g., confirmatory versus exploratory, comparing competing (non)nested models, model parsimony, explanatory power, etc.). Several papers discuss recommendations for the use of the different fit indices described above (and several others) and their potential problems (e.g., see Schermelleh-Engel, Moosbrugger &amp; Müller, 2003; Hu &amp; Bentler, 1999; Marsh, Hau &amp; Wen, 2004). Most importantly, as a researcher one should not forget that substantive theory-relevant criteria can (and should always) play a major role in the evaluation of model fit (e.g., Barret, 2007; Hayduk, et al., 2007).</p>
</div>
<div id="difference-in-model-fit" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> Difference in model fit<a href="ch11.html#difference-in-model-fit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In applications of covariance structure analysis, researchers often face the problem of choosing among two or more alternative models. The choice of which measure to use for selecting one of several competing models depends on whether or not the models are nested. A specific model (Model A) is said to be nested within a less restricted model (Model B) with more parameters (i.e., fewer <span class="math inline">\(df\)</span>) than Model A, if Model A can be derived from Model B only by introducing restrictions. For example, by fixing free parameters in Model B or by constraining a free parameter to equal to one or more other parameters. This is known as <em>parameter nesting</em><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>: any two models are nested when the free parameters in the more restrictive model are a subset of the free parameters in the less restrictive model. Additionally, if A and B have the same <span class="math inline">\(df\)</span>, then they are <em>equivalent</em> models, which is a special case of nesting.</p>
<p>As the test statistic of each of the nested models follows a <span class="math inline">\(\chi^2\)</span> distribution, the difference in <span class="math inline">\(\chi^2\)</span> values between two nested models is also <span class="math inline">\(\chi^2\)</span> distributed:</p>
<span class="math display" id="eq:11-16">\[\begin{equation}
\Delta\chi^2= \chi_A^2 - \chi_B^2 ,
\tag{11.16}
\end{equation}\]</span>
<p>with df for the difference equal to the difference in df for the two models:</p>
<span class="math display" id="eq:11-17">\[\begin{equation}
\Delta df = df_A - df_B
\tag{11.17}
\end{equation}\]</span>
<p>Thus, testing the difference in model fit can be tested comparing <span class="math inline">\(\Delta\chi^2\)</span> to a <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(\Delta df\)</span>, which is called the <span class="math inline">\(\chi^2\)</span> difference test. If <span class="math inline">\(\Delta\chi^2\)</span> is significant, the null hypothesis of equal fit for both models is rejected, so the less restrictive Model B should be retained. But if <span class="math inline">\(\Delta\chi^2\)</span> is not significant, the fit of the restricted model (Model A) is not significantly worse than the fit of the unrestricted model (Model B), so the null hypothesis of equal fit cannot be rejected. On the parsimony principle (Occam’s razor), we should favour the more restrictive (i.e., simpler) Model A.</p>
<p>In our illustrative example of child anxiety, the difference in model fit between the full mediation model (Model A) and the partial mediation model (Model B) is:
<span class="math display">\[
\Delta\chi^2= \chi_A^2-\chi_B^2 = 7.429 - 0.402 = 7.027,
\]</span>
<span class="math display">\[
\text{with} \hspace{2mm} \Delta df = df_A - df_B = 2 - 1 = 1 .
\]</span></p>
<p>The associated <span class="math inline">\(p\)</span> value is .008, indicating that the difference in model fit is significant at <span class="math inline">\(α = .05\)</span>. The fit of the full mediation model is significantly worse than the fit of the partial mediation model, so we would favour the latter model.</p>
<p>Likewise, a single target model’s <span class="math inline">\(\chi^2\)</span> statistic can be thought of as a <span class="math inline">\(\Delta\chi^2\)</span> statistic using equations <a href="ch11.html#eq:11-16">(11.16)</a> and <a href="ch11.html#eq:11-17">(11.17)</a>, where Model B is replaced with the saturated Model S. In our illustrative example of child anxiety the overall <span class="math inline">\(\chi^2\)</span> is then obtained by:
<span class="math display">\[
\Delta\chi^2 = \chi_A^2 - \chi_S^2 = \chi_A^2 - 0 = 7.429 - 0 = 7.429 ,     
\]</span>
<span class="math display">\[
\text{with} \hspace{2mm} \Delta df = df_A - df_S = df_A - 0 = 2 - 0 = 2.
\]</span></p>
<div id="deltachi2-as-a-likelihood-ratio-test" class="section level3 hasAnchor" number="11.5.1">
<h3><span class="header-section-number">11.5.1</span> <span class="math inline">\(\Delta\chi^2\)</span> as a likelihood ratio test<a href="ch11.html#deltachi2-as-a-likelihood-ratio-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall from equation 11.03 that a model’s <span class="math inline">\(\chi^2\)</span> statistic is the LRT from equation 9.06, treating the target model as Model A and the saturated model as Model B. The <span class="math inline">\(\Delta\chi^2\)</span> test is also a log-likelihood ratio, so equation 11.15 could equivalently be calculated using equation 11.03. The reason the two equations yield the same result is that each model’s <span class="math inline">\(\chi^2\)</span> statistic is calculated using the same saturated model’s log-likelihood (<span class="math inline">\(\ell_S\)</span>), so they cancel out. Labelling the saturated model as Model S instead of B in equation 11.03, the LRT for two nested hypothetical Models A (in ) and B (in ) could be calculated using each of their LRT statistics:</p>
<p><span class="math display">\[\begin{align*}
\Delta\chi^2 &amp; =  \color{green}{[-2\ell_A-(-2\ell_S )]}-\color{blue}{[-2\ell_B-(-2\ell_S )]} \\
&amp; =\color{green}{-2\ell_A}+\color{red}{2\ell_S}+\color{blue}{2\ell_B}-\color{red}{2\ell_S} \\
&amp; =\color{green}{-2\ell_A}+\color{blue}{2\ell_B} \\
&amp; =\color{green}{-2\ell_A}-\color{blue}{(-2\ell_B )}
\end{align*}\]</span></p>
</div>
<div id="describing-differences-in-fit" class="section level3 hasAnchor" number="11.5.2">
<h3><span class="header-section-number">11.5.2</span> Describing differences in fit<a href="ch11.html#describing-differences-in-fit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <span class="math inline">\(\chi^2\)</span> difference test applied to nested models has essentially the same strengths and weaknesses as the <span class="math inline">\(\chi^2\)</span> test applied to any single model; namely, trivial differences can be detected as statistically significant in large samples. Thus, a researcher may supplement the significance test for difference in fit by reporting a difference in a descriptive fit index. In the case of RMSEA, equation <a href="ch11.html#eq:11-08">(11.8)</a> can actually be applied to <span class="math inline">\(\Delta\chi^2\)</span> and <span class="math inline">\(\Delta df\)</span> instead of <span class="math inline">\(\chi^2\)</span> and <span class="math inline">\(df\)</span>. This was proposed as the Root Deterioration per Restriction (RDR), but it never became popular because it behaved so erratically. Recall that the RMSEA itself performs very poorly when either <span class="math inline">\(N\)</span> or <span class="math inline">\(df\)</span> are small, which explains why RDR performs so poorly: rarely will two models be compared that have a very large difference in <span class="math inline">\(df\)</span> (<span class="math inline">\(\Delta df\)</span>).</p>
<p>Instead, <span class="math inline">\(\Delta\text{CFI}\)</span> has become very popular, particularly when testing measurement equivalence across groups or occasions (we will discuss this later in the course). However, these fit indices have unknown sampling distributions, they should not be used as test statistics<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>, but rather as a kind of effect size that would typically accompany a significance test. Analogously, when using a t test to compare means, small differences might be statistically significant in large samples, so Cohen’s <span class="math inline">\(d\)</span> is used to indicate whether the observed difference is of practical importance. Unfortunately, there are few guidelines for what would constitute a meaningful difference in CFIs between models, and the few proposed rules-of-thumb have been made for very specific situations (e.g., measurement invariance).</p>
<p>Incremental fit indices in general have the advantage of being able to compare models regardless of whether they are nested (Bentler &amp; Bonett, 1980). This is because all possible competing models are nested within the same saturated model, by definition. So as long as a single null model is specified <em>that is nested within each candidate model</em><a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>, calculating the CFI for each candidate models allows us to see where each competing model lies on the same continuum between poor and perfect fit. Supposing we have three candidate models, the one with the largest CFI is the one furthest to the left in Figure <a href="ch11.html#fig:fig11-3">11.3</a> (i.e., Target Model 3):</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fig11-3"></span>
<img src="images/ch11_competing_models.png" alt="Placing competing models on the same continuum." width="80%" />
<p class="caption">
Figure 11.3: Placing competing models on the same continuum.
</p>
</div>
<p>Because CFI and TLI implicitly account for model complexity by using the model’s <span class="math inline">\(df\)</span> to adjust the model’s fit (using the noncentrality parameter and the <span class="math inline">\(\chi^2\)</span>-to-<span class="math inline">\(df\)</span> ratio, respectively), the continuum in Figure <a href="ch11.html#fig:fig11-3">11.3</a> represents complexity-adjusted fit.</p>
<p>The model with the lowest AIC (or BIC) could also be selected as the model that best balances fit and parsimony. This model-selection procedure has typically been used in place of a <span class="math inline">\(\chi^2\)</span> difference test when the models are not nested; however, this procedure does not take sampling variability into account, so it is not truly a test of (comparative) model fit. Furthermore, simply choosing the lowest AIC suffers the same limitation as choosing the highest CFI—it is unclear what constitutes a meaningful difference in values between two models.</p>
</div>
<div id="testing-differences-in-fit-between-non-nested-models" class="section level3 hasAnchor" number="11.5.3">
<h3><span class="header-section-number">11.5.3</span> Testing differences in fit between non-nested models<a href="ch11.html#testing-differences-in-fit-between-non-nested-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Test statistics have also been developed for non-nested models (Merkle, You, &amp; Preacher, 2016). If each individual log-likelihood <span class="math inline">\(\ell_i\)</span> is calculated under Model A and under Model B, then the difference between individual <span class="math inline">\(i\)</span>’s log-likelihoods (<span class="math inline">\(\Delta\ell_i\)</span>) reveals which model most likely “generated” this person’s observed data. A weighted sum of these <span class="math inline">\(\Delta\ell_i\)</span> is an asymptotically normally distributed statistic, with a <span class="math inline">\(\mu = 0\)</span> if the null hypothesis of equal fit is true, so it can be used to conduct a <span class="math inline">\(z\)</span> test. A significant test indicates that Model A fits better than Model B (if the statistic is positive) or vice versa (if the statistic is negative); otherwise there is not enough evidence to prefer one model over another. This is called the Vuong test after its developer (Vuong, 1989, as cited in Merkle et al., 2016).</p>
<p>We can also use the variability of <span class="math inline">\(\Delta\ell_i\)</span> to calculate a 95% CI (assuming <span class="math inline">\(α = .05\)</span>) for the difference between two model’s AICs (or BICs). This provides a test of fit that takes model parsimony into account. Assuming the null hypothesis of equal complexity-adjusted fit is true, <span class="math inline">\(\Delta\text{AIC}\)</span> (or <span class="math inline">\(\Delta\text{BIC}\)</span>) is zero in the population. Testing this null hypothesis is as simple as checking whether the 95% CI for <span class="math inline">\(\Delta\text{AIC}\)</span> (or <span class="math inline">\(\
\)</span>$ includes zero. If so, you cannot reject the null hypothesis. Otherwise, the model with the lower AIC (or BIC) should be preferred.</p>
<p>Because the Vuong test and CIs for information criteria area calculated from individual <span class="math inline">\(\Delta\ell_i\)</span>, they can only be calculated when using MLE to fit the model to complete data that are multivariate normally distributed. Furthermore, they cannot be used if you only have access to summary statistics (like most of our teaching examples), which is rarely a problem in practice. Although it is theoretically possible to extend the Vuong test to least-squares estimators (e.g., WLS for categorical outcomes), this extension has yet to be developed (Merkle et al., 2016). Because these tests have only recently begun being investigated in an SEM framework, more research is needed to see how robust they are when data deviate from multivariate normality (i.e., when <span class="math inline">\(\ell_i\)</span> are calculated using equation <a href="ch10.html#eq:10-05">(10.5)</a> even though data do not follow the distribution described by <a href="ch10.html#eq:10-04">(10.4)</a>).</p>
</div>
</div>
<div id="request-fit-measures-in-lavaan" class="section level2 hasAnchor" number="11.6">
<h2><span class="header-section-number">11.6</span> Request fit measures in <code>lavaan</code><a href="ch11.html#request-fit-measures-in-lavaan" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <code>summary()</code> function has an argument to request information about model fit from the lavaan output:</p>
<pre><code>summary(AWmodelOut, fit.measures = TRUE)</code></pre>
<p>Notice that <code>lavaan</code> will print the <span class="math inline">\(\chi^2\)</span> test for both the target model and the default baseline model (i.e., the independence model), as well as RMSEA (including a 90% CI), CFI and TLI, SRMR (and WRMR when outcomes are categorical), and information criteria when using MLE (specifically, AIC, BIC, and SABIC). Several other fit indices are available from two different functions. The first is <code>lavaan</code>’s function <code>fitMeasures()</code>. The default is to print all available fit measures:</p>
<pre><code>fitMeasures(AWmodelOut)</code></pre>
<p>But there are too many to easily read. It is better to request only the fit measures you want to see (e.g., when you want to calculate changes such as <span class="math inline">\(\Delta\text{CFI}\)</span>):</p>
<pre><code>myFitIndices &lt;- c(&quot;chisq&quot;,&quot;df&quot;,&quot;pvalue&quot;,&quot;cfi&quot;,&quot;aic&quot;)
fitMeasures(AWmodelOut, fit.measures = myFitIndices)</code></pre>
<p>The function <code>moreFitIndices()</code> is available in the <code>semTools</code> package, and it provides a few other options, such as AICc (labelled “<code>aic.smallN</code>”):</p>
<pre><code>library(semTools)
moreFitIndices(AWmodelOut, fit.measures = &quot;aic.smallN&quot;)</code></pre>
<div id="compare-fit-of-lavaan-models" class="section level3 hasAnchor" number="11.6.1">
<h3><span class="header-section-number">11.6.1</span> Compare fit of lavaan models<a href="ch11.html#compare-fit-of-lavaan-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the difference in fit between the original path model for the development of child anxiety from <a href="#Ch3">Chapter 3</a> and the less constrained model with the additional direct effect from Parent Anxiety to Child Anxiety from <a href="#Ch8">Chapter 8</a>. You can use the <code>anova()</code> function, providing both models as arguments. The order of models does not matter because <code>lavaan</code> will sort them in order of increasing df automatically.</p>
<pre><code>anova(AWmodelOut, AWmodel2Out) </code></pre>
<p>The function <code>lavTestLRT()</code> is used the same way as <code>anova()</code>, but it has some more options (mainly, what adjustment to use if data are not normally distributed). In fact the anova() function merely calls <code>lavTestLRT()</code> with all its default arguments. Using either function, the output would be:</p>
<pre><code>Chi Square Difference Test
            Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)   
AWmodel2Out  1 2138.5 2159.6 0.3972                                 
AWmodelOut   2 2143.5 2162.3 7.3327     6.9355       1    0.00845 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</code></pre>
<p>Notice that the actual <span class="math inline">\(\Delta\chi^2\)</span> (6.9355) is very similar to the expected <span class="math inline">\(\Delta\chi^2\)</span> indicated by the modification index for this additional parameter (6.716) in <a href="#Ch8">Chapter 8</a>, Table 2. Also, the AIC and BIC for each model are displayed. The <code>anova()</code> function is not suitable for comparing non-nested models, so if your models are not nested, you can simply use a function to request AIC or BIC:</p>
<pre><code>AIC(AWmodelOut, AWmodel2Out) 
BIC(AWmodelOut, AWmodel2Out) </code></pre>
<p>Note that these functions output a column labeled <code>df</code>, which is actually the number of free model parameters, not the model’s <span class="math inline">\(df\)</span>. In order to actually test differences in fit of non-nested models, use functions that are available in the R package <code>nonnest2</code>. Suppose that in our examples, we had actually fit our models to raw data. The following functions would allow us to run the Vuong test (analogous to <span class="math inline">\(\Delta\chi^2\)</span> test for non-nested models):</p>
<pre><code>library(nonnest2)
vuongtest(AWmodelOut, AWmodel2Out)</code></pre>
<p>Or we could test differences in parsimony-adjusted fit using CIs for <span class="math inline">\(\Delta\text{AIC}\)</span> or <span class="math inline">\(\Delta\text{BIC}\)</span>:</p>
<pre><code>icci(AWmodelOut, AWmodel2Out, conf.level = 0.95)</code></pre>
<p>CIs for both <span class="math inline">\(\Delta\text{AIC}\)</span> and <span class="math inline">\(\Delta\text{BIC}\)</span> would be provided, but you should only use one or the other, based upon whether you can assume one of the models is “correct” (BIC) or whether you merely wish to find the most generalizable model (AIC). Note, again, that these tests require analysing the raw data, not summary statistics.</p>
</div>
<div id="fit-measures-in-lavaan-when-adjusting-for-non-normal-data" class="section level3 hasAnchor" number="11.6.2">
<h3><span class="header-section-number">11.6.2</span> Fit measures in <code>lavaan</code> when adjusting for non-normal data<a href="ch11.html#fit-measures-in-lavaan-when-adjusting-for-non-normal-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When correcting for non-normality, <code>lavTestLRT()</code> and <code>anova()</code> automatically calculate the correct adjusted <span class="math inline">\(\Delta\chi^2\)</span> test. However, the default method (<code>"satorra.bentler.2001"</code>) can sometimes yield a negative test statistic, in which case it is impossible to compute a <span class="math inline">\(p\)</span> value. If this happens, you can use a version of the test that will always yield a positive scaled test statistic:</p>
<pre><code>lavTestLRT(AWmodelOut, AWmodel2Out, method = &quot;satorra.bentler.2010&quot;) </code></pre>
<p>When correcting for non-normality, the <code>summary(..., fit.measures = TRUE)</code> output includes a second column labelled “<code>Robust</code>” that contains the scaled <span class="math inline">\(\chi^2\)</span> test results, as well as robust versions of RMSEA, CFI, and TLI that incorporate the scaling factor to adjust for non-normality. The other fit measures (AIC, BIC, and SRMR) are unaffected by the adjustment, so those values are identical in the two columns. The left column of unadjusted measures can be ignored, but it is included for the sake of comparison.</p>
<p>However, when you use the <code>fitMeasures()</code> function, you will see not only the unadjusted fit measures, but also two different copies of any measure based on the <span class="math inline">\(\chi^2\)</span> statistic. The first set are labelled with a suffix “<code>.scaled</code>”, which corresponds to the corrected <span class="math inline">\(\chi^2\)</span> statistic. For RMSEA, TLI, and CFI (which are based on <span class="math inline">\(\chi^2\)</span>), “.scaled” indicates that they were calculated naïvely by simply plugging the scaled <span class="math inline">\(\chi^2\)</span> statistic (“<code>chisq.scaled</code>”) into equations <a href="ch11.html#eq:11-08">(11.8)</a>, <a href="ch11.html#eq:11-09">(11.9)</a>, and <a href="ch11.html#eq:11-10">(11.10)</a>, respectively. However, using those formulas with simple substitutions would yield fit measures that do not, on average, equal their population-level counterparts (i.e., if models were fit to <span class="math inline">\(\mathbfΣ_{\text{population}}\)</span> and adjusted for non-normality using population information). Instead, special formulas were developed by Brosseau-Liard and colleagues (2012, 2014) to yield consistent sample values of these three fit indices. These are labelled with a suffix “<code>.robust</code>”, they are the ones displayed in the <code>summary()</code> output, and they are the ones you should request from <code>fitMeasures()</code>:</p>
<pre><code>myFitIndices &lt;- c(&quot;chisq.scaled&quot;,&quot;df&quot;,&quot;pvalue.scaled&quot;,&quot;cfi.robust&quot;,&quot;aic&quot;)
fitMeasures(AWmodelOut, fit.measures = myFitIndices)</code></pre>
<p>Likewise, the output of <code>modificationindices()</code> will contain a column “<code>mi.scaled</code>”. If you are comparing MIs to a critical value, this is the column you should pay attention to.</p>
</div>
<div id="test-statistic-adjusted-for-small-sample-size" class="section level3 hasAnchor" number="11.6.3">
<h3><span class="header-section-number">11.6.3</span> Test statistic adjusted for small sample size<a href="ch11.html#test-statistic-adjusted-for-small-sample-size" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One last issue is that the <span class="math inline">\((\Delta)\chi^2\)</span> statistic is only asymptotically (i.e., as <span class="math inline">\(N \rightarrow \infty\)</span>) distributed as a <span class="math inline">\(\chi^2\)</span> random variable. In finite samples, it is approximately distributed as a <span class="math inline">\(\chi^2\)</span> random variable, but in small samples the approximation is poor. In this case, your p values will be incorrect because the <span class="math inline">\((\Delta)\chi^2\)</span> statistic will be too big, suggesting that the model fits worse than it actually does. It is simple to correct for this by multiplying the observed <span class="math inline">\((\Delta)\chi^2\)</span> statistic by a correction factor <span class="math inline">\(c\)</span><a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a>:</p>
<span class="math display" id="eq:11-18">\[\begin{equation}
c=1-\frac{2p+4k+5}{6N} ,
\tag{11.18}
\end{equation}\]</span>
<p>where <span class="math inline">\(p\)</span> is the number of observed variables, <span class="math inline">\(k\)</span> is the number of factors, and <span class="math inline">\(N\)</span> is the sample size (Nevitt &amp; Hancock, 2004). Note that in a path model, <span class="math inline">\(k = 0\)</span>, reducing the numerator to <span class="math inline">\(2p + 5\)</span>. The multiplicative correction will typically be , so it will usually make <span class="math inline">\(\chi^2\)</span> smaller, reducing the inflated Type I error rate in small samples. This correction will be small whenever the denominator in <a href="ch11.html#eq:11-18">(11.18)</a> (<span class="math inline">\(N\)</span>) is large, although how large depends on the size of the model. For example, models with more variables (<span class="math inline">\(p\)</span> and <span class="math inline">\(k\)</span>) have a larger numerator, requiring larger <span class="math inline">\(N\)</span> to overcome the inflation of <span class="math inline">\(\chi^2\)</span>.</p>
<p>When data are normal, you simply multiply the <span class="math inline">\(\chi^2\)</span> statistic by <span class="math inline">\(c\)</span> and calculate a <span class="math inline">\(p\)</span> value for the corrected statistic:</p>
<pre><code>N &lt;- lavInspect(fit, &quot;ntotal&quot;) # subtract 1 if likelihood = &quot;wishart&quot;
P &lt;- length(lavNames(AWmodelOut, type = &quot;ov&quot;)) # count observed variables
K &lt;- length(lavNames(AWmodelOut, type = &quot;lv&quot;)) # count latent factors
cc &lt;- 1 - ((2*P + 4*K + 5) / (6*N)) # correction factor
(chi &lt;- fitMeasures(AWmodelOut, &quot;chisq&quot;))
(DF &lt;- fitMeasures(AWmodelOut, &quot;df&quot;))
(pValue &lt;- pchisq(chi*cc, DF, lower.tail = FALSE))</code></pre>
<p>When adjusting for non-normality (in which case the model must be fit to raw data instead of summary statistics), you simply multiply the scaled <span class="math inline">\(\chi^2\)</span> statistic by <span class="math inline">\(c\)</span> and calculate a <span class="math inline">\(p\)</span> value for the corrected statistic.</p>
<pre><code>chi &lt;- fitMeasures(AWmodelOut, &quot;chisq.scaled&quot;) # nothing else changes</code></pre>
<p>When correcting the <span class="math inline">\(\Delta\chi^2\)</span> statistic for model comparison, you can extract the <span class="math inline">\(\Delta\chi^2\)</span> statistic from the <code>anova()</code> output, which will already be the scaled <span class="math inline">\(\Delta\chi^2\)</span> when adjusting for non-normality. The <span class="math inline">\(\Delta df\)</span> can also be extracted from the output.</p>
<pre><code>AOV &lt;- anova(AWmodelOut, AWmodel2Out)
chi &lt;- AOV[[&quot;Chisq diff&quot;]][2]
DF &lt;- AOV[[&quot;Df diff&quot;]][2]</code></pre>
<p>Although the calculation of <code>cc</code> will not be affected by sample size or number of variables (because both models must be fit to the same sample people and variables), the number of factors <span class="math inline">\(k\)</span> may differ between nested models. In this case, it is probably best to choose the larger <span class="math inline">\(k\)</span> between the two models, because the model with fewer factors is statistically equivalent to the model with more factors if the factor variances were constrained to equality and factor correlations were constrained to 1 (i.e., if the factors are the same variable). This typically works in our favour because choosing the larger <span class="math inline">\(k\)</span> will also decrease the <span class="math inline">\(\chi^2\)</span> more, so the model will appear to fit better.</p>
</div>
</div>
<div id="references-7" class="section level2 unnumbered hasAnchor">
<h2>References<a href="ch11.html#references-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Akaike, H. (1987). Factor analysis and AIC. <em>Psychometrika, 52</em>, 317–332. <a href="doi:10.1007/BF02294359" class="uri">doi:10.1007/BF02294359</a></p>
<p>Barret, P. (2007). Structural equation modelling: Adjudging model fit. <em>Personality and Individual Differences, 42</em>(5), 815–824. <a href="doi:10.1016/j.paid.2006.09.018" class="uri">doi:10.1016/j.paid.2006.09.018</a></p>
<p>Bentler, P. M. (1990). Comparative fit indexes in structural models. <em>Psychological Bulletin, 107</em>(2), 238–246. <a href="doi:10.1037/0033-2909.107.2.238" class="uri">doi:10.1037/0033-2909.107.2.238</a></p>
<p>Bentler, P. M. (1995). <em>EQS structural equations program manual</em>. Encino, CA: Multivariate Software.</p>
<p>Bentler, P. M., &amp; Bonett, D. G. (1980). Significance tests and goodness of fit in the analysis of covariance structures. <em>Psychological Bulletin, 88</em>(3), 588–606. <a href="doi:10.1037/0033-2909.88.3.588" class="uri">doi:10.1037/0033-2909.88.3.588</a></p>
<p>Bollen, K. A. (1989). <em>Structural equations with latent variables.</em> Hoboken, NJ: Wiley</p>
<p>Bollen, K. A. (1990). Overall fit in covariance structure models: Two types of sample size effects. <em>Psychological Bulletin, 107</em>(2), 256–259. <a href="doi:10.1037/0033-2909.107.2.256" class="uri">doi:10.1037/0033-2909.107.2.256</a></p>
<p>Brosseau-Liard, P. E., Savalei, V., &amp; Li, L. (2012). An investigation of the sample performance of two nonnormality corrections for RMSEA. <em>Multivariate Behavioral Research, 47</em>(6), 904–930. <a href="doi:10.1080/00273171.2012.715252" class="uri">doi:10.1080/00273171.2012.715252</a></p>
<p>Brosseau-Liard, P. E., &amp; Savalei, V. (2014). Adjusting incremental fit indices for nonnormality. <em>Multivariate Behavioral Research, 49</em>(5), 460–470. <a href="doi:10.1080/00273171.2014.933697" class="uri">doi:10.1080/00273171.2014.933697</a></p>
<p>Browne, M. W., &amp; Cudeck, R. (1989). Single sample cross-validation indices for covariance structures. <em>Multivariate Behavioral Research, 24</em>(4), 445–455. <a href="doi:10.1207/s15327906mbr2404_4" class="uri">doi:10.1207/s15327906mbr2404_4</a></p>
<p>Browne, M. W., &amp; Cudeck, R. (1992). Alternative ways of assessing model fit. <em>Sociological Methods &amp; Research, 21</em>, 230–258. <a href="doi:10.1177/0049124192021002005" class="uri">doi:10.1177/0049124192021002005</a></p>
<p>Burnham, K., &amp; Anderson, D. (2003). <em>Model selection and multimodel inference: A practical-theoretic approach.</em> New York, NY: Springer-Verlag.</p>
<p>Cudeck, R., &amp; Henly, S. J. (1991). Model selection in covariance structures analysis and the “problem” of sample size: A clarification. <em>Psychological Bulletin, 109</em>(3), 512–519. <a href="doi:10.1037/0033-2909.109.3.512" class="uri">doi:10.1037/0033-2909.109.3.512</a></p>
<p>Hayduk, L., Cummings, G., Boada, K., Pazderka-Robinson, H., &amp; Boulianne, S. (2007). Testing! testing! one, two, three—Testing the theory in structural equation models! <em>Personality and Individual Differences, 42</em>, 841–850. <a href="doi:10.1016/j.paid.2006.10.001" class="uri">doi:10.1016/j.paid.2006.10.001</a></p>
<p>Hu, L.-t., &amp; Bentler, P. M. (1998). Fit indices in covariance structure modeling: Sensitivity to underparameterized model misspecification. <em>Psychological Methods, 3</em>(4), 424–453. <a href="doi:10.1037/1082-989X.3.4.424" class="uri">doi:10.1037/1082-989X.3.4.424</a></p>
<p>Hu, L.-t., &amp; Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. <em>Structural Equation Modeling, 6</em>(1), 1–55. <a href="doi:10.1080/10705519909540118" class="uri">doi:10.1080/10705519909540118</a></p>
<p>Jöreskog, K. G., &amp; Sörbom, D. (1981). <em>LISREL V: Analysis of linear structural relationships by maximum likelihood</em>. Chicago: National Educational Resources.</p>
<p>Kenny, D. A., Kaniskan, B., &amp; McCoach, D. B. (2015). The performance of RMSEA in models with small degrees of freedom. <em>Sociological Methods &amp; Research, 44</em>(3), 486–507. <a href="doi:10.1177/0049124114543236" class="uri">doi:10.1177/0049124114543236</a></p>
<p>MacCallum, R. C., Browne, M. W., &amp; Sugawara, H. M. (1996). Power analysis and determination of sample size for covariance structure modeling. <em>Psychological Methods, 1</em>(2), 130–149. <a href="doi:10.1037//1082-989X.1.2.130" class="uri">doi:10.1037//1082-989X.1.2.130</a></p>
<p>Marsh, H. W., Balla, J. R., &amp; McDonald, R. P. (1988). Goodness of fit indexes in confirmatory factor analysis: The effect of sample size. <em>Psychological Bulletin, 103</em>, 391–410. <a href="doi:10.1037/0033-2909.103.3.391" class="uri">doi:10.1037/0033-2909.103.3.391</a></p>
<p>Marsh, H. W., Hau, K.-T., &amp; Wen, Z. (2004). In search of golden rules: Comment on hypothesis-testing approaches to setting cutoff values for fit indexes and dangers in overgeneralizing Hu &amp; Bentler’s (1999) findings. <em>Structural Equation Modeling, 11</em>, 320–341. <a href="doi:10.1207/s15328007sem1103_2" class="uri">doi:10.1207/s15328007sem1103_2</a></p>
<p>Merkle, E. C., You, D., &amp; Preacher, K. J. (2016). Testing nonnested structural equation models. <em>Psychological Methods, 21</em>(2), 151–163. Advance online publication. <a href="doi:10.1037/met0000038" class="uri">doi:10.1037/met0000038</a></p>
<p>Millsap, R. E. (2007). Structural equation modeling made difficult. <em>Personality and Individual Differences, 42</em>(5), 875–881. <a href="doi:10.1016/j.paid.2006.09.021" class="uri">doi:10.1016/j.paid.2006.09.021</a></p>
<p>Nevitt, J., &amp; Hancock, G. R. (2004). Evaluating small sample approaches for model test statistics in structural equation modelling. <em>Multivariate Behavioral Research, 39</em>(3) 439–478. <a href="doi:10.1207/S15327906MBR3903_3" class="uri">doi:10.1207/S15327906MBR3903_3</a></p>
<p>Pornprasertmanit, S., Wu, W., &amp; Little, T. D. (2013). A Monte Carlo approach for nested model comparisons in structural equation modeling. In R. E. Millsap, L. A. van der Ark, D. M. Bolt, &amp; C. M. Woods (Eds.), <em>New developments in quantitative psychology</em> (Vol. 66, pp. 187–197). New York, NY: Springer. <a href="doi:10.1007/978-1-4614-9348-8_12" class="uri">doi:10.1007/978-1-4614-9348-8_12</a></p>
<p>Raftery, A. E. (1986). Choosing models for cross-classification. <em>American Sociological Review, 51</em>(1), 145–146.</p>
<p>Raftery, A. E. (1995). Bayesian model selection in social research. <em>Sociological Methodology, 25</em>, 111–163.</p>
<p>Schermelleh-Engel, K., Moosbrugger, H., &amp; Müller, H. (2003). Evaluating the fit of structural equation models: Tests of significance and descriptive goodness-of-fit measures. <em>Methods of Psychological Research Online, 8</em>(2), 23–74.</p>
<p>Sclove, S. L. (1987). Application of model-selection criteria to some problems in multivariate analysis. <em>Psychometrika, 52</em>, 333–343. <a href="doi:10.1007/BF02294360" class="uri">doi:10.1007/BF02294360</a></p>
<p>Steiger, J. H., &amp; Lind, J. (1980). <em>Statistically based tests fort the number of common factors</em>. Paper presented at the annual meeting of the Psychometric Society, Iowa City.</p>
<p>Tucker, L. R., &amp; Lewis, C. (1973). A reliability coefficient for maximum likelihood factor analysis. <em>Psychometrika, 38</em>, 1–10. <a href="doi:10.1007/BF02291170" class="uri">doi:10.1007/BF02291170</a></p>
<p>West, S. G., Taylor, A. B., &amp; Wu, W. (2012). Model fit and model selection in structural equation modeling. In R. H. Hoyle (Ed.), <em>Handbook of structural equation modeling</em> (pp. 209–231). New York, NY: Guilford.</p>
<p>Widaman, K. F., &amp; Thompson, J. S. (2003). On specifying the null model for incremental fit indices in structural equation modeling. <em>Psychological Methods, 8</em>(1), 16–37. <a href="doi:10.1037/1082-989X.8.1.16" class="uri">doi:10.1037/1082-989X.8.1.16</a></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>Recall that the log-likelihood <span class="math inline">\(\ell\)</span> for a sample is the sum of all the individual log-likelihoods (<span class="math inline">\(\ell = \mathbf\Sigma\ell_i\)</span>).<a href="ch11.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>It is possible to use simulation-based methods to generate an empirical sampling distribution with which to derive critical values and p values (see, e.g., Millsap, 2007; Pornprasertmanit, Wu, &amp; Little, 2013).<a href="ch11.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>For all calculations in the RMSEA section, replace N − 1 with N when using normal likelihood instead of Wishart likelihood, which is only used to analyze complete-data covariance structure.<a href="ch11.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>The most common requirements for specifying an alternative baseline model would be when comparing models with different levels of measurement equivalence across groups or occasions (see chapters on invariance in multiple-group and longitudinal CFA models) or when evaluating homogeneity of residual variances in a latent growth curve model (see Widamin &amp; Thompson, 2003, for discussion).<a href="ch11.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>This is the formula used by Bentler’s (1995) EQS program. Bollen (1989) proposed calculating SRMR from actual correlation residuals, by first standardizing the observed covariance matrix using observed variances, then standardizing the model-implied covariance matrix using model-implied variances, and taking the differences. Maydeu-Olivares (2017) refers to these as “correlation residuals”, yielding a CRMR. When the observed and model-implied variances are equal (which is typically the case), these methods produce the same result. Currently, M<em>plus</em> uses Bollen’s (1989) method for means and for off-diagonal elements (correlations, as well as for means when a mean-structure is modeled) and uses Bentler’s method for diagonal elements (variances). All three versions are available in lavaan, with Bentler’s method being the default output.<a href="ch11.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>The BIC is also known as Akaike’s Bayesian Information Criterion (ABIC), or as the Schwarz (1978) Bayesian Criterion (SBC) after its developer. BIC is calculated only from information about the data, without using any information from a posterior distribution, so despite its name it is not really a Bayesian quantity. It is also not derived from information theory, so it is not really an “information” criterion either.<a href="ch11.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>There is also a more general concept of covariance matrix nesting (Bentler &amp; Bonett, 1980), which simply states that if a less restrictive model (B) can fit perfectly to the same (or larger) set of covariance matrices than a more restrictive model (A) can, then A is nested within B. Covariance matrix nesting includes the special case of parameter nesting, but also includes situations where nested models have very different forms, so they do not have an equivalent set of parameters to estimate.<a href="ch11.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Unless an empirical sampling distribution can be derived, for example, using bootstrapping, permutation, or Monte Carlo simulation.<a href="ch11.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>The default independence model might not be nested within each competing model (Widamin &amp; Thompson, 2003).<a href="ch11.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Replace the <span class="math inline">\(N\)</span> in the denominator with <span class="math inline">\(N − 1\)</span> when using Wishart likelihood for modelling covariance structure only.<a href="ch11.html#fnref17" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch10.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch12.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
